{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"basic-concepts/","text":"General concepts \u00b6 Application Programming Interface (API) \u00b6 An API is a well-defined interface that can be called from a remote process. There are many styles and protocols available to enable calls to APIs. The most popular at the moment is the REST API style that piggy-backs on top of the HTTP protocol that powers the Internet. Egeria makes extensive use of REST APIs. Further information Details of the different types of APIs provided by Egeria can be found in the developer guide . In addition, it is possible to automatically catalog details of the APIs that your organization uses: Cataloguing API Event \u00b6 An event is a message that describes a specific situation, or more typically a change in situation. It is sent on a topic to share its information with other servers. Further information Details of the different types of events used by Egeria OMRS topic events - for open metadata repository cohorts InTopic Events - for outgoing events to an Open Metadata Access Service ( OMAS ) OutTopic Events - for incoming events from an Open Metadata Access Service ( OMAS ) In addition, it is possible to automatically catalog details of the types of events that your organization uses: Cataloguing topics and event types for an event broker Event Broker \u00b6 An event broker is an infrastructure service that provides a publish-subscribe capability through topics . There are many different event broker implementations with greater or lesser reliability and performance. Egeria's default event broker is Apache Kafka . This is an open source event broker with a high level of performance, scalability and reliability. Many organizations establish a standard choice of their event broker service which is why Egeria uses connectors to connect to the event broker so that Apache Kafka can be swapped out for a different event broker implementation. As such, each topic is accessed through an open metadata topic connector . Further information Configuring the event broker for Egeria Cataloguing topics and event types for an event broker Topic \u00b6 A topic is a service provided by an event broker that offers a publish-subscribe capability for a specific type of event. Multiple servers can read and write events to a topic. Each topic maintains information about the events that a server has not read so that it can receive each event even if it restarts. Typically the events are processed in a first-in-first-out (FIFO) order, but that is not necessarily guaranteed since it depends on the type and configuration of the event broker. Further information Details of the different types of topics used by Egeria OMRSTopic - for open metadata repository cohorts InTopic - for sending events to an Open Metadata Access Service ( OMAS ) OutTopic - for receiving events from an Open Metadata Access Service ( OMAS ) In addition, it is possible to automatically catalog details of the event brokers that your organization uses: Cataloguing topics and event types for an event broker","title":"General Concepts"},{"location":"basic-concepts/#general-concepts","text":"","title":"General concepts"},{"location":"basic-concepts/#application-programming-interface-api","text":"An API is a well-defined interface that can be called from a remote process. There are many styles and protocols available to enable calls to APIs. The most popular at the moment is the REST API style that piggy-backs on top of the HTTP protocol that powers the Internet. Egeria makes extensive use of REST APIs. Further information Details of the different types of APIs provided by Egeria can be found in the developer guide . In addition, it is possible to automatically catalog details of the APIs that your organization uses: Cataloguing API","title":"Application Programming Interface (API)"},{"location":"basic-concepts/#event","text":"An event is a message that describes a specific situation, or more typically a change in situation. It is sent on a topic to share its information with other servers. Further information Details of the different types of events used by Egeria OMRS topic events - for open metadata repository cohorts InTopic Events - for outgoing events to an Open Metadata Access Service ( OMAS ) OutTopic Events - for incoming events from an Open Metadata Access Service ( OMAS ) In addition, it is possible to automatically catalog details of the types of events that your organization uses: Cataloguing topics and event types for an event broker","title":"Event"},{"location":"basic-concepts/#event-broker","text":"An event broker is an infrastructure service that provides a publish-subscribe capability through topics . There are many different event broker implementations with greater or lesser reliability and performance. Egeria's default event broker is Apache Kafka . This is an open source event broker with a high level of performance, scalability and reliability. Many organizations establish a standard choice of their event broker service which is why Egeria uses connectors to connect to the event broker so that Apache Kafka can be swapped out for a different event broker implementation. As such, each topic is accessed through an open metadata topic connector . Further information Configuring the event broker for Egeria Cataloguing topics and event types for an event broker","title":"Event Broker"},{"location":"basic-concepts/#topic","text":"A topic is a service provided by an event broker that offers a publish-subscribe capability for a specific type of event. Multiple servers can read and write events to a topic. Each topic maintains information about the events that a server has not read so that it can receive each event even if it restarts. Typically the events are processed in a first-in-first-out (FIFO) order, but that is not necessarily guaranteed since it depends on the type and configuration of the event broker. Further information Details of the different types of topics used by Egeria OMRSTopic - for open metadata repository cohorts InTopic - for sending events to an Open Metadata Access Service ( OMAS ) OutTopic - for receiving events from an Open Metadata Access Service ( OMAS ) In addition, it is possible to automatically catalog details of the event brokers that your organization uses: Cataloguing topics and event types for an event broker","title":"Topic"},{"location":"concepts/anchor/","text":"Anchor \u00b6 An anchor is a Referenceable metadata entity that groups other entities together as if they were logically a part of the anchor. This means, for example, if the anchor entity is deleted then the entities anchored to this entity are also deleted. The value of establishing this grouping is to ensure that entities that have little meaning without their anchor entity are cleaned up properly and are not left to uselessly clutter the repository. Example: personal messages and profiles For example, if a personal message is attached to a personal profile then that personal profile is its anchor. If the personal profile is deleted then the personal message is deleted too. Anchored entities are also bound by the visibility and security restrictions of their anchor. Example: Assets For example, Asset visibility is controlled by governance zones . An Asset is only visible through a service if it is a member of that service's supportedZones . Similarly, authorization to perform specific operations on an Asset is granted by the Open Metadata Security Services . When a SchemaType is attached to an Asset, it is anchored to that Asset. Subsequent requests to read or update the SchemaType will result in visibility and authorization checks for the requesting user being made with respect to its Asset anchor. The anchor grouping is limited to particular types of metadata entities that are only meaningful in the context of their anchor entity. So not all metadata entities linked to an anchor are anchored to it. They have an independent existence and may be linked to many anchors, without obligation. Example: personal profiles and Assets For example, a personal profile may contain links to specific \"favorite\" Assets. When the personal profile is deleted, the assets are not effected - except that they lose their relationship to the personal profile. Anchors classification \u00b6 The Anchors classification makes it easier to find the anchor entity. It is attached to any entity anchored to a Referenceable. Example: SchemaElements and Comments In the example above, Anchors would be on all the SchemaElements and Comments. Anchors would contain the unique identifier ( GUID ) of the anchor Referenceable. There is also the unique identifier ( GUID ) of the SchemaType at the root of a schema structure and the unique identifier ( GUID ) of the Comment at root of a comment tree to make it easier to process these elements as a group. Following is an illustration of this example, with the addition of an Asset. The entities that have the Anchors classification are those that are anchored to the Asset. This includes entities such as Ratings, Likes and Attachments (from the Open Discovery Framework ( ODF ) . It is worthwhile maintaining the Anchors classification because reads of and updates to the anchored entities will happen many times, and it is rare that an anchored entity will change its anchor during its lifetime. If a GlossaryTerm , or InformalTag is attached to the Asset, they are not anchored to it. GlossaryTerms and InformalTags are independent entities. They are not anchored to the Asset and hence do not have an Anchors classification. Any change to these entities does not reflect in the LatestChange classification of the Asset. However, the act of attaching them to, or detaching them from the Asset is recorded in the Asset's LatestChange classification. Since the GlossaryTerm is also an anchor, when the GlossaryTerm and the Asset are linked together, this change is reflected in both of their LatestChange classifications because they are both Referenceable anchors. NoteLogs are Referenceables that can be attached to many other Referenceables. They can be set up either to be anchored with a single Referenceable or to be their own anchor to allow then to be attached to and detached from many Referenceables over its lifetime. Example: NoteLog and Referenceables For example, these are cases where the NoteLog is anchored to another Referenceable NoteLogs are used to support the personal blog linked off of the Personal Profile in Community Profile OMAS . Assets may have a NoteLog to record \"news\" for consumers such as planned maintenance and unexpected situations. Egeria uses the Anchors classification on a NoteLog to indicate that the NoteLog is tied to the Referenceable it is attached to. The presence of this classification would prevent it from being linked to another Referenceable. Following is an illustration of the additional objects connecting to an asset that do not have the Anchors classification because they are not anchored to the Asset. Also notice there are two NoteLogs attached to the asset, one with the Anchors classification and one without. The one with the Anchors classification is anchored to the the Asset. The one without the Anchors classification is independent of the Asset. Further information Anchor Management provide support for the Anchors and LatestChange classifications.","title":"Anchor"},{"location":"concepts/anchor/#anchor","text":"An anchor is a Referenceable metadata entity that groups other entities together as if they were logically a part of the anchor. This means, for example, if the anchor entity is deleted then the entities anchored to this entity are also deleted. The value of establishing this grouping is to ensure that entities that have little meaning without their anchor entity are cleaned up properly and are not left to uselessly clutter the repository. Example: personal messages and profiles For example, if a personal message is attached to a personal profile then that personal profile is its anchor. If the personal profile is deleted then the personal message is deleted too. Anchored entities are also bound by the visibility and security restrictions of their anchor. Example: Assets For example, Asset visibility is controlled by governance zones . An Asset is only visible through a service if it is a member of that service's supportedZones . Similarly, authorization to perform specific operations on an Asset is granted by the Open Metadata Security Services . When a SchemaType is attached to an Asset, it is anchored to that Asset. Subsequent requests to read or update the SchemaType will result in visibility and authorization checks for the requesting user being made with respect to its Asset anchor. The anchor grouping is limited to particular types of metadata entities that are only meaningful in the context of their anchor entity. So not all metadata entities linked to an anchor are anchored to it. They have an independent existence and may be linked to many anchors, without obligation. Example: personal profiles and Assets For example, a personal profile may contain links to specific \"favorite\" Assets. When the personal profile is deleted, the assets are not effected - except that they lose their relationship to the personal profile.","title":"Anchor"},{"location":"concepts/anchor/#anchors-classification","text":"The Anchors classification makes it easier to find the anchor entity. It is attached to any entity anchored to a Referenceable. Example: SchemaElements and Comments In the example above, Anchors would be on all the SchemaElements and Comments. Anchors would contain the unique identifier ( GUID ) of the anchor Referenceable. There is also the unique identifier ( GUID ) of the SchemaType at the root of a schema structure and the unique identifier ( GUID ) of the Comment at root of a comment tree to make it easier to process these elements as a group. Following is an illustration of this example, with the addition of an Asset. The entities that have the Anchors classification are those that are anchored to the Asset. This includes entities such as Ratings, Likes and Attachments (from the Open Discovery Framework ( ODF ) . It is worthwhile maintaining the Anchors classification because reads of and updates to the anchored entities will happen many times, and it is rare that an anchored entity will change its anchor during its lifetime. If a GlossaryTerm , or InformalTag is attached to the Asset, they are not anchored to it. GlossaryTerms and InformalTags are independent entities. They are not anchored to the Asset and hence do not have an Anchors classification. Any change to these entities does not reflect in the LatestChange classification of the Asset. However, the act of attaching them to, or detaching them from the Asset is recorded in the Asset's LatestChange classification. Since the GlossaryTerm is also an anchor, when the GlossaryTerm and the Asset are linked together, this change is reflected in both of their LatestChange classifications because they are both Referenceable anchors. NoteLogs are Referenceables that can be attached to many other Referenceables. They can be set up either to be anchored with a single Referenceable or to be their own anchor to allow then to be attached to and detached from many Referenceables over its lifetime. Example: NoteLog and Referenceables For example, these are cases where the NoteLog is anchored to another Referenceable NoteLogs are used to support the personal blog linked off of the Personal Profile in Community Profile OMAS . Assets may have a NoteLog to record \"news\" for consumers such as planned maintenance and unexpected situations. Egeria uses the Anchors classification on a NoteLog to indicate that the NoteLog is tied to the Referenceable it is attached to. The presence of this classification would prevent it from being linked to another Referenceable. Following is an illustration of the additional objects connecting to an asset that do not have the Anchors classification because they are not anchored to the Asset. Also notice there are two NoteLogs attached to the asset, one with the Anchors classification and one without. The one with the Anchors classification is anchored to the the Asset. The one without the Anchors classification is independent of the Asset. Further information Anchor Management provide support for the Anchors and LatestChange classifications.","title":"Anchors classification"},{"location":"concepts/asset-log-message/","text":"Asset log message \u00b6 The asset log message is a type of log record that can be added to the local server's audit log . It is used to record that a specific action has been taken on an asset. The log record contains the following information: userId - userId of user making request. requestType - unique id for the asset. connectorInstanceId - (optional) id of connector in use (if any). connectionName - (optional) name of the connection (extracted from the connector). connectorType - (optional) type of connector in use (if any). contextId - (optional) function name, or processId of the activity that the caller is performing. message - log record content.","title":"Asset Log Message"},{"location":"concepts/asset-log-message/#asset-log-message","text":"The asset log message is a type of log record that can be added to the local server's audit log . It is used to record that a specific action has been taken on an asset. The log record contains the following information: userId - userId of user making request. requestType - unique id for the asset. connectorInstanceId - (optional) id of connector in use (if any). connectionName - (optional) name of the connection (extracted from the connector). connectorType - (optional) type of connector in use (if any). contextId - (optional) function name, or processId of the activity that the caller is performing. message - log record content.","title":"Asset log message"},{"location":"concepts/asset/","text":"Asset \u00b6 An asset is a metadata element that describes either a digital or physical resource. This resource is described in the metadata catalog because it provides value to the organization that owns it. Examples of resources that might be catalogued as assets include: Data sources such as databases, files and data feeds. IT infrastructure and applications that automate many aspects of an organization's operation. APIs that provide access to the services offered by the organization. Analytical models and processes that differentiate an organization from its competitors or ensure it is operating legally and ethically. Buildings and other locations. Physical objects that have a unique identity (eg a serial number). Much governance is centered around an organization's resources since they represent tangible value. This involves maintaining information about the resource and managing events related to the resource in order to keep it protected and to get the maximum value from it. Egeria is particularly focused on maintaining the information necessary for managing digital resources and the infrastructure that supports them. It also has a flexible type model to allow the definition of asset to be expanded to include a broader range of physical resources. Open metadata types \u00b6 The information about a resource that covers its characteristics and how it should be managed is stored in a sub-graph of open metadata instances (entities and relationships) with the Asset entity at the root. The asset entity contains a small amount of information that merely captures the existence of the real resource. Then other entities are linked to it to add more information. It is likely that this additional information is identified, captured and stored by different tools. The open metadata services gather this information together and distribute it to provide the most complete view of the resource's properties. More information on the types of attachments that can be added to an asset can be found here . Inheriting from asset is a hierarchy of increasingly-specialized definitions for different types of assets. Each definition adds more properties about the asset: Area 2 is where the asset hierarchy is built out. Accessing asset content through connectors \u00b6 Egeria provides an open framework for accessing the content of digital assets and the information about them. It is called the Open Connector Framework ( OCF ) and it provides specialized connectors (clients) for accessing specific types of assets and the information about them. The type of connector to use is specified in the connection entity that is linked to the asset. Model 0205 in the open metadata types shows how an asset is associated with a connection object. The connection object provides the properties necessary to create a connector to access the asset's contents. APIs and events for managing asset information (metadata) \u00b6 Egeria's Open Metadata Access Services ( OMAS ) provide the specialized services for managing assets. Each OMAS focuses on a particular part of the asset lifecycle or person/tool that is working with the assets. Some examples: OMAS Description Analytics Modeling OMAS enables business intelligence and data virtualization tools to maintain information about the data views and reporting assets they are maintaining. Asset Catalog OMAS provides a search service for locating assets. Asset Consumer OMAS provides a service for accessing the content of an asset, extracting additional information that is known about the asset and providing feedback about the asset. It is designed for tools that consume assets to support the work of their users. These users can provide feedback on the asset description and the resource that it describes. Asset Manager OMAS provides a service for exchanging metadata about assets and related information with a third party asset manager . This API supports the many-to-many correlation of identifiers used in the third party asset manager and the open metadata ecosystem. Asset Owner OMAS provides a service for the owner of an asset to classify and manage the asset, and understand how it is being used by the organization. Discovery Engine OMAS provides a service for adding annotations to an asset's information that has been determined by specific analysis of the asset's contents by a discovery service . Data Manager OMAS enables a data manager (such as a database or file system) to maintain information about the assets it stores. Governance Engine OMAS provides the metadata services for governance action services that verify, enhance and correct the properties of assets and their associated elements. IT Infrastructure OMAS provides a service for maintaining information about the IT assets and supporting infrastructure owned or used by an organization. Data Science OMAS provides a service for maintaining information about analytical models and related assets such as python notebooks. Sharing information about assets \u00b6 Egeria's Open Metadata Repository Services ( OMRS ) provides the ability to store and extract information about assets in a distributed collection of servers called an open metadata repository cohort . The cohort provides both peer-to-peer exchange of metadata via an event bus topic and federated queries between different members of the cohort. Egeria provides a metadata server , a metadata access point and a repository proxy server that are all able to join a cohort. The repository proxy supports the integration of third party servers (typically asset managers ) into the cohort. The mapping between the third party server's APIs and the open metadata APIs in this case is implemented in an repository connector . It is also possible to manage the exchange of asset metadata with other types of third party technologies using the Open Metadata Integration Services ( OMIS ) running in an integration daemon . Using this pattern is simpler to integrate but involves maintaining a copy of the third party technology's metadata in a metadata server that can then join one or more open metadata repository cohorts to share this metadata more broadly. The mapping between the third party technology's APIs and the open metadata APIs in this case is implemented in an integration connector .","title":"Asset"},{"location":"concepts/asset/#asset","text":"An asset is a metadata element that describes either a digital or physical resource. This resource is described in the metadata catalog because it provides value to the organization that owns it. Examples of resources that might be catalogued as assets include: Data sources such as databases, files and data feeds. IT infrastructure and applications that automate many aspects of an organization's operation. APIs that provide access to the services offered by the organization. Analytical models and processes that differentiate an organization from its competitors or ensure it is operating legally and ethically. Buildings and other locations. Physical objects that have a unique identity (eg a serial number). Much governance is centered around an organization's resources since they represent tangible value. This involves maintaining information about the resource and managing events related to the resource in order to keep it protected and to get the maximum value from it. Egeria is particularly focused on maintaining the information necessary for managing digital resources and the infrastructure that supports them. It also has a flexible type model to allow the definition of asset to be expanded to include a broader range of physical resources.","title":"Asset"},{"location":"concepts/asset/#open-metadata-types","text":"The information about a resource that covers its characteristics and how it should be managed is stored in a sub-graph of open metadata instances (entities and relationships) with the Asset entity at the root. The asset entity contains a small amount of information that merely captures the existence of the real resource. Then other entities are linked to it to add more information. It is likely that this additional information is identified, captured and stored by different tools. The open metadata services gather this information together and distribute it to provide the most complete view of the resource's properties. More information on the types of attachments that can be added to an asset can be found here . Inheriting from asset is a hierarchy of increasingly-specialized definitions for different types of assets. Each definition adds more properties about the asset: Area 2 is where the asset hierarchy is built out.","title":"Open metadata types"},{"location":"concepts/asset/#accessing-asset-content-through-connectors","text":"Egeria provides an open framework for accessing the content of digital assets and the information about them. It is called the Open Connector Framework ( OCF ) and it provides specialized connectors (clients) for accessing specific types of assets and the information about them. The type of connector to use is specified in the connection entity that is linked to the asset. Model 0205 in the open metadata types shows how an asset is associated with a connection object. The connection object provides the properties necessary to create a connector to access the asset's contents.","title":"Accessing asset content through connectors"},{"location":"concepts/asset/#apis-and-events-for-managing-asset-information-metadata","text":"Egeria's Open Metadata Access Services ( OMAS ) provide the specialized services for managing assets. Each OMAS focuses on a particular part of the asset lifecycle or person/tool that is working with the assets. Some examples: OMAS Description Analytics Modeling OMAS enables business intelligence and data virtualization tools to maintain information about the data views and reporting assets they are maintaining. Asset Catalog OMAS provides a search service for locating assets. Asset Consumer OMAS provides a service for accessing the content of an asset, extracting additional information that is known about the asset and providing feedback about the asset. It is designed for tools that consume assets to support the work of their users. These users can provide feedback on the asset description and the resource that it describes. Asset Manager OMAS provides a service for exchanging metadata about assets and related information with a third party asset manager . This API supports the many-to-many correlation of identifiers used in the third party asset manager and the open metadata ecosystem. Asset Owner OMAS provides a service for the owner of an asset to classify and manage the asset, and understand how it is being used by the organization. Discovery Engine OMAS provides a service for adding annotations to an asset's information that has been determined by specific analysis of the asset's contents by a discovery service . Data Manager OMAS enables a data manager (such as a database or file system) to maintain information about the assets it stores. Governance Engine OMAS provides the metadata services for governance action services that verify, enhance and correct the properties of assets and their associated elements. IT Infrastructure OMAS provides a service for maintaining information about the IT assets and supporting infrastructure owned or used by an organization. Data Science OMAS provides a service for maintaining information about analytical models and related assets such as python notebooks.","title":"APIs and events for managing asset information (metadata)"},{"location":"concepts/asset/#sharing-information-about-assets","text":"Egeria's Open Metadata Repository Services ( OMRS ) provides the ability to store and extract information about assets in a distributed collection of servers called an open metadata repository cohort . The cohort provides both peer-to-peer exchange of metadata via an event bus topic and federated queries between different members of the cohort. Egeria provides a metadata server , a metadata access point and a repository proxy server that are all able to join a cohort. The repository proxy supports the integration of third party servers (typically asset managers ) into the cohort. The mapping between the third party server's APIs and the open metadata APIs in this case is implemented in an repository connector . It is also possible to manage the exchange of asset metadata with other types of third party technologies using the Open Metadata Integration Services ( OMIS ) running in an integration daemon . Using this pattern is simpler to integrate but involves maintaining a copy of the third party technology's metadata in a metadata server that can then join one or more open metadata repository cohorts to share this metadata more broadly. The mapping between the third party technology's APIs and the open metadata APIs in this case is implemented in an integration connector .","title":"Sharing information about assets"},{"location":"concepts/audit-log/","text":"Audit Log \u00b6 The audit log provides detailed information relating to the activities within an OMAG Server . It builds on the Audit Log Framework to support multiple destinations for the audit log records written to the audit log by the server's subsystems. Figure 1: Structure of the audit log record Configure the audit log \u00b6 Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination. Add audit log destinations \u00b6 There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations Remove audit logs \u00b6 The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none","title":"Audit Log"},{"location":"concepts/audit-log/#audit-log","text":"The audit log provides detailed information relating to the activities within an OMAG Server . It builds on the Audit Log Framework to support multiple destinations for the audit log records written to the audit log by the server's subsystems. Figure 1: Structure of the audit log record","title":"Audit Log"},{"location":"concepts/audit-log/#configure-the-audit-log","text":"Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination.","title":"Configure the audit log"},{"location":"concepts/audit-log/#add-audit-log-destinations","text":"There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations","title":"Add audit log destinations"},{"location":"concepts/audit-log/#remove-audit-logs","text":"The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none","title":"Remove audit logs"},{"location":"concepts/cohort-events/","text":"Cohort events \u00b6 Cohort events are messages used to notify members of an open metadata repository cohort of changes to: The membership of the open metadata repository cohort. The types of metadata being managed by members of the open metadata repository cohort. The changes to the metadata instances stored by each of the members of the open metadata repository cohort. The motivation for sending cohort events between the members of the cohort is to ensure open metadata is as widely available as security permits and access to it is as efficient as possible. The events are broadcast to the membership of the open metadata repository cohort through one or more cohort event topic(s) and no replies are expected. Each member is expected to receive each event and make a local decision on whether to act on it or ignore it. Cohort topics \u00b6 A cohort can be configured to use: One cohort event topic for all types of cohort events Three cohort event topics, one for each type of OMRS event Both options This is shown in figure 1. Which to use? Using the single cohort topic is ok for small environments. However, the use of the three topics gives the best throughput, ensures rapid inclusion of new members in the cohort and is required for clustered members: when multiple instances of the same member operate in a cohort for high availability (HA). Notes for cohorts involving members at versions prior to 2.11 Versions of the OMRS prior to release 2.11 only support the single cohort topic. To allow a server running an older version of OMRS to join a cohort using the three topics, it is possible to configure the other members to use both the single topic and the three topics. This ensures all members see the same metadata, but the members configured to use both options will process all events twice. This configuration should only be used when absolutely needed and attention should be paid to upgrading the back-level server so it can use the three topics. Details of configuring the different topic options can be found in the administration guide . Enterprise event topic \u00b6 The enterprise event topic combines the cohort events from all cohorts that the server is connected to and makes them available to each local Open Metadata Access Service ( OMAS ) . It runs in memory but can be configured to also push these events to a topic managed by an event broker. Cohort event types \u00b6 Every event has a: Timestamp - indicating the time the event was created. Originator - detailing the server that originated the message. The metadata collection id of the sending open metadata repository's metadata collection. (The only time this is not set is when a message is sent from a server that does not have a local metadata repository configured.) The server name, type and organization are optional descriptive fields used in audit logging and problem determination. These values are set up through the administration services . Version - the version number of the event (set to OMRS V1.0 in the initial version). The setting of the category determines which category-specific section is used. Each category-specific section begins with a category-specific event type that describes the type of the event, and hence the properties that will be found in the category-specific section. If the event is reporting an error, there is also an optional error section. The error section has an error code, error message and a target metadata collection id . The target metadata collection id indicates which member of the cohort is the target for the error message. Other members may pick up the error and act on it as well. Registry events \u00b6 Registry events are used by metadata servers to register with a cohort. Figure 2: Different formats of a registry event TypeDef events \u00b6 TypeDef events are used by members of a cohort to exchange information about the open metadata types they support. Figure 3: Different formats of a TypeDef event Instance events \u00b6 Instance events are used by members of a cohort to exchange information about changes to metadata instances. Figure 4: Different formats of an instance event","title":"Cohort Events"},{"location":"concepts/cohort-events/#cohort-events","text":"Cohort events are messages used to notify members of an open metadata repository cohort of changes to: The membership of the open metadata repository cohort. The types of metadata being managed by members of the open metadata repository cohort. The changes to the metadata instances stored by each of the members of the open metadata repository cohort. The motivation for sending cohort events between the members of the cohort is to ensure open metadata is as widely available as security permits and access to it is as efficient as possible. The events are broadcast to the membership of the open metadata repository cohort through one or more cohort event topic(s) and no replies are expected. Each member is expected to receive each event and make a local decision on whether to act on it or ignore it.","title":"Cohort events"},{"location":"concepts/cohort-events/#cohort-topics","text":"A cohort can be configured to use: One cohort event topic for all types of cohort events Three cohort event topics, one for each type of OMRS event Both options This is shown in figure 1. Which to use? Using the single cohort topic is ok for small environments. However, the use of the three topics gives the best throughput, ensures rapid inclusion of new members in the cohort and is required for clustered members: when multiple instances of the same member operate in a cohort for high availability (HA). Notes for cohorts involving members at versions prior to 2.11 Versions of the OMRS prior to release 2.11 only support the single cohort topic. To allow a server running an older version of OMRS to join a cohort using the three topics, it is possible to configure the other members to use both the single topic and the three topics. This ensures all members see the same metadata, but the members configured to use both options will process all events twice. This configuration should only be used when absolutely needed and attention should be paid to upgrading the back-level server so it can use the three topics. Details of configuring the different topic options can be found in the administration guide .","title":"Cohort topics"},{"location":"concepts/cohort-events/#enterprise-event-topic","text":"The enterprise event topic combines the cohort events from all cohorts that the server is connected to and makes them available to each local Open Metadata Access Service ( OMAS ) . It runs in memory but can be configured to also push these events to a topic managed by an event broker.","title":"Enterprise event topic"},{"location":"concepts/cohort-events/#cohort-event-types","text":"Every event has a: Timestamp - indicating the time the event was created. Originator - detailing the server that originated the message. The metadata collection id of the sending open metadata repository's metadata collection. (The only time this is not set is when a message is sent from a server that does not have a local metadata repository configured.) The server name, type and organization are optional descriptive fields used in audit logging and problem determination. These values are set up through the administration services . Version - the version number of the event (set to OMRS V1.0 in the initial version). The setting of the category determines which category-specific section is used. Each category-specific section begins with a category-specific event type that describes the type of the event, and hence the properties that will be found in the category-specific section. If the event is reporting an error, there is also an optional error section. The error section has an error code, error message and a target metadata collection id . The target metadata collection id indicates which member of the cohort is the target for the error message. Other members may pick up the error and act on it as well.","title":"Cohort event types"},{"location":"concepts/cohort-events/#registry-events","text":"Registry events are used by metadata servers to register with a cohort. Figure 2: Different formats of a registry event","title":"Registry events"},{"location":"concepts/cohort-events/#typedef-events","text":"TypeDef events are used by members of a cohort to exchange information about the open metadata types they support. Figure 3: Different formats of a TypeDef event","title":"TypeDef events"},{"location":"concepts/cohort-events/#instance-events","text":"Instance events are used by members of a cohort to exchange information about changes to metadata instances. Figure 4: Different formats of an instance event","title":"Instance events"},{"location":"concepts/cohort-member/","text":"Cohort Member \u00b6 A Cohort Member is an OMAG Server that is capable of joining an open metadata repository cohort . The open metadata repository cohort (or cohort for short) is a group of OMAG servers that are exchanging metadata using a peer-to-peer replication protocol and federated queries. This is shown in Figure 1. Figure 1: OMAG Servers connected via a cohort The cohort is self-configuring. At the heart of it is between one and four shared [cohort topics]. Each member publishes a registration request on the appropriate topic when they want to join. This is picked up by the existing members who add this new server to their registry of members known as the cohort registry and re-send their registration through the same topic to allow the new member to build up its own registry. When an OMAG server permanently leaves the cohort, it sends an unregistration request. This enables the other members to remove the parting member from their registries. The purpose of the cohort registry in each member is to configure its federated query capability. The registration information includes the URL Root and server name of the member. The federation capability in each OMAG server allows it to issue metadata create, update, delete and search requests to each and every member of the cohort. This is the primary mechanism for accessing metadata. In addition, any change to metadata made by a member is replicated to the other members of the cohort through the relevant cohort topic. This gives the other members to opportunity to maintain cached copies of the metadata for performance / availability reasons. A member may also request that metadata is \"refreshed\" across the cohort. The originator of the requested metadata then sends the latest version of this metadata to the rest of the cohort through the cohort topic. This mechanism is useful to seed the cache in a new member of the cohort and is invoked as a result of a federated query issued from the new member. (A federated query occurs whenever an access service make a request for metadata.) The exchange of metadata is using the Open Metadata Repository Services ( OMRS ) interfaces which gives fine-grained metadata notifications and updates. (See the OMRS metamodel for more details). The server's metadata security connector provides fine-grained control on which metadata is send, received and/or stored by the server. This level of control is necessary for metadata repositories that are managing specific collections of valuable objects such as Assets . Figure 2 shows the different types of cohort members. Follow the links below the diagram to find out more about each one's purpose. Figure 2: Different types of OMAG Servers that can be connected via a cohort Metadata Access Server Metadata Access Store Metadata Access Point Repository Proxy Conformance Test Server More information \u00b6 There is more detailed information about the operation of an open metadata repository cohort in Cohort Operation . The administration hands on lab called \" Understanding Cohort Configuration Lab \" provides an opportunities to query the cohort registries of cohort members as they exchange metadata for Coco Pharmaceuticals. Instructions for running the labs can be found here .","title":"Cohort Member"},{"location":"concepts/cohort-member/#cohort-member","text":"A Cohort Member is an OMAG Server that is capable of joining an open metadata repository cohort . The open metadata repository cohort (or cohort for short) is a group of OMAG servers that are exchanging metadata using a peer-to-peer replication protocol and federated queries. This is shown in Figure 1. Figure 1: OMAG Servers connected via a cohort The cohort is self-configuring. At the heart of it is between one and four shared [cohort topics]. Each member publishes a registration request on the appropriate topic when they want to join. This is picked up by the existing members who add this new server to their registry of members known as the cohort registry and re-send their registration through the same topic to allow the new member to build up its own registry. When an OMAG server permanently leaves the cohort, it sends an unregistration request. This enables the other members to remove the parting member from their registries. The purpose of the cohort registry in each member is to configure its federated query capability. The registration information includes the URL Root and server name of the member. The federation capability in each OMAG server allows it to issue metadata create, update, delete and search requests to each and every member of the cohort. This is the primary mechanism for accessing metadata. In addition, any change to metadata made by a member is replicated to the other members of the cohort through the relevant cohort topic. This gives the other members to opportunity to maintain cached copies of the metadata for performance / availability reasons. A member may also request that metadata is \"refreshed\" across the cohort. The originator of the requested metadata then sends the latest version of this metadata to the rest of the cohort through the cohort topic. This mechanism is useful to seed the cache in a new member of the cohort and is invoked as a result of a federated query issued from the new member. (A federated query occurs whenever an access service make a request for metadata.) The exchange of metadata is using the Open Metadata Repository Services ( OMRS ) interfaces which gives fine-grained metadata notifications and updates. (See the OMRS metamodel for more details). The server's metadata security connector provides fine-grained control on which metadata is send, received and/or stored by the server. This level of control is necessary for metadata repositories that are managing specific collections of valuable objects such as Assets . Figure 2 shows the different types of cohort members. Follow the links below the diagram to find out more about each one's purpose. Figure 2: Different types of OMAG Servers that can be connected via a cohort Metadata Access Server Metadata Access Store Metadata Access Point Repository Proxy Conformance Test Server","title":"Cohort Member"},{"location":"concepts/cohort-member/#more-information","text":"There is more detailed information about the operation of an open metadata repository cohort in Cohort Operation . The administration hands on lab called \" Understanding Cohort Configuration Lab \" provides an opportunities to query the cohort registries of cohort members as they exchange metadata for Coco Pharmaceuticals. Instructions for running the labs can be found here .","title":"More information"},{"location":"concepts/cohort-registry-store/","text":"Cohort Registry Store \u00b6 The Cohort Registry resides in each cohort member . It is responsible for registering a member with a specific cohort and maintaining a list of the other members of this cohort. The registration process is managed by exchanging Registry Events over the Cohort Topic . The cohort registry maintains its record of the membership of the cohort in a Cohort Registry Store . Further information \u00b6 Configuring the cohort registry in an OMAG Server Overview of a cohort","title":"Cohort registry store"},{"location":"concepts/cohort-registry-store/#cohort-registry-store","text":"The Cohort Registry resides in each cohort member . It is responsible for registering a member with a specific cohort and maintaining a list of the other members of this cohort. The registration process is managed by exchanging Registry Events over the Cohort Topic . The cohort registry maintains its record of the membership of the cohort in a Cohort Registry Store .","title":"Cohort Registry Store"},{"location":"concepts/cohort-registry-store/#further-information","text":"Configuring the cohort registry in an OMAG Server Overview of a cohort","title":"Further information"},{"location":"concepts/collection/","text":"Collections \u00b6 A collection is a reusable resource list . Assets and other resources can be linked to a collection. The collection itself can then be added to a resource list, say for a community or a personal profile .","title":"Collection"},{"location":"concepts/collection/#collections","text":"A collection is a reusable resource list . Assets and other resources can be linked to a collection. The collection itself can then be added to a resource list, say for a community or a personal profile .","title":"Collections"},{"location":"concepts/comment/","text":"Comments \u00b6 [Comments] are informal messages or feedback. They can be attached to many places, for example a personal note , a community , a community forum or community forum contribution , a review , an external reference , or another comment. Sometimes specific names are used for comments depending on what they are attached to. For example: * a personal note comment is a comment attached to a personal note. * a forum comment is a comment attached to a community forum either directly or via a community forum contribution. * a comment reply is a comment attached to another comment. The ability to reply to a comment (or a comment reply) means that comments can be chained together to show a detailed conversation on a topic. The owner of a personal profile or the administrator of a community are able to remove inappropriate or out-of-date comments attached to their personal profile or community respectively. See: * [Removing]","title":"Comment"},{"location":"concepts/comment/#comments","text":"[Comments] are informal messages or feedback. They can be attached to many places, for example a personal note , a community , a community forum or community forum contribution , a review , an external reference , or another comment. Sometimes specific names are used for comments depending on what they are attached to. For example: * a personal note comment is a comment attached to a personal note. * a forum comment is a comment attached to a community forum either directly or via a community forum contribution. * a comment reply is a comment attached to another comment. The ability to reply to a comment (or a comment reply) means that comments can be chained together to show a detailed conversation on a topic. The owner of a personal profile or the administrator of a community are able to remove inappropriate or out-of-date comments attached to their personal profile or community respectively. See: * [Removing]","title":"Comments"},{"location":"concepts/community/","text":"Community \u00b6 A community is a anchor point for grouping people and resources together around a common interest. Communities are typically long running endeavours. Communities have members . These are the people working together in the community. The community can gather together a list of useful resources and a list of external references . The members can create forums on different topics to share information. The members can attach comments to the community itself and to forum contributions, and add replies to them. Members can also provide reviews to forum contributions. This includes a star rating and review comment. Members can add tags to the community and any of its contents. Members can also add a like to the community and any of its contents. Community Member \u00b6 A community member is a person whose profile is linked to a community . There are different roles a community member can be assigned to. Each has different privileges. Community Forum \u00b6 A community forum provides a place for a community to store notes and comments about a specific topic. Forums can be created by community contributors, administrators and leaders . Each forum has a name, description and a list of forum contributions . Forum contributions can be created by community members, leaders and administrators. Each contribution can be updated/deleted by the community administrators. Anyone can add comments to a forum contribution. Thus it is possible for a forum contribution to simply pose a question to the membership and the membership creates the discussion and possible answers using comments. Community roles \u00b6 Members of a community are assigned a role. The roles are additive. At a minimum, a members is a Community Observer . This means they receive notifications from the community. This can be upgraded to Community Contributor to add the right to post content to the community. Next is a Community Administrator who is given the additional ability to add members and delete inappropriate content. Finally the Community Leader has all of the powers of the administrator but really focuses on the health and content of the community - typically creating forums, keeping the exchange of information flowing, ensuring the lists of useful resources and external references are up to date, and more. The person creating a community is the first community leader. This can be changed. Typically the community leader assigns administrators to manage the membership lists to free them up to manage the content. Community Observer \u00b6 A community observer is someone who is interested in a community but is not contributing. Community Contributor \u00b6 A community contributor is a role for a community member who is able to create content for the community. This could be a new forum and contributions to any forum, comments, likes, tags and reviews. Community Administrator \u00b6 A community administrator is someone who is responsible for managing the membership list of a community. When a community is created, the administrator defaults to the person who created it. This can be changed. Community Leader \u00b6 A community leader is a person who gives direction to a community.","title":"Community"},{"location":"concepts/community/#community","text":"A community is a anchor point for grouping people and resources together around a common interest. Communities are typically long running endeavours. Communities have members . These are the people working together in the community. The community can gather together a list of useful resources and a list of external references . The members can create forums on different topics to share information. The members can attach comments to the community itself and to forum contributions, and add replies to them. Members can also provide reviews to forum contributions. This includes a star rating and review comment. Members can add tags to the community and any of its contents. Members can also add a like to the community and any of its contents.","title":"Community"},{"location":"concepts/community/#community-member","text":"A community member is a person whose profile is linked to a community . There are different roles a community member can be assigned to. Each has different privileges.","title":"Community Member"},{"location":"concepts/community/#community-forum","text":"A community forum provides a place for a community to store notes and comments about a specific topic. Forums can be created by community contributors, administrators and leaders . Each forum has a name, description and a list of forum contributions . Forum contributions can be created by community members, leaders and administrators. Each contribution can be updated/deleted by the community administrators. Anyone can add comments to a forum contribution. Thus it is possible for a forum contribution to simply pose a question to the membership and the membership creates the discussion and possible answers using comments.","title":"Community Forum"},{"location":"concepts/community/#community-roles","text":"Members of a community are assigned a role. The roles are additive. At a minimum, a members is a Community Observer . This means they receive notifications from the community. This can be upgraded to Community Contributor to add the right to post content to the community. Next is a Community Administrator who is given the additional ability to add members and delete inappropriate content. Finally the Community Leader has all of the powers of the administrator but really focuses on the health and content of the community - typically creating forums, keeping the exchange of information flowing, ensuring the lists of useful resources and external references are up to date, and more. The person creating a community is the first community leader. This can be changed. Typically the community leader assigns administrators to manage the membership lists to free them up to manage the content.","title":"Community roles"},{"location":"concepts/community/#community-observer","text":"A community observer is someone who is interested in a community but is not contributing.","title":"Community Observer"},{"location":"concepts/community/#community-contributor","text":"A community contributor is a role for a community member who is able to create content for the community. This could be a new forum and contributions to any forum, comments, likes, tags and reviews.","title":"Community Contributor"},{"location":"concepts/community/#community-administrator","text":"A community administrator is someone who is responsible for managing the membership list of a community. When a community is created, the administrator defaults to the person who created it. This can be changed.","title":"Community Administrator"},{"location":"concepts/community/#community-leader","text":"A community leader is a person who gives direction to a community.","title":"Community Leader"},{"location":"concepts/configuration-document/","text":"Configuration Documents \u00b6 A configuration document provides the configuration details for a single OMAG Server . It defines which subsystems are activated in the server and which connector implementations it should use. Configuration document structure \u00b6 An OMAG Server's configuration document is structured into elements that each describe the configuration properties for each of its desired capabilities. The sections are as follows: Default values to use when creating other configuration elements. These values need to be set up first. Basic properties of any OMAG Server. Specific subsystem configurations that provide the key capabilities for different types of OMAG Servers. Audit trail that documents the changes that have been made to the configuration document. It is possible to retrieve the configuration document for a server using the following command: GET - retrieve configuration document for a server {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/configuration When the server is running, the following command returns the configuration document that was used to start it (since it may have changed in the configuration document store since the server was started): GET - retrieve configuration document used to start a server {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/configuration Default values \u00b6 At the top of the configuration document are: Local server URL root , which defines the root of the network address for the OMAG Server Platform where the OMAG Server will run. Event bus config , which provides the configuration of the event bus (Apache Kafka or similar) where all the event topics that the server will use are located. Both of these elements provide default values for other configuration elements. If they are changed, their new values do not affect existing definitions in the configuration document. Basic properties \u00b6 The basic properties of the OMAG Server are used in logging, events handing and security. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. Find more information on configuring each through the sub-sections of the configuring an OMAG Server portion of the administration guide. Specific subsystem configurations \u00b6 Different types of servers can be configured with other specific subsystems, such as a local metadata repository, registering with a cohort, configuring access services or others. Since these vary depending on the type of OMAG Server, find more details in the sub-sections under the configuring an OMAG Server portion of the administration guide. Audit trail \u00b6 The audit trail allows you to keep track of changes to the configuration document. This is helpful to audit what any recent changes might have been - particularly if a working server suddenly stops working - the first question is always, \"what has changed recently?\" It also acts as a nice summary of how the server has been configured. Example of an audit trail { \"auditTrail\" : [ \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server's URL root to https://localhost:9444.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for maximum page size to 100.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server type name to Open Metadata Server.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server's owning organization's name to Coco Pharmaceuticals.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server's userId to cocoMDS1npa.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server's password to cocoMDS1passw0rd.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke added configuration for an Open Metadata Server Security Connector\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for default event bus.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for the local repository.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for the local repository.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke preserving local metadata collection id bfdfdc61-01bb-4564-9c29-6b81c0fb79f8.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for cohort cocoCohort.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:44:10 GMT 2020 garygeeke deployed configuration for server.\" ] } Storage \u00b6 By default, the configuration document is stored as a JSON in a file in the default directory for the OMAG Server Platform that creates them. These files may contain security certificates and passwords and so should be treated as sensitive. It is possible to change the storage location of configuration documents - or even the type of store. The configuration document's persistence is managed by the configuration document store connector . Configuration document store connector interface The admin-services-api module provides the interface definition for this connector. Its interface is simple -- consisting of save, retrieve and delete operations: /** * OMAGServerConfigStore provides the interface to the configuration for an OMAG Server. This is accessed * through a connector. */ public interface OMAGServerConfigStore { /** * Save the server configuration. * * @param configuration configuration properties to save */ void saveServerConfig ( OMAGServerConfig configuration ); /** * Retrieve the configuration saved from a previous run of the server. * * @return server configuration */ OMAGServerConfig retrieveServerConfig (); /** * Remove the server configuration. */ void removeServerConfig (); } The configuration document is represented by the OMAGServerConfig structure. The name of the server is stored in the localServerName property in OMAGServerConfig . Sample implementations \u00b6 The implementations of this connector provided by Egeria are found in the configuration-store-connectors module. There are two connectors: configuration-file-store-connector supports managing the open metadata configuration as a clear text JSON file. configuration-encrypted-file-store-connector supports managing the open metadata configuration as an encrypted JSON file. It is also possible to write your own implementation . Configuring the connector \u00b6 See configuring the configuration document store for the command to install a particular configuration document store connector into the OMAG Server Platform. Further information Open Connector Framework ( OCF ) defines open connectors and connections since many of the sections in the configuration document take connection objects for connectors. Configuring an OMAG Server provides more detail on the process of creating a configuration document for various types of OMAG Servers.","title":"Configuration Document"},{"location":"concepts/configuration-document/#configuration-documents","text":"A configuration document provides the configuration details for a single OMAG Server . It defines which subsystems are activated in the server and which connector implementations it should use.","title":"Configuration Documents"},{"location":"concepts/configuration-document/#configuration-document-structure","text":"An OMAG Server's configuration document is structured into elements that each describe the configuration properties for each of its desired capabilities. The sections are as follows: Default values to use when creating other configuration elements. These values need to be set up first. Basic properties of any OMAG Server. Specific subsystem configurations that provide the key capabilities for different types of OMAG Servers. Audit trail that documents the changes that have been made to the configuration document. It is possible to retrieve the configuration document for a server using the following command: GET - retrieve configuration document for a server {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/configuration When the server is running, the following command returns the configuration document that was used to start it (since it may have changed in the configuration document store since the server was started): GET - retrieve configuration document used to start a server {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/configuration","title":"Configuration document structure"},{"location":"concepts/configuration-document/#default-values","text":"At the top of the configuration document are: Local server URL root , which defines the root of the network address for the OMAG Server Platform where the OMAG Server will run. Event bus config , which provides the configuration of the event bus (Apache Kafka or similar) where all the event topics that the server will use are located. Both of these elements provide default values for other configuration elements. If they are changed, their new values do not affect existing definitions in the configuration document.","title":"Default values"},{"location":"concepts/configuration-document/#basic-properties","text":"The basic properties of the OMAG Server are used in logging, events handing and security. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. Find more information on configuring each through the sub-sections of the configuring an OMAG Server portion of the administration guide.","title":"Basic properties"},{"location":"concepts/configuration-document/#specific-subsystem-configurations","text":"Different types of servers can be configured with other specific subsystems, such as a local metadata repository, registering with a cohort, configuring access services or others. Since these vary depending on the type of OMAG Server, find more details in the sub-sections under the configuring an OMAG Server portion of the administration guide.","title":"Specific subsystem configurations"},{"location":"concepts/configuration-document/#audit-trail","text":"The audit trail allows you to keep track of changes to the configuration document. This is helpful to audit what any recent changes might have been - particularly if a working server suddenly stops working - the first question is always, \"what has changed recently?\" It also acts as a nice summary of how the server has been configured. Example of an audit trail { \"auditTrail\" : [ \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server's URL root to https://localhost:9444.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for maximum page size to 100.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server type name to Open Metadata Server.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server's owning organization's name to Coco Pharmaceuticals.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server's userId to cocoMDS1npa.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for local server's password to cocoMDS1passw0rd.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke added configuration for an Open Metadata Server Security Connector\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for default event bus.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for the local repository.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for the local repository.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke preserving local metadata collection id bfdfdc61-01bb-4564-9c29-6b81c0fb79f8.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for cohort cocoCohort.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:12 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for access services.\", \"Thu Jan 30 22:37:13 GMT 2020 garygeeke updated configuration for enterprise repository services (used by access services).\", \"Thu Jan 30 22:44:10 GMT 2020 garygeeke deployed configuration for server.\" ] }","title":"Audit trail"},{"location":"concepts/configuration-document/#storage","text":"By default, the configuration document is stored as a JSON in a file in the default directory for the OMAG Server Platform that creates them. These files may contain security certificates and passwords and so should be treated as sensitive. It is possible to change the storage location of configuration documents - or even the type of store. The configuration document's persistence is managed by the configuration document store connector . Configuration document store connector interface The admin-services-api module provides the interface definition for this connector. Its interface is simple -- consisting of save, retrieve and delete operations: /** * OMAGServerConfigStore provides the interface to the configuration for an OMAG Server. This is accessed * through a connector. */ public interface OMAGServerConfigStore { /** * Save the server configuration. * * @param configuration configuration properties to save */ void saveServerConfig ( OMAGServerConfig configuration ); /** * Retrieve the configuration saved from a previous run of the server. * * @return server configuration */ OMAGServerConfig retrieveServerConfig (); /** * Remove the server configuration. */ void removeServerConfig (); } The configuration document is represented by the OMAGServerConfig structure. The name of the server is stored in the localServerName property in OMAGServerConfig .","title":"Storage"},{"location":"concepts/configuration-document/#sample-implementations","text":"The implementations of this connector provided by Egeria are found in the configuration-store-connectors module. There are two connectors: configuration-file-store-connector supports managing the open metadata configuration as a clear text JSON file. configuration-encrypted-file-store-connector supports managing the open metadata configuration as an encrypted JSON file. It is also possible to write your own implementation .","title":"Sample implementations"},{"location":"concepts/configuration-document/#configuring-the-connector","text":"See configuring the configuration document store for the command to install a particular configuration document store connector into the OMAG Server Platform. Further information Open Connector Framework ( OCF ) defines open connectors and connections since many of the sections in the configuration document take connection objects for connectors. Configuring an OMAG Server provides more detail on the process of creating a configuration document for various types of OMAG Servers.","title":"Configuring the connector"},{"location":"concepts/conformance-test-server/","text":"Conformance Test Server \u00b6 The conformance test server is an OMAG Server that hosts the Conformance Test Suite ( CTS ) .","title":"Conformance Test Server"},{"location":"concepts/conformance-test-server/#conformance-test-server","text":"The conformance test server is an OMAG Server that hosts the Conformance Test Suite ( CTS ) .","title":"Conformance Test Server"},{"location":"concepts/connected-asset-properties/","text":"Connected Asset Properties - part of the Open Connector Framework ( OCF ) \u00b6 Connected Asset Properties are the properties known about an asset accessed through a connector. These properties are presented at three levels: AssetSummary AssetDetails AssetUniverse Figure 1: The structure of the connected asset properties Asset Summary \u00b6 AssetSummary holds asset properties that are used for displaying details of an asset in summary lists or hover text. It includes the following properties: type - metadata type information for the asset guid - globally unique identifier for the asset url - external link for the asset qualifiedName - The official (unique) name for the asset. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. (Sourced from the qualifiedName attribute in Referenceable - model 0010 ) displayName - A consumable name for the asset. Often a shortened form of the asset's qualifiedName for use on user interfaces and messages. The asset's displayName should be only be used for audit logs and error messages if the qualifiedName is not set. (Sourced from displayName attribute within Asset - model 0010 )) shortDescription - short description about the asset. (Sourced from assetSummary within ConnectionsToAsset - model 0205 ) description - full description of the asset. (Sourced from description attribute within Asset - model 0010 )) owner - name of the person or organization that owns the asset. (Sourced from the AssetOwnership Classification - model 0445 ). zoneMembership - list of governance zones assigned to the asset. (Sourced from the AssetZoneMembership classification - model 0445 )) classifications - full list of the classifications assigned to the asset along with their properties. Asset Detail \u00b6 AssetDetail extends AssetSummary to provide all of the properties directly related to this asset. It includes: ExternalIdentifiers - list of identifiers for this asset that are used in other systems. RelatedMediaReferences - list of links to external media (images, audio, video) about this asset. NoteLogs - list of NoteLogs for this asset, often providing more detail on how to use the asset and its current status. ExternalReferences - list of links to additional information about this asset. Connections - list of connections defined to access this asset. Licenses - list of licenses associated with the asset. Certifications - list of certifications that have been awarded to this asset. Asset Universe \u00b6 AssetUniverse extends AssetDetail which extend AssetSummary. AssetUniverse adds information about the common open metadata entities related to this asset. meanings - glossary term(s) assigned to this asset. schema - details of the schema type associated with the asset. feedback - details of the likes, reviews and comments, that are connected to the asset. knownLocations - details of the known locations of the asset. lineage - details of the lineage for the asset. relatedAssets - details of the assets linked to this asset. Implementation details \u00b6 The Connector Broker does not have access to a metadata repository because the OCF is metadata repository neutral. When it creates a connector, the connected asset properties are null. Egeria Open Metadata Access Services (OMASs) such as Asset Consumer OMAS , Asset Owner OMAS and Discovery Engine OMAS , include the connector broker in their clients and support APIs for managing connections and creating connectors. Connectors created by the Egeria access services will include the Connected Asset Properties object configured to retrieve metadata from the same open metadata repository where the OMAS is running. The Connected Asset Properties are retrieved from the open metadata repositories by OCF Metadata Management . It will use the same user id that was used to create the connector.","title":"Connected Asset Properties"},{"location":"concepts/connected-asset-properties/#connected-asset-properties-part-of-the-open-connector-framework-ocf","text":"Connected Asset Properties are the properties known about an asset accessed through a connector. These properties are presented at three levels: AssetSummary AssetDetails AssetUniverse Figure 1: The structure of the connected asset properties","title":"Connected Asset Properties - part of the Open Connector Framework (OCF)"},{"location":"concepts/connected-asset-properties/#asset-summary","text":"AssetSummary holds asset properties that are used for displaying details of an asset in summary lists or hover text. It includes the following properties: type - metadata type information for the asset guid - globally unique identifier for the asset url - external link for the asset qualifiedName - The official (unique) name for the asset. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. (Sourced from the qualifiedName attribute in Referenceable - model 0010 ) displayName - A consumable name for the asset. Often a shortened form of the asset's qualifiedName for use on user interfaces and messages. The asset's displayName should be only be used for audit logs and error messages if the qualifiedName is not set. (Sourced from displayName attribute within Asset - model 0010 )) shortDescription - short description about the asset. (Sourced from assetSummary within ConnectionsToAsset - model 0205 ) description - full description of the asset. (Sourced from description attribute within Asset - model 0010 )) owner - name of the person or organization that owns the asset. (Sourced from the AssetOwnership Classification - model 0445 ). zoneMembership - list of governance zones assigned to the asset. (Sourced from the AssetZoneMembership classification - model 0445 )) classifications - full list of the classifications assigned to the asset along with their properties.","title":"Asset Summary"},{"location":"concepts/connected-asset-properties/#asset-detail","text":"AssetDetail extends AssetSummary to provide all of the properties directly related to this asset. It includes: ExternalIdentifiers - list of identifiers for this asset that are used in other systems. RelatedMediaReferences - list of links to external media (images, audio, video) about this asset. NoteLogs - list of NoteLogs for this asset, often providing more detail on how to use the asset and its current status. ExternalReferences - list of links to additional information about this asset. Connections - list of connections defined to access this asset. Licenses - list of licenses associated with the asset. Certifications - list of certifications that have been awarded to this asset.","title":"Asset Detail"},{"location":"concepts/connected-asset-properties/#asset-universe","text":"AssetUniverse extends AssetDetail which extend AssetSummary. AssetUniverse adds information about the common open metadata entities related to this asset. meanings - glossary term(s) assigned to this asset. schema - details of the schema type associated with the asset. feedback - details of the likes, reviews and comments, that are connected to the asset. knownLocations - details of the known locations of the asset. lineage - details of the lineage for the asset. relatedAssets - details of the assets linked to this asset.","title":"Asset Universe"},{"location":"concepts/connected-asset-properties/#implementation-details","text":"The Connector Broker does not have access to a metadata repository because the OCF is metadata repository neutral. When it creates a connector, the connected asset properties are null. Egeria Open Metadata Access Services (OMASs) such as Asset Consumer OMAS , Asset Owner OMAS and Discovery Engine OMAS , include the connector broker in their clients and support APIs for managing connections and creating connectors. Connectors created by the Egeria access services will include the Connected Asset Properties object configured to retrieve metadata from the same open metadata repository where the OMAS is running. The Connected Asset Properties are retrieved from the open metadata repositories by OCF Metadata Management . It will use the same user id that was used to create the connector.","title":"Implementation details"},{"location":"concepts/connection/","text":"Connection - part of the Open Connector Framework ( OCF ) \u00b6 The Connection provides the set of properties needed to create and initialize an instance of a connector . Inside a Connection \u00b6 A Connection contains properties about the specific use of the connector, such as user Id and password, or parameters that control the scope or resources that should be made available to the connector. It links to an optional Endpoint and/or ConnectorType object. ConnectorType - this is a object that describes the type of the connector that needs to be created in order to access the Asset. Endpoint - this is the object that describes the server endpoint where the asset is accessed from. Connector types and endpoints can be reused in multiple connections. Figure 1: Connection structure Connections are typically managed in a metadata repository but they can also be manually populated. Connection implementations \u00b6 The OCF offers two implementations of the Connection. org.odpi.openmetadata.frameworks.connectors.properties.beans.Connection Connection is a bean implementation of the connection used in REST API requests and events. It allows properties for be set up and retrieved. org.odpi.openmetadata.frameworks.connectors.properties.ConnectionProperties ConnectionProperties is a read-only wrapper for the Connection properties that is used in client interfaces that do not allow the properties to be updated. Connection properties \u00b6 The properties for a connection are defined in model 0201. They include the following identifiers: * guid - Globally unique identifier for the connection. * url - URL of the connection definition in the metadata repository. * qualifiedName - The official (unique) name for the connection. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. The qualifiedName is defined in the 0010 model as part of Referenceable. * displayName - A consumable name for the connection. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. Other properties for the connection include: type - information about the TypeDef for Connection description - A full description of the connection covering details of the assets it connects to along with usage and version information. additionalProperties - Any additional properties associated with the connection. configurationProperties - properties for configuring the connector. securedProperties - Protected properties for secure log on by connector to back end server. These are protected properties that can only be retrieved by privileged connector code. userId - name or URI or connecting user. encryptedPassword - password for the userId - needs decrypting by connector before use. clearPassword - password for userId - ready to use. connectorType - Properties that describe the connector type for the connector. endpoint - Properties that describe the server endpoint where the connector will retrieve the assets. Using Connections from open metadata repositories \u00b6 Each connection stored in a metadata repository has a unique identifier. An application can request a connector instance through selected Egeria OMAS interfaces, such as the Asset Consumer OMAS , with just the unique identifier or name of a connection. The OMAS retrieves the connection object from the open metadata repositories and passes it to the Connector Broker factory object. The Connector Broker (and underlying Connector Provider ) uses the information from the Connection object to create an instance of the connector. The advantage of retrieving the connection information from a metadata repository is that the connection properties do not need to be hard-coded in the consuming applications and the metadata associated with the linked Asset can be retrieved via the connectors Connected Asset Properties interface. Connections can be created in the open metadata repositories through the following interfaces: * Asset Owner OMAS * Asset Manager OMAS * Data Manager OMAS * Database Integrator OMIS * Files Integrator OMIS * Governance Action OMES Configuring Egeria Connections \u00b6 The Administration Guide describes how to configure Egeria's OMAG Server Platforms and Servers. Both the platform and the servers used connectors for access to the external resources to support their basic operation and to coordinate metadata and governance with third party technologies. This means that the configuration includes Connection definitions for these connectors. All of these interfaces have Java clients that enable you to set up the connection using the OCF Connection bean. However if you want to use the REST API directly, then you need to specify the connection in JSON. Egeria's JSON structures map one-to-ene with the properties in the equivalent Java beans and also include a class property that includes the name of the class that it maps to. So a simple Connection object would look something like this in JSON: { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"...fully qualified class name...\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"... network address of resource ...\" } } }","title":"Connection"},{"location":"concepts/connection/#connection-part-of-the-open-connector-framework-ocf","text":"The Connection provides the set of properties needed to create and initialize an instance of a connector .","title":"Connection - part of the Open Connector Framework (OCF)"},{"location":"concepts/connection/#inside-a-connection","text":"A Connection contains properties about the specific use of the connector, such as user Id and password, or parameters that control the scope or resources that should be made available to the connector. It links to an optional Endpoint and/or ConnectorType object. ConnectorType - this is a object that describes the type of the connector that needs to be created in order to access the Asset. Endpoint - this is the object that describes the server endpoint where the asset is accessed from. Connector types and endpoints can be reused in multiple connections. Figure 1: Connection structure Connections are typically managed in a metadata repository but they can also be manually populated.","title":"Inside a Connection"},{"location":"concepts/connection/#connection-implementations","text":"The OCF offers two implementations of the Connection. org.odpi.openmetadata.frameworks.connectors.properties.beans.Connection Connection is a bean implementation of the connection used in REST API requests and events. It allows properties for be set up and retrieved. org.odpi.openmetadata.frameworks.connectors.properties.ConnectionProperties ConnectionProperties is a read-only wrapper for the Connection properties that is used in client interfaces that do not allow the properties to be updated.","title":"Connection implementations"},{"location":"concepts/connection/#connection-properties","text":"The properties for a connection are defined in model 0201. They include the following identifiers: * guid - Globally unique identifier for the connection. * url - URL of the connection definition in the metadata repository. * qualifiedName - The official (unique) name for the connection. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. The qualifiedName is defined in the 0010 model as part of Referenceable. * displayName - A consumable name for the connection. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. Other properties for the connection include: type - information about the TypeDef for Connection description - A full description of the connection covering details of the assets it connects to along with usage and version information. additionalProperties - Any additional properties associated with the connection. configurationProperties - properties for configuring the connector. securedProperties - Protected properties for secure log on by connector to back end server. These are protected properties that can only be retrieved by privileged connector code. userId - name or URI or connecting user. encryptedPassword - password for the userId - needs decrypting by connector before use. clearPassword - password for userId - ready to use. connectorType - Properties that describe the connector type for the connector. endpoint - Properties that describe the server endpoint where the connector will retrieve the assets.","title":"Connection properties"},{"location":"concepts/connection/#using-connections-from-open-metadata-repositories","text":"Each connection stored in a metadata repository has a unique identifier. An application can request a connector instance through selected Egeria OMAS interfaces, such as the Asset Consumer OMAS , with just the unique identifier or name of a connection. The OMAS retrieves the connection object from the open metadata repositories and passes it to the Connector Broker factory object. The Connector Broker (and underlying Connector Provider ) uses the information from the Connection object to create an instance of the connector. The advantage of retrieving the connection information from a metadata repository is that the connection properties do not need to be hard-coded in the consuming applications and the metadata associated with the linked Asset can be retrieved via the connectors Connected Asset Properties interface. Connections can be created in the open metadata repositories through the following interfaces: * Asset Owner OMAS * Asset Manager OMAS * Data Manager OMAS * Database Integrator OMIS * Files Integrator OMIS * Governance Action OMES","title":"Using Connections from open metadata repositories"},{"location":"concepts/connection/#configuring-egeria-connections","text":"The Administration Guide describes how to configure Egeria's OMAG Server Platforms and Servers. Both the platform and the servers used connectors for access to the external resources to support their basic operation and to coordinate metadata and governance with third party technologies. This means that the configuration includes Connection definitions for these connectors. All of these interfaces have Java clients that enable you to set up the connection using the OCF Connection bean. However if you want to use the REST API directly, then you need to specify the connection in JSON. Egeria's JSON structures map one-to-ene with the properties in the equivalent Java beans and also include a class property that includes the name of the class that it maps to. So a simple Connection object would look something like this in JSON: { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"...fully qualified class name...\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"... network address of resource ...\" } } }","title":"Configuring Egeria Connections"},{"location":"concepts/connector-broker/","text":"Connector Broker - part of the Open Connector Framework ( OCF ) \u00b6 The Connector Broker is the factory class for all open connectors. Given a valid Connection object, the Connector Broker is able to create a new instance of a connector. This means the caller does not need to know the implementation details of the connector - just its interface. It is implemented in the following Java class: org.odpi.openmetadata.frameworks.connectors.ConnectorBroker and is used as follows: import org.odpi.openmetadata.frameworks.connectors.Connector; import org.odpi.openmetadata.frameworks.connectors.ConnectorBroker; : ConnectorBroker connectorBroker = new ConnectorBroker(); Connector connector = connectorBroker.getConnector(connection); When the connector instance is requested, the Connector Broker uses the ConnectorType properties from the supplied Connection to identify the appropriate Connector Provider . The Connector Broker delegates the connector instance request to the Connector Provider and returns the result to its caller. Use of the Connector Broker in Egeria \u00b6 The Connector Broker is used in the client code of the Open Metadata Access Services (OMASs) that provide connector instances to their consumers. Examples include: Asset Consumer OMAS Asset Owner OMAS","title":"Connector Broker"},{"location":"concepts/connector-broker/#connector-broker-part-of-the-open-connector-framework-ocf","text":"The Connector Broker is the factory class for all open connectors. Given a valid Connection object, the Connector Broker is able to create a new instance of a connector. This means the caller does not need to know the implementation details of the connector - just its interface. It is implemented in the following Java class: org.odpi.openmetadata.frameworks.connectors.ConnectorBroker and is used as follows: import org.odpi.openmetadata.frameworks.connectors.Connector; import org.odpi.openmetadata.frameworks.connectors.ConnectorBroker; : ConnectorBroker connectorBroker = new ConnectorBroker(); Connector connector = connectorBroker.getConnector(connection); When the connector instance is requested, the Connector Broker uses the ConnectorType properties from the supplied Connection to identify the appropriate Connector Provider . The Connector Broker delegates the connector instance request to the Connector Provider and returns the result to its caller.","title":"Connector Broker - part of the Open Connector Framework (OCF)"},{"location":"concepts/connector-broker/#use-of-the-connector-broker-in-egeria","text":"The Connector Broker is used in the client code of the Open Metadata Access Services (OMASs) that provide connector instances to their consumers. Examples include: Asset Consumer OMAS Asset Owner OMAS","title":"Use of the Connector Broker in Egeria"},{"location":"concepts/connector-provider/","text":"Connector Provider - part of the Open Connector Framework ( OCF ) \u00b6 A Connector Provider is the factory for a particular type of Connector . It is typically called from the Connector Broker , although it may be called directly. Each Connector Provider implements the following interface: org.odpi.openmetadata.frameworks.connectors.ConnectorProvider It has two types of methods: Return the ConnectorType object that is added to a Connection object used to hold the properties needed to create an instance of the connector. Return a new instance of the connector based on the properties in a Connection object. The Connection object that has all of the properties needed to create and configure the instance of the connector. There is a base class that provides much of the implementation for a connector provider. org.odpi.openmetadata.frameworks.connectors.ConnectorProviderBase If you have a simple connector implementation then your connector provider follows the following template. It assumes the connector is for the XXXStore and is called XXXStoreConnector . With this base implementation, a specific Connector Provider implementation need only implement a constructor to configure the base class's function with details of itself and the Java class of the connector it needs. /** * XXXStoreProvider is the OCF connector provider for the XXX store connector. */ public class XXXStoreProvider extends ConnectorProviderBase { static final String connectorTypeGUID = \"Add unique GUID here\" ; static final String connectorTypeName = \"XXX Store Connector\" ; static final String connectorTypeDescription = \"Connector supports ... add details here\" ; /** * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific * store implementation. */ public BasicFileStoreProvider () { Class <?> connectorClass = XXXStoreConnector . class ; super . setConnectorClassName ( connectorClass . getName ()); ConnectorType connectorType = new ConnectorType (); connectorType . setType ( ConnectorType . getConnectorTypeType ()); connectorType . setGUID ( connectorTypeGUID ); connectorType . setQualifiedName ( connectorTypeName ); connectorType . setDisplayName ( connectorTypeName ); connectorType . setDescription ( connectorTypeDescription ); connectorType . setConnectorProviderClassName ( this . getClass (). getName ()); super . connectorTypeBean = connectorType ; } } For example, here is the implementation of the Connector Provider for the basic file connector . /* SPDX-License-Identifier: Apache-2.0 */ /* Copyright Contributors to the ODPi Egeria project. */ package org.odpi.openmetadata.adapters.connectors.datastore.basicfile ; import org.odpi.openmetadata.frameworks.connectors.ConnectorProviderBase ; import org.odpi.openmetadata.frameworks.connectors.properties.beans.ConnectorType ; /** * BasicFileStoreProvider is the OCF connector provider for the basic file store connector. */ public class BasicFileStoreProvider extends ConnectorProviderBase { static final String connectorTypeGUID = \"ba213761-f5f5-4cf5-a95f-6150aef09e0b\" ; static final String connectorTypeName = \"Basic File Store Connector\" ; static final String connectorTypeDescription = \"Connector supports reading of Files.\" ; /** * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific * store implementation. */ public BasicFileStoreProvider () { Class <?> connectorClass = BasicFileStoreConnector . class ; super . setConnectorClassName ( connectorClass . getName ()); ConnectorType connectorType = new ConnectorType (); connectorType . setType ( ConnectorType . getConnectorTypeType ()); connectorType . setGUID ( connectorTypeGUID ); connectorType . setQualifiedName ( connectorTypeName ); connectorType . setDisplayName ( connectorTypeName ); connectorType . setDescription ( connectorTypeDescription ); connectorType . setConnectorProviderClassName ( this . getClass (). getName ()); super . connectorTypeBean = connectorType ; } }","title":"Connector Provider"},{"location":"concepts/connector-provider/#connector-provider-part-of-the-open-connector-framework-ocf","text":"A Connector Provider is the factory for a particular type of Connector . It is typically called from the Connector Broker , although it may be called directly. Each Connector Provider implements the following interface: org.odpi.openmetadata.frameworks.connectors.ConnectorProvider It has two types of methods: Return the ConnectorType object that is added to a Connection object used to hold the properties needed to create an instance of the connector. Return a new instance of the connector based on the properties in a Connection object. The Connection object that has all of the properties needed to create and configure the instance of the connector. There is a base class that provides much of the implementation for a connector provider. org.odpi.openmetadata.frameworks.connectors.ConnectorProviderBase If you have a simple connector implementation then your connector provider follows the following template. It assumes the connector is for the XXXStore and is called XXXStoreConnector . With this base implementation, a specific Connector Provider implementation need only implement a constructor to configure the base class's function with details of itself and the Java class of the connector it needs. /** * XXXStoreProvider is the OCF connector provider for the XXX store connector. */ public class XXXStoreProvider extends ConnectorProviderBase { static final String connectorTypeGUID = \"Add unique GUID here\" ; static final String connectorTypeName = \"XXX Store Connector\" ; static final String connectorTypeDescription = \"Connector supports ... add details here\" ; /** * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific * store implementation. */ public BasicFileStoreProvider () { Class <?> connectorClass = XXXStoreConnector . class ; super . setConnectorClassName ( connectorClass . getName ()); ConnectorType connectorType = new ConnectorType (); connectorType . setType ( ConnectorType . getConnectorTypeType ()); connectorType . setGUID ( connectorTypeGUID ); connectorType . setQualifiedName ( connectorTypeName ); connectorType . setDisplayName ( connectorTypeName ); connectorType . setDescription ( connectorTypeDescription ); connectorType . setConnectorProviderClassName ( this . getClass (). getName ()); super . connectorTypeBean = connectorType ; } } For example, here is the implementation of the Connector Provider for the basic file connector . /* SPDX-License-Identifier: Apache-2.0 */ /* Copyright Contributors to the ODPi Egeria project. */ package org.odpi.openmetadata.adapters.connectors.datastore.basicfile ; import org.odpi.openmetadata.frameworks.connectors.ConnectorProviderBase ; import org.odpi.openmetadata.frameworks.connectors.properties.beans.ConnectorType ; /** * BasicFileStoreProvider is the OCF connector provider for the basic file store connector. */ public class BasicFileStoreProvider extends ConnectorProviderBase { static final String connectorTypeGUID = \"ba213761-f5f5-4cf5-a95f-6150aef09e0b\" ; static final String connectorTypeName = \"Basic File Store Connector\" ; static final String connectorTypeDescription = \"Connector supports reading of Files.\" ; /** * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific * store implementation. */ public BasicFileStoreProvider () { Class <?> connectorClass = BasicFileStoreConnector . class ; super . setConnectorClassName ( connectorClass . getName ()); ConnectorType connectorType = new ConnectorType (); connectorType . setType ( ConnectorType . getConnectorTypeType ()); connectorType . setGUID ( connectorTypeGUID ); connectorType . setQualifiedName ( connectorTypeName ); connectorType . setDisplayName ( connectorTypeName ); connectorType . setDescription ( connectorTypeDescription ); connectorType . setConnectorProviderClassName ( this . getClass (). getName ()); super . connectorTypeBean = connectorType ; } }","title":"Connector Provider - part of the Open Connector Framework (OCF)"},{"location":"concepts/connector-type/","text":"Connector Type - part of the Open Connector Framework ( OCF ) \u00b6 The connector type is a set of properties that defines the supported capabilities and the identity of the connector provider for a connector . Its properties are: guid - Globally unique identifier for the connector type. url - External link address for the connector type properties in the metadata repository. qualifiedName - The official (unique) name for the connector type. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. displayName - A consumable name for the connector type. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. description - A full description of the connector type covering details of the assets it connects to along with usage and versioning information. connectorProviderClassName - The connector provider is the factory for a particular type of connector. This property defines the class name for the connector provider that the Connector Broker should use to request new connector instances. recognizedAdditionalProperties - these are the Connection additional properties recognized by the connector implementation recognizedConfigurationProperties - these are the Connection configuration properties recognized by the connector implementation recognizedSecuredProperties - these are the Connection secured properties recognized by the connector implementation additionalProperties - Any additional properties that the connector provider needs to know in order to create connector instances. The connector type is linked to the Connection objects that request this type of connector. Figure 1: Connection structure Further information \u00b6 The open metadata type for a connector type is defined in model 0201 . The open connector archives module provides an open metadata archive that contains connector types for connectors supported by Egeria.","title":"Connector Type"},{"location":"concepts/connector-type/#connector-type-part-of-the-open-connector-framework-ocf","text":"The connector type is a set of properties that defines the supported capabilities and the identity of the connector provider for a connector . Its properties are: guid - Globally unique identifier for the connector type. url - External link address for the connector type properties in the metadata repository. qualifiedName - The official (unique) name for the connector type. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. displayName - A consumable name for the connector type. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. description - A full description of the connector type covering details of the assets it connects to along with usage and versioning information. connectorProviderClassName - The connector provider is the factory for a particular type of connector. This property defines the class name for the connector provider that the Connector Broker should use to request new connector instances. recognizedAdditionalProperties - these are the Connection additional properties recognized by the connector implementation recognizedConfigurationProperties - these are the Connection configuration properties recognized by the connector implementation recognizedSecuredProperties - these are the Connection secured properties recognized by the connector implementation additionalProperties - Any additional properties that the connector provider needs to know in order to create connector instances. The connector type is linked to the Connection objects that request this type of connector. Figure 1: Connection structure","title":"Connector Type - part of the Open Connector Framework (OCF)"},{"location":"concepts/connector-type/#further-information","text":"The open metadata type for a connector type is defined in model 0201 . The open connector archives module provides an open metadata archive that contains connector types for connectors supported by Egeria.","title":"Further information"},{"location":"concepts/connector/","text":"Connector - part of the Open Connector Framework ( OCF ) \u00b6 A connector is a java client object that provides applications with access to a data source or service (known as an asset ) along with its related metadata. An OCF connector provides four APIs. Connector Lifecycle : manages the lifecycle state of the connector and includes initialize() , start() and disconnect() . Metadata store initialization : if the connector is created by a metadata service then it adds a client to the metadata server called ConnectedAssetProperties to the connector between initialize() and start() . The ConnectedAssetProperties client can be retrieved from the connector instance and used to retrieve metadata about the asset that is stored in the metadata server. Specific initialization for the type of connector : some types of connectors need additional initialization. These methods are called by the component creating the connector before the start() method is called. Asset Content : this API is crafted to provide the most natural interface to the Asset's contents. Therefore the Asset Content API is typically different for each type of connector. OCF connectors are not limited to representing Assets as they are physically implemented. An OCF connector can represent a simplified logical (virtual) asset, such as a data set, that is designed for the needs of a specific application or tool. This type of connector delegates the requests it receives to one or more physical data resources. It is called a virtual connector. Further Information \u00b6 See the Egeria Developer Guide for information on writing connectors.","title":"Connector"},{"location":"concepts/connector/#connector-part-of-the-open-connector-framework-ocf","text":"A connector is a java client object that provides applications with access to a data source or service (known as an asset ) along with its related metadata. An OCF connector provides four APIs. Connector Lifecycle : manages the lifecycle state of the connector and includes initialize() , start() and disconnect() . Metadata store initialization : if the connector is created by a metadata service then it adds a client to the metadata server called ConnectedAssetProperties to the connector between initialize() and start() . The ConnectedAssetProperties client can be retrieved from the connector instance and used to retrieve metadata about the asset that is stored in the metadata server. Specific initialization for the type of connector : some types of connectors need additional initialization. These methods are called by the component creating the connector before the start() method is called. Asset Content : this API is crafted to provide the most natural interface to the Asset's contents. Therefore the Asset Content API is typically different for each type of connector. OCF connectors are not limited to representing Assets as they are physically implemented. An OCF connector can represent a simplified logical (virtual) asset, such as a data set, that is designed for the needs of a specific application or tool. This type of connector delegates the requests it receives to one or more physical data resources. It is called a virtual connector.","title":"Connector - part of the Open Connector Framework (OCF)"},{"location":"concepts/connector/#further-information","text":"See the Egeria Developer Guide for information on writing connectors.","title":"Further Information"},{"location":"concepts/contact-method/","text":"Contact method \u00b6 A contact method provides a means to send a person or a team a message. This includes email, phone, or through their personal profile .","title":"Contact Method"},{"location":"concepts/contact-method/#contact-method","text":"A contact method provides a means to send a person or a team a message. This includes email, phone, or through their personal profile .","title":"Contact method"},{"location":"concepts/data-engine-proxy/","text":"Data engine proxy \u00b6 The data engine proxy is a governance server that can capture metadata about data movement processes (such as ETL jobs) from a data engine. This information results in new Process being defined in open metadata linked to the data sources that it works with. This is valuable information for lineage. The data engine proxy is paired with the Data Engine OMAS . Its connector interfaces are defined in the data-engine-proxy-connector module. Further information Setting up the data engine proxy","title":"Data Engine Proxy"},{"location":"concepts/data-engine-proxy/#data-engine-proxy","text":"The data engine proxy is a governance server that can capture metadata about data movement processes (such as ETL jobs) from a data engine. This information results in new Process being defined in open metadata linked to the data sources that it works with. This is valuable information for lineage. The data engine proxy is paired with the Data Engine OMAS . Its connector interfaces are defined in the data-engine-proxy-connector module. Further information Setting up the data engine proxy","title":"Data engine proxy"},{"location":"concepts/discovery-analysis-report/","text":"Discovery Analysis Report \u00b6 The discovery analysis report lists the discovery annotations that were created during the execution of a discovery service . The discovery analysis report is created in the open metadata repository by the discovery engine when it creates the discovery service instance. The discovery service can retrieve information about the discovery analysis report through the discovery analysis report store client. This client is accessed through the discovery annotation store . The discovery analysis report store also enables a long running discovery service (typically a discovery pipeline ) to record its current analysis step.","title":"Discovery Analysis Report"},{"location":"concepts/discovery-analysis-report/#discovery-analysis-report","text":"The discovery analysis report lists the discovery annotations that were created during the execution of a discovery service . The discovery analysis report is created in the open metadata repository by the discovery engine when it creates the discovery service instance. The discovery service can retrieve information about the discovery analysis report through the discovery analysis report store client. This client is accessed through the discovery annotation store . The discovery analysis report store also enables a long running discovery service (typically a discovery pipeline ) to record its current analysis step.","title":"Discovery Analysis Report"},{"location":"concepts/endpoint/","text":"Endpoint - part of the Open Connector Framework ( OCF ) \u00b6 The endpoint is a set of properties that defines the network address and how to connect to it for a resource deployed in the digital landscape. Its properties are: guid - Globally unique identifier for the endpoint. url - External link address for the endpoint properties in the metadata repository. This URL can be stored as a property in another entity to create an explicit link to this endpoint. qualifiedName - The official (unique) name for the endpoint. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. displayName - A consumable name for the endpoint. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. description - A description for the endpoint. address - The location of the asset. For network connected resources, this is typically the URL and port number (if needed) for the server where the asset is located (or at least accessible by the connector). For file-based resources, this is typically the name of the file. protocol - The communication protocol that the connection should use to connect to the server. encryptionMethod - Describes the encryption method to use (if any). This is an open value allowing information needed by the connector user to retrieve all of the information they need to work with the endpoint. additionalProperties - Any additional properties that the connector need to know in order to access the Asset. Further information \u00b6 The open metadata type for an endpoint is defined in model 0026 .","title":"Endpoint"},{"location":"concepts/endpoint/#endpoint-part-of-the-open-connector-framework-ocf","text":"The endpoint is a set of properties that defines the network address and how to connect to it for a resource deployed in the digital landscape. Its properties are: guid - Globally unique identifier for the endpoint. url - External link address for the endpoint properties in the metadata repository. This URL can be stored as a property in another entity to create an explicit link to this endpoint. qualifiedName - The official (unique) name for the endpoint. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. displayName - A consumable name for the endpoint. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. description - A description for the endpoint. address - The location of the asset. For network connected resources, this is typically the URL and port number (if needed) for the server where the asset is located (or at least accessible by the connector). For file-based resources, this is typically the name of the file. protocol - The communication protocol that the connection should use to connect to the server. encryptionMethod - Describes the encryption method to use (if any). This is an open value allowing information needed by the connector user to retrieve all of the information they need to work with the endpoint. additionalProperties - Any additional properties that the connector need to know in order to access the Asset.","title":"Endpoint - part of the Open Connector Framework (OCF)"},{"location":"concepts/endpoint/#further-information","text":"The open metadata type for an endpoint is defined in model 0026 .","title":"Further information"},{"location":"concepts/engine-host/","text":"Governance Engine Hosting Servers \u00b6 An engine host is an OMAG Server that hosts one or more governance engines. Governance engines provide collections of services used to support the governance of the digital landscape and the metadata that describes it. The services within the governance engines may access third party technology to perform their responsibilities or implement their behavior directly. The engine host uses a metadata server to store the definitions of the governance engines and the services within them. These definitions are retrieved through the Governance Engine OMAS . The Governance Engine OMAS also manages the definition of governance action processes that choreograph calls to the services in a governance engine in order to implement technical controls in the governance program. Typically, an engine host is deployed close to where the artifacts/resources/data are stored because it can generate a lot of network traffic when its services are running. The metadata interfaces needed by the governance engines are provided by the Open Metadata Engine Services ( OMES ) (or engine services for short). The engine services also run in the engine host OMAG Server. The engine services are: Asset Analysis - For running Open Discovery Services that analyse the content of an asset's real world counterpart in the digital landscape, generates annotations in an open discovery analysis report that is attached to the asset in the open metadata repositories. Governance Action - For running Governance Action Services . There are five types of governance action services: Watchdog governance service - Monitors changes in the open metadata repositories and initiates governance activity as a result. This is typically by creating a governance action , a governance action process or an incident report . One example of a watchdog governance service is to monitor for the addition of a new asset. Verification governance service - Runs checks on the metadata properties to ensure they are complete and correct. One example of a verification governance service is detection for metadata elements with the same qualified name, or an asset without an owner. Triage governance service - Runs triage tasks to determine how to manage an incident or situation. For example, it could initiate an external workflow, assign a task to a steward, wait for manual decision or initiate a remediation request. Remediation governance service - Makes updates to the open metadata or the digital landscape. An example of a remediation governance service could be to link or consolidate metadata elements with the same qualified name. Another remediation governance service may move assets between zones when a particular date is reached. Provisioning governance service - Invokes a provisioning service whenever a provisioning request is made. Typically, the provisioning service is an external service. It may also create lineage metadata to describe the work of the provisioning engine. An engine service is paired with a specific access service running in either a metadata access point or a metadata server . The specific access services are: Discovery Engine OMAS for Asset Analysis OMES . Governance Engine OMAS for Governance Action OMES . The name and URL root of the server where the access service is running is needed to configure an engine service. The metadata server used by the engine services does not need to be the same metadata server as the one used by the engine host server. This enables the management of metadata about the assets to be maintained close to the assets, and the definitions of the governance engines, services and processes to be maintained close to the governance team: The engine host services have a REST API to query the status of the governance engines running in the engine services. The engine services also have a REST API to query specific details of their governance engines. All these REST APIs may be called by a view server as part of the support for a user interface. Further information The capabilities of each of the engine services are described in the engine services . Details of how to create the definitions of the governance engines and governance services are described in the Governance Engine OMAS documentation.","title":"Engine Host"},{"location":"concepts/engine-host/#governance-engine-hosting-servers","text":"An engine host is an OMAG Server that hosts one or more governance engines. Governance engines provide collections of services used to support the governance of the digital landscape and the metadata that describes it. The services within the governance engines may access third party technology to perform their responsibilities or implement their behavior directly. The engine host uses a metadata server to store the definitions of the governance engines and the services within them. These definitions are retrieved through the Governance Engine OMAS . The Governance Engine OMAS also manages the definition of governance action processes that choreograph calls to the services in a governance engine in order to implement technical controls in the governance program. Typically, an engine host is deployed close to where the artifacts/resources/data are stored because it can generate a lot of network traffic when its services are running. The metadata interfaces needed by the governance engines are provided by the Open Metadata Engine Services ( OMES ) (or engine services for short). The engine services also run in the engine host OMAG Server. The engine services are: Asset Analysis - For running Open Discovery Services that analyse the content of an asset's real world counterpart in the digital landscape, generates annotations in an open discovery analysis report that is attached to the asset in the open metadata repositories. Governance Action - For running Governance Action Services . There are five types of governance action services: Watchdog governance service - Monitors changes in the open metadata repositories and initiates governance activity as a result. This is typically by creating a governance action , a governance action process or an incident report . One example of a watchdog governance service is to monitor for the addition of a new asset. Verification governance service - Runs checks on the metadata properties to ensure they are complete and correct. One example of a verification governance service is detection for metadata elements with the same qualified name, or an asset without an owner. Triage governance service - Runs triage tasks to determine how to manage an incident or situation. For example, it could initiate an external workflow, assign a task to a steward, wait for manual decision or initiate a remediation request. Remediation governance service - Makes updates to the open metadata or the digital landscape. An example of a remediation governance service could be to link or consolidate metadata elements with the same qualified name. Another remediation governance service may move assets between zones when a particular date is reached. Provisioning governance service - Invokes a provisioning service whenever a provisioning request is made. Typically, the provisioning service is an external service. It may also create lineage metadata to describe the work of the provisioning engine. An engine service is paired with a specific access service running in either a metadata access point or a metadata server . The specific access services are: Discovery Engine OMAS for Asset Analysis OMES . Governance Engine OMAS for Governance Action OMES . The name and URL root of the server where the access service is running is needed to configure an engine service. The metadata server used by the engine services does not need to be the same metadata server as the one used by the engine host server. This enables the management of metadata about the assets to be maintained close to the assets, and the definitions of the governance engines, services and processes to be maintained close to the governance team: The engine host services have a REST API to query the status of the governance engines running in the engine services. The engine services also have a REST API to query specific details of their governance engines. All these REST APIs may be called by a view server as part of the support for a user interface. Further information The capabilities of each of the engine services are described in the engine services . Details of how to create the definitions of the governance engines and governance services are described in the Governance Engine OMAS documentation.","title":"Governance Engine Hosting Servers"},{"location":"concepts/event-bus/","text":"Event Bus \u00b6 Egeria's event bus service is constructed from an event broker infrastructure service and a set of well-known topics . Collectively they provide the ability to reliably pass events between different OMAG Servers : To register with an open metadata repository cohort , exchange type definitions and share changes to metadata with other members of the cohort via the OMRS topic(s) . To exchange details of metadata changes through an Open Metadata Access Service ( OMAS ) 's InTopic and OutTopic . Each topic maintains a pointer to the last event that a server has read so that it receives each event that is added even if it restarts. There are different event broker implementations with greater or lesser reliability and performance. Many organizations establish a standard choice of their event broker service which is why Egeria uses connectors to implement its event bus. Egeria's default event broker is Apache Kafka . Each topic is accessed through an open metadata topic connector . Details of open metadata topic connectors are needed in multiple places in a server's configuration document . To simplify this configuration, the event bus config is added to the server's configuration document at the start of the configuration process . The event bus config establishes a set of defaults for the open metadata topic connectors. These defaults are used whenever open metadata topic connectors are configured. The subsystems using the event bus have a specialized connector that supports event exchange for a specific type of event. Since it is necessary to be able to swap the event broker implementation, these connectors embed an open metadata topic connector within their implementation. When the connection for one of these subsystem topic connectors is configured, the defaults from the event bus config are used to set up the nested open metadata topic connection. The resulting configuration for these nested connectors is as follows: The common configuration for the event bus is identified and configured using the event bus config. This configuration is encoded in a connection object for the generic open metadata topic connector. When the consuming component is configured, a connection object for its specialized topic connector is created, with the generic open metadata topic connector embedded inside. When the connector broker inside Egeria's runtime is called upon to create the specialized topic connector at server start up, it navigates the hierarchy of connection objects, creating the nested hierarchy of connectors as specified.","title":"Event Bus"},{"location":"concepts/event-bus/#event-bus","text":"Egeria's event bus service is constructed from an event broker infrastructure service and a set of well-known topics . Collectively they provide the ability to reliably pass events between different OMAG Servers : To register with an open metadata repository cohort , exchange type definitions and share changes to metadata with other members of the cohort via the OMRS topic(s) . To exchange details of metadata changes through an Open Metadata Access Service ( OMAS ) 's InTopic and OutTopic . Each topic maintains a pointer to the last event that a server has read so that it receives each event that is added even if it restarts. There are different event broker implementations with greater or lesser reliability and performance. Many organizations establish a standard choice of their event broker service which is why Egeria uses connectors to implement its event bus. Egeria's default event broker is Apache Kafka . Each topic is accessed through an open metadata topic connector . Details of open metadata topic connectors are needed in multiple places in a server's configuration document . To simplify this configuration, the event bus config is added to the server's configuration document at the start of the configuration process . The event bus config establishes a set of defaults for the open metadata topic connectors. These defaults are used whenever open metadata topic connectors are configured. The subsystems using the event bus have a specialized connector that supports event exchange for a specific type of event. Since it is necessary to be able to swap the event broker implementation, these connectors embed an open metadata topic connector within their implementation. When the connection for one of these subsystem topic connectors is configured, the defaults from the event bus config are used to set up the nested open metadata topic connection. The resulting configuration for these nested connectors is as follows: The common configuration for the event bus is identified and configured using the event bus config. This configuration is encoded in a connection object for the generic open metadata topic connector. When the consuming component is configured, a connection object for its specialized topic connector is created, with the generic open metadata topic connector embedded inside. When the connector broker inside Egeria's runtime is called upon to create the specialized topic connector at server start up, it navigates the hierarchy of connection objects, creating the nested hierarchy of connectors as specified.","title":"Event Bus"},{"location":"concepts/external-reference/","text":"External references \u00b6 External references describe and contain a URL to a document or online resource outside of open metadata. A list of external references can be attached to a personal profile , a community or a team","title":"External Reference"},{"location":"concepts/external-reference/#external-references","text":"External references describe and contain a URL to a document or online resource outside of open metadata. A list of external references can be attached to a personal profile , a community or a team","title":"External references"},{"location":"concepts/favorite-things-collection/","text":"Favorite collections \u00b6 Collections are sharable lists of things. A collection may, for example, be a member of a useful resource list that is attached to multiple anchors such as communities and personal profiles. There are three special types of collections managed by Community Profile OMAS that are only attached to a single personal profile . They are to manage collections of assets , projects and communities for the individual owner of the","title":"Favorite things collection"},{"location":"concepts/favorite-things-collection/#favorite-collections","text":"Collections are sharable lists of things. A collection may, for example, be a member of a useful resource list that is attached to multiple anchors such as communities and personal profiles. There are three special types of collections managed by Community Profile OMAS that are only attached to a single personal profile . They are to manage collections of assets , projects and communities for the individual owner of the","title":"Favorite collections"},{"location":"concepts/glossary-term/","text":"Glossary term \u00b6 A glossary term is a definition of the meaning of a concept, object or activity.","title":"Glossary term"},{"location":"concepts/glossary-term/#glossary-term","text":"A glossary term is a definition of the meaning of a concept, object or activity.","title":"Glossary term"},{"location":"concepts/governance-action-engine/","text":"Governance Action Engine \u00b6 The governance action engine describes a set of related governance action services . It is hosted in an Open Metadata Engine Service ( OMES ) running on one or more Engine Host OMAG Servers . The Open Metadata Types used to define the governance action engines are located in model 0461 Governance Action Engines .","title":"Governance Action Engine"},{"location":"concepts/governance-action-engine/#governance-action-engine","text":"The governance action engine describes a set of related governance action services . It is hosted in an Open Metadata Engine Service ( OMES ) running on one or more Engine Host OMAG Servers . The Open Metadata Types used to define the governance action engines are located in model 0461 Governance Action Engines .","title":"Governance Action Engine"},{"location":"concepts/governance-action/","text":"Governance Action \u00b6 A governance action describes a specific governance activity that needs to be performed on one or more metadata elements, or their counterparts in the digital landscape. A governance action is represented as a metadata entity in the open metadata repositories and linked to: The source (cause) of the governance action. The target elements that need to be acted upon. The governance engine that will run the governance service that implements the desired behavior. The governance action metadata entity is used to coordinate the desired activity in the governance engine, record its current state and act as a record of the activity for future audits. Governance actions can be created through the Governance Engine OMAS API . Some governance services (for example, the Watchdog Governance Action Service ) can create governance actions when they run. Governance services produce output strings called guards that indicate specific conditions or outcomes. These guards can be used to trigger new governance actions. Triggered governance actions are linked to their predecessor so it possible to trace through the governance actions that ran. The governance action process defines the flow of governance actions. It uses governance action types to build up a template of possible governance actions linked via the guards. When the process runs, its linked governance action types control the triggering of new governance actions. If the start date of the governance action is in the future, the Engine Host Services running in the same Engine Host OMAG Server as the nominated governance engine will schedule the governance service to run soon after the requested start date. If the start date is left blank, the requested governance service is run as soon as possible.","title":"Governance Action"},{"location":"concepts/governance-action/#governance-action","text":"A governance action describes a specific governance activity that needs to be performed on one or more metadata elements, or their counterparts in the digital landscape. A governance action is represented as a metadata entity in the open metadata repositories and linked to: The source (cause) of the governance action. The target elements that need to be acted upon. The governance engine that will run the governance service that implements the desired behavior. The governance action metadata entity is used to coordinate the desired activity in the governance engine, record its current state and act as a record of the activity for future audits. Governance actions can be created through the Governance Engine OMAS API . Some governance services (for example, the Watchdog Governance Action Service ) can create governance actions when they run. Governance services produce output strings called guards that indicate specific conditions or outcomes. These guards can be used to trigger new governance actions. Triggered governance actions are linked to their predecessor so it possible to trace through the governance actions that ran. The governance action process defines the flow of governance actions. It uses governance action types to build up a template of possible governance actions linked via the guards. When the process runs, its linked governance action types control the triggering of new governance actions. If the start date of the governance action is in the future, the Engine Host Services running in the same Engine Host OMAG Server as the nominated governance engine will schedule the governance service to run soon after the requested start date. If the start date is left blank, the requested governance service is run as soon as possible.","title":"Governance Action"},{"location":"concepts/governance-server/","text":"Governance server \u00b6 Governance servers host specific integration or governance connectors for technology that does not integrate directly with open metadata. These are the different types: Engine hosts - host governance engines for active management of the open metadata ecosystem. Integration daemons - manage the exchange of metadata with third party technologies. Data engine proxy - captures information about processes and the data sources that they work with and catalogs them in open metadata. Open lineage server - accumulates lineage information to provide a comprehensive historical reporting service for lineage.","title":"Governance Server"},{"location":"concepts/governance-server/#governance-server","text":"Governance servers host specific integration or governance connectors for technology that does not integrate directly with open metadata. These are the different types: Engine hosts - host governance engines for active management of the open metadata ecosystem. Integration daemons - manage the exchange of metadata with third party technologies. Data engine proxy - captures information about processes and the data sources that they work with and catalogs them in open metadata. Open lineage server - accumulates lineage information to provide a comprehensive historical reporting service for lineage.","title":"Governance server"},{"location":"concepts/governance-zone/","text":"Governance Zone \u00b6 A governance zone defines a list of assets that are grouped together for a specific purpose. A zone may represent assets that are consumed or managed in a particular way; or should only be visible to particular groups of users, or processed by particular types of engine. There may also be zones used to indicate that the asset is in a particular state. For example, Coco Pharmaceuticals use a quarantine zone for data that has arrived from an external partner. It is not visible to the researchers until it has been cataloged and verified. Then it is added to the zones that others can see. Zones are typically independent of one another, but they can be nested if desired. An asset can belong to all, one or many zones. The list of zones that an asset belongs to is configured in its zoneMembership property. If it is blank, it means the asset logically belongs to all zones. Otherwise, it belongs only to the zones that are listed. Add or remove it from a zone by updating the asset's zoneMembership property. All Open Metadata Access Services ( OMAS ) that retrieve assets, such as Asset Catalog , Asset Consumer and Asset Owner , use the supportedZones option that is configured for the service in their server's configuration document. This property defines the zones of assets that can be returned by this instance of the access service. In addition, access services that create assets use the defaultZones option to define the list of zones set up in any new asset they create. Finally, access services that are synchronizing assets between different third party technologies, such as the Data Manager OMAS , will also use the publishZones option to publish an asset to consumer zones once they are completely defined in the catalog. The meaning, purpose and governance requirements for assets within a specific zone are maintained through the Governance Program OMAS . It is also possible to associate security access control with a governance zone .","title":"Governance Zone"},{"location":"concepts/governance-zone/#governance-zone","text":"A governance zone defines a list of assets that are grouped together for a specific purpose. A zone may represent assets that are consumed or managed in a particular way; or should only be visible to particular groups of users, or processed by particular types of engine. There may also be zones used to indicate that the asset is in a particular state. For example, Coco Pharmaceuticals use a quarantine zone for data that has arrived from an external partner. It is not visible to the researchers until it has been cataloged and verified. Then it is added to the zones that others can see. Zones are typically independent of one another, but they can be nested if desired. An asset can belong to all, one or many zones. The list of zones that an asset belongs to is configured in its zoneMembership property. If it is blank, it means the asset logically belongs to all zones. Otherwise, it belongs only to the zones that are listed. Add or remove it from a zone by updating the asset's zoneMembership property. All Open Metadata Access Services ( OMAS ) that retrieve assets, such as Asset Catalog , Asset Consumer and Asset Owner , use the supportedZones option that is configured for the service in their server's configuration document. This property defines the zones of assets that can be returned by this instance of the access service. In addition, access services that create assets use the defaultZones option to define the list of zones set up in any new asset they create. Finally, access services that are synchronizing assets between different third party technologies, such as the Data Manager OMAS , will also use the publishZones option to publish an asset to consumer zones once they are completely defined in the catalog. The meaning, purpose and governance requirements for assets within a specific zone are maintained through the Governance Program OMAS . It is also possible to associate security access control with a governance zone .","title":"Governance Zone"},{"location":"concepts/head-count-limit-for-role/","text":"Head count limit \u00b6 The head count limit is an optional value that can be set in a personal role . This determines how many people are funded for the role. Open metadata does not prevent more people than this limit being appointed to the role, but it does send a notification to indicate that the limit has been breached. The organization can choose to increase the head count limit or remove one of the appointed people. --8<-- \"snippets/abbr.md","title":"Head count limit for role"},{"location":"concepts/head-count-limit-for-role/#head-count-limit","text":"The head count limit is an optional value that can be set in a personal role . This determines how many people are funded for the role. Open metadata does not prevent more people than this limit being appointed to the role, but it does send a notification to indicate that the limit has been breached. The organization can choose to increase the head count limit or remove one of the appointed people. --8<-- \"snippets/abbr.md","title":"Head count limit"},{"location":"concepts/home-metadata-repository/","text":"Home Metadata Repositories \u00b6 The metadata repository where a metadata entity or relationship is created is called its home repository . Metadata in its home repository can be updated and deleted. The Open Metadata Repository Services ( OMRS ) is responsible for sharing this metadata with other metadata repositories who are members of the same cohort . The shared copies are called reference copies and are read-only. Update requests to a reference copy are automatically redirected to the home repository by Egeria, without the caller being aware. Every metadata repository in a cohort has a unique identifier called the local metadata collection id . This identifier is set up in the server configuration and shared when this server connects to a cohort. When metadata is shared by Egeria, each element is tagged with the metadata collection id of its home repository. Egeria is able to route update requests to the right server by comparing the metadata collection id in the metadata instance with the cohort registration information passed between members of the cohort when they connect.","title":"Home Metadata Repository"},{"location":"concepts/home-metadata-repository/#home-metadata-repositories","text":"The metadata repository where a metadata entity or relationship is created is called its home repository . Metadata in its home repository can be updated and deleted. The Open Metadata Repository Services ( OMRS ) is responsible for sharing this metadata with other metadata repositories who are members of the same cohort . The shared copies are called reference copies and are read-only. Update requests to a reference copy are automatically redirected to the home repository by Egeria, without the caller being aware. Every metadata repository in a cohort has a unique identifier called the local metadata collection id . This identifier is set up in the server configuration and shared when this server connects to a cohort. When metadata is shared by Egeria, each element is tagged with the metadata collection id of its home repository. Egeria is able to route update requests to the right server by comparing the metadata collection id in the metadata instance with the cohort registration information passed between members of the cohort when they connect.","title":"Home Metadata Repositories"},{"location":"concepts/in-topic/","text":"OMAS InTopic \u00b6 The InTopic of an Open Metadata Access Service is the location where the OMAS will received incoming events from its consumers.","title":"In Topic"},{"location":"concepts/in-topic/#omas-intopic","text":"The InTopic of an Open Metadata Access Service is the location where the OMAS will received incoming events from its consumers.","title":"OMAS InTopic"},{"location":"concepts/informal-tag/","text":"Informal Tag \u00b6 A tag is a descriptive name with optional description that can be attached to resources such as personal profiles, personal messages, personal notes, community forums and forum contributions, comments and communities. The process of adding a tag to an object is called tagging . A tag can be public (visible to all users) or private (visible only to the user that created it). Working with tags \u00b6 Finding existing tags Accessing resources attached to a tag Accessing my tags Creating a tag Attaching a tag Detaching my tag Detaching a tag from a resource Deleting my private tag Deleting public tags","title":"Tag"},{"location":"concepts/informal-tag/#informal-tag","text":"A tag is a descriptive name with optional description that can be attached to resources such as personal profiles, personal messages, personal notes, community forums and forum contributions, comments and communities. The process of adding a tag to an object is called tagging . A tag can be public (visible to all users) or private (visible only to the user that created it).","title":"Informal Tag"},{"location":"concepts/informal-tag/#working-with-tags","text":"Finding existing tags Accessing resources attached to a tag Accessing my tags Creating a tag Attaching a tag Detaching my tag Detaching a tag from a resource Deleting my private tag Deleting public tags","title":"Working with tags"},{"location":"concepts/integration-daemon/","text":"Integration Daemon \u00b6 An integration daemon is an OMAG Server that provides metadata exchange services between third party technology and the open metadata ecosystem. The integration daemon interacts with the open metadata ecosystem through Open Metadata Access Services ( OMAS ) running in a metadata access point or metadata server . Inside the integration daemon are one or more Open Metadata Integration Services ( OMIS ) that each focus on metadata exchange with a specific type of technology. They are paired with a specific Open Metadata Access Service ( OMAS ) running in the metadata access point / metadata server. To understand how an integration daemon works, it is necessary to look in a bit more detail at how technologies can be connected together to exchange metadata. Integration mechanisms \u00b6 Closed technology \u00b6 Closed technology describes technology that is only accessible through a user interface. Not considered Egeria does not provide any particular consideration for these technologies, given they provide no integration mechanisms. Active and passive open technology \u00b6 Passive open technology offers open APIs that can be called to configure and operate the technology, while active open technology provides active, ongoing exchange of information with another technology that covers its operation and specific situations it has detected. The integration daemon provides support for both active and passive open technologies: For passive open technology, an integration service will continuously poll the connector to allow it to repeatedly call the technology's API to determine if anything has changed and then pass any changes to the metadata access point / metadata server. The active open technology support is similar except that rather than polling for changes in the third party technology, the connector listens on the third party technology's event topic and translate the events it receives and passes the information onto the access service via calls to the integration service. The integration service also listens for events from its access service's Out Topic . If there is new metadata that is of interest to the third party technology, the access service publishes the information and it is picked up by the integration service and passed on to the connector. The connector may then push metadata to the third party technology. Thus, the integration services of the integration daemon enable metadata to flow both in and out of the open metadata ecosystem. Integrated technology \u00b6 Integrated technology describes technology that integrates with open metadata APIs to events \"out of the box.\" Where an Egeria conformance test exists, this technology has a conformance mark. An integrated technology is able to interact directly with a metadata access point or metadata server by calling the open metadata services or consuming them directly: Integration connectors \u00b6 The code that manages the specific APIs and formats of the third party technology is encapsulated in a special type of connector called an integration connector . The specific interface that the integration connector needs to implement is defined by the integration service . This interface enables the integration service to pass a context object to the connector before it is started. The context enables the connector to register a listener with the associated access service's Out Topic , or call its REST API, or to push events to the access service's In Topic . By default, the context uses the integration daemon's userId for requests to the access service which means that the metadata created by the integration connector will be credited to this user. If you want to use a different userId for metadata from each connector, the server's userId can be overridden in the connector's configuration.","title":"Integration Daemon"},{"location":"concepts/integration-daemon/#integration-daemon","text":"An integration daemon is an OMAG Server that provides metadata exchange services between third party technology and the open metadata ecosystem. The integration daemon interacts with the open metadata ecosystem through Open Metadata Access Services ( OMAS ) running in a metadata access point or metadata server . Inside the integration daemon are one or more Open Metadata Integration Services ( OMIS ) that each focus on metadata exchange with a specific type of technology. They are paired with a specific Open Metadata Access Service ( OMAS ) running in the metadata access point / metadata server. To understand how an integration daemon works, it is necessary to look in a bit more detail at how technologies can be connected together to exchange metadata.","title":"Integration Daemon"},{"location":"concepts/integration-daemon/#integration-mechanisms","text":"","title":"Integration mechanisms"},{"location":"concepts/integration-daemon/#closed-technology","text":"Closed technology describes technology that is only accessible through a user interface. Not considered Egeria does not provide any particular consideration for these technologies, given they provide no integration mechanisms.","title":"Closed technology"},{"location":"concepts/integration-daemon/#active-and-passive-open-technology","text":"Passive open technology offers open APIs that can be called to configure and operate the technology, while active open technology provides active, ongoing exchange of information with another technology that covers its operation and specific situations it has detected. The integration daemon provides support for both active and passive open technologies: For passive open technology, an integration service will continuously poll the connector to allow it to repeatedly call the technology's API to determine if anything has changed and then pass any changes to the metadata access point / metadata server. The active open technology support is similar except that rather than polling for changes in the third party technology, the connector listens on the third party technology's event topic and translate the events it receives and passes the information onto the access service via calls to the integration service. The integration service also listens for events from its access service's Out Topic . If there is new metadata that is of interest to the third party technology, the access service publishes the information and it is picked up by the integration service and passed on to the connector. The connector may then push metadata to the third party technology. Thus, the integration services of the integration daemon enable metadata to flow both in and out of the open metadata ecosystem.","title":"Active and passive open technology"},{"location":"concepts/integration-daemon/#integrated-technology","text":"Integrated technology describes technology that integrates with open metadata APIs to events \"out of the box.\" Where an Egeria conformance test exists, this technology has a conformance mark. An integrated technology is able to interact directly with a metadata access point or metadata server by calling the open metadata services or consuming them directly:","title":"Integrated technology"},{"location":"concepts/integration-daemon/#integration-connectors","text":"The code that manages the specific APIs and formats of the third party technology is encapsulated in a special type of connector called an integration connector . The specific interface that the integration connector needs to implement is defined by the integration service . This interface enables the integration service to pass a context object to the connector before it is started. The context enables the connector to register a listener with the associated access service's Out Topic , or call its REST API, or to push events to the access service's In Topic . By default, the context uses the integration daemon's userId for requests to the access service which means that the metadata created by the integration connector will be credited to this user. If you want to use a different userId for metadata from each connector, the server's userId can be overridden in the connector's configuration.","title":"Integration connectors"},{"location":"concepts/karma-point-plateau/","text":"Karma Point Plateau \u00b6 A karma point plateau identifies a significant contribution to open metadata. By default, a karma point plateau is achieved for every 500 karma points awarded. However the threshold for the karma point plateau can be changed at server start up . The Community Profile OMAS generates a Karma Point Plateau Event each time a person achieves a karma point plateau. This is sent on the Community Profile OMAS 's OutTopic","title":"Karma Point Plateau"},{"location":"concepts/karma-point-plateau/#karma-point-plateau","text":"A karma point plateau identifies a significant contribution to open metadata. By default, a karma point plateau is achieved for every 500 karma points awarded. However the threshold for the karma point plateau can be changed at server start up . The Community Profile OMAS generates a Karma Point Plateau Event each time a person achieves a karma point plateau. This is sent on the Community Profile OMAS 's OutTopic","title":"Karma Point Plateau"},{"location":"concepts/karma-point/","text":"Karma Point \u00b6 A karma point is a reward given to an individual for making a contribution to open metadata. This may be for: Creating some information Correcting or enhancing some information Linking information together Removing obsolete information Karma points are awarded automatically. They are stored in an individual's personal profile . When an individual's karma point total reaches a multiple of the karma point notification threshold, the Community Profile OMAS sends a notification on its OutTopic . Related information \u00b6 [Configuring the notification threshold for karma points]","title":"Karma Point"},{"location":"concepts/karma-point/#karma-point","text":"A karma point is a reward given to an individual for making a contribution to open metadata. This may be for: Creating some information Correcting or enhancing some information Linking information together Removing obsolete information Karma points are awarded automatically. They are stored in an individual's personal profile . When an individual's karma point total reaches a multiple of the karma point notification threshold, the Community Profile OMAS sends a notification on its OutTopic .","title":"Karma Point"},{"location":"concepts/karma-point/#related-information","text":"[Configuring the notification threshold for karma points]","title":"Related information"},{"location":"concepts/like/","text":"Like \u00b6 A like is an attachment that a user can attach to a referenceable to indicate his/her approval of the element's presence or content.","title":"Like"},{"location":"concepts/like/#like","text":"A like is an attachment that a user can attach to a referenceable to indicate his/her approval of the element's presence or content.","title":"Like"},{"location":"concepts/metadata-access-point/","text":"Metadata Access Point \u00b6 A metadata access point is an OMAG Server that can be a member of a cohort and supports the access services . This means it provides specialist metadata APIs to user interfaces and governance servers that embrace metadata from all connected open metadata repository cohorts. The basic metadata access point has no metadata repository and metadata is retrieved and stored from remote repositories via the cohort . It can be upgraded to a metadata server by adding a metadata repository which will enable it to store metadata locally.","title":"Metadata Access Point"},{"location":"concepts/metadata-access-point/#metadata-access-point","text":"A metadata access point is an OMAG Server that can be a member of a cohort and supports the access services . This means it provides specialist metadata APIs to user interfaces and governance servers that embrace metadata from all connected open metadata repository cohorts. The basic metadata access point has no metadata repository and metadata is retrieved and stored from remote repositories via the cohort . It can be upgraded to a metadata server by adding a metadata repository which will enable it to store metadata locally.","title":"Metadata Access Point"},{"location":"concepts/metadata-access-server/","text":"Metadata access server \u00b6 Metadata access servers provide access to open metadata for governance servers and view servers . These are the different types: Metadata Access Point - a cohort member with support for the Open Metadata Access Services (OMASs) . Metadata Access Store - metadata access point with a native metadata repository.","title":"Metadata access server"},{"location":"concepts/metadata-access-server/#metadata-access-server","text":"Metadata access servers provide access to open metadata for governance servers and view servers . These are the different types: Metadata Access Point - a cohort member with support for the Open Metadata Access Services (OMASs) . Metadata Access Store - metadata access point with a native metadata repository.","title":"Metadata access server"},{"location":"concepts/metadata-access-store/","text":"Metadata access store \u00b6 A metadata access store is an OMAG Server that hosts a metadata repository with native support for open metadata types and instances. It is able to be a member of a cohort and so can exchange metadata with other members of the cohort. It is important to have at least one metadata access store in each cohort in order to support all types of metadata. Similar to the metadata access point , the metadata access store typically has the access services configured.","title":"Metadata access store"},{"location":"concepts/metadata-access-store/#metadata-access-store","text":"A metadata access store is an OMAG Server that hosts a metadata repository with native support for open metadata types and instances. It is able to be a member of a cohort and so can exchange metadata with other members of the cohort. It is important to have at least one metadata access store in each cohort in order to support all types of metadata. Similar to the metadata access point , the metadata access store typically has the access services configured.","title":"Metadata access store"},{"location":"concepts/metadata-collection-id/","text":"Metadata Collection Id \u00b6 Every metadata repository has a unique identifier called the local-metadata-collection-id . This identifier is assigned automatically during the configuration of the local repository but can be overridden through administrative commands. Figure 1 shows the local metadata collection id of 1b96495f-82d3-4224-9fdd-31bcb84c224c in the server configuration. A new local metadata collection id is assigned when the local repository is set up. Figure 1: local metadata collection id in server configuration It also appears in an audit log message written at start up. OMRS-AUDIT-0001 The Open Metadata Repository Services (OMRS) is initializing : : : OMRS-AUDIT-0003 The local repository is initializing with metadata collection id 1b96495f-82d3-4224-9fdd-31bcb84c224c If the server is connected to a cohort, it sends the local metadata collection id and details of how to call the server in a registration event. { \"localRegistration\" : { \"metadataCollectionId\" : \"1b96495f-82d3-4224-9fdd-31bcb84c224c\" , \"serverName\" : \"cocoMDS1\" , \"serverType\" : \"Open Metadata and Governance Server\" , \"registrationTime\" : 1531820378765 , \"repositoryConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"64e67923-8190-45ea-8f96-39320d638c02\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.ConnectorType.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.ConnectorType.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connector type.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/openmetadata/repositoryservices/\" } } } }","title":"Metadata Collection Id"},{"location":"concepts/metadata-collection-id/#metadata-collection-id","text":"Every metadata repository has a unique identifier called the local-metadata-collection-id . This identifier is assigned automatically during the configuration of the local repository but can be overridden through administrative commands. Figure 1 shows the local metadata collection id of 1b96495f-82d3-4224-9fdd-31bcb84c224c in the server configuration. A new local metadata collection id is assigned when the local repository is set up. Figure 1: local metadata collection id in server configuration It also appears in an audit log message written at start up. OMRS-AUDIT-0001 The Open Metadata Repository Services (OMRS) is initializing : : : OMRS-AUDIT-0003 The local repository is initializing with metadata collection id 1b96495f-82d3-4224-9fdd-31bcb84c224c If the server is connected to a cohort, it sends the local metadata collection id and details of how to call the server in a registration event. { \"localRegistration\" : { \"metadataCollectionId\" : \"1b96495f-82d3-4224-9fdd-31bcb84c224c\" , \"serverName\" : \"cocoMDS1\" , \"serverType\" : \"Open Metadata and Governance Server\" , \"registrationTime\" : 1531820378765 , \"repositoryConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"64e67923-8190-45ea-8f96-39320d638c02\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.ConnectorType.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.ConnectorType.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connector type.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/openmetadata/repositoryservices/\" } } } }","title":"Metadata Collection Id"},{"location":"concepts/note-log/","text":"Note log \u00b6 A note log is an attachment to a referenceable that acts as a series of ordered notes.","title":"Note log"},{"location":"concepts/note-log/#note-log","text":"A note log is an attachment to a referenceable that acts as a series of ordered notes.","title":"Note log"},{"location":"concepts/omag-server-platform/","text":"OMAG Server Platform \u00b6 The OMAG Server Platform provides a runtime process and platform for four broad groups of services: Server origin service - used to determine the type and level of the OMAG Server Platform. Platform services - used to determine the servers and their services running on the platform. Administration services - used to configure and manage the OMAG Servers running inside the OMAG Server Platform. Open Metadata and Governance ( OMAG ) services - used to work with metadata and govern the assets of an organization. The OMAG services are configured and activated in OMAG Servers using the administration services . The configuration operations of the admin services create configuration documents , one for each OMAG Server. Inside a configuration document is the definition of which OMAG services to activate in the server. These include the repository services (any type of server), the access services (for metadata access points and metadata servers), governance services (for governance servers) and view services (for view servers). Once a configuration document is defined, the OMAG Server can be started and stopped multiple times by the admin services server instance operations. The OMAG Server Platform also supports some platform services to query details of the servers running on the platform. The OMAG Server Platform can also host multiple OMAG Servers at any one time: The choices are as follows: A - Each OMAG Server has its own dedicated OMAG Server Platform - useful when only one server is needed in a deployment environment, or there is a desire to keep each server isolated in its own stack. B - Multiple OMAG Servers are hosted on the same OMAG Server Platform. The OMAG Server Platform routes inbound requests to the right server based on the server name specified in the request URL. The servers may all be of the same type (multi-tenant operation) or be a set of collaborating servers of different types consolidated onto the same platform. C - Multiple copies of same server instance running on different platforms to provide high availability and distribution of workload (horizontal scalability). Each OMAG Server is isolated within the server platform and so the OMAG Server platform can be used to support multi-tenant operation for a cloud service, or host a variety of different OMAG Servers needed at a particular location. Further reading Configuring the OMAG Server Platform Installing the OMAG Server Platform Tutorial Running the OMAG Server Platform Tutorial Inside the OMAG server platform \u00b6 The OMAG server platform provides the server environment for running open metadata and governance services. It hosts one or more OMAG servers . Each server is configured to support specific open metadata and governance services. Thus each server performance a specific role in an deployment landscape. The OMAG server platform is included in the Egeria Distribution TAR file which can be installed on your machine by following the Installing Egeria Tutorial . The OMAG server platform supports four broad groups of services: Server Origin Service - used to determine the type and level of the OMAG server platform. Platform Services - used to determine the servers and their services running on the platform. Administration Services - used to configure and manage the OMAG servers running inside the OMAG server platform. Open Metadata and Governance Services - used to work with metadata and govern the assets of an organization. Figure 1 shows the OMAG server platform when it first starts up. Figure 1: OMAG server platform at start up The server origin service is operational at this point. It can be used by operational scripts to determine if the OMAG server platform is still running. The administration services are active at this point, while the open metadata and governance services will return an error if called since there are no OMAG servers running. The configuration services are used to create configuration documents . Each configuration document describes the open metadata and governance services that should be activated in a OMAG server. Figure 2 shows the configuration services creating three configuration documents: * one for the cdoMetadataRepository OMAG server * one for the stewardshipServer OMAG Server * one for the dataLakeDiscoveryEngine OMAG Server Figure 2: Creating configuration documents for OMAG Servers The Administration Guide provides detailed instructions on creating configuration documents. Once a configuration document for an OMAG server is used by the operational services initialize the requested services in the OMAG server. The OMAG server can be started in any OMAG server platform. It does not have to be the same OMAG server platform that created the configuration document. Figure 3 shows an OMAG server platform with the cdoMetadataRepository local OMAG server running. Figure 3: Starting a OMAG Server through the operational services Once the OMAG server has initialized successfully, the open metadata and governance services can route requests to it. An OMAG server platform can run multiple OMAG servers at one time. Figure 4 shows an OMAG server platform running multiple servers. Figure 4: An OMAG server platform running multiple OMAG servers","title":"OMAG Server Platform"},{"location":"concepts/omag-server-platform/#omag-server-platform","text":"The OMAG Server Platform provides a runtime process and platform for four broad groups of services: Server origin service - used to determine the type and level of the OMAG Server Platform. Platform services - used to determine the servers and their services running on the platform. Administration services - used to configure and manage the OMAG Servers running inside the OMAG Server Platform. Open Metadata and Governance ( OMAG ) services - used to work with metadata and govern the assets of an organization. The OMAG services are configured and activated in OMAG Servers using the administration services . The configuration operations of the admin services create configuration documents , one for each OMAG Server. Inside a configuration document is the definition of which OMAG services to activate in the server. These include the repository services (any type of server), the access services (for metadata access points and metadata servers), governance services (for governance servers) and view services (for view servers). Once a configuration document is defined, the OMAG Server can be started and stopped multiple times by the admin services server instance operations. The OMAG Server Platform also supports some platform services to query details of the servers running on the platform. The OMAG Server Platform can also host multiple OMAG Servers at any one time: The choices are as follows: A - Each OMAG Server has its own dedicated OMAG Server Platform - useful when only one server is needed in a deployment environment, or there is a desire to keep each server isolated in its own stack. B - Multiple OMAG Servers are hosted on the same OMAG Server Platform. The OMAG Server Platform routes inbound requests to the right server based on the server name specified in the request URL. The servers may all be of the same type (multi-tenant operation) or be a set of collaborating servers of different types consolidated onto the same platform. C - Multiple copies of same server instance running on different platforms to provide high availability and distribution of workload (horizontal scalability). Each OMAG Server is isolated within the server platform and so the OMAG Server platform can be used to support multi-tenant operation for a cloud service, or host a variety of different OMAG Servers needed at a particular location. Further reading Configuring the OMAG Server Platform Installing the OMAG Server Platform Tutorial Running the OMAG Server Platform Tutorial","title":"OMAG Server Platform"},{"location":"concepts/omag-server-platform/#inside-the-omag-server-platform","text":"The OMAG server platform provides the server environment for running open metadata and governance services. It hosts one or more OMAG servers . Each server is configured to support specific open metadata and governance services. Thus each server performance a specific role in an deployment landscape. The OMAG server platform is included in the Egeria Distribution TAR file which can be installed on your machine by following the Installing Egeria Tutorial . The OMAG server platform supports four broad groups of services: Server Origin Service - used to determine the type and level of the OMAG server platform. Platform Services - used to determine the servers and their services running on the platform. Administration Services - used to configure and manage the OMAG servers running inside the OMAG server platform. Open Metadata and Governance Services - used to work with metadata and govern the assets of an organization. Figure 1 shows the OMAG server platform when it first starts up. Figure 1: OMAG server platform at start up The server origin service is operational at this point. It can be used by operational scripts to determine if the OMAG server platform is still running. The administration services are active at this point, while the open metadata and governance services will return an error if called since there are no OMAG servers running. The configuration services are used to create configuration documents . Each configuration document describes the open metadata and governance services that should be activated in a OMAG server. Figure 2 shows the configuration services creating three configuration documents: * one for the cdoMetadataRepository OMAG server * one for the stewardshipServer OMAG Server * one for the dataLakeDiscoveryEngine OMAG Server Figure 2: Creating configuration documents for OMAG Servers The Administration Guide provides detailed instructions on creating configuration documents. Once a configuration document for an OMAG server is used by the operational services initialize the requested services in the OMAG server. The OMAG server can be started in any OMAG server platform. It does not have to be the same OMAG server platform that created the configuration document. Figure 3 shows an OMAG server platform with the cdoMetadataRepository local OMAG server running. Figure 3: Starting a OMAG Server through the operational services Once the OMAG server has initialized successfully, the open metadata and governance services can route requests to it. An OMAG server platform can run multiple OMAG servers at one time. Figure 4 shows an OMAG server platform running multiple servers. Figure 4: An OMAG server platform running multiple OMAG servers","title":"Inside the OMAG server platform"},{"location":"concepts/omag-server/","text":"Open Metadata and Governance ( OMAG ) Server \u00b6 An OMAG server is a software server that runs inside the OMAG Server Platform . It is therefore sometimes referred to as a \"logical\" server rather than a physical server that runs in its own process. It supports the integration of one or more technologies by hosting connectors that interact with that technology, or providing specialist APIs or event topics (both in and out). Because of the wide variety of technologies deployed in organizations today, each with very different capabilities and needs, the integration and exchange of metadata needs to be organized. This organization is managed through the Egeria frameworks and services supported by the OMAG Servers. There are different types of OMAG Server, each supporting specific technologies. The OMAG Server ensures this type of technology is integrated appropriately for its needs. The capabilities that are activated in an OMAG Server are defined in its configuration document . When the server is started, the operational services of the OMAG Server Platform reads the configuration document and activates the OMAG Server with the requested services. Platform URL root \u00b6 An OMAG server's platform URL root is the network address of the OMAG Server Platform where the OMAG Server is going to run. This is often the host name of the computer or container where the platform runs plus the port number allocated to the OMAG Server Platform. Its value is needed when creating clients or configuring services that will call the OMAG Server because it provides the root of the URL used to call the server's open metadata and governance REST calls, which have the following format in their URLs: {{platformURLRoot}}/servers/{{serverName}}/<operation-name-and-parameters> The platform URL root is the content of the URL prior to /servers/ . The default value an OMAG Server Platform is https://localhost:9443 . Server name \u00b6 Most APIs in Egeria require both a platform URL root and a server name. The server name is the name of an OMAG Server where the desired service is running. Types of OMAG Server \u00b6 The types of OMAG Server are shown in Figure 1. The hierarchy groups similar types of server together. Figure 1: Types of OMAG server Detailed explanation of diagram The way to understand the diagram is that the arrows should be read as IS A . For example, the repository proxy IS A cohort member and the cohort member IS A OMAG Server . This means that everything documented about a particular type of server is also true for all server types that point to it through the IS A arrow, all the way down the hierarchy. Object-oriented software engineers would know of this type of relationship as behavior inheritance. Cohort member - able to exchange metadata through an open metadata repository cohort Metadata access store - supports a metadata repository that can natively store open metadata types as well as specialized metadata APIs for different types of tools (these APIs are called access services ). Metadata access point - supports the access services like the metadata server but does not have a repository. All metadata it serves up and stores belongs to the metadata repositories in other members of the cohort. Repository proxy - acts as an open metadata translator for a third party metadata repository. It supports open metadata API calls and translates them to the proprietary APIs of the repository. It also translates events from the proprietary repository into open metadata events that flow over the cohort. Conformance test server - validates that a member of the cohort is conforming with the open metadata protocols. This server is typically only seen in development and test cohorts rather than production. View server - manages specialist services for user interfaces. Governance server - supports the use of metadata in the broader IT landscape. Engine host - provides a runtime for a specific type of governance engine . Integration daemon - manages the synchronization with third party technology that can not call the access services directly through the integration services . Data engine proxy - supports the capture of metadata from a data engine. This includes details of the processing of data that it is doing which is valuable when piecing together lineage. Open lineage server - Manages the collation of lineage information am maintains it in a format for reporting. This includes the state of the lineage at different points in time. Inter-connectivity \u00b6 The different types of OMAG Servers connect together as illustrated in Figure 2. There is an inner ring of cohort members communicating via the cohort. Each cohort member is sharing the metadata they receive with the governance servers and view servers that connect to it. The governance servers connect out to external tools, engines and platforms. Figure 2: The inter-connectivity between OMAG servers Further information The configuration for an OMAG Server is defined in a configuration document . This configuration document is stored by a configuration document store connector . Configuring an OMAG Server Start and stop an OMAG Server","title":"OMAG Server"},{"location":"concepts/omag-server/#open-metadata-and-governance-omag-server","text":"An OMAG server is a software server that runs inside the OMAG Server Platform . It is therefore sometimes referred to as a \"logical\" server rather than a physical server that runs in its own process. It supports the integration of one or more technologies by hosting connectors that interact with that technology, or providing specialist APIs or event topics (both in and out). Because of the wide variety of technologies deployed in organizations today, each with very different capabilities and needs, the integration and exchange of metadata needs to be organized. This organization is managed through the Egeria frameworks and services supported by the OMAG Servers. There are different types of OMAG Server, each supporting specific technologies. The OMAG Server ensures this type of technology is integrated appropriately for its needs. The capabilities that are activated in an OMAG Server are defined in its configuration document . When the server is started, the operational services of the OMAG Server Platform reads the configuration document and activates the OMAG Server with the requested services.","title":"Open Metadata and Governance (OMAG) Server"},{"location":"concepts/omag-server/#platform-url-root","text":"An OMAG server's platform URL root is the network address of the OMAG Server Platform where the OMAG Server is going to run. This is often the host name of the computer or container where the platform runs plus the port number allocated to the OMAG Server Platform. Its value is needed when creating clients or configuring services that will call the OMAG Server because it provides the root of the URL used to call the server's open metadata and governance REST calls, which have the following format in their URLs: {{platformURLRoot}}/servers/{{serverName}}/<operation-name-and-parameters> The platform URL root is the content of the URL prior to /servers/ . The default value an OMAG Server Platform is https://localhost:9443 .","title":"Platform URL root"},{"location":"concepts/omag-server/#server-name","text":"Most APIs in Egeria require both a platform URL root and a server name. The server name is the name of an OMAG Server where the desired service is running.","title":"Server name"},{"location":"concepts/omag-server/#types-of-omag-server","text":"The types of OMAG Server are shown in Figure 1. The hierarchy groups similar types of server together. Figure 1: Types of OMAG server Detailed explanation of diagram The way to understand the diagram is that the arrows should be read as IS A . For example, the repository proxy IS A cohort member and the cohort member IS A OMAG Server . This means that everything documented about a particular type of server is also true for all server types that point to it through the IS A arrow, all the way down the hierarchy. Object-oriented software engineers would know of this type of relationship as behavior inheritance. Cohort member - able to exchange metadata through an open metadata repository cohort Metadata access store - supports a metadata repository that can natively store open metadata types as well as specialized metadata APIs for different types of tools (these APIs are called access services ). Metadata access point - supports the access services like the metadata server but does not have a repository. All metadata it serves up and stores belongs to the metadata repositories in other members of the cohort. Repository proxy - acts as an open metadata translator for a third party metadata repository. It supports open metadata API calls and translates them to the proprietary APIs of the repository. It also translates events from the proprietary repository into open metadata events that flow over the cohort. Conformance test server - validates that a member of the cohort is conforming with the open metadata protocols. This server is typically only seen in development and test cohorts rather than production. View server - manages specialist services for user interfaces. Governance server - supports the use of metadata in the broader IT landscape. Engine host - provides a runtime for a specific type of governance engine . Integration daemon - manages the synchronization with third party technology that can not call the access services directly through the integration services . Data engine proxy - supports the capture of metadata from a data engine. This includes details of the processing of data that it is doing which is valuable when piecing together lineage. Open lineage server - Manages the collation of lineage information am maintains it in a format for reporting. This includes the state of the lineage at different points in time.","title":"Types of OMAG Server"},{"location":"concepts/omag-server/#inter-connectivity","text":"The different types of OMAG Servers connect together as illustrated in Figure 2. There is an inner ring of cohort members communicating via the cohort. Each cohort member is sharing the metadata they receive with the governance servers and view servers that connect to it. The governance servers connect out to external tools, engines and platforms. Figure 2: The inter-connectivity between OMAG servers Further information The configuration for an OMAG Server is defined in a configuration document . This configuration document is stored by a configuration document store connector . Configuring an OMAG Server Start and stop an OMAG Server","title":"Inter-connectivity"},{"location":"concepts/omag-subsystem/","text":"Open Metadata and Governance ( OMAG ) Subsystems \u00b6 A subsystem is a collection of components within a software server that supports one or more related services. Subsystems can be organized in a hierarchy where course-grained subsystems can be decomposed into more fine-grained subsystems. The OMAG Server is a flexible software server whose subsystems can be activated (or not) through the presence (or absence) of the subsystem's configuration properties in the OMAG Server's configuration document . The potential subsystems within an OMAG Server are as follows: Open Metadata Repository Services ( OMRS ) for supporting access to metadata stored in metadata repositories and the exchange of metadata between repositories via an open metadata repository cohort . The repository services are further divided into OMRS subsystems that can be activated independently. Integration daemon services for running integration connectors that exchange metadata with third party technologies. Connected Asset Services for supporting the ConnectedAsset interface of a connector. Dynamically registered services provide specialist APIs for particular technologies and user roles. Each of these services runs in their own subsystem independent of the other registered services. The implementation may come from Egeria or a third party. The links are to Egeria provided dynamic services. Open Metadata Access Services ( OMAS ) for supporting domain-specific services for metadata access and governance. Access services run in the metadata server and metadata access point server. Open Metadata Engine Services ( OMES ) for supporting specialized governance engines that drive governance activity in the open metadata ecosystem. The engine services run in the engine host server. Open Metadata Integration Services ( OMIS ) for supporting specific types of integration connectors . The integration services run in the integration daemon server. Open Metadata View Services ( OMVS ) for supporting REST services for a User Interface (UI). The view services run in a view server .","title":"OMAG Subsystem"},{"location":"concepts/omag-subsystem/#open-metadata-and-governance-omag-subsystems","text":"A subsystem is a collection of components within a software server that supports one or more related services. Subsystems can be organized in a hierarchy where course-grained subsystems can be decomposed into more fine-grained subsystems. The OMAG Server is a flexible software server whose subsystems can be activated (or not) through the presence (or absence) of the subsystem's configuration properties in the OMAG Server's configuration document . The potential subsystems within an OMAG Server are as follows: Open Metadata Repository Services ( OMRS ) for supporting access to metadata stored in metadata repositories and the exchange of metadata between repositories via an open metadata repository cohort . The repository services are further divided into OMRS subsystems that can be activated independently. Integration daemon services for running integration connectors that exchange metadata with third party technologies. Connected Asset Services for supporting the ConnectedAsset interface of a connector. Dynamically registered services provide specialist APIs for particular technologies and user roles. Each of these services runs in their own subsystem independent of the other registered services. The implementation may come from Egeria or a third party. The links are to Egeria provided dynamic services. Open Metadata Access Services ( OMAS ) for supporting domain-specific services for metadata access and governance. Access services run in the metadata server and metadata access point server. Open Metadata Engine Services ( OMES ) for supporting specialized governance engines that drive governance activity in the open metadata ecosystem. The engine services run in the engine host server. Open Metadata Integration Services ( OMIS ) for supporting specific types of integration connectors . The integration services run in the integration daemon server. Open Metadata View Services ( OMVS ) for supporting REST services for a User Interface (UI). The view services run in a view server .","title":"Open Metadata and Governance (OMAG) Subsystems"},{"location":"concepts/open-discovery-service/","text":"Open Discovery Service \u00b6 An open discovery service is a component that performs analysis of the contents of a specific resource and adds the results to a discovery analysis report linked off of the resources's Asset on request. It is implemented as a specialized Open Connector Framework ( OCF ) connector. The interface and base class are provided by the Open Discovery Framework ( ODF ) . A discovery service is initialized with a connector to the Asset it is to analyze and details of the results of other discovery services that have run before it if it is part of a discovery pipeline . Discovery Pipeline \u00b6 A discovery pipeline is a specialized implementation of an open discovery service that runs a set of discovery services against a single asset. The implementation of the discovery pipeline determines the order that these discovery services are run. The aim of the discovery pipeline is to enable a detailed picture of the properties of an asset to be built up by the discovery services it calls. Each discovery service is able to access the results of the discovery services that have run before it.","title":"Open discovery service"},{"location":"concepts/open-discovery-service/#open-discovery-service","text":"An open discovery service is a component that performs analysis of the contents of a specific resource and adds the results to a discovery analysis report linked off of the resources's Asset on request. It is implemented as a specialized Open Connector Framework ( OCF ) connector. The interface and base class are provided by the Open Discovery Framework ( ODF ) . A discovery service is initialized with a connector to the Asset it is to analyze and details of the results of other discovery services that have run before it if it is part of a discovery pipeline .","title":"Open Discovery Service"},{"location":"concepts/open-discovery-service/#discovery-pipeline","text":"A discovery pipeline is a specialized implementation of an open discovery service that runs a set of discovery services against a single asset. The implementation of the discovery pipeline determines the order that these discovery services are run. The aim of the discovery pipeline is to enable a detailed picture of the properties of an asset to be built up by the discovery services it calls. Each discovery service is able to access the results of the discovery services that have run before it.","title":"Discovery Pipeline"},{"location":"concepts/open-lineage-server/","text":"Open lineage server \u00b6 The open lineage server is a governance server that manages a historical warehouse of lineage information. Its behavior and configuration is described here .","title":"Open Lineage Server"},{"location":"concepts/open-lineage-server/#open-lineage-server","text":"The open lineage server is a governance server that manages a historical warehouse of lineage information. Its behavior and configuration is described here .","title":"Open lineage server"},{"location":"concepts/open-metadata-archive/","text":"Open Metadata Archive \u00b6 An open metadata archive is a document containing open metadata type definitions and instances . The open metadata archive has two types: A content pack containing reusable definitions that are generally useful. They may come from the Egeria community or third parties. A metadata export containing an export of metadata from a repository. They are used to transfer metadata between repositories that are not connected to the same cohort . Structure \u00b6 The logical structure of an open metadata archive is as follows: Instances are linked together as follows: Entities are stored as EntityDetail structures. Relationships are stored as Relationship structures and link to their entities through the embedded EntityProxy structure. The entities will include their classifications; however, for classifications that are attached to entities that are not included in the archive, they are stored in an ClassificationEntityExtension structure. Typically, open metadata archives are encoded in JSON format and stored in a file; however, both the format and storage method can be changed by changing the open metadata archive connector . Example of the header from the Cloud Information Model archive { \"class\" : \"OpenMetadataArchive\" , \"archiveProperties\" : { \"class\" : \"OpenMetadataArchiveProperties\" , \"archiveGUID\" : \"9dc75637-92a7-4926-b47b-a3d407546f89\" , \"archiveName\" : \"Cloud Information Model (CIM) glossary and concept model\" , \"archiveDescription\" : \"Data types for commerce focused cloud applications.\" , \"archiveType\" : \"CONTENT_PACK\" , \"originatorName\" : \"The Cloud Information Model\" , \"originatorLicense\" : \"Apache 2.0\" , \"creationDate\" : 1570383385107 , \"dependsOnArchives\" :[ \"bce3b0a0-662a-4f87-b8dc-844078a11a6e\" ] }, \"archiveTypeStore\" :{}, \"archiveInstanceStore\" :{} } Processing \u00b6 Open metadata archives are introduced into the server through the admin services either: provided as part of the contents of the server's configuration document, or through the operational command that added the archive directly into the running server's repository. The archive is passed to the repository services' operational services, which in turn passes it on to the archive manager . Type information is passed to the repository content manager . Both the types and instances are passed to the local repository (if there is one). The archive loads in the following order: Attribute Type Definitions ( AttributeTypeDef s) from the type store, through verifyAttributeTypeDef() and then addAttributeTypeDef() : PrimitiveDefs CollectionDefs EnumDefs New Type Definitions ( TypeDef s) from the type store, through verifyTypeDef() and addTypeDef() : EntityDefs RelationshipDefs ClassificationDefs Updates to types ( TypeDefPatch es) Instances, as reference copies: Entities Relationships Classifications Cohort propagation If the server is connected to the cohort, the new content is sent as notifications to the rest of the cohort. Further information More information about open metadata archives can be found in the open-metadata-archives module. In addition, these articles may be of interest: Configuring an open metadata archive in an OMAG Server Adding an open metadata archive to a running OMAG Server","title":"Open Metadata Archive"},{"location":"concepts/open-metadata-archive/#open-metadata-archive","text":"An open metadata archive is a document containing open metadata type definitions and instances . The open metadata archive has two types: A content pack containing reusable definitions that are generally useful. They may come from the Egeria community or third parties. A metadata export containing an export of metadata from a repository. They are used to transfer metadata between repositories that are not connected to the same cohort .","title":"Open Metadata Archive"},{"location":"concepts/open-metadata-archive/#structure","text":"The logical structure of an open metadata archive is as follows: Instances are linked together as follows: Entities are stored as EntityDetail structures. Relationships are stored as Relationship structures and link to their entities through the embedded EntityProxy structure. The entities will include their classifications; however, for classifications that are attached to entities that are not included in the archive, they are stored in an ClassificationEntityExtension structure. Typically, open metadata archives are encoded in JSON format and stored in a file; however, both the format and storage method can be changed by changing the open metadata archive connector . Example of the header from the Cloud Information Model archive { \"class\" : \"OpenMetadataArchive\" , \"archiveProperties\" : { \"class\" : \"OpenMetadataArchiveProperties\" , \"archiveGUID\" : \"9dc75637-92a7-4926-b47b-a3d407546f89\" , \"archiveName\" : \"Cloud Information Model (CIM) glossary and concept model\" , \"archiveDescription\" : \"Data types for commerce focused cloud applications.\" , \"archiveType\" : \"CONTENT_PACK\" , \"originatorName\" : \"The Cloud Information Model\" , \"originatorLicense\" : \"Apache 2.0\" , \"creationDate\" : 1570383385107 , \"dependsOnArchives\" :[ \"bce3b0a0-662a-4f87-b8dc-844078a11a6e\" ] }, \"archiveTypeStore\" :{}, \"archiveInstanceStore\" :{} }","title":"Structure"},{"location":"concepts/open-metadata-archive/#processing","text":"Open metadata archives are introduced into the server through the admin services either: provided as part of the contents of the server's configuration document, or through the operational command that added the archive directly into the running server's repository. The archive is passed to the repository services' operational services, which in turn passes it on to the archive manager . Type information is passed to the repository content manager . Both the types and instances are passed to the local repository (if there is one). The archive loads in the following order: Attribute Type Definitions ( AttributeTypeDef s) from the type store, through verifyAttributeTypeDef() and then addAttributeTypeDef() : PrimitiveDefs CollectionDefs EnumDefs New Type Definitions ( TypeDef s) from the type store, through verifyTypeDef() and addTypeDef() : EntityDefs RelationshipDefs ClassificationDefs Updates to types ( TypeDefPatch es) Instances, as reference copies: Entities Relationships Classifications Cohort propagation If the server is connected to the cohort, the new content is sent as notifications to the rest of the cohort. Further information More information about open metadata archives can be found in the open-metadata-archives module. In addition, these articles may be of interest: Configuring an open metadata archive in an OMAG Server Adding an open metadata archive to a running OMAG Server","title":"Processing"},{"location":"concepts/open-metadata-exchange-rule/","text":"Open Metadata Exchange Rule \u00b6 The open metadata exchange rule can be used to limit the exchange of metadata in a cohort. There are three rules that are configured in each cohort members : EventsToSend Rule : controls the events that should be sent to the cohort by the cohort member. EventsToProcess Rule : controls which incoming events are received by the cohort member from the other members of the cohort. Instance events are passed to the: Open Metadata Access Services (OMASs) running in the cohort member. the local repository (if any) where the EventsToSave Rule is run. EventsToSave Rule : controls which of the inbound events received from the cohort and passed by the EventsToProcess Rule should be saved to the local repository. Rule values \u00b6 The open metadata exchange rule can be set to one of the following values: REGISTRATION_ONLY - Only registration exchange; no TypeDefs or metadata instances JUST_TYPEDEFS - Only registration and type definitions (TypeDefs) exchange SELECTED_TYPES - Registration plus all type definitions (TypeDefs) and metadata instances (Entities and Relationships) of selected types. LEARNED_TYPES - Registration plus all type definitions (TypeDefs) and metadata instances (Entities and Relationships) of types requested by local users to this server. DESELECTED_TYPES - Registration plus all type definitions (TypeDefs) and metadata instances (Entities and Relationships) NOT listed in selected types. ALL - Registration plus all type definitions (TypeDefs) and metadata instances (Entities and Relationships). This is the default setting for all of the rules. These settings are fairly course-grained. If you need to control the flow of instance events at a more granular level then the open metadata security connectors provide control at the individual","title":"Open metadata exchange rule"},{"location":"concepts/open-metadata-exchange-rule/#open-metadata-exchange-rule","text":"The open metadata exchange rule can be used to limit the exchange of metadata in a cohort. There are three rules that are configured in each cohort members : EventsToSend Rule : controls the events that should be sent to the cohort by the cohort member. EventsToProcess Rule : controls which incoming events are received by the cohort member from the other members of the cohort. Instance events are passed to the: Open Metadata Access Services (OMASs) running in the cohort member. the local repository (if any) where the EventsToSave Rule is run. EventsToSave Rule : controls which of the inbound events received from the cohort and passed by the EventsToProcess Rule should be saved to the local repository.","title":"Open Metadata Exchange Rule"},{"location":"concepts/open-metadata-exchange-rule/#rule-values","text":"The open metadata exchange rule can be set to one of the following values: REGISTRATION_ONLY - Only registration exchange; no TypeDefs or metadata instances JUST_TYPEDEFS - Only registration and type definitions (TypeDefs) exchange SELECTED_TYPES - Registration plus all type definitions (TypeDefs) and metadata instances (Entities and Relationships) of selected types. LEARNED_TYPES - Registration plus all type definitions (TypeDefs) and metadata instances (Entities and Relationships) of types requested by local users to this server. DESELECTED_TYPES - Registration plus all type definitions (TypeDefs) and metadata instances (Entities and Relationships) NOT listed in selected types. ALL - Registration plus all type definitions (TypeDefs) and metadata instances (Entities and Relationships). This is the default setting for all of the rules. These settings are fairly course-grained. If you need to control the flow of instance events at a more granular level then the open metadata security connectors provide control at the individual","title":"Rule values"},{"location":"concepts/out-topic/","text":"OMAS OutTopic \u00b6 The OutTopic of an Open Metadata Access Service is the location where the OMAS will sent outgoing events to its consumers.","title":"Out Topic"},{"location":"concepts/out-topic/#omas-outtopic","text":"The OutTopic of an Open Metadata Access Service is the location where the OMAS will sent outgoing events to its consumers.","title":"OMAS OutTopic"},{"location":"concepts/peer-network/","text":"Peer Network \u00b6 An individual can maintain a list of their close/important colleagues. This is called their peer network and it is chained off of their personal profile . It is important to note that the perspective on who is a close/important colleague is a personal perspective. Therefore Community Profile OMAS separates the concept of who has linked to them from who they have linked to.","title":"Peer Network"},{"location":"concepts/peer-network/#peer-network","text":"An individual can maintain a list of their close/important colleagues. This is called their peer network and it is chained off of their personal profile . It is important to note that the perspective on who is a close/important colleague is a personal perspective. Therefore Community Profile OMAS separates the concept of who has linked to them from who they have linked to.","title":"Peer Network"},{"location":"concepts/personal-message/","text":"Personal Message \u00b6 A personal message is a message that is attached to a personal profile, or as a reply to another personal message. If is possible to add tags and likes to a personal message.","title":"Personal Messsge"},{"location":"concepts/personal-message/#personal-message","text":"A personal message is a message that is attached to a personal profile, or as a reply to another personal message. If is possible to add tags and likes to a personal message.","title":"Personal Message"},{"location":"concepts/personal-notes/","text":"Personal notes \u00b6","title":"Personal Notes"},{"location":"concepts/personal-notes/#personal-notes","text":"","title":"Personal notes"},{"location":"concepts/personal-profile/","text":"Personal Profile \u00b6 A personal profile provides a place for an individual to share information about themselves with the other people they are collaborating with. It is associated with one or more of the person's userIds. Each userId is linked to the profile as a UserIdentity object. There can be more than one userId for a profile (for example if a user has an administrator userId and a normal userId) However, the same userId can not be linked to two profiles. This means we can retrieve a profile from the UserId. Each profile has a qualified name that should uniquely identify the individual. For example, an employee identifier. There is space to provide the name the individual wants to be known as, and their full name, along with a job title. An individual can also maintain collections of their favourite Assets, Projects and Communities and control notifications about changes to the member of these lists. Working with personal profiles \u00b6 Retrieving my personal profile Creating my personal profile Updating my personal profile Removing my personal profile Retrieving a personal profile for another user Loading personal profiles of existing members of an organization Synchronizing updates to personal profiles from another system","title":"Personal Profile"},{"location":"concepts/personal-profile/#personal-profile","text":"A personal profile provides a place for an individual to share information about themselves with the other people they are collaborating with. It is associated with one or more of the person's userIds. Each userId is linked to the profile as a UserIdentity object. There can be more than one userId for a profile (for example if a user has an administrator userId and a normal userId) However, the same userId can not be linked to two profiles. This means we can retrieve a profile from the UserId. Each profile has a qualified name that should uniquely identify the individual. For example, an employee identifier. There is space to provide the name the individual wants to be known as, and their full name, along with a job title. An individual can also maintain collections of their favourite Assets, Projects and Communities and control notifications about changes to the member of these lists.","title":"Personal Profile"},{"location":"concepts/personal-profile/#working-with-personal-profiles","text":"Retrieving my personal profile Creating my personal profile Updating my personal profile Removing my personal profile Retrieving a personal profile for another user Loading personal profiles of existing members of an organization Synchronizing updates to personal profiles from another system","title":"Working with personal profiles"},{"location":"concepts/personal-roles/","text":"Personal roles \u00b6 Personal roles are the list of person roles that an individual is currently appointed to. Community Member , Team Leader and Team Member are examples of personal roles.","title":"Personal Roles"},{"location":"concepts/personal-roles/#personal-roles","text":"Personal roles are the list of person roles that an individual is currently appointed to. Community Member , Team Leader and Team Member are examples of personal roles.","title":"Personal roles"},{"location":"concepts/presentation-server/","text":"Presentation server \u00b6 The presentation server hosts the JavaScript applications that provide an interactive browser-based user interface for Egeria. The JavaScript applications call REST API services running in a view server to retrieve information and perform operations relating to open metadata. The presentation server supports multi-tenant operation. Each presentation server tenant is designed to support an organization. These may be independent organizations or divisions/departments within an organization. The tenant is configured with the appropriate view server to use, which in turn routes requests to its governance servers and metadata servers . Therefore, each tenant sees a different collection of metadata and operates in isolation to the other tenants. Further information The setup and user guide for the presentation server is held in a separate repository.","title":"Presentation Server"},{"location":"concepts/presentation-server/#presentation-server","text":"The presentation server hosts the JavaScript applications that provide an interactive browser-based user interface for Egeria. The JavaScript applications call REST API services running in a view server to retrieve information and perform operations relating to open metadata. The presentation server supports multi-tenant operation. Each presentation server tenant is designed to support an organization. These may be independent organizations or divisions/departments within an organization. The tenant is configured with the appropriate view server to use, which in turn routes requests to its governance servers and metadata servers . Therefore, each tenant sees a different collection of metadata and operates in isolation to the other tenants. Further information The setup and user guide for the presentation server is held in a separate repository.","title":"Presentation server"},{"location":"concepts/referenceable/","text":"Referenceable \u00b6 A referenceable is the description of a resource that is significant enough to need its own unique name so that it can be referred to accurately in different contexts (typically outside of open metadata). The unique name is stored in the qualified name ( qualifiedName ) property and the open metadata servers validate that this value is unique within its type. It is possible that two different metadata elements with the same qualified name could be created in different metadata servers. This may be because both servers have loaded metadata about the same object. Alternatively, there is a name clash as two servers have used the same unique name for two different objects.","title":"Referenceable"},{"location":"concepts/referenceable/#referenceable","text":"A referenceable is the description of a resource that is significant enough to need its own unique name so that it can be referred to accurately in different contexts (typically outside of open metadata). The unique name is stored in the qualified name ( qualifiedName ) property and the open metadata servers validate that this value is unique within its type. It is possible that two different metadata elements with the same qualified name could be created in different metadata servers. This may be because both servers have loaded metadata about the same object. Alternatively, there is a name clash as two servers have used the same unique name for two different objects.","title":"Referenceable"},{"location":"concepts/repository-helper/","text":"Repository helper \u00b6 The repository helper provides methods to simplify the actions of creating and manipulating the repository services property objects.","title":"Repository Helper"},{"location":"concepts/repository-helper/#repository-helper","text":"The repository helper provides methods to simplify the actions of creating and manipulating the repository services property objects.","title":"Repository helper"},{"location":"concepts/repository-proxy/","text":"Repository Proxy \u00b6 A repository proxy is an OMAG Server that has been configured to act as a proxy to a third party metadata repository. It is used by a technology that is integrating using the adapter integration pattern . There are two repository proxy implementations included with Egeria Repository proxy for Apache Atlas Repository proxy for IBM Information Governance Catalog ( IGC )","title":"Repository Proxy"},{"location":"concepts/repository-proxy/#repository-proxy","text":"A repository proxy is an OMAG Server that has been configured to act as a proxy to a third party metadata repository. It is used by a technology that is integrating using the adapter integration pattern . There are two repository proxy implementations included with Egeria Repository proxy for Apache Atlas Repository proxy for IBM Information Governance Catalog ( IGC )","title":"Repository Proxy"},{"location":"concepts/repository-validator/","text":"Repository validator \u00b6 The repository validator provides common validation functions for use when working with repository services property objects.","title":"Repository Validator"},{"location":"concepts/repository-validator/#repository-validator","text":"The repository validator provides common validation functions for use when working with repository services property objects.","title":"Repository validator"},{"location":"concepts/review/","text":"Reviews \u00b6 A review is an attachment that can be made to a personal note or forum contribution. It includes a star rating and an optional review comment. Reviews are used to provide feedback on ideas that are proposed in personal notes and forums.","title":"Star Rating"},{"location":"concepts/review/#reviews","text":"A review is an attachment that can be made to a personal note or forum contribution. It includes a star rating and an optional review comment. Reviews are used to provide feedback on ideas that are proposed in personal notes and forums.","title":"Reviews"},{"location":"concepts/to-do/","text":"To Dos \u00b6 A to do is a record of an action. It includes details of the action to perform and the time frame it needs to be completed for. To dos are normally created as a result of a meeting, or a process, such as a discovery process . The requested action may be ad hoc in nature, or part of a stewardship process that identified a specific action for an individual, or group of individuals. The creator of a to do is called the originator . The person, or people assigned to complete the task are called the assigned resources . Assigned to dos are attached to one of their roles rather than directly to their personal profile . Each to do has a priority and a status: * Open - no work has started. * In Progress - work is ongoing. * Waiting - work is on hold, typically blocked. * Complete - Work is completed. * Abandoned - No work will happen. Working with to dos \u00b6 Below are the descriptions of how to use the Community Profile OMAS to work with to dos. Accessing my to dos Creating a to do Managing a to do Design information \u00b6 ToDo Bean Open Metadata Type","title":"To Do"},{"location":"concepts/to-do/#to-dos","text":"A to do is a record of an action. It includes details of the action to perform and the time frame it needs to be completed for. To dos are normally created as a result of a meeting, or a process, such as a discovery process . The requested action may be ad hoc in nature, or part of a stewardship process that identified a specific action for an individual, or group of individuals. The creator of a to do is called the originator . The person, or people assigned to complete the task are called the assigned resources . Assigned to dos are attached to one of their roles rather than directly to their personal profile . Each to do has a priority and a status: * Open - no work has started. * In Progress - work is ongoing. * Waiting - work is on hold, typically blocked. * Complete - Work is completed. * Abandoned - No work will happen.","title":"To Dos"},{"location":"concepts/to-do/#working-with-to-dos","text":"Below are the descriptions of how to use the Community Profile OMAS to work with to dos. Accessing my to dos Creating a to do Managing a to do","title":"Working with to dos"},{"location":"concepts/to-do/#design-information","text":"ToDo Bean Open Metadata Type","title":"Design information"},{"location":"concepts/useful-resource/","text":"Useful Resources \u00b6 A resource is definition that is used frequently and so it is helpful to have a link to it. Examples of resources include glossaries, or categories and terms from a glossary, governance definitions, models, system definitions or process definitions. It is possible to maintain a list of useful resources for a personal profile , a team or a community . Working with resources and resource lists \u00b6 Finding a resource","title":"Useful Resource"},{"location":"concepts/useful-resource/#useful-resources","text":"A resource is definition that is used frequently and so it is helpful to have a link to it. Examples of resources include glossaries, or categories and terms from a glossary, governance definitions, models, system definitions or process definitions. It is possible to maintain a list of useful resources for a personal profile , a team or a community .","title":"Useful Resources"},{"location":"concepts/useful-resource/#working-with-resources-and-resource-lists","text":"Finding a resource","title":"Working with resources and resource lists"},{"location":"concepts/user-identity/","text":"User identity \u00b6 The user identity is the unique name of a user's logon account.","title":"User Identity"},{"location":"concepts/user-identity/#user-identity","text":"The user identity is the unique name of a user's logon account.","title":"User identity"},{"location":"concepts/view-server/","text":"View Server \u00b6 A view server is an OMAG Server that hosts the REST API services to support a UI. These REST API services are called Open Metadata View Services ( OMVS ) and they are designed to support specific display paradigms needed by different types of UIs. The view services are typically called by the presentation server , but may also be used by third parties. The presentation server hosts the JavaScript that controls the browser display.","title":"View Server"},{"location":"concepts/view-server/#view-server","text":"A view server is an OMAG Server that hosts the REST API services to support a UI. These REST API services are called Open Metadata View Services ( OMVS ) and they are designed to support specific display paradigms needed by different types of UIs. The view services are typically called by the presentation server , but may also be used by third parties. The presentation server hosts the JavaScript that controls the browser display.","title":"View Server"},{"location":"connectors/","text":"Connector catalog \u00b6 Egeria has a growing collection of connectors to third party technologies. These connectors help to accelerate the rollout of your open metadata ecosystem since they can be used to automate the extraction and distribution of metadata to the third party technologies. A connector is a client to a third party technology. It supports a standard API that Egeria calls and it then translates these calls into requests to the third party technology. Some connectors are also able to listen for notifications from the third party technology. When a notification is received, the connector converts its content into a call to Egeria to distribute the information to the open metadata ecosystem. Connectors enable Egeria to operate in many environments and with many types of third party technologies, just by managing the configuration of the OMAG servers. The Connector Catalog list the connector implementations supplied by the Egeria community. There are three broad categories of connectors and the connector catalog is organized accordingly: Connectors that support the exchange and maintenance of metadata . This includes the integration connectors, repository connectors, discovery services and governance action services. Connectors that support Egeria\u2019s runtime . This includes the event bus connectors, cohort registry stores, configuration stores, audit log destination connectors, open metadata archive stores, REST client connectors and the cohort member remote repository connectors Connectors that provide access to digital resources and their metadata that is stored in the open metadata ecosystem. Metadata exchange and maintenance connectors \u00b6 The connectors that support the exchange and maintenance of metadata help to accelerate the rollout of your open metadata ecosystem since they can be used to automate the extraction and distribution of metadata to the third party technologies. Type Description Integration connectors manage the metadata exchange to a third party technology through an integration service . Repository and Event Mapper connectors integrate metadata repositories through one or more open metadata repository cohorts . Open Discovery Services analyze the content of resources in the digital landscape and create annotations that are attached to the resource's asset metadata element in the open metadata repositories in the form of an open discovery report Governance Action Services perform monitoring of metadata changes, validation of metadata, triage of issues, assessment and/or remediation activities as required. Integration Connectors \u00b6 The integration connectors support the exchange of metadata with third party technologies. This exchange may be inbound, outbound, synchronous, polling or event-driven. Figure 1: Integration Connectors Details of how integration connectors work is described in the developer guide . Files \u00b6 The files integration connectors run in the Files Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon . Connector Description Data files monitor maintains a DataFile asset for each file in the directory (or any subdirectory). When a new file is created, a new DataFile asset is created. If a file is modified, the lastModified property of the corresponding DataFile asset is updated. When a file is deleted, its corresponding DataFile asset is also deleted (or archived if it is still needed for lineage). Data folder monitor maintains a DataFolder asset for the directory. The files and directories underneath it are assumed to be elements/records in the DataFolder asset and so each time there is a change to the files and directories under the monitored directory, it results in an update to the lastModified property of the corresponding DataFolder asset. Databases \u00b6 The database integration connectors run in the Database Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon . Connector Description PostgreSQL database connector automatically maintains the open metadata instances for the databases hosted on a PostgreSQL server This includes the database schemas, tables, columns, primary keys and foreign keys. Topics \u00b6 The topic integration connectors run in the Topic Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon . Connector Description Kafka Monitor topic integration connector automatically maintains the open metadata instances for the topics hosted on an Apache Kafka server . APIs \u00b6 The API integration connectors run in the API Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon . Connector Description Open API Monitor integration connector automatically maintains the open metadata instances for the APIs extracted from the Open API Specification extracted from an application. Security Enforcement Engines \u00b6 TThe security integration connectors run in the Security Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon . Repository and Event Mapper Connectors \u00b6 The repository connectors provide the ability to integrate a third party metadata repository into an open metadata repository cohort . Figure 2 shows the repository connector providing a native open metadata repository that uses a particular type of store within an Egeria Metadata Access Server . Figure 2: Repository connector supporting a native open metadata repository Connector Description JanusGraph OMRS Repository Connector provides a native repository for a metadata server using JanusGraph as the backend. XTDB OMRS Repository Connector provides a native repository for a metadata server that supports historical queries, using XTDB as the backend. In-memory OMRS Repository Connector provides a simple native repository implementation that \"stores\" metadata in HashMaps within the JVM ; it is used for testing, or for environments where metadata maintained in other repositories needs to be cached locally for performance/scalability reasons. Read-only OMRS Repository Connector provides a native repository implementation that does not support the interfaces for create, update, delete; however, it does support the search interfaces and is able to cache metadata -- this means it can be loaded with open metadata archives to provide standard metadata definitions. Figure 3 shows the repository connector providing a native open metadata repository that uses a particular type of store within an Egeria Metadata Access Server . Figure 3: Repository connector and optional event mapper supporting an adapter to a third party metadata catalog Connector Description Apache Atlas OMRS Repository Connector implements read-only connectivity to the Apache Atlas metadata repository IBM Information Governance Catalog ( IGC ) OMRS Repository Connector implements read-only connectivity to the metadata repository within the IBM InfoSphere Information Server suite SAS Viya OMRS Repository Connector implements metadata exchange to the metadata repository within the SAS Viya Platform The repository connectors implement the OMRSMetadataCollection interface to allow metadata to be communicated and exchanged according to Egeria's protocols and type definitions . Open Discovery Services \u00b6 Open discovery services are connectors that analyze the content of resources in the digital landscape and create annotations that are attached to the resource's Asset metadata element in the open metadata repositories in the form of an open discovery report. Figure 4: Discovery Services The definition of the connector interfaces for discovery services is defined in the open-discovery-services module. Connector Description CSV Discovery Service extracts the column names from the first line of the file, counts up the number of records in the file and extracts its last modified time. Sequential Discovery Pipeline runs nested discovery services in a sequence ( more information on discovery pipelines ). Governance Action Services \u00b6 Governance action services are connectors that perform monitoring of metadata changes, validation of metadata, triage of issues, assessment and/or remediation activities on request. Figure 5: Governance Action Services They run in the Governance Action Open Metadata Engine Service ( OMES ) hosted by the Engine Host OMAG Server . Connector Description Generic Element Watchdog Governance Action Service listens for changing metadata elements and initiates governance action processes when certain events occur. Generic Folder Watchdog Governance Action Service listens for changing assets linked to a DataFolder element and initiates governance actions when specific events occur. This may be for files directly linked to the folder or located in sub-folders. Move/Copy File Provisioning Governance Action Service moves or copies files from one location to another and maintains the lineage of the action. Origin Seeker Remediation Governance Action Service walks backwards through the lineage mappings to discover the origin of the data The definition of the connector interfaces for governance action services is defined in the governance-action-framework module. Runtime connectors \u00b6 Runtime connectors support Egeria's runtime: Connectors enable Egeria to operate in many environments by providing plug-in points for the runtime services it needs to operate. Most of these connectors relate to persistent storage, or connections to distributed services. Open Metadata Topic Connectors \u00b6 The Open Metadata Topic Connectors are used by Egeria to read and write events to a topic managed by an event broker . These events contain notifications relating to changes in metadata and the topic provides an asynchronous event exchange service hosted in the event broker. Figure 6: Open Metadata Topic Connectors The Open Metadata Topic Connectors connect servers into an open metadata repository cohort and exchange notifications through the Open Metadata Access Services ( OMAS )'s topics called the InTopic and OutTopic . Egeria provides a single implementation of an open metadata connector for Apache Kafka that it uses by default. The Kafka Open Metadata Topic Connector implements an Apache Kafka connector for a topic that exchanges Java Objects as JSON payloads. The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.openmetadatatopic Java package. It is configured in the Egeria OMAG Servers through the Event Bus Configuration . Configuration Document Store Connectors \u00b6 The configuration store connectors contain the connector implementations that manage the Configuration Documents for OMAG Servers . Figure 7: Configuration Document Store Connector There is one configuration document store connector defined for each OMAG Server Platform . There are two implementations of the configuration document store connector provided by Egeria: one for an encrypted store (default) and the other for a plain text store. Encrypted File Configuration Store Connector stores each configuration document as an encrypted JSON file. File Configuration Store stores each configuration document as a clear text JSON file. The definition of the connector interface for these connectors is defined in the admin-services-api module in the org.odpi.openmetadata.adminservices.store Java package. Configuring a configuration store connector in the OMAG Server Platform is described in the Administration Guide . If no connector is configured, the OMAG Server Platform uses the Encrypted File Configuration Store Connector. Cohort Registry Store Connectors \u00b6 The cohort registry store connectors store the open metadata repository cohort membership details used and maintained by the cohort registry . The cohort protocols are peer-to-peer and hence there is a cohort registry (with a cohort registry store ) for each member of a cohort . Figure 8: Open Metadata Topic Connectors Egeria provides a single implementation of a cohort registry store connector: Cohort Registry File Store Connector provides the means to store the cohort registry membership details as a JSON file. The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.stores.cohortregistrystore Java package. Open Metadata Archive Store Connectors \u00b6 The open metadata archive store connectors can read and write open metadata archives . Open metadata archives store open metadata types and instances for sharing, or for back up. These archives can be loaded into an OMAG Server at start up or added to a running OMAG Server . Figure 9: Open Metadata Archive Store Connector Egeria provides a single implementation of the open metadata archive store connector: Open Metadata Archive File Store Connector stores an open metadata archive as a plain text JSON file. The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.stores.archivestore Java package. Audit Log Destination Connectors \u00b6 The audit log destination connectors support different destinations for audit log records. Multiple of these connectors can be active in an OMAG Server at any one time and they can each be configured to only process particular types of audit log records. Figure 10: Audit Log Destination Connector Below are the connector implementations provided by Egeria Console Audit Log Connector writes selected parts of each audit log record to stdout. slf4j Audit Log Connector writes full log records to the slf4j ecosystem. File Audit Log Connector creates log records as JSON files in a shared directory. Event Topic Audit Log Connector sends each log record as an event on the supplied event topic. The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.stores.auditlogstore Java package. There is more information on the use of audit logging in the Diagnostic Guide . REST Client Connectors \u00b6 Egeria makes extensive use of REST API calls for synchronous (request-response) communication with its own deployed runtimes and third party technologies. The client connectors are used to issue the REST API calls. Egeria provides a single implementation for Spring. Spring REST Client Connector uses the Spring RESTClient to issue REST API calls. This is embedded in Egeria's clients . Figure 11: REST Client Connector The definition of the connector interface for these connectors is defined in the rest-client-connector-api module in the org.odpi.openmetadata.adapters.connectors.restclients Java package. Cohort Member Client Connector \u00b6 Members of an Open Metadata Repository Cohort provide the other cohort members with a Connection to a connector that supports the OMRSRepositoryConnector interface during the cohort registration process. This connector translates calls to retrieve and maintain metadata in the member's repository into remote calls to the real repository. Figure 12: Cohort Member Client Connector used for federating queries across the cohort Egeria's Open Metadata Repository Services ( OMRS ) provides a default REST API implementation and a corresponding client: REST Cohort Client Connector supports remote calls to the OMRS REST API. The connection for this connector is configured in the LocalRepositoryRemoteConnection property of the cohort member's Local Repository Configuration . The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector Java package. It is the same interface as the repository connectors that are used to provide the local repository to a metadata server so that the Open Metadata Repository Services ( OMRS ) issue calls to the same interface irrespective of whether the call is to the local repository or a remote cohort member. Digital resource connectors \u00b6 Digital resource connectors provide access to digital resources and their metadata that is stored in the open metadata ecosystem. These connectors are for use by external applications and tools to connect with resources and services in the digital landscape. These connectors also supply the Asset metadata from Egeria that describes these resources. Instances of these connectors are created through the Asset Consumer OMAS or Asset Owner OMAS interfaces. They use the Connection linked to the corresponding Asset in the open metadata ecosystem. Connection objects are associated with assets in the metadata catalog using the Asset Owner OMAS , Data Manager OMAS and Asset Manager OMAS . Files \u00b6 The Avro file connector provides access to an Avro file that has been catalogued using open metadata. The basic file connector provides support to read and write to a file using the Java File object. The CSV file connector is able to retrieve data from a Comma Separated Values (CSV) file where the contents are stored in logical columns with a special character delimiter between the columns. The data folder connector is for accessing data that is stored as a number of files within a folder (directory). Databases \u00b6 More coming ...","title":"Connector Overview"},{"location":"connectors/#connector-catalog","text":"Egeria has a growing collection of connectors to third party technologies. These connectors help to accelerate the rollout of your open metadata ecosystem since they can be used to automate the extraction and distribution of metadata to the third party technologies. A connector is a client to a third party technology. It supports a standard API that Egeria calls and it then translates these calls into requests to the third party technology. Some connectors are also able to listen for notifications from the third party technology. When a notification is received, the connector converts its content into a call to Egeria to distribute the information to the open metadata ecosystem. Connectors enable Egeria to operate in many environments and with many types of third party technologies, just by managing the configuration of the OMAG servers. The Connector Catalog list the connector implementations supplied by the Egeria community. There are three broad categories of connectors and the connector catalog is organized accordingly: Connectors that support the exchange and maintenance of metadata . This includes the integration connectors, repository connectors, discovery services and governance action services. Connectors that support Egeria\u2019s runtime . This includes the event bus connectors, cohort registry stores, configuration stores, audit log destination connectors, open metadata archive stores, REST client connectors and the cohort member remote repository connectors Connectors that provide access to digital resources and their metadata that is stored in the open metadata ecosystem.","title":"Connector catalog"},{"location":"connectors/#metadata-exchange-and-maintenance-connectors","text":"The connectors that support the exchange and maintenance of metadata help to accelerate the rollout of your open metadata ecosystem since they can be used to automate the extraction and distribution of metadata to the third party technologies. Type Description Integration connectors manage the metadata exchange to a third party technology through an integration service . Repository and Event Mapper connectors integrate metadata repositories through one or more open metadata repository cohorts . Open Discovery Services analyze the content of resources in the digital landscape and create annotations that are attached to the resource's asset metadata element in the open metadata repositories in the form of an open discovery report Governance Action Services perform monitoring of metadata changes, validation of metadata, triage of issues, assessment and/or remediation activities as required.","title":"Metadata exchange and maintenance connectors"},{"location":"connectors/#integration-connectors","text":"The integration connectors support the exchange of metadata with third party technologies. This exchange may be inbound, outbound, synchronous, polling or event-driven. Figure 1: Integration Connectors Details of how integration connectors work is described in the developer guide .","title":"Integration Connectors"},{"location":"connectors/#files","text":"The files integration connectors run in the Files Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon . Connector Description Data files monitor maintains a DataFile asset for each file in the directory (or any subdirectory). When a new file is created, a new DataFile asset is created. If a file is modified, the lastModified property of the corresponding DataFile asset is updated. When a file is deleted, its corresponding DataFile asset is also deleted (or archived if it is still needed for lineage). Data folder monitor maintains a DataFolder asset for the directory. The files and directories underneath it are assumed to be elements/records in the DataFolder asset and so each time there is a change to the files and directories under the monitored directory, it results in an update to the lastModified property of the corresponding DataFolder asset.","title":"Files"},{"location":"connectors/#databases","text":"The database integration connectors run in the Database Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon . Connector Description PostgreSQL database connector automatically maintains the open metadata instances for the databases hosted on a PostgreSQL server This includes the database schemas, tables, columns, primary keys and foreign keys.","title":"Databases"},{"location":"connectors/#topics","text":"The topic integration connectors run in the Topic Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon . Connector Description Kafka Monitor topic integration connector automatically maintains the open metadata instances for the topics hosted on an Apache Kafka server .","title":"Topics"},{"location":"connectors/#apis","text":"The API integration connectors run in the API Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon . Connector Description Open API Monitor integration connector automatically maintains the open metadata instances for the APIs extracted from the Open API Specification extracted from an application.","title":"APIs"},{"location":"connectors/#security-enforcement-engines","text":"TThe security integration connectors run in the Security Integrator Open Metadata Integration Service ( OMIS ) hosted in the integration daemon .","title":"Security Enforcement Engines"},{"location":"connectors/#repository-and-event-mapper-connectors","text":"The repository connectors provide the ability to integrate a third party metadata repository into an open metadata repository cohort . Figure 2 shows the repository connector providing a native open metadata repository that uses a particular type of store within an Egeria Metadata Access Server . Figure 2: Repository connector supporting a native open metadata repository Connector Description JanusGraph OMRS Repository Connector provides a native repository for a metadata server using JanusGraph as the backend. XTDB OMRS Repository Connector provides a native repository for a metadata server that supports historical queries, using XTDB as the backend. In-memory OMRS Repository Connector provides a simple native repository implementation that \"stores\" metadata in HashMaps within the JVM ; it is used for testing, or for environments where metadata maintained in other repositories needs to be cached locally for performance/scalability reasons. Read-only OMRS Repository Connector provides a native repository implementation that does not support the interfaces for create, update, delete; however, it does support the search interfaces and is able to cache metadata -- this means it can be loaded with open metadata archives to provide standard metadata definitions. Figure 3 shows the repository connector providing a native open metadata repository that uses a particular type of store within an Egeria Metadata Access Server . Figure 3: Repository connector and optional event mapper supporting an adapter to a third party metadata catalog Connector Description Apache Atlas OMRS Repository Connector implements read-only connectivity to the Apache Atlas metadata repository IBM Information Governance Catalog ( IGC ) OMRS Repository Connector implements read-only connectivity to the metadata repository within the IBM InfoSphere Information Server suite SAS Viya OMRS Repository Connector implements metadata exchange to the metadata repository within the SAS Viya Platform The repository connectors implement the OMRSMetadataCollection interface to allow metadata to be communicated and exchanged according to Egeria's protocols and type definitions .","title":"Repository and Event Mapper Connectors"},{"location":"connectors/#open-discovery-services","text":"Open discovery services are connectors that analyze the content of resources in the digital landscape and create annotations that are attached to the resource's Asset metadata element in the open metadata repositories in the form of an open discovery report. Figure 4: Discovery Services The definition of the connector interfaces for discovery services is defined in the open-discovery-services module. Connector Description CSV Discovery Service extracts the column names from the first line of the file, counts up the number of records in the file and extracts its last modified time. Sequential Discovery Pipeline runs nested discovery services in a sequence ( more information on discovery pipelines ).","title":"Open Discovery Services"},{"location":"connectors/#governance-action-services","text":"Governance action services are connectors that perform monitoring of metadata changes, validation of metadata, triage of issues, assessment and/or remediation activities on request. Figure 5: Governance Action Services They run in the Governance Action Open Metadata Engine Service ( OMES ) hosted by the Engine Host OMAG Server . Connector Description Generic Element Watchdog Governance Action Service listens for changing metadata elements and initiates governance action processes when certain events occur. Generic Folder Watchdog Governance Action Service listens for changing assets linked to a DataFolder element and initiates governance actions when specific events occur. This may be for files directly linked to the folder or located in sub-folders. Move/Copy File Provisioning Governance Action Service moves or copies files from one location to another and maintains the lineage of the action. Origin Seeker Remediation Governance Action Service walks backwards through the lineage mappings to discover the origin of the data The definition of the connector interfaces for governance action services is defined in the governance-action-framework module.","title":"Governance Action Services"},{"location":"connectors/#runtime-connectors","text":"Runtime connectors support Egeria's runtime: Connectors enable Egeria to operate in many environments by providing plug-in points for the runtime services it needs to operate. Most of these connectors relate to persistent storage, or connections to distributed services.","title":"Runtime connectors"},{"location":"connectors/#open-metadata-topic-connectors","text":"The Open Metadata Topic Connectors are used by Egeria to read and write events to a topic managed by an event broker . These events contain notifications relating to changes in metadata and the topic provides an asynchronous event exchange service hosted in the event broker. Figure 6: Open Metadata Topic Connectors The Open Metadata Topic Connectors connect servers into an open metadata repository cohort and exchange notifications through the Open Metadata Access Services ( OMAS )'s topics called the InTopic and OutTopic . Egeria provides a single implementation of an open metadata connector for Apache Kafka that it uses by default. The Kafka Open Metadata Topic Connector implements an Apache Kafka connector for a topic that exchanges Java Objects as JSON payloads. The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.openmetadatatopic Java package. It is configured in the Egeria OMAG Servers through the Event Bus Configuration .","title":"Open Metadata Topic Connectors"},{"location":"connectors/#configuration-document-store-connectors","text":"The configuration store connectors contain the connector implementations that manage the Configuration Documents for OMAG Servers . Figure 7: Configuration Document Store Connector There is one configuration document store connector defined for each OMAG Server Platform . There are two implementations of the configuration document store connector provided by Egeria: one for an encrypted store (default) and the other for a plain text store. Encrypted File Configuration Store Connector stores each configuration document as an encrypted JSON file. File Configuration Store stores each configuration document as a clear text JSON file. The definition of the connector interface for these connectors is defined in the admin-services-api module in the org.odpi.openmetadata.adminservices.store Java package. Configuring a configuration store connector in the OMAG Server Platform is described in the Administration Guide . If no connector is configured, the OMAG Server Platform uses the Encrypted File Configuration Store Connector.","title":"Configuration Document Store Connectors"},{"location":"connectors/#cohort-registry-store-connectors","text":"The cohort registry store connectors store the open metadata repository cohort membership details used and maintained by the cohort registry . The cohort protocols are peer-to-peer and hence there is a cohort registry (with a cohort registry store ) for each member of a cohort . Figure 8: Open Metadata Topic Connectors Egeria provides a single implementation of a cohort registry store connector: Cohort Registry File Store Connector provides the means to store the cohort registry membership details as a JSON file. The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.stores.cohortregistrystore Java package.","title":"Cohort Registry Store Connectors"},{"location":"connectors/#open-metadata-archive-store-connectors","text":"The open metadata archive store connectors can read and write open metadata archives . Open metadata archives store open metadata types and instances for sharing, or for back up. These archives can be loaded into an OMAG Server at start up or added to a running OMAG Server . Figure 9: Open Metadata Archive Store Connector Egeria provides a single implementation of the open metadata archive store connector: Open Metadata Archive File Store Connector stores an open metadata archive as a plain text JSON file. The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.stores.archivestore Java package.","title":"Open Metadata Archive Store Connectors"},{"location":"connectors/#audit-log-destination-connectors","text":"The audit log destination connectors support different destinations for audit log records. Multiple of these connectors can be active in an OMAG Server at any one time and they can each be configured to only process particular types of audit log records. Figure 10: Audit Log Destination Connector Below are the connector implementations provided by Egeria Console Audit Log Connector writes selected parts of each audit log record to stdout. slf4j Audit Log Connector writes full log records to the slf4j ecosystem. File Audit Log Connector creates log records as JSON files in a shared directory. Event Topic Audit Log Connector sends each log record as an event on the supplied event topic. The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.stores.auditlogstore Java package. There is more information on the use of audit logging in the Diagnostic Guide .","title":"Audit Log Destination Connectors"},{"location":"connectors/#rest-client-connectors","text":"Egeria makes extensive use of REST API calls for synchronous (request-response) communication with its own deployed runtimes and third party technologies. The client connectors are used to issue the REST API calls. Egeria provides a single implementation for Spring. Spring REST Client Connector uses the Spring RESTClient to issue REST API calls. This is embedded in Egeria's clients . Figure 11: REST Client Connector The definition of the connector interface for these connectors is defined in the rest-client-connector-api module in the org.odpi.openmetadata.adapters.connectors.restclients Java package.","title":"REST Client Connectors"},{"location":"connectors/#cohort-member-client-connector","text":"Members of an Open Metadata Repository Cohort provide the other cohort members with a Connection to a connector that supports the OMRSRepositoryConnector interface during the cohort registration process. This connector translates calls to retrieve and maintain metadata in the member's repository into remote calls to the real repository. Figure 12: Cohort Member Client Connector used for federating queries across the cohort Egeria's Open Metadata Repository Services ( OMRS ) provides a default REST API implementation and a corresponding client: REST Cohort Client Connector supports remote calls to the OMRS REST API. The connection for this connector is configured in the LocalRepositoryRemoteConnection property of the cohort member's Local Repository Configuration . The definition of the connector interface for these connectors is defined in the repository-services-api module in the org.odpi.openmetadata.repositoryservices.connectors.stores.metadatacollectionstore.repositoryconnector Java package. It is the same interface as the repository connectors that are used to provide the local repository to a metadata server so that the Open Metadata Repository Services ( OMRS ) issue calls to the same interface irrespective of whether the call is to the local repository or a remote cohort member.","title":"Cohort Member Client Connector"},{"location":"connectors/#digital-resource-connectors","text":"Digital resource connectors provide access to digital resources and their metadata that is stored in the open metadata ecosystem. These connectors are for use by external applications and tools to connect with resources and services in the digital landscape. These connectors also supply the Asset metadata from Egeria that describes these resources. Instances of these connectors are created through the Asset Consumer OMAS or Asset Owner OMAS interfaces. They use the Connection linked to the corresponding Asset in the open metadata ecosystem. Connection objects are associated with assets in the metadata catalog using the Asset Owner OMAS , Data Manager OMAS and Asset Manager OMAS .","title":"Digital resource connectors"},{"location":"connectors/#files_1","text":"The Avro file connector provides access to an Avro file that has been catalogued using open metadata. The basic file connector provides support to read and write to a file using the Java File object. The CSV file connector is able to retrieve data from a Comma Separated Values (CSV) file where the contents are stored in logical columns with a special character delimiter between the columns. The data folder connector is for accessing data that is stored as a number of files within a folder (directory).","title":"Files"},{"location":"connectors/#databases_1","text":"More coming ...","title":"Databases"},{"location":"connectors/governance-action/generic-element-watchdog-governance-action-service/","text":"Generic Element Watchdog Governance Action Service \u00b6 Connector summary Connector Category: Watchdog Governance Action Service Hosting Service: Governance Action OMES Hosting Server: Engine Host Source Module: governance-action-connectors Jar File Name: governance-action-connectors.jar ConnectorProviderClassName: org.odpi.openmetadata.adapters.connectors.governanceactions.watchdog/GenericElementWatchdogGovernanceActionProvider.java The Generic Element Watchdog governance action service detects changes to requested elements and initiates a governance action process when they occur. It has two modes of operation: listening for a single event and then terminating when it occurs, or continuously listening for multiple events. It is possible to listen for: specific types of elements specific instances specific types of events Configuration \u00b6 This connector uses the Governance Action OMES running in the engine host . The following properties can be set up in its connection's configuration properties and overridden by the request parameters: The interestingTypeName property takes the name of an element type. If set, it determines which types of elements are to be monitored. This monitoring includes all subtypes of this interesting type. If interestingTypeName is not set the default value is OpenMetadataRoot - effectively all elements with an open metadata type. The instanceToMonitor property takes the unique identifier of a metadata element. If set, this service will only consider events for this instance. If it is not set then all elements of the interesting type are monitored unless there are one or more action targets that are labelled with instanceToMonitor when this service starts. If the action targets are set up then these are the instances that are monitored. The rest of the properties are the governance action processes to call for specific types of events. The property is set to the qualified name of the process to run if the type of event occurs on the metadata instance(s) being monitored. If the property is not set, the type of event it refers to is ignored. Property Description newElementProcessName listen for new or refreshed elements updatedElementProcessName listen for changes to the properties in the element deletedElementProcessName listen for elements that have been deleted classifiedElementProcessName listen for elements that have had a new classification attached reclassifiedElementProcessName listen for elements that have had the properties in one of their classifications changed declassifiedElementProcessName listen for elements that have had a classification removed newRelationshipProcessName listen for new relationships linking these elements to other elements updatedRelationshipProcessName listen for changes to the properties of relationships that are attached to these elements deletedRelationshipProcessName listen for the removal of relationships attached to these elements Connection configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.governanceactions.watchdog.GenericElementWatchdogGovernanceActionProvider\" }, \"configurationProperties\" : { \"interestingTypeName\" : \"{{typeName}}\" , \"instanceToMonitor\" : \"{{guid}}\" , \"newElementProcessName\" : \"{{processQualifiedName}}\" , \"updatedElementProcessName\" : \"{{processQualifiedName}}\" , \"deletedElementProcessName\" : \"{{processQualifiedName}}\" , \"classifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"reclassifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"declassifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"newRelationshipProcessName\" : \"{{processQualifiedName}}\" , \"updatedRelationshipProcessName\" : \"{{processQualifiedName}}\" , \"deletedRelationshipProcessName\" : \"{{processQualifiedName}}\" } } } This is its connection definition to use when creating the definition of the governance action service using the Governance Engine OMAS . Remove the configuration properties that are not required. Replace {{typeName}} , {{guid}} and {{processQualifiedName}} as required. Governance action settings \u00b6 When this governance action service is called through a GovernanceAction it supports the following options: Request types and parameters \u00b6 There are two request types that control its modes of operation: process-single-event to request it monitors for a single specific event and then completes. process-multiple-events to request it continuously monitors for events until it fails. If the engine host server where it is running is restarted, this governance action service is also restarted. Any of the configuration properties can be overridden by request parameters of the same name. Action targets \u00b6 The instanceToMonitor property can be supplied as a name action target. Using action targets allows the instance to be dynamically controlled and for multiple instances to be monitored. Completion status and guards \u00b6 This service will only complete and produce a guard if it encounters an unrecoverable error or it is set up to listen for a single event and that event occurs. On completion, this governance action service uses: CompletionStatus.ACTIONED with guard monitoring-complete - requested single event occurred, or CompletionStatus.FAILED with guard monitoring-failed - monitor not configured correctly or failed Further information This connector is configured in the governDL01 engine host server as part of the automated curation asset management hands-on lab .","title":"Generic Element Watchdog"},{"location":"connectors/governance-action/generic-element-watchdog-governance-action-service/#generic-element-watchdog-governance-action-service","text":"Connector summary Connector Category: Watchdog Governance Action Service Hosting Service: Governance Action OMES Hosting Server: Engine Host Source Module: governance-action-connectors Jar File Name: governance-action-connectors.jar ConnectorProviderClassName: org.odpi.openmetadata.adapters.connectors.governanceactions.watchdog/GenericElementWatchdogGovernanceActionProvider.java The Generic Element Watchdog governance action service detects changes to requested elements and initiates a governance action process when they occur. It has two modes of operation: listening for a single event and then terminating when it occurs, or continuously listening for multiple events. It is possible to listen for: specific types of elements specific instances specific types of events","title":"Generic Element Watchdog Governance Action Service"},{"location":"connectors/governance-action/generic-element-watchdog-governance-action-service/#configuration","text":"This connector uses the Governance Action OMES running in the engine host . The following properties can be set up in its connection's configuration properties and overridden by the request parameters: The interestingTypeName property takes the name of an element type. If set, it determines which types of elements are to be monitored. This monitoring includes all subtypes of this interesting type. If interestingTypeName is not set the default value is OpenMetadataRoot - effectively all elements with an open metadata type. The instanceToMonitor property takes the unique identifier of a metadata element. If set, this service will only consider events for this instance. If it is not set then all elements of the interesting type are monitored unless there are one or more action targets that are labelled with instanceToMonitor when this service starts. If the action targets are set up then these are the instances that are monitored. The rest of the properties are the governance action processes to call for specific types of events. The property is set to the qualified name of the process to run if the type of event occurs on the metadata instance(s) being monitored. If the property is not set, the type of event it refers to is ignored. Property Description newElementProcessName listen for new or refreshed elements updatedElementProcessName listen for changes to the properties in the element deletedElementProcessName listen for elements that have been deleted classifiedElementProcessName listen for elements that have had a new classification attached reclassifiedElementProcessName listen for elements that have had the properties in one of their classifications changed declassifiedElementProcessName listen for elements that have had a classification removed newRelationshipProcessName listen for new relationships linking these elements to other elements updatedRelationshipProcessName listen for changes to the properties of relationships that are attached to these elements deletedRelationshipProcessName listen for the removal of relationships attached to these elements Connection configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.governanceactions.watchdog.GenericElementWatchdogGovernanceActionProvider\" }, \"configurationProperties\" : { \"interestingTypeName\" : \"{{typeName}}\" , \"instanceToMonitor\" : \"{{guid}}\" , \"newElementProcessName\" : \"{{processQualifiedName}}\" , \"updatedElementProcessName\" : \"{{processQualifiedName}}\" , \"deletedElementProcessName\" : \"{{processQualifiedName}}\" , \"classifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"reclassifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"declassifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"newRelationshipProcessName\" : \"{{processQualifiedName}}\" , \"updatedRelationshipProcessName\" : \"{{processQualifiedName}}\" , \"deletedRelationshipProcessName\" : \"{{processQualifiedName}}\" } } } This is its connection definition to use when creating the definition of the governance action service using the Governance Engine OMAS . Remove the configuration properties that are not required. Replace {{typeName}} , {{guid}} and {{processQualifiedName}} as required.","title":"Configuration"},{"location":"connectors/governance-action/generic-element-watchdog-governance-action-service/#governance-action-settings","text":"When this governance action service is called through a GovernanceAction it supports the following options:","title":"Governance action settings"},{"location":"connectors/governance-action/generic-element-watchdog-governance-action-service/#request-types-and-parameters","text":"There are two request types that control its modes of operation: process-single-event to request it monitors for a single specific event and then completes. process-multiple-events to request it continuously monitors for events until it fails. If the engine host server where it is running is restarted, this governance action service is also restarted. Any of the configuration properties can be overridden by request parameters of the same name.","title":"Request types and parameters"},{"location":"connectors/governance-action/generic-element-watchdog-governance-action-service/#action-targets","text":"The instanceToMonitor property can be supplied as a name action target. Using action targets allows the instance to be dynamically controlled and for multiple instances to be monitored.","title":"Action targets"},{"location":"connectors/governance-action/generic-element-watchdog-governance-action-service/#completion-status-and-guards","text":"This service will only complete and produce a guard if it encounters an unrecoverable error or it is set up to listen for a single event and that event occurs. On completion, this governance action service uses: CompletionStatus.ACTIONED with guard monitoring-complete - requested single event occurred, or CompletionStatus.FAILED with guard monitoring-failed - monitor not configured correctly or failed Further information This connector is configured in the governDL01 engine host server as part of the automated curation asset management hands-on lab .","title":"Completion status and guards"},{"location":"connectors/governance-action/generic-folder-watchdog-governance-action-service/","text":"Generic Folder Watchdog Governance Action Service \u00b6 Connector details Connector Category: Watchdog Governance Action Service Hosting Service: Governance Action OMES Hosting Server: Engine Host Source Module: governance-action-connectors Jar File Name: governance-action-connectors.jar ConnectorProviderClassName: org.odpi.openmetadata.adapters.connectors.governanceactions.watchdog.GenericFolderWatchdogGovernanceActionProvider Source: GenericFolderWatchdogGovernanceActionProvider Connector archive: governance-action-connectors.jar The generic folder watchdog governance action service detects changes to the assets in a specific folder and initiates a governance action process when they occur. It has two modes of operation: listening for a single event and then terminating when it occurs, or continuously listening for multiple events. It is possible to listen for: assets directly in the folder - and optionally assets in any nested folder specific types of events Configuration \u00b6 This connector uses the Governance Action OMES running in the engine host . The following properties that can be set up in its connection's configuration properties and overridden by the request parameters. The interestingTypeName property takes the name of a DataFile type. If set, it determines which types of assets are to be monitored. This monitoring includes all subtypes of this interesting type. If interestingTypeName is not set the default value is DataFile - effectively all files with an open metadata type. The rest of the properties are the governance action processes to call for specific types of events. The property is set to the qualified name of the process to run if the type of event occurs on the metadata instance(s) being monitored. If the property is not set, the type of event it refers to is ignored. Property Description newElementProcessName listen for new or refreshed elements updatedElementProcessName listen for changes to the properties in the element deletedElementProcessName listen for elements that have been deleted classifiedElementProcessName listen for elements that have had a new classification attached reclassifiedElementProcessName listen for elements that have had the properties in one of their classifications changed declassifiedElementProcessName listen for elements that have had a classification removed Connection configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.governanceactions.watchdog.GenericFolderWatchdogGovernanceActionProvider\" }, \"configurationProperties\" : { \"interestingTypeName\" : \"{{typeName}}\" , \"newElementProcessName\" : \"{{processQualifiedName}}\" , \"updatedElementProcessName\" : \"{{processQualifiedName}}\" , \"deletedElementProcessName\" : \"{{processQualifiedName}}\" , \"classifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"reclassifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"declassifiedElementProcessName\" : \"{{processQualifiedName}}\" } } } This is its connection definition to use when creating the definition of the governance action service using the Governance Engine OMAS . Remove the configuration properties that are not required. Replace {{typeName}} , {{guid}} and {{processQualifiedName}} as required. Governance action settings \u00b6 When this governance action service is called through a GovernanceAction it supports the following options: Request types and parameters \u00b6 There are two request types that control its modes of operation: member-of-folder to request it monitors for file assets that are directly in the named folder. nested-in-folder to request it monitors for file assets that are either directly in the named folder or any sub-folder. Any of the configuration properties can be overridden by request parameters of the same name. Action targets \u00b6 The folderTarget property can be supplied as a named action target. Using action targets allows the instance to be dynamically controlled and for multiple instances to be monitored. Completion status and guards \u00b6 This service will only complete and produce a guard if it encounters an unrecoverable error. In which case, this governance action service uses: CompletionStatus.FAILED with guard monitoring-failed It is also possible to shutdown the governance action service by setting CompletionStatus.ACTIONED with guard monitoring-completed in the governance action. Further information This connector is configured in the governDL01 engine host server as part of the automated curation asset management hands-on lab .","title":"Generic Folder Watchdog"},{"location":"connectors/governance-action/generic-folder-watchdog-governance-action-service/#generic-folder-watchdog-governance-action-service","text":"Connector details Connector Category: Watchdog Governance Action Service Hosting Service: Governance Action OMES Hosting Server: Engine Host Source Module: governance-action-connectors Jar File Name: governance-action-connectors.jar ConnectorProviderClassName: org.odpi.openmetadata.adapters.connectors.governanceactions.watchdog.GenericFolderWatchdogGovernanceActionProvider Source: GenericFolderWatchdogGovernanceActionProvider Connector archive: governance-action-connectors.jar The generic folder watchdog governance action service detects changes to the assets in a specific folder and initiates a governance action process when they occur. It has two modes of operation: listening for a single event and then terminating when it occurs, or continuously listening for multiple events. It is possible to listen for: assets directly in the folder - and optionally assets in any nested folder specific types of events","title":"Generic Folder Watchdog Governance Action Service"},{"location":"connectors/governance-action/generic-folder-watchdog-governance-action-service/#configuration","text":"This connector uses the Governance Action OMES running in the engine host . The following properties that can be set up in its connection's configuration properties and overridden by the request parameters. The interestingTypeName property takes the name of a DataFile type. If set, it determines which types of assets are to be monitored. This monitoring includes all subtypes of this interesting type. If interestingTypeName is not set the default value is DataFile - effectively all files with an open metadata type. The rest of the properties are the governance action processes to call for specific types of events. The property is set to the qualified name of the process to run if the type of event occurs on the metadata instance(s) being monitored. If the property is not set, the type of event it refers to is ignored. Property Description newElementProcessName listen for new or refreshed elements updatedElementProcessName listen for changes to the properties in the element deletedElementProcessName listen for elements that have been deleted classifiedElementProcessName listen for elements that have had a new classification attached reclassifiedElementProcessName listen for elements that have had the properties in one of their classifications changed declassifiedElementProcessName listen for elements that have had a classification removed Connection configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.governanceactions.watchdog.GenericFolderWatchdogGovernanceActionProvider\" }, \"configurationProperties\" : { \"interestingTypeName\" : \"{{typeName}}\" , \"newElementProcessName\" : \"{{processQualifiedName}}\" , \"updatedElementProcessName\" : \"{{processQualifiedName}}\" , \"deletedElementProcessName\" : \"{{processQualifiedName}}\" , \"classifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"reclassifiedElementProcessName\" : \"{{processQualifiedName}}\" , \"declassifiedElementProcessName\" : \"{{processQualifiedName}}\" } } } This is its connection definition to use when creating the definition of the governance action service using the Governance Engine OMAS . Remove the configuration properties that are not required. Replace {{typeName}} , {{guid}} and {{processQualifiedName}} as required.","title":"Configuration"},{"location":"connectors/governance-action/generic-folder-watchdog-governance-action-service/#governance-action-settings","text":"When this governance action service is called through a GovernanceAction it supports the following options:","title":"Governance action settings"},{"location":"connectors/governance-action/generic-folder-watchdog-governance-action-service/#request-types-and-parameters","text":"There are two request types that control its modes of operation: member-of-folder to request it monitors for file assets that are directly in the named folder. nested-in-folder to request it monitors for file assets that are either directly in the named folder or any sub-folder. Any of the configuration properties can be overridden by request parameters of the same name.","title":"Request types and parameters"},{"location":"connectors/governance-action/generic-folder-watchdog-governance-action-service/#action-targets","text":"The folderTarget property can be supplied as a named action target. Using action targets allows the instance to be dynamically controlled and for multiple instances to be monitored.","title":"Action targets"},{"location":"connectors/governance-action/generic-folder-watchdog-governance-action-service/#completion-status-and-guards","text":"This service will only complete and produce a guard if it encounters an unrecoverable error. In which case, this governance action service uses: CompletionStatus.FAILED with guard monitoring-failed It is also possible to shutdown the governance action service by setting CompletionStatus.ACTIONED with guard monitoring-completed in the governance action. Further information This connector is configured in the governDL01 engine host server as part of the automated curation asset management hands-on lab .","title":"Completion status and guards"},{"location":"connectors/governance-action/move-copy-file-provisioning-governance-action-service/","text":"Move/Copy File Provisioning Governance Action Service \u00b6 Connector summary Connector Category: Provisioning Governance Action Service Hosting Service: Governance Action OMES Hosting Server: Engine Host Source Module: governance-action-connectors Jar File Name: governance-action-connectors.jar ConnectorProviderClassName: org.odpi.openmetadata.adapters.connectors.governanceactions.provisioning.MoveCopyFileGovernanceActionProvider Move/Copy File Provisioning Governance Action Service moves or copies files from one location to another and optionally creates lineage between them. This governance action service is highly configurable. It can be set up to perform a move file, a copy file or a delete file action. The destination file name may be adapted from the source file name using a file pattern and the lineage may be turned on or off. Figure 1: Operation of the move/copy file provisioning governance action service If lineage is requested, it includes adding a new DataFile asset for the new file in the destination folder and creating LineageMapping relationships between the process that represents this governance action service and both the asset for the original source file and as well as the destination. There are four choices for lineage: Figure 2 shows the default lineage from this service. It allows exact traceability between source file and destination file. Figure 2: Exact traceability between source and destination files Figure 3 shows lineage where there is no need to track the the lineage between individual files, because for example, the source files always come from the same source and all go to the same destination. Figure 3: Traceability between the collection of source files and the collection of destination files Figure 4 links the source files to the instance of this governance action process but not to the individual destination files. Figure 4: Traceability between the collection of source files and the provisioning instance and the destination folder Figure 5 shows the traceability between the source files and the governance action process and the destination folder. It is not possible to tell which instance of the governance action service processes each source file. Figure 5: Traceability between the collection of source files and the destination folder Figure 6 shows the most abbreviated lineage that shows the linkage from the source folder to the governance action process to the destination folder. There is no traceability at the file level. This pattern is appropriate when the files themselves are very numerous, they all follow the same processing path and the folders represent the data sets. Figure 6: Traceability between the source files' folder and the destination folder Irrespective of the pattern used, the resulting changes to the metadata can lead to the triggering of additional activity in the open metadata ecosystem. For example: The Asset Lineage OMAS may publish the lineage to the Open Lineage Server . Additional Governance Action Services may be triggered. Configuration \u00b6 This connector uses the Governance Action OMES running in the Engine Host . The following configuration properties can be set to control the behavior of the service on every instance. provisionUncataloguedFiles - if this property is set to any value, the service may work with files that are not catalogued in open metadata. This is used when processing files that are entering the open metadata ecosystem. targetFileNamePattern - pattern to construct the name of the destination file. If this is not set, the source file name is used. noLineage - if this property is set to any value, do not produce lineage as part of the provisioning process. processName - if this property is set, it overrides the default process name (ie the name of this governance action service) with the value that this property is set to. lineageWithTopLevelProcessOnly - if this property is set, lineage mappings are connected to the top level process representing this lineageToDestinationFolderOnly - if this property is set, the lineage relationship from the governance action service to the destination is linked to the destination folder rather than the new file in the destination folder. Without this value, the default behavior is to show lineage from governance action process to file. lineageFromSourceFolderOnly - if this property is set, the lineage relationship from the source to the governance action service is linked from the source folder rather than the source file. Without this value, the default behavior is to show lineage from source file to governance action process. This is its connection definition to use when creating the definition of the governance action service using the Governance Engine OMAS . Remove the configuration properties that are not required. Replace {processName} and {pattern} as required. { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.governanceactions.provisioning.MoveCopyFileGovernanceActionProvider\" }, \"configurationProperties\" : { \"provisionUncataloguedFiles\" : \"\" , \"targetFileNamePattern\" : \"{pattern}\" , \"noLineage\" : \"\" , \"processName\" : \"{processName}\" , \"lineageWithTopLevelProcessOnly\" : \"\" , \"lineageToDestinationFolderOnly\" : \"\" , \"lineageFromSourceFolderOnly\" : \"\" } } } Governance Action Settings \u00b6 When this governance action service is called through a GovernanceAction it supports the following options. Request Types and Parameters \u00b6 There are three request types: copy-file to request a file copy move-file to request a file move delete-file to request a file delete The source and destination can be configured as request parameters: source-file destination-folder Which can be overridden by the following named action targets source-file destination-folder Completion Status and Guards \u00b6 On completion, this governance action service uses: CompletionStatus.ACTIONED with guard provisioning-complete or CompletionStatus.FAILED with guard provisioning-failed Examples of use \u00b6 Open Metadata Labs : this connector is configured in the governDL01 engine host server as part of the automated curation asset management lab. Further information Designing a Provisioning Governance Action Service Return to the Connector Catalog Return to the Governance Action Connectors Overview","title":"Move/Copy File Provisioning"},{"location":"connectors/governance-action/move-copy-file-provisioning-governance-action-service/#movecopy-file-provisioning-governance-action-service","text":"Connector summary Connector Category: Provisioning Governance Action Service Hosting Service: Governance Action OMES Hosting Server: Engine Host Source Module: governance-action-connectors Jar File Name: governance-action-connectors.jar ConnectorProviderClassName: org.odpi.openmetadata.adapters.connectors.governanceactions.provisioning.MoveCopyFileGovernanceActionProvider Move/Copy File Provisioning Governance Action Service moves or copies files from one location to another and optionally creates lineage between them. This governance action service is highly configurable. It can be set up to perform a move file, a copy file or a delete file action. The destination file name may be adapted from the source file name using a file pattern and the lineage may be turned on or off. Figure 1: Operation of the move/copy file provisioning governance action service If lineage is requested, it includes adding a new DataFile asset for the new file in the destination folder and creating LineageMapping relationships between the process that represents this governance action service and both the asset for the original source file and as well as the destination. There are four choices for lineage: Figure 2 shows the default lineage from this service. It allows exact traceability between source file and destination file. Figure 2: Exact traceability between source and destination files Figure 3 shows lineage where there is no need to track the the lineage between individual files, because for example, the source files always come from the same source and all go to the same destination. Figure 3: Traceability between the collection of source files and the collection of destination files Figure 4 links the source files to the instance of this governance action process but not to the individual destination files. Figure 4: Traceability between the collection of source files and the provisioning instance and the destination folder Figure 5 shows the traceability between the source files and the governance action process and the destination folder. It is not possible to tell which instance of the governance action service processes each source file. Figure 5: Traceability between the collection of source files and the destination folder Figure 6 shows the most abbreviated lineage that shows the linkage from the source folder to the governance action process to the destination folder. There is no traceability at the file level. This pattern is appropriate when the files themselves are very numerous, they all follow the same processing path and the folders represent the data sets. Figure 6: Traceability between the source files' folder and the destination folder Irrespective of the pattern used, the resulting changes to the metadata can lead to the triggering of additional activity in the open metadata ecosystem. For example: The Asset Lineage OMAS may publish the lineage to the Open Lineage Server . Additional Governance Action Services may be triggered.","title":"Move/Copy File Provisioning Governance Action Service"},{"location":"connectors/governance-action/move-copy-file-provisioning-governance-action-service/#configuration","text":"This connector uses the Governance Action OMES running in the Engine Host . The following configuration properties can be set to control the behavior of the service on every instance. provisionUncataloguedFiles - if this property is set to any value, the service may work with files that are not catalogued in open metadata. This is used when processing files that are entering the open metadata ecosystem. targetFileNamePattern - pattern to construct the name of the destination file. If this is not set, the source file name is used. noLineage - if this property is set to any value, do not produce lineage as part of the provisioning process. processName - if this property is set, it overrides the default process name (ie the name of this governance action service) with the value that this property is set to. lineageWithTopLevelProcessOnly - if this property is set, lineage mappings are connected to the top level process representing this lineageToDestinationFolderOnly - if this property is set, the lineage relationship from the governance action service to the destination is linked to the destination folder rather than the new file in the destination folder. Without this value, the default behavior is to show lineage from governance action process to file. lineageFromSourceFolderOnly - if this property is set, the lineage relationship from the source to the governance action service is linked from the source folder rather than the source file. Without this value, the default behavior is to show lineage from source file to governance action process. This is its connection definition to use when creating the definition of the governance action service using the Governance Engine OMAS . Remove the configuration properties that are not required. Replace {processName} and {pattern} as required. { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.governanceactions.provisioning.MoveCopyFileGovernanceActionProvider\" }, \"configurationProperties\" : { \"provisionUncataloguedFiles\" : \"\" , \"targetFileNamePattern\" : \"{pattern}\" , \"noLineage\" : \"\" , \"processName\" : \"{processName}\" , \"lineageWithTopLevelProcessOnly\" : \"\" , \"lineageToDestinationFolderOnly\" : \"\" , \"lineageFromSourceFolderOnly\" : \"\" } } }","title":"Configuration"},{"location":"connectors/governance-action/move-copy-file-provisioning-governance-action-service/#governance-action-settings","text":"When this governance action service is called through a GovernanceAction it supports the following options.","title":"Governance Action Settings"},{"location":"connectors/governance-action/move-copy-file-provisioning-governance-action-service/#request-types-and-parameters","text":"There are three request types: copy-file to request a file copy move-file to request a file move delete-file to request a file delete The source and destination can be configured as request parameters: source-file destination-folder Which can be overridden by the following named action targets source-file destination-folder","title":"Request Types and Parameters"},{"location":"connectors/governance-action/move-copy-file-provisioning-governance-action-service/#completion-status-and-guards","text":"On completion, this governance action service uses: CompletionStatus.ACTIONED with guard provisioning-complete or CompletionStatus.FAILED with guard provisioning-failed","title":"Completion Status and Guards"},{"location":"connectors/governance-action/move-copy-file-provisioning-governance-action-service/#examples-of-use","text":"Open Metadata Labs : this connector is configured in the governDL01 engine host server as part of the automated curation asset management lab. Further information Designing a Provisioning Governance Action Service Return to the Connector Catalog Return to the Governance Action Connectors Overview","title":"Examples of use"},{"location":"connectors/integration/data-files-monitor-integration-connector/","text":"Data Files Monitor Integration Connector \u00b6 Connector details An integration connector , hosted by the Files Integrator OMIS , running on an integration daemon . Source: files-integration-connectors Connector archive: files-integration-connectors.jar The data files monitor integration connector monitors changes in a file directory (folder) and updates the open metadata repository/repositories to reflect the changes to both the files and folders underneath it. Specifically: A DataFile asset is created and then maintained for each file in the folder (or any sub-folder). When a new file is created, a new DataFile asset is created. If a file is modified, the lastModified property of the corresponding DataFile asset is updated. When a file is deleted, its corresponding DataFile asset is either: Archived: this means the asset is no longer returned on standard asset catalog searches, but it is still visible in lineage graphs . This is the default behavior. Deleted: this means that all metadata associated with the data file is removed. Only use this option if lineage is not important for these file. A FileFolder metadata asset for the monitored folder is created when the first file is catalogued, if it does not already exist. Configuration \u00b6 This connector uses the Files Integrator OMIS running in the integration daemon . Following is its connection definition to use on the administration commands that configure the Files Integrator OMIS : Connection configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.integration.basicfiles.DataFilesMonitorIntegrationProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"{{folderName}}\" }, \"configurationProperties\" : { \"templateQualifiedName\" : \"{{templateQualifiedName}}\" , \"allowCatalogDelete\" : \"\" } } } Replace {{folderName}} with the path name of the folder where the files will be located. The configurationProperties are optional and are used to override the connector's default behavior: If templateQualifiedName is present in the configuration properties then {{templateQualifiedName}} must be set to the qualified name of a DataFile metadata element that should be used as a template for the catalog entry for new files discovered by this connector. The base properties, schema, connection, classifications and any other attachments connected to the template are copied to the new metadata element for the file. (See templated cataloging for more information on the use of templates.) If allowCatalogDelete is present in the configuration properties then the metadata element for a file is deleted when the file is deleted. If this property is not in the configuration properties, then the metadata element is archived (by adding the Memento classification to its entry). The archived element is no longer returned in standard catalog queries, but it is still visible in lineage . Do not set allowCatalogDelete if lineage of these files is important. Further information This connector is configured in the exchangeDL01 integration daemon server in the open metadata labs","title":"Data Files Monitor"},{"location":"connectors/integration/data-files-monitor-integration-connector/#data-files-monitor-integration-connector","text":"Connector details An integration connector , hosted by the Files Integrator OMIS , running on an integration daemon . Source: files-integration-connectors Connector archive: files-integration-connectors.jar The data files monitor integration connector monitors changes in a file directory (folder) and updates the open metadata repository/repositories to reflect the changes to both the files and folders underneath it. Specifically: A DataFile asset is created and then maintained for each file in the folder (or any sub-folder). When a new file is created, a new DataFile asset is created. If a file is modified, the lastModified property of the corresponding DataFile asset is updated. When a file is deleted, its corresponding DataFile asset is either: Archived: this means the asset is no longer returned on standard asset catalog searches, but it is still visible in lineage graphs . This is the default behavior. Deleted: this means that all metadata associated with the data file is removed. Only use this option if lineage is not important for these file. A FileFolder metadata asset for the monitored folder is created when the first file is catalogued, if it does not already exist.","title":"Data Files Monitor Integration Connector"},{"location":"connectors/integration/data-files-monitor-integration-connector/#configuration","text":"This connector uses the Files Integrator OMIS running in the integration daemon . Following is its connection definition to use on the administration commands that configure the Files Integrator OMIS : Connection configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.integration.basicfiles.DataFilesMonitorIntegrationProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"{{folderName}}\" }, \"configurationProperties\" : { \"templateQualifiedName\" : \"{{templateQualifiedName}}\" , \"allowCatalogDelete\" : \"\" } } } Replace {{folderName}} with the path name of the folder where the files will be located. The configurationProperties are optional and are used to override the connector's default behavior: If templateQualifiedName is present in the configuration properties then {{templateQualifiedName}} must be set to the qualified name of a DataFile metadata element that should be used as a template for the catalog entry for new files discovered by this connector. The base properties, schema, connection, classifications and any other attachments connected to the template are copied to the new metadata element for the file. (See templated cataloging for more information on the use of templates.) If allowCatalogDelete is present in the configuration properties then the metadata element for a file is deleted when the file is deleted. If this property is not in the configuration properties, then the metadata element is archived (by adding the Memento classification to its entry). The archived element is no longer returned in standard catalog queries, but it is still visible in lineage . Do not set allowCatalogDelete if lineage of these files is important. Further information This connector is configured in the exchangeDL01 integration daemon server in the open metadata labs","title":"Configuration"},{"location":"connectors/integration/data-folder-monitor-integration-connector/","text":"Data Folder Monitor Integration Connector \u00b6 Connector details An integration connector , hosted by the Files Integrator OMIS , running on an integration daemon . Source: files-integration-connectors Connector archive: files-integration-connectors.jar The data folder monitor integration connector monitor changes in a file directory (folder) and maintains a DataFolder asset for the folder. The files and directories underneath it are assumed to be elements/records in the DataFolder asset and so each time there is a change to the files and directories under the monitored directory, it results in an update to the lastModified property of the corresponding DataFolder asset. Assumes the DataFolder asset already exists This connector assumes that the DataFolder asset is already defined. If it cannot retrieve the DataFolder asset, it ignores file changes. Configuration \u00b6 This connector uses the Files Integrator OMIS running in the integration daemon . Following is its connection definition to use on the administration commands that configure the Files Integrator OMIS : Connection configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.integration.basicfiles.DataFolderMonitorIntegrationProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"{{folderName}}\" } } } Replace {{folderName}} with the path name of the folder to monitor. Further information This connector is configured in the exchangeDL01 integration daemon server in the open metadata labs","title":"Data Folder Monitor"},{"location":"connectors/integration/data-folder-monitor-integration-connector/#data-folder-monitor-integration-connector","text":"Connector details An integration connector , hosted by the Files Integrator OMIS , running on an integration daemon . Source: files-integration-connectors Connector archive: files-integration-connectors.jar The data folder monitor integration connector monitor changes in a file directory (folder) and maintains a DataFolder asset for the folder. The files and directories underneath it are assumed to be elements/records in the DataFolder asset and so each time there is a change to the files and directories under the monitored directory, it results in an update to the lastModified property of the corresponding DataFolder asset. Assumes the DataFolder asset already exists This connector assumes that the DataFolder asset is already defined. If it cannot retrieve the DataFolder asset, it ignores file changes.","title":"Data Folder Monitor Integration Connector"},{"location":"connectors/integration/data-folder-monitor-integration-connector/#configuration","text":"This connector uses the Files Integrator OMIS running in the integration daemon . Following is its connection definition to use on the administration commands that configure the Files Integrator OMIS : Connection configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.integration.basicfiles.DataFolderMonitorIntegrationProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"{{folderName}}\" } } } Replace {{folderName}} with the path name of the folder to monitor. Further information This connector is configured in the exchangeDL01 integration daemon server in the open metadata labs","title":"Configuration"},{"location":"connectors/integration/kafka-monitor-integration-connector/","text":"Kafka Monitor Integration Connector \u00b6 Connector Category: Integration Connector Hosting Service: Topic Integrator OMIS Hosting Server: Integration Daemon Source Module: kafka-integration-connector Jar File Name: kafka-integration-connector.jar Overview \u00b6 The kafka monitor integration connector monitors an Apache Kafka server a creates a KafkaTopic asset for each topic that is known to the server. If the topic is removed from the Apache Kafka Server, its corresponding KafkaTopic asset is also removed. Figure 1: Operation of the kafka monitor integration connector Configuration \u00b6 This connector uses the Topic Integrator OMIS running in the Integration Daemon . This is its connection definition to use on the administration commands that configure the Topic Integrator OMIS . Replace {serverURL} with the network address of Kafka's bootstrap server (for example, localhost:9092 ). { \"connection\" : { \"class\" : \"Connection\" , \"qualifiedName\" : \"TopicMonitorConnection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.integration.kafka.KafkaMonitorIntegrationProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"{serverURL}\" } } } Return to Connector Catalog License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Kafka Monitor Connector"},{"location":"connectors/integration/kafka-monitor-integration-connector/#kafka-monitor-integration-connector","text":"Connector Category: Integration Connector Hosting Service: Topic Integrator OMIS Hosting Server: Integration Daemon Source Module: kafka-integration-connector Jar File Name: kafka-integration-connector.jar","title":"Kafka Monitor Integration Connector"},{"location":"connectors/integration/kafka-monitor-integration-connector/#overview","text":"The kafka monitor integration connector monitors an Apache Kafka server a creates a KafkaTopic asset for each topic that is known to the server. If the topic is removed from the Apache Kafka Server, its corresponding KafkaTopic asset is also removed. Figure 1: Operation of the kafka monitor integration connector","title":"Overview"},{"location":"connectors/integration/kafka-monitor-integration-connector/#configuration","text":"This connector uses the Topic Integrator OMIS running in the Integration Daemon . This is its connection definition to use on the administration commands that configure the Topic Integrator OMIS . Replace {serverURL} with the network address of Kafka's bootstrap server (for example, localhost:9092 ). { \"connection\" : { \"class\" : \"Connection\" , \"qualifiedName\" : \"TopicMonitorConnection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.integration.kafka.KafkaMonitorIntegrationProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"{serverURL}\" } } } Return to Connector Catalog License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Configuration"},{"location":"connectors/integration/open-api-monitor-integration-connector/","text":"Open API Monitor Integration Connector \u00b6 Connector Category: Integration Connector Hosting Service: API Integrator OMIS Hosting Server: Integration Daemon Source Module: openapi-integration-connector Jar File Name: openapi-integration-connector.jar Overview \u00b6 The Open API monitor integration connector connects to an endpoint and extracts the open API specification through the GET {serverURL}/v3/api-docs request. creates a DeployedAPI asset for each API Tag that is known to the server. A new APIOperation is create for each combination of path name and operation (GET, POST, PUT, DELETE). Figure 1: Operation of the Open API monitor integration connector Configuration \u00b6 This connector uses the API Integrator OMIS running in the Integration Daemon . This is its connection definition to use on the administration commands that configure the API Integrator OMIS . Replace {serverURL} with the network address of the process (for example, localhost:9443 ). { \"connection\" : { \"class\" : \"Connection\" , \"qualifiedName\" : \"APIMonitorConnection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.integration.openapis.OpenAPIMonitorIntegrationProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"{serverURL}\" } } } Return to Connector Catalog License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Open API Monitor Connector"},{"location":"connectors/integration/open-api-monitor-integration-connector/#open-api-monitor-integration-connector","text":"Connector Category: Integration Connector Hosting Service: API Integrator OMIS Hosting Server: Integration Daemon Source Module: openapi-integration-connector Jar File Name: openapi-integration-connector.jar","title":"Open API Monitor Integration Connector"},{"location":"connectors/integration/open-api-monitor-integration-connector/#overview","text":"The Open API monitor integration connector connects to an endpoint and extracts the open API specification through the GET {serverURL}/v3/api-docs request. creates a DeployedAPI asset for each API Tag that is known to the server. A new APIOperation is create for each combination of path name and operation (GET, POST, PUT, DELETE). Figure 1: Operation of the Open API monitor integration connector","title":"Overview"},{"location":"connectors/integration/open-api-monitor-integration-connector/#configuration","text":"This connector uses the API Integrator OMIS running in the Integration Daemon . This is its connection definition to use on the administration commands that configure the API Integrator OMIS . Replace {serverURL} with the network address of the process (for example, localhost:9443 ). { \"connection\" : { \"class\" : \"Connection\" , \"qualifiedName\" : \"APIMonitorConnection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.connectors.integration.openapis.OpenAPIMonitorIntegrationProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"{serverURL}\" } } } Return to Connector Catalog License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Configuration"},{"location":"connectors/repository/xtdb/","text":"XTDB OMRS Repository Connector \u00b6 Fully conformant with all Egeria profiles Last tested on release 3.1 of Egeria, release 3.1 of connector using release 1.18.1 of XTDB . Profile Result Metadata sharing CONFORMANT_FULL_SUPPORT Reference copies CONFORMANT_FULL_SUPPORT Metadata maintenance CONFORMANT_FULL_SUPPORT Dynamic types UNKNOWN_STATUS Graph queries CONFORMANT_FULL_SUPPORT Historical search CONFORMANT_FULL_SUPPORT Entity proxies CONFORMANT_FULL_SUPPORT Soft-delete and restore CONFORMANT_FULL_SUPPORT Undo an update CONFORMANT_FULL_SUPPORT Reidentify instance CONFORMANT_FULL_SUPPORT Retype instance CONFORMANT_FULL_SUPPORT Rehome instance CONFORMANT_FULL_SUPPORT Entity search CONFORMANT_FULL_SUPPORT Relationship search CONFORMANT_FULL_SUPPORT Entity advanced search CONFORMANT_FULL_SUPPORT Relationship advanced search CONFORMANT_FULL_SUPPORT Additional notes The entity search tests could fail a particular long-running query pattern unless Lucene is configured: typically where a query by value or attribute is done without providing any restriction on the type of instances against which the query should run. Configure the connector with Lucene to avoid these timeouts. The Dynamic types profile currently does not have any tests defined, so will be UNKNOWN_STATUS for all repositories and connectors. Latest release Latest snapshot Navigate to the latest snapshot directory, and within that find the latest connector archive with the name: egeria-connector-xtdb-{version}-jar-with-dependencies.jar Source The connector is hosted in its own repository at odpi/egeria-connector-xtdb , where the source code can be cloned and the connector built from source. The XTDB OMRS repository connector enables the use of XTDB (formerly known as \"Crux\") and its own pluggable architecture to support a variety of underlying storage back-ends including S3, RocksDB, Apache Kafka, LMDB, JDBC and more. XTDB supports temporal graph queries to provide native support for storing historical information and answering temporal queries. The connector is also capable of running as a highly-available service. In addition, currently this is the highest-performance open source persistent repository for Egeria across all operations: read, write, update, search and purge. How it works \u00b6 The XTDB OMRS Repository Connector is a repository connector , hosted by the plugin repository proxy , running on a metadata access store . XTDB itself is started as an embedded process within the connector. It can be configured to use any of the various pluggable persistence layers supported by XTDB itself, and communication between the Java code of the connector and XTDB itself (which is implemented in Clojure) occurs directly via the XTDB Java API (not via REST). The repository connector (and metadata collection) methods of the repository connector interface simply communicate with XTDB via XTDB's Java API to read and write information to the underlying XTDB node. XTDB itself handles write transactions and persistence guarantees via its APIs, ensuring that all data is at least recorded into the transaction log and document store prior to any write method returning. Synchronous by default, but configurable for asynchronous operation By default, the repository connector further awaits confirmation that any write has been indexed (and is therefore available for read operations) prior to returning. However, it is also possible to configure the connector in an \"ingest-optimized\" mode that allows the indexing to occur asynchronously, and can therefore improve the speed of write operations significantly. Configuration \u00b6 The following options are used to configure this connector, as part of the configure the local repository step when configuring a metadata server . Pluggable persistence \u00b6 There are many options for configuring XTDB itself. A list of overall persistence modules and deeper configuration options for each can be found through XTDB's own documentation . To enable persistence, there are two options: send in the JSON document configuration outlined in XTDB's own documentation directly to the xtdbConfig key of the configurationProperties property of Egeria's connector configuration send in a string to the xtdbConfigEDN key of the configurationProperties of Egeria's connector configuration, which gives the EDN form of configuration outlined in XTDB's own documentation Both approaches are valid and should be equally functional, but occasionally a bug may crop up that makes one or the other more or less feasible for a particular configuration. Example persistence using JSON configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" }, \"configurationProperties\" : { \"xtdbConfig\" : { \"xtdb.lucene/lucene-store\" : { \"db-dir\" : \"data/servers/xtdb/lucene\" }, \"xtdb/index-store\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-index\" } }, \"xtdb/document-store\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-docs\" } }, \"xtdb/tx-log\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-tx\" } } } } } Some of the Lucene configuration will be automatically injected When using the JSON-based configuration, some additional entries will be automatically injected to the Lucene configuration by Egeria: specifically the indexer and analyzer entries used to configure the Lucene index optimally for the OMRS -level search interfaces that Egeria defines. If you have defined your own analyzer or indexer in the configuration, these will be overridden by the connector's injection process -- in other words, any custom configuration you attempt for analyzer or indexer will be ignored. It is highly recommended to include the Lucene entry like that above as it offers significant performance improvements for any text-based queries. The remainder of the configuration in this example defines RocksDB to act as the persistence layer for XTDB's index and document stores, as well as its transaction log. Example persistence using EDN configuration 1 2 3 4 5 6 7 8 9 10 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" }, \"configurationProperties\" : { \"xtdbConfigEDN\" : \"{:xtdb/index-store {:kv-store {:xtdb/module xtdb.rocksdb/->kv-store :db-dir \\\"data/servers/xtdb/rdb-index\\\"}} :xtdb/document-store {:xtdb/module xtdb.jdbc/->document-store :connection-pool {:dialect {:xtdb/module xtdb.jdbc.psql/->dialect} :db-spec {:jdbcUrl \\\"jdbc:postgresql://myserver.com:5432/mydb?user=myuser&password=mypassword\\\"}}} :xtdb/tx-log {:kv-store {:xtdb/module xtdb.rocksdb/->kv-store :db-dir \\\"data/servers/xtdb/rdb-tx\\\"}} :xtdb.lucene/lucene-store {:db-dir \\\"data/servers/xtdb/lucene\\\" :indexer {:xtdb/module xtdb.lucene.egeria/->egeria-indexer} :analyzer {:xtdb/module xtdb.lucene.egeria/->ci-analyzer}}}\" } } The Lucene configuration will NOT be automatically injected Unlike the JSON-based configuration, when using the EDN-based configuration the necessary Egeria components of the Lucene configuration will not be automatically injected. Therefore, make sure that your EDN configuration string includes in the Lucene configuration the following keys and settings in addition to the :db-dir : { :xtdb.lucene/lucene-store { :db-dir \"data/servers/xtdb/lucene\" :indexer { :xtdb/module xtdb.lucene.egeria/->egeria-indexer } :analyzer { :xtdb/module xtdb.lucene.egeria/->ci-analyzer }} These configure the Lucene index optimally for the OMRS -level search interfaces that Egeria defines. The remainder of the configuration in this example defines RocksDB to act as the persistence layer for XTDB's index and document stores, as well as its transaction log. You may need to download additional dependencies In general the dependent libraries for most persistence (other than JDBC) is included in the connector .jar file itself. For JDBC, you will need to download the appropriate driver for your specific data store and make this .jar file available in the same directory as the connector. For example, when using PostgreSQL you will need org.postgresql:postgresql . You can generally determine the additional dependencies you will need by looking at the project.clj file of the relevant XTDB module -- specifically its :dependencies section. For example, sticking with JDBC, here is the project.clj : 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 :dependencies [[ org.clojure/clojure \"1.10.3\" ] [ org.clojure/tools.logging \"1.1.0\" ] [ com.xtdb/xtdb-core ] [ pro.juxt.clojars-mirrors.com.github.seancorfield/next.jdbc \"1.2.674\" ] [ org.clojure/java.data \"1.0.86\" ] [ com.zaxxer/HikariCP \"3.4.5\" ] [ pro.juxt.clojars-mirrors.com.taoensso/nippy \"3.1.1\" ] ;; Sample driver dependencies [ org.postgresql/postgresql \"42.2.18\" :scope \"provided\" ] [ com.oracle.ojdbc/ojdbc8 \"19.3.0.0\" :scope \"provided\" ] [ com.h2database/h2 \"1.4.200\" :scope \"provided\" ] [ org.xerial/sqlite-jdbc \"3.28.0\" :scope \"provided\" ] [ mysql/mysql-connector-java \"8.0.23\" :scope \"provided\" ] [ com.microsoft.sqlserver/mssql-jdbc \"8.2.2.jre8\" :scope \"provided\" ]] Connector options \u00b6 There are currently two configuration options for the connector itself: Option Description luceneRegexes Controls whether the connector will interpret unquoted regexes as Lucene-compatible (true) or not (false): in the latter case ensuring that we fallback to full Java regex checking (which will be significantly slower). syncIndex Controls whether the connector will wait for the XTDB indexes to be updated before returning from write operations (true) or only that they are only guaranteed to be persisted (false). Example configuration showing the default settings { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" }, \"configurationProperties\" : { \"xtdbConfig\" : { }, \"luceneRegexes\" : true , \"syncIndex\" : true } } Be careful with syncIndex set to false The syncIndex parameter should only be set to false for mass ingestion where you make your own guarantees that the same metadata instances are only created or updated once by that ingestion process. Afterwards, the configuration of the connector for that repository should have the syncIndex setting changed back to true for business-as-usual operation. When set to false, all write operations are guaranteed but are not done atomically relative to other read operations. In particular, this means that certain operations that rely on first retrieving some metadata instance's state, changing it, and persisting that change must be done only once (up to you to guarantee when syncIndex is false) or in synchronous mode ( syncIndex set to true). Otherwise, there is every possibility that the operation will retrieve a stale version of the metadata instance, update it, and persist that -- ultimately clobbering whatever asynchronous update may have been made in-between. This applies to essentially all write operations: classifyEntity , updateEntityClassification , declassifyEntity , save...ReferenceCopy , delete... , purge... , purge...ReferenceCopy , restore... , update...Status , update...Properties , undo...Update , reIdentify... , reType... , and reHome... High availability \u00b6 A sample Helm chart is provided for configuring the XTDB connector for high availability . This chart starts up a number of different elements and configures them in a specific sequence. Requires a pre-existing JDBC database The chart relies on a pre-existing JDBC database somewhere to use as the document store, and the moment assumes this will be of a PostgreSQL variety (that's the only driver it downloads). A quick setup would be to use Enterprise DB's k8s operator to quickly start up a PostgreSQL cluster in your kubernetes cluster, which is what the following diagrams illustrate 1 . Startup \u00b6 When it is first deployed, the Helm chart starts a number of pods and services: for Egeria (purple), Kafka (red), execution of the Performance Test Suite and a pod used for configuration. (As mentioned above, it assumes a pre-existing JDBC database: a vanilla PostgreSQL cluster (grey) deployed and managed independently by EnterpriseDB's k8s operator.) Each XTDB pod runs its own separate OMAG Server Platform , in its own JVM , and a script in the init-and-report pod will wait until all three pods' OMAG Server Platforms are running before proceeding to any of the following steps. (The headless service allows each pod to be directly addressed, without load-balancing, to do such a check.) Configure \u00b6 The next script creates a singular configuration document via the pts pod, and deploys this common configuration to each of the pods (again using the headless service to directly address each one individually): each will have a separate xtdb server configured with the same XTDB connector (same metadata collection id ). When the /instance is called against each pod to start the connector, each will create a local index and instance of the IXtdb interface: all pointing to the same golden stores (in this example, Kafka and EDB) where all persistence for XTDB is handled. All servers will refer to the singular xtdb load-balancing service as their root URL. Run \u00b6 Now when we start the Performance Test Suite, all traffic to the technology under test is routed via this xtdb load-balancing service: which will round-robin each request it receives to the underlying pods running the XTDB plugin repository connector. Kafka has a similar service, which handles load-balancing across its own pods for all write operations. The underlying JDBC cluster may have a similar load-balancing service again (e.g. if the data store uses sharding), but also may not. In this example the edb-rw service layer is instead an abstraction of the primary data store ( edb-1 ): all writes will go to this primary data store, while the others act as secondary / standby servers to which EnterpriseDB is automatically handling data replication from the primary. If the primary pod fails, EnterpriseDB can re-point the edb-rw service layer to one of these existing secondary stores (which is automatically promoted to primary by EnterpriseDB). Outages \u00b6 Should there be any outage (in the example above, an Egeria pod, a Kafka pod, and an EnterpriseDB pod all going down) the Kubernetes services will simply stop routing traffic to those pods and the overall service will continue uninterrupted. Depending on how the underlying services are managed, they may also be able to self-heal: Kafka is deployed as a StatefulSet in kubernetes, so if any pod fails kubernetes will automatically attempt to start another in its place to keep the total number of replicas defined by the StatefulSet running at all times. EnterpriseDB in our example was deployed through an operator: this operator self-heals any individual pod failure to e.g. start another standby server pointing at the same PersistentVolumeClaim as the failed pod (to pick up the data that was already replicated), switch the primary server to one of the standby servers if the primary server fails, and so on. Limitations \u00b6 There are a number of limitations to be aware of with the high availability configuration: Must use a non-embedded XTDB back-end Write operations will only be consistent when using a non-embedded XTDB back-end: e.g. Kafka, S3, or JDBC. Read operations are eventually consistent Since the indexes are local to each pod, read operations will be eventually consistent: the specific pod to which a query is routed may not yet have updated its embedded index with the results of the very latest write operations from some other pod. (Note in particular that this has a knock-on impact to our test suites, which currently assume immediate consistency: expect various scenarios to fail if you decide to run them against an eventually-consistent HA configuration.) Cannot yet be dynamically scaled Currently configuration of Egeria requires making a number of REST API calls, which limits how dynamic we can be in adding or removing pods to an already-running cluster (in particular: we cannot rely on a readiness probe to indicate pod readiness to process actual work, but only its readiness to be configured ). We hope to address this soon by allowing configuration and startup to be done without relying on REST calls, at which point we should be able to also support dynamically adding and removing pods from the cluster. For other databases, modify the JDBC_DRIVER_URL value in the configmap.yaml of the chart to point to the location of the appropriate driver, and replace the use of the bin/bootstrapConfig.sh script in the init-and-report.yaml template with an inline script in that template (to specify the appropriate XTDB configuration and JDBC dialect to use for the document store ). \u21a9","title":"XTDB OMRS Repository Connector"},{"location":"connectors/repository/xtdb/#xtdb-omrs-repository-connector","text":"Fully conformant with all Egeria profiles Last tested on release 3.1 of Egeria, release 3.1 of connector using release 1.18.1 of XTDB . Profile Result Metadata sharing CONFORMANT_FULL_SUPPORT Reference copies CONFORMANT_FULL_SUPPORT Metadata maintenance CONFORMANT_FULL_SUPPORT Dynamic types UNKNOWN_STATUS Graph queries CONFORMANT_FULL_SUPPORT Historical search CONFORMANT_FULL_SUPPORT Entity proxies CONFORMANT_FULL_SUPPORT Soft-delete and restore CONFORMANT_FULL_SUPPORT Undo an update CONFORMANT_FULL_SUPPORT Reidentify instance CONFORMANT_FULL_SUPPORT Retype instance CONFORMANT_FULL_SUPPORT Rehome instance CONFORMANT_FULL_SUPPORT Entity search CONFORMANT_FULL_SUPPORT Relationship search CONFORMANT_FULL_SUPPORT Entity advanced search CONFORMANT_FULL_SUPPORT Relationship advanced search CONFORMANT_FULL_SUPPORT Additional notes The entity search tests could fail a particular long-running query pattern unless Lucene is configured: typically where a query by value or attribute is done without providing any restriction on the type of instances against which the query should run. Configure the connector with Lucene to avoid these timeouts. The Dynamic types profile currently does not have any tests defined, so will be UNKNOWN_STATUS for all repositories and connectors. Latest release Latest snapshot Navigate to the latest snapshot directory, and within that find the latest connector archive with the name: egeria-connector-xtdb-{version}-jar-with-dependencies.jar Source The connector is hosted in its own repository at odpi/egeria-connector-xtdb , where the source code can be cloned and the connector built from source. The XTDB OMRS repository connector enables the use of XTDB (formerly known as \"Crux\") and its own pluggable architecture to support a variety of underlying storage back-ends including S3, RocksDB, Apache Kafka, LMDB, JDBC and more. XTDB supports temporal graph queries to provide native support for storing historical information and answering temporal queries. The connector is also capable of running as a highly-available service. In addition, currently this is the highest-performance open source persistent repository for Egeria across all operations: read, write, update, search and purge.","title":"XTDB OMRS Repository Connector"},{"location":"connectors/repository/xtdb/#how-it-works","text":"The XTDB OMRS Repository Connector is a repository connector , hosted by the plugin repository proxy , running on a metadata access store . XTDB itself is started as an embedded process within the connector. It can be configured to use any of the various pluggable persistence layers supported by XTDB itself, and communication between the Java code of the connector and XTDB itself (which is implemented in Clojure) occurs directly via the XTDB Java API (not via REST). The repository connector (and metadata collection) methods of the repository connector interface simply communicate with XTDB via XTDB's Java API to read and write information to the underlying XTDB node. XTDB itself handles write transactions and persistence guarantees via its APIs, ensuring that all data is at least recorded into the transaction log and document store prior to any write method returning. Synchronous by default, but configurable for asynchronous operation By default, the repository connector further awaits confirmation that any write has been indexed (and is therefore available for read operations) prior to returning. However, it is also possible to configure the connector in an \"ingest-optimized\" mode that allows the indexing to occur asynchronously, and can therefore improve the speed of write operations significantly.","title":"How it works"},{"location":"connectors/repository/xtdb/#configuration","text":"The following options are used to configure this connector, as part of the configure the local repository step when configuring a metadata server .","title":"Configuration"},{"location":"connectors/repository/xtdb/#pluggable-persistence","text":"There are many options for configuring XTDB itself. A list of overall persistence modules and deeper configuration options for each can be found through XTDB's own documentation . To enable persistence, there are two options: send in the JSON document configuration outlined in XTDB's own documentation directly to the xtdbConfig key of the configurationProperties property of Egeria's connector configuration send in a string to the xtdbConfigEDN key of the configurationProperties of Egeria's connector configuration, which gives the EDN form of configuration outlined in XTDB's own documentation Both approaches are valid and should be equally functional, but occasionally a bug may crop up that makes one or the other more or less feasible for a particular configuration. Example persistence using JSON configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" }, \"configurationProperties\" : { \"xtdbConfig\" : { \"xtdb.lucene/lucene-store\" : { \"db-dir\" : \"data/servers/xtdb/lucene\" }, \"xtdb/index-store\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-index\" } }, \"xtdb/document-store\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-docs\" } }, \"xtdb/tx-log\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-tx\" } } } } } Some of the Lucene configuration will be automatically injected When using the JSON-based configuration, some additional entries will be automatically injected to the Lucene configuration by Egeria: specifically the indexer and analyzer entries used to configure the Lucene index optimally for the OMRS -level search interfaces that Egeria defines. If you have defined your own analyzer or indexer in the configuration, these will be overridden by the connector's injection process -- in other words, any custom configuration you attempt for analyzer or indexer will be ignored. It is highly recommended to include the Lucene entry like that above as it offers significant performance improvements for any text-based queries. The remainder of the configuration in this example defines RocksDB to act as the persistence layer for XTDB's index and document stores, as well as its transaction log. Example persistence using EDN configuration 1 2 3 4 5 6 7 8 9 10 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" }, \"configurationProperties\" : { \"xtdbConfigEDN\" : \"{:xtdb/index-store {:kv-store {:xtdb/module xtdb.rocksdb/->kv-store :db-dir \\\"data/servers/xtdb/rdb-index\\\"}} :xtdb/document-store {:xtdb/module xtdb.jdbc/->document-store :connection-pool {:dialect {:xtdb/module xtdb.jdbc.psql/->dialect} :db-spec {:jdbcUrl \\\"jdbc:postgresql://myserver.com:5432/mydb?user=myuser&password=mypassword\\\"}}} :xtdb/tx-log {:kv-store {:xtdb/module xtdb.rocksdb/->kv-store :db-dir \\\"data/servers/xtdb/rdb-tx\\\"}} :xtdb.lucene/lucene-store {:db-dir \\\"data/servers/xtdb/lucene\\\" :indexer {:xtdb/module xtdb.lucene.egeria/->egeria-indexer} :analyzer {:xtdb/module xtdb.lucene.egeria/->ci-analyzer}}}\" } } The Lucene configuration will NOT be automatically injected Unlike the JSON-based configuration, when using the EDN-based configuration the necessary Egeria components of the Lucene configuration will not be automatically injected. Therefore, make sure that your EDN configuration string includes in the Lucene configuration the following keys and settings in addition to the :db-dir : { :xtdb.lucene/lucene-store { :db-dir \"data/servers/xtdb/lucene\" :indexer { :xtdb/module xtdb.lucene.egeria/->egeria-indexer } :analyzer { :xtdb/module xtdb.lucene.egeria/->ci-analyzer }} These configure the Lucene index optimally for the OMRS -level search interfaces that Egeria defines. The remainder of the configuration in this example defines RocksDB to act as the persistence layer for XTDB's index and document stores, as well as its transaction log. You may need to download additional dependencies In general the dependent libraries for most persistence (other than JDBC) is included in the connector .jar file itself. For JDBC, you will need to download the appropriate driver for your specific data store and make this .jar file available in the same directory as the connector. For example, when using PostgreSQL you will need org.postgresql:postgresql . You can generally determine the additional dependencies you will need by looking at the project.clj file of the relevant XTDB module -- specifically its :dependencies section. For example, sticking with JDBC, here is the project.clj : 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 :dependencies [[ org.clojure/clojure \"1.10.3\" ] [ org.clojure/tools.logging \"1.1.0\" ] [ com.xtdb/xtdb-core ] [ pro.juxt.clojars-mirrors.com.github.seancorfield/next.jdbc \"1.2.674\" ] [ org.clojure/java.data \"1.0.86\" ] [ com.zaxxer/HikariCP \"3.4.5\" ] [ pro.juxt.clojars-mirrors.com.taoensso/nippy \"3.1.1\" ] ;; Sample driver dependencies [ org.postgresql/postgresql \"42.2.18\" :scope \"provided\" ] [ com.oracle.ojdbc/ojdbc8 \"19.3.0.0\" :scope \"provided\" ] [ com.h2database/h2 \"1.4.200\" :scope \"provided\" ] [ org.xerial/sqlite-jdbc \"3.28.0\" :scope \"provided\" ] [ mysql/mysql-connector-java \"8.0.23\" :scope \"provided\" ] [ com.microsoft.sqlserver/mssql-jdbc \"8.2.2.jre8\" :scope \"provided\" ]]","title":"Pluggable persistence"},{"location":"connectors/repository/xtdb/#connector-options","text":"There are currently two configuration options for the connector itself: Option Description luceneRegexes Controls whether the connector will interpret unquoted regexes as Lucene-compatible (true) or not (false): in the latter case ensuring that we fallback to full Java regex checking (which will be significantly slower). syncIndex Controls whether the connector will wait for the XTDB indexes to be updated before returning from write operations (true) or only that they are only guaranteed to be persisted (false). Example configuration showing the default settings { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" }, \"configurationProperties\" : { \"xtdbConfig\" : { }, \"luceneRegexes\" : true , \"syncIndex\" : true } } Be careful with syncIndex set to false The syncIndex parameter should only be set to false for mass ingestion where you make your own guarantees that the same metadata instances are only created or updated once by that ingestion process. Afterwards, the configuration of the connector for that repository should have the syncIndex setting changed back to true for business-as-usual operation. When set to false, all write operations are guaranteed but are not done atomically relative to other read operations. In particular, this means that certain operations that rely on first retrieving some metadata instance's state, changing it, and persisting that change must be done only once (up to you to guarantee when syncIndex is false) or in synchronous mode ( syncIndex set to true). Otherwise, there is every possibility that the operation will retrieve a stale version of the metadata instance, update it, and persist that -- ultimately clobbering whatever asynchronous update may have been made in-between. This applies to essentially all write operations: classifyEntity , updateEntityClassification , declassifyEntity , save...ReferenceCopy , delete... , purge... , purge...ReferenceCopy , restore... , update...Status , update...Properties , undo...Update , reIdentify... , reType... , and reHome...","title":"Connector options"},{"location":"connectors/repository/xtdb/#high-availability","text":"A sample Helm chart is provided for configuring the XTDB connector for high availability . This chart starts up a number of different elements and configures them in a specific sequence. Requires a pre-existing JDBC database The chart relies on a pre-existing JDBC database somewhere to use as the document store, and the moment assumes this will be of a PostgreSQL variety (that's the only driver it downloads). A quick setup would be to use Enterprise DB's k8s operator to quickly start up a PostgreSQL cluster in your kubernetes cluster, which is what the following diagrams illustrate 1 .","title":"High availability"},{"location":"connectors/repository/xtdb/#startup","text":"When it is first deployed, the Helm chart starts a number of pods and services: for Egeria (purple), Kafka (red), execution of the Performance Test Suite and a pod used for configuration. (As mentioned above, it assumes a pre-existing JDBC database: a vanilla PostgreSQL cluster (grey) deployed and managed independently by EnterpriseDB's k8s operator.) Each XTDB pod runs its own separate OMAG Server Platform , in its own JVM , and a script in the init-and-report pod will wait until all three pods' OMAG Server Platforms are running before proceeding to any of the following steps. (The headless service allows each pod to be directly addressed, without load-balancing, to do such a check.)","title":"Startup"},{"location":"connectors/repository/xtdb/#configure","text":"The next script creates a singular configuration document via the pts pod, and deploys this common configuration to each of the pods (again using the headless service to directly address each one individually): each will have a separate xtdb server configured with the same XTDB connector (same metadata collection id ). When the /instance is called against each pod to start the connector, each will create a local index and instance of the IXtdb interface: all pointing to the same golden stores (in this example, Kafka and EDB) where all persistence for XTDB is handled. All servers will refer to the singular xtdb load-balancing service as their root URL.","title":"Configure"},{"location":"connectors/repository/xtdb/#run","text":"Now when we start the Performance Test Suite, all traffic to the technology under test is routed via this xtdb load-balancing service: which will round-robin each request it receives to the underlying pods running the XTDB plugin repository connector. Kafka has a similar service, which handles load-balancing across its own pods for all write operations. The underlying JDBC cluster may have a similar load-balancing service again (e.g. if the data store uses sharding), but also may not. In this example the edb-rw service layer is instead an abstraction of the primary data store ( edb-1 ): all writes will go to this primary data store, while the others act as secondary / standby servers to which EnterpriseDB is automatically handling data replication from the primary. If the primary pod fails, EnterpriseDB can re-point the edb-rw service layer to one of these existing secondary stores (which is automatically promoted to primary by EnterpriseDB).","title":"Run"},{"location":"connectors/repository/xtdb/#outages","text":"Should there be any outage (in the example above, an Egeria pod, a Kafka pod, and an EnterpriseDB pod all going down) the Kubernetes services will simply stop routing traffic to those pods and the overall service will continue uninterrupted. Depending on how the underlying services are managed, they may also be able to self-heal: Kafka is deployed as a StatefulSet in kubernetes, so if any pod fails kubernetes will automatically attempt to start another in its place to keep the total number of replicas defined by the StatefulSet running at all times. EnterpriseDB in our example was deployed through an operator: this operator self-heals any individual pod failure to e.g. start another standby server pointing at the same PersistentVolumeClaim as the failed pod (to pick up the data that was already replicated), switch the primary server to one of the standby servers if the primary server fails, and so on.","title":"Outages"},{"location":"connectors/repository/xtdb/#limitations","text":"There are a number of limitations to be aware of with the high availability configuration: Must use a non-embedded XTDB back-end Write operations will only be consistent when using a non-embedded XTDB back-end: e.g. Kafka, S3, or JDBC. Read operations are eventually consistent Since the indexes are local to each pod, read operations will be eventually consistent: the specific pod to which a query is routed may not yet have updated its embedded index with the results of the very latest write operations from some other pod. (Note in particular that this has a knock-on impact to our test suites, which currently assume immediate consistency: expect various scenarios to fail if you decide to run them against an eventually-consistent HA configuration.) Cannot yet be dynamically scaled Currently configuration of Egeria requires making a number of REST API calls, which limits how dynamic we can be in adding or removing pods to an already-running cluster (in particular: we cannot rely on a readiness probe to indicate pod readiness to process actual work, but only its readiness to be configured ). We hope to address this soon by allowing configuration and startup to be done without relying on REST calls, at which point we should be able to also support dynamically adding and removing pods from the cluster. For other databases, modify the JDBC_DRIVER_URL value in the configmap.yaml of the chart to point to the location of the appropriate driver, and replace the use of the bin/bootstrapConfig.sh script in the init-and-report.yaml template with an inline script in that template (to specify the appropriate XTDB configuration and JDBC dialect to use for the document store ). \u21a9","title":"Limitations"},{"location":"connectors/repository/xtdb/performance/","text":"XTDB Connector Performance \u00b6 Following are details on XTDB's performance at the latest release of the connector (v3.1, using XTDB v1.18.1). All raw metrics and elements used to produce the results are described further under reproducibility below, but the historical details themselves are no longer included below in the interest of being concise. Details on the performance metrics The median of all results for that method across all executions for a given set of volume parameters is given (all times in milliseconds) to give an idea of the \"typical\" result, while limiting potential skew from significant outliers. A more detailed set of statistics is best reviewed through the Jupyter Notebook provided in each results directory, where you can review: the full distributions of execution times (including the outliers) detailed individual outlier results (e.g. the top-10 slowest response times per method) volumes in place during the tests (how many entities, how many relationships, etc) The volume parameters that were used for each test are specified using the convention i-s , where i is the value for the instancesPerType parameter to the PTS and s is the value for maxSearchResults . For example, 5-2 means 5 instances will be created for every open metadata type and 2 will be the maximum number of results per page for methods that include paging. All tests are run from 5-2 through 20-10 to give a sense of the performance impact of doubling the number of instances and search results. Above this, the graph queries are no longer included: they become exponentially more complex as the volumes grow, and while they will still return results, the depth of their testing in the PTS means that they can contribute many hours (or even days) to the overall suite execution -- they are therefore left out to be able to more quickly produce results for the other methods at progressively higher volumes. The page size is left at a maximum of 10 for subsequent tests so that it is only the volume of instances in total that are doubling each time, rather than also the number of detailed results. Instance counts range from a few thousand (at 5-2 ) up to nearly one hundred thousand (at 80-10 ). In the graphical comparisons, a point plot is used to show the typical execution time of each method at the different volumes / by repository. Each point on the plot represents the median execution time for that method, at a given volume of metadata. (For the repository comparison plots, pts = XTDB and janus = JanusGraph.) The horizontal lines that appear around each point are confidence intervals calculated by a bootstrapping process: in simple terms, the larger the horizontal line, the more variability there is for that particular method's execution time (a singular median value is insufficient to represent such variability on its own). XTDB at varying volumes \u00b6 Summary The retrieval and write operations remain very consistent, with almost no variability, throughout the growth in volume. The search operations, however, begin to clearly degrade at the highest volumes tested. Further investigation into other optimized settings for the search operations for these larger volumes is likely warranted as the next step to continue to improve performance. Profile Method 05-02 (4,850) 10-05 (9,700) 20-10 (19,400) 40-10 (38,800) 80-10 (77,600) Entity creation addEntity 55.0 48.0 46.0 48.0 44.0 ... saveEntityReferenceCopy 52.0 45.0 43.0 46.0 42.0 Entity search findEntities 54.0 65.0 88.0 215.0 413.0 ... findEntitiesByProperty 31.0 36.0 44.0 100.0 151.0 ... findEntitiesByPropertyValue 58.0 71.0 102.0 170.0 331.0 Relationship creation addRelationship 48.0 47.0 45.0 47.0 44.0 ... saveRelationshipReferenceCopy 52.0 49.0 47.0 49.0 46.0 Relationship search findRelationships 28.0 30.0 33.0 39.0 39.0 ... findRelationshipsByProperty 29.0 35.0 43.0 105.0 166.0 ... findRelationshipsByPropertyValue 47.0 59.0 78.0 159.0 362.0 Entity classification classifyEntity 78.0 73.5 72.0 75.0 73.0 ... saveClassificationReferenceCopy 70.0 59.0 63.0 64.0 62.0 Classification search findEntitiesByClassification 37.0 44.0 60.0 97.0 113.0 Entity update reTypeEntity 44.0 41.0 40.0 46.0 41.0 ... updateEntityProperties 58.0 53.0 53.0 49.0 49.0 Relationship update updateRelationshipProperties 63.0 56.0 56.0 56.0 54.0 Classification update updateEntityClassification 96.0 92.5 87.0 90.0 88.0 Entity undo undoEntityUpdate 49.0 53.0 50.0 48.0 44.0 Relationship undo undoRelationshipUpdate 56.0 55.0 54.0 53.0 52.0 Entity retrieval getEntityDetail 17.0 16.0 16.0 16.0 16.0 ... getEntitySummary 17.0 16.0 16.0 16.0 16.0 ... isEntityKnown 17.0 16.0 16.0 16.0 16.0 Entity history retrieval getEntityDetail 20.0 19.0 19.0 19.0 19.0 ... getEntityDetailHistory 22.0 21.0 21.0 21.0 21.0 Relationship retrieval getRelationship 18.0 17.0 17.0 18.0 17.0 ... isRelationshipKnown 18.0 17.0 17.0 18.0 17.0 Relationship history retrieval getRelationship 21.0 21.0 21.0 21.0 21.0 ... getRelationshipHistory 23.0 22.0 22.0 22.0 22.0 Entity history search findEntities 60.5 89.0 140.0 549.5 1574.0 ... findEntitiesByProperty 31.0 34.0 40.0 55.0 73.0 ... findEntitiesByPropertyValue 54.0 75.0 129.5 295.5 676.0 Relationship history search findRelationships 28.0 34.0 43.0 49.0 49.0 ... findRelationshipsByProperty 33.0 41.0 55.0 63.0 65.0 ... findRelationshipsByPropertyValue 55.0 84.0 143.0 228.0 516.0 Graph queries getEntityNeighborhood 27.0 26.0 24.0 -- -- ... getLinkingEntities 21.0 25.0 26.0 -- -- ... getRelatedEntities 563.0 1057.0 1873.0 -- -- ... getRelationshipsForEntity 26.0 27.0 25.0 -- -- Graph history queries getEntityNeighborhood 26.0 25.0 24.0 -- -- ... getLinkingEntities 21.0 25.0 26.0 -- -- ... getRelatedEntities 559.5 1057.5 1873.0 -- -- ... getRelationshipsForEntity 25.0 25.0 24.0 -- -- Entity re-home reHomeEntity 46.0 45.0 44.0 51.0 45.0 Relationship re-home reHomeRelationship 43.0 45.0 41.0 46.0 44.0 Entity declassify declassifyEntity 66.0 63.0 63.0 68.5 64.0 ... purgeClassificationReferenceCopy 58.0 55.5 55.5 62.0 56.0 Entity re-identify reIdentifyEntity 55.0 51.0 49.0 64.0 56.0 Relationship re-identify reIdentifyRelationship 44.0 47.0 40.0 49.0 44.0 Relationship delete deleteRelationship 40.0 40.0 39.0 47.0 41.0 Entity delete deleteEntity 45.0 45.0 43.0 55.0 48.0 Entity restore restoreEntity 39.0 39.0 37.0 45.0 40.0 Relationship restore restoreRelationship 37.0 39.0 36.0 43.0 36.0 Relationship purge purgeRelationship 32.0 32.0 30.0 39.0 33.0 ... purgeRelationshipReferenceCopy 23.0 24.0 22.0 27.0 24.0 Entity purge purgeEntity 40.0 40.0 40.0 52.0 45.0 ... purgeEntityReferenceCopy 24.0 24.0 24.0 29.0 26.0 XTDB vs JanusGraph \u00b6 Summary In almost all cases, the XTDB repository is significantly faster than JanusGraph: at most volumes completing all methods in less than 100ms and with very little variability. For JanusGraph, on the other hand, there is significant variability (in particular for methods like findEntitiesByClassification ), and there are numerous examples of the median execution time taking more than multiple seconds. Even at 8 times the volume of metadata the XTDB connector still outperforms the JanusGraph connector in almost every method (the only exceptions being a few of the find methods, where the performance is approximately even at 2-4 times the volume). Graph queries were disabled for JanusGraph The graph queries were disabled for JanusGraph in order to have results in a timely manner: it would take more than a month to produce results for these queries for the JanusGraph connector. The XTDB results can be difficult to see in detail due to the skew from the Janus results, so it may be easier to look at this more granular comparison that drops the higher scales of Janus for readability of the XTDB results: Profile Method 05-02 (XTDB) 05-02 (Janus) 10-05 (XTDB) 10-05 (Janus) 20-10 (XTDB) 20-10 (Janus) 40-10 (XTDB) 40-10 (Janus) 80-10 (XTDB) 80-10 (Janus) Entity creation addEntity 55.0 440.0 48.0 450.0 46.0 483.0 48.0 481.0 44.0 DNF ... saveEntityReferenceCopy 52.0 435.0 45.0 451.0 43.0 481.0 46.0 479.0 42.0 DNF Entity search findEntities 54.0 260.0 65.0 454.0 88.0 973.5 215.0 2104.0 413.0 DNF ... findEntitiesByProperty 31.0 40.0 36.0 50.0 44.0 79.0 100.0 115.0 151.0 DNF ... findEntitiesByPropertyValue 58.0 85.0 71.0 94.0 102.0 123.0 170.0 165.0 331.0 DNF Relationship creation addRelationship 48.0 160.0 47.0 162.0 45.0 162.5 47.0 156.0 44.0 DNF ... saveRelationshipReferenceCopy 52.0 460.0 49.0 456.0 47.0 480.0 49.0 464.0 46.0 DNF Relationship search findRelationships 28.0 45.0 30.0 60.0 33.0 99.0 39.0 146.0 39.0 DNF ... findRelationshipsByProperty 29.0 48.0 35.0 63.0 43.0 109.0 105.0 171.0 166.0 DNF ... findRelationshipsByPropertyValue 47.0 71.0 59.0 86.0 78.0 120.0 159.0 181.0 362.0 DNF Entity classification classifyEntity 78.0 886.0 73.5 921.5 72.0 1031.0 75.0 961.0 73.0 DNF ... saveClassificationReferenceCopy 70.0 738.0 59.0 845.5 63.0 969.5 64.0 895.5 62.0 DNF Classification search findEntitiesByClassification 37.0 606.0 44.0 1029.0 60.0 2195.5 97.0 3696.0 113.0 DNF Entity update reTypeEntity 44.0 390.0 41.0 374.5 40.0 453.0 46.0 381.0 41.0 DNF ... updateEntityProperties 58.0 698.0 53.0 720.5 53.0 804.0 49.0 776.5 49.0 DNF Relationship update updateRelationshipProperties 63.0 456.5 56.0 467.0 56.0 499.0 56.0 456.0 54.0 DNF Classification update updateEntityClassification 96.0 1178.5 92.5 1259.5 87.0 1410.0 90.0 1262.0 88.0 DNF Entity undo undoEntityUpdate 49.0 -- 53.0 -- 50.0 -- 48.0 -- 44.0 -- Relationship undo undoRelationshipUpdate 56.0 -- 55.0 -- 54.0 -- 53.0 -- 52.0 -- Entity retrieval getEntityDetail 17.0 18.0 16.0 18.0 16.0 16.0 16.0 16.0 16.0 DNF ... getEntitySummary 17.0 17.0 16.0 17.0 16.0 15.0 16.0 15.0 16.0 DNF ... isEntityKnown 17.0 19.0 16.0 18.0 16.0 16.0 16.0 16.0 16.0 DNF Entity history retrieval getEntityDetail 20.0 -- 19.0 -- 19.0 -- 19.0 -- 19.0 -- ... getEntityDetailHistory 22.0 -- 21.0 -- 21.0 -- 21.0 -- 21.0 -- Relationship retrieval getRelationship 18.0 23.0 17.0 20.0 17.0 19.0 18.0 18.0 17.0 DNF ... isRelationshipKnown 18.0 23.0 17.0 20.0 17.0 19.0 18.0 18.0 17.0 DNF Relationship history retrieval getRelationship 21.0 -- 21.0 -- 21.0 -- 21.0 -- 21.0 -- ... getRelationshipHistory 23.0 -- 22.0 -- 22.0 -- 22.0 -- 22.0 -- Entity history search findEntities 60.5 -- 89.0 -- 140.0 -- 549.5 -- 1574.0 -- ... findEntitiesByProperty 31.0 -- 34.0 -- 40.0 -- 55.0 -- 73.0 -- ... findEntitiesByPropertyValue 54.0 -- 75.0 -- 129.5 -- 295.5 -- 676.0 -- Relationship history search findRelationships 28.0 -- 34.0 -- 43.0 -- 49.0 -- 49.0 -- ... findRelationshipsByProperty 33.0 -- 41.0 -- 55.0 -- 63.0 -- 65.0 -- ... findRelationshipsByPropertyValue 55.0 -- 84.0 -- 143.0 -- 228.0 -- 516.0 -- Graph queries getEntityNeighborhood 27.0 -- 26.0 -- 24.0 -- -- -- -- -- ... getLinkingEntities 21.0 -- 25.0 -- 26.0 -- -- -- -- -- ... getRelatedEntities 563.0 -- 1057.0 -- 1873.0 -- -- -- -- -- ... getRelationshipsForEntity 26.0 -- 27.0 -- 25.0 -- -- -- -- -- Graph history queries getEntityNeighborhood 26.0 -- 25.0 -- 24.0 -- -- -- -- -- ... getLinkingEntities 21.0 -- 25.0 -- 26.0 -- -- -- -- -- ... getRelatedEntities 559.5 -- 1057.5 -- 1873.0 -- -- -- -- -- ... getRelationshipsForEntity 25.0 -- 25.0 -- 24.0 -- -- -- -- -- Entity re-home reHomeEntity 46.0 759.0 45.0 739.0 44.0 909.0 51.0 775.0 45.0 DNF Relationship re-home reHomeRelationship 43.0 405.5 45.0 394.0 41.0 453.0 46.0 394.0 44.0 DNF Entity declassify declassifyEntity 66.0 1302.0 63.0 1374.5 63.0 1629.0 68.5 1420.0 64.0 DNF ... purgeClassificationReferenceCopy 58.0 -- 55.5 -- 55.5 -- 62.0 -- 56.0 -- Entity re-identify reIdentifyEntity 55.0 1745.0 51.0 1735.0 49.0 2310.5 64.0 1864.0 56.0 DNF Relationship re-identify reIdentifyRelationship 44.0 855.0 47.0 823.5 40.0 950.5 49.0 885.0 44.0 DNF Relationship delete deleteRelationship 40.0 398.0 40.0 407.0 39.0 466.0 47.0 434.0 41.0 DNF Entity delete deleteEntity 45.0 785.0 45.0 824.0 43.0 1054.0 55.0 886.0 48.0 DNF Entity restore restoreEntity 39.0 809.5 39.0 871.0 37.0 1091.0 45.0 874.0 40.0 DNF Relationship restore restoreRelationship 37.0 395.0 39.0 401.0 36.0 517.0 43.0 443.0 36.0 DNF Relationship purge purgeRelationship 32.0 146.0 32.0 194.0 30.0 210.0 39.0 202.0 33.0 DNF ... purgeRelationshipReferenceCopy 23.0 118.0 24.0 116.0 22.0 126.0 27.0 117.0 24.0 DNF Entity purge purgeEntity 40.0 271.0 40.0 381.0 40.0 433.5 52.0 416.0 45.0 DNF ... purgeEntityReferenceCopy 24.0 271.0 24.0 259.0 24.0 277.0 29.0 253.0 26.0 DNF Reproducibility \u00b6 Re-running the tests \u00b6 Two Helm charts are provided, that were used to automate the execution of these suites against the XTDB repository connector: The Helm chart used to execute the CTS suite The Helm chart used to execute the PTS suite These use a default configuration for the XTDB repository where Lucene is used as a text index and RocksDB is used for all persistence: index store, document store and transaction log. No additional tuning of any parameters (XTDB or RocksDB) is applied: they use all of their default settings. Data points \u00b6 The cts/results directory in the code repository for the connector contains results of running the suites against the XTDB connector. For each test suite execution, you will find the following details: openmetadata_cts_summary.json - a summary of the results of each profile Description of the k8s environment deployment - details of the deployed components used for the test configmap.yaml - details of the variables used within the components of the test The OMAG Server configurations: omag.server.[crux|xtdb].config - the configuration of the XTDB connector (proxy) omag.server.cts.config - the configuration of the test workbench The cohort registrations: cohort.coco.[crux|xtdb].local - the local XTDB connector (proxy) cohort registration information cohort.coco.[crux|xtdb].remote - the cohort members considered remote from the XTDB connector (proxy)'s perspective cohort.coco.cts.local - the local test Workbench cohort registration cohort.coco.cts.remote - the cohort members considered remote from the test Workbench's perspective Detailed results: pd.tar.gz - an archive containing the full detailed results of every profile tested tcd.tar.gz - an archive containing the full detailed results of every test case executed Jupyter Notebooks used to analyze the results: analyze-performance-results.ipynb - details about the environment, instance counts, and distribution of elapsed times per method, also illustrating how the results can be analyzed more deeply calculate-medians.ipynb - used to calculate the medians displayed in the table further below (to run either of these notebooks, you will need to first extract the pd.tar.gz file to have the JSON results files for analysis)","title":"XTDB Connector Performance"},{"location":"connectors/repository/xtdb/performance/#xtdb-connector-performance","text":"Following are details on XTDB's performance at the latest release of the connector (v3.1, using XTDB v1.18.1). All raw metrics and elements used to produce the results are described further under reproducibility below, but the historical details themselves are no longer included below in the interest of being concise. Details on the performance metrics The median of all results for that method across all executions for a given set of volume parameters is given (all times in milliseconds) to give an idea of the \"typical\" result, while limiting potential skew from significant outliers. A more detailed set of statistics is best reviewed through the Jupyter Notebook provided in each results directory, where you can review: the full distributions of execution times (including the outliers) detailed individual outlier results (e.g. the top-10 slowest response times per method) volumes in place during the tests (how many entities, how many relationships, etc) The volume parameters that were used for each test are specified using the convention i-s , where i is the value for the instancesPerType parameter to the PTS and s is the value for maxSearchResults . For example, 5-2 means 5 instances will be created for every open metadata type and 2 will be the maximum number of results per page for methods that include paging. All tests are run from 5-2 through 20-10 to give a sense of the performance impact of doubling the number of instances and search results. Above this, the graph queries are no longer included: they become exponentially more complex as the volumes grow, and while they will still return results, the depth of their testing in the PTS means that they can contribute many hours (or even days) to the overall suite execution -- they are therefore left out to be able to more quickly produce results for the other methods at progressively higher volumes. The page size is left at a maximum of 10 for subsequent tests so that it is only the volume of instances in total that are doubling each time, rather than also the number of detailed results. Instance counts range from a few thousand (at 5-2 ) up to nearly one hundred thousand (at 80-10 ). In the graphical comparisons, a point plot is used to show the typical execution time of each method at the different volumes / by repository. Each point on the plot represents the median execution time for that method, at a given volume of metadata. (For the repository comparison plots, pts = XTDB and janus = JanusGraph.) The horizontal lines that appear around each point are confidence intervals calculated by a bootstrapping process: in simple terms, the larger the horizontal line, the more variability there is for that particular method's execution time (a singular median value is insufficient to represent such variability on its own).","title":"XTDB Connector Performance"},{"location":"connectors/repository/xtdb/performance/#xtdb-at-varying-volumes","text":"Summary The retrieval and write operations remain very consistent, with almost no variability, throughout the growth in volume. The search operations, however, begin to clearly degrade at the highest volumes tested. Further investigation into other optimized settings for the search operations for these larger volumes is likely warranted as the next step to continue to improve performance. Profile Method 05-02 (4,850) 10-05 (9,700) 20-10 (19,400) 40-10 (38,800) 80-10 (77,600) Entity creation addEntity 55.0 48.0 46.0 48.0 44.0 ... saveEntityReferenceCopy 52.0 45.0 43.0 46.0 42.0 Entity search findEntities 54.0 65.0 88.0 215.0 413.0 ... findEntitiesByProperty 31.0 36.0 44.0 100.0 151.0 ... findEntitiesByPropertyValue 58.0 71.0 102.0 170.0 331.0 Relationship creation addRelationship 48.0 47.0 45.0 47.0 44.0 ... saveRelationshipReferenceCopy 52.0 49.0 47.0 49.0 46.0 Relationship search findRelationships 28.0 30.0 33.0 39.0 39.0 ... findRelationshipsByProperty 29.0 35.0 43.0 105.0 166.0 ... findRelationshipsByPropertyValue 47.0 59.0 78.0 159.0 362.0 Entity classification classifyEntity 78.0 73.5 72.0 75.0 73.0 ... saveClassificationReferenceCopy 70.0 59.0 63.0 64.0 62.0 Classification search findEntitiesByClassification 37.0 44.0 60.0 97.0 113.0 Entity update reTypeEntity 44.0 41.0 40.0 46.0 41.0 ... updateEntityProperties 58.0 53.0 53.0 49.0 49.0 Relationship update updateRelationshipProperties 63.0 56.0 56.0 56.0 54.0 Classification update updateEntityClassification 96.0 92.5 87.0 90.0 88.0 Entity undo undoEntityUpdate 49.0 53.0 50.0 48.0 44.0 Relationship undo undoRelationshipUpdate 56.0 55.0 54.0 53.0 52.0 Entity retrieval getEntityDetail 17.0 16.0 16.0 16.0 16.0 ... getEntitySummary 17.0 16.0 16.0 16.0 16.0 ... isEntityKnown 17.0 16.0 16.0 16.0 16.0 Entity history retrieval getEntityDetail 20.0 19.0 19.0 19.0 19.0 ... getEntityDetailHistory 22.0 21.0 21.0 21.0 21.0 Relationship retrieval getRelationship 18.0 17.0 17.0 18.0 17.0 ... isRelationshipKnown 18.0 17.0 17.0 18.0 17.0 Relationship history retrieval getRelationship 21.0 21.0 21.0 21.0 21.0 ... getRelationshipHistory 23.0 22.0 22.0 22.0 22.0 Entity history search findEntities 60.5 89.0 140.0 549.5 1574.0 ... findEntitiesByProperty 31.0 34.0 40.0 55.0 73.0 ... findEntitiesByPropertyValue 54.0 75.0 129.5 295.5 676.0 Relationship history search findRelationships 28.0 34.0 43.0 49.0 49.0 ... findRelationshipsByProperty 33.0 41.0 55.0 63.0 65.0 ... findRelationshipsByPropertyValue 55.0 84.0 143.0 228.0 516.0 Graph queries getEntityNeighborhood 27.0 26.0 24.0 -- -- ... getLinkingEntities 21.0 25.0 26.0 -- -- ... getRelatedEntities 563.0 1057.0 1873.0 -- -- ... getRelationshipsForEntity 26.0 27.0 25.0 -- -- Graph history queries getEntityNeighborhood 26.0 25.0 24.0 -- -- ... getLinkingEntities 21.0 25.0 26.0 -- -- ... getRelatedEntities 559.5 1057.5 1873.0 -- -- ... getRelationshipsForEntity 25.0 25.0 24.0 -- -- Entity re-home reHomeEntity 46.0 45.0 44.0 51.0 45.0 Relationship re-home reHomeRelationship 43.0 45.0 41.0 46.0 44.0 Entity declassify declassifyEntity 66.0 63.0 63.0 68.5 64.0 ... purgeClassificationReferenceCopy 58.0 55.5 55.5 62.0 56.0 Entity re-identify reIdentifyEntity 55.0 51.0 49.0 64.0 56.0 Relationship re-identify reIdentifyRelationship 44.0 47.0 40.0 49.0 44.0 Relationship delete deleteRelationship 40.0 40.0 39.0 47.0 41.0 Entity delete deleteEntity 45.0 45.0 43.0 55.0 48.0 Entity restore restoreEntity 39.0 39.0 37.0 45.0 40.0 Relationship restore restoreRelationship 37.0 39.0 36.0 43.0 36.0 Relationship purge purgeRelationship 32.0 32.0 30.0 39.0 33.0 ... purgeRelationshipReferenceCopy 23.0 24.0 22.0 27.0 24.0 Entity purge purgeEntity 40.0 40.0 40.0 52.0 45.0 ... purgeEntityReferenceCopy 24.0 24.0 24.0 29.0 26.0","title":"XTDB at varying volumes"},{"location":"connectors/repository/xtdb/performance/#xtdb-vs-janusgraph","text":"Summary In almost all cases, the XTDB repository is significantly faster than JanusGraph: at most volumes completing all methods in less than 100ms and with very little variability. For JanusGraph, on the other hand, there is significant variability (in particular for methods like findEntitiesByClassification ), and there are numerous examples of the median execution time taking more than multiple seconds. Even at 8 times the volume of metadata the XTDB connector still outperforms the JanusGraph connector in almost every method (the only exceptions being a few of the find methods, where the performance is approximately even at 2-4 times the volume). Graph queries were disabled for JanusGraph The graph queries were disabled for JanusGraph in order to have results in a timely manner: it would take more than a month to produce results for these queries for the JanusGraph connector. The XTDB results can be difficult to see in detail due to the skew from the Janus results, so it may be easier to look at this more granular comparison that drops the higher scales of Janus for readability of the XTDB results: Profile Method 05-02 (XTDB) 05-02 (Janus) 10-05 (XTDB) 10-05 (Janus) 20-10 (XTDB) 20-10 (Janus) 40-10 (XTDB) 40-10 (Janus) 80-10 (XTDB) 80-10 (Janus) Entity creation addEntity 55.0 440.0 48.0 450.0 46.0 483.0 48.0 481.0 44.0 DNF ... saveEntityReferenceCopy 52.0 435.0 45.0 451.0 43.0 481.0 46.0 479.0 42.0 DNF Entity search findEntities 54.0 260.0 65.0 454.0 88.0 973.5 215.0 2104.0 413.0 DNF ... findEntitiesByProperty 31.0 40.0 36.0 50.0 44.0 79.0 100.0 115.0 151.0 DNF ... findEntitiesByPropertyValue 58.0 85.0 71.0 94.0 102.0 123.0 170.0 165.0 331.0 DNF Relationship creation addRelationship 48.0 160.0 47.0 162.0 45.0 162.5 47.0 156.0 44.0 DNF ... saveRelationshipReferenceCopy 52.0 460.0 49.0 456.0 47.0 480.0 49.0 464.0 46.0 DNF Relationship search findRelationships 28.0 45.0 30.0 60.0 33.0 99.0 39.0 146.0 39.0 DNF ... findRelationshipsByProperty 29.0 48.0 35.0 63.0 43.0 109.0 105.0 171.0 166.0 DNF ... findRelationshipsByPropertyValue 47.0 71.0 59.0 86.0 78.0 120.0 159.0 181.0 362.0 DNF Entity classification classifyEntity 78.0 886.0 73.5 921.5 72.0 1031.0 75.0 961.0 73.0 DNF ... saveClassificationReferenceCopy 70.0 738.0 59.0 845.5 63.0 969.5 64.0 895.5 62.0 DNF Classification search findEntitiesByClassification 37.0 606.0 44.0 1029.0 60.0 2195.5 97.0 3696.0 113.0 DNF Entity update reTypeEntity 44.0 390.0 41.0 374.5 40.0 453.0 46.0 381.0 41.0 DNF ... updateEntityProperties 58.0 698.0 53.0 720.5 53.0 804.0 49.0 776.5 49.0 DNF Relationship update updateRelationshipProperties 63.0 456.5 56.0 467.0 56.0 499.0 56.0 456.0 54.0 DNF Classification update updateEntityClassification 96.0 1178.5 92.5 1259.5 87.0 1410.0 90.0 1262.0 88.0 DNF Entity undo undoEntityUpdate 49.0 -- 53.0 -- 50.0 -- 48.0 -- 44.0 -- Relationship undo undoRelationshipUpdate 56.0 -- 55.0 -- 54.0 -- 53.0 -- 52.0 -- Entity retrieval getEntityDetail 17.0 18.0 16.0 18.0 16.0 16.0 16.0 16.0 16.0 DNF ... getEntitySummary 17.0 17.0 16.0 17.0 16.0 15.0 16.0 15.0 16.0 DNF ... isEntityKnown 17.0 19.0 16.0 18.0 16.0 16.0 16.0 16.0 16.0 DNF Entity history retrieval getEntityDetail 20.0 -- 19.0 -- 19.0 -- 19.0 -- 19.0 -- ... getEntityDetailHistory 22.0 -- 21.0 -- 21.0 -- 21.0 -- 21.0 -- Relationship retrieval getRelationship 18.0 23.0 17.0 20.0 17.0 19.0 18.0 18.0 17.0 DNF ... isRelationshipKnown 18.0 23.0 17.0 20.0 17.0 19.0 18.0 18.0 17.0 DNF Relationship history retrieval getRelationship 21.0 -- 21.0 -- 21.0 -- 21.0 -- 21.0 -- ... getRelationshipHistory 23.0 -- 22.0 -- 22.0 -- 22.0 -- 22.0 -- Entity history search findEntities 60.5 -- 89.0 -- 140.0 -- 549.5 -- 1574.0 -- ... findEntitiesByProperty 31.0 -- 34.0 -- 40.0 -- 55.0 -- 73.0 -- ... findEntitiesByPropertyValue 54.0 -- 75.0 -- 129.5 -- 295.5 -- 676.0 -- Relationship history search findRelationships 28.0 -- 34.0 -- 43.0 -- 49.0 -- 49.0 -- ... findRelationshipsByProperty 33.0 -- 41.0 -- 55.0 -- 63.0 -- 65.0 -- ... findRelationshipsByPropertyValue 55.0 -- 84.0 -- 143.0 -- 228.0 -- 516.0 -- Graph queries getEntityNeighborhood 27.0 -- 26.0 -- 24.0 -- -- -- -- -- ... getLinkingEntities 21.0 -- 25.0 -- 26.0 -- -- -- -- -- ... getRelatedEntities 563.0 -- 1057.0 -- 1873.0 -- -- -- -- -- ... getRelationshipsForEntity 26.0 -- 27.0 -- 25.0 -- -- -- -- -- Graph history queries getEntityNeighborhood 26.0 -- 25.0 -- 24.0 -- -- -- -- -- ... getLinkingEntities 21.0 -- 25.0 -- 26.0 -- -- -- -- -- ... getRelatedEntities 559.5 -- 1057.5 -- 1873.0 -- -- -- -- -- ... getRelationshipsForEntity 25.0 -- 25.0 -- 24.0 -- -- -- -- -- Entity re-home reHomeEntity 46.0 759.0 45.0 739.0 44.0 909.0 51.0 775.0 45.0 DNF Relationship re-home reHomeRelationship 43.0 405.5 45.0 394.0 41.0 453.0 46.0 394.0 44.0 DNF Entity declassify declassifyEntity 66.0 1302.0 63.0 1374.5 63.0 1629.0 68.5 1420.0 64.0 DNF ... purgeClassificationReferenceCopy 58.0 -- 55.5 -- 55.5 -- 62.0 -- 56.0 -- Entity re-identify reIdentifyEntity 55.0 1745.0 51.0 1735.0 49.0 2310.5 64.0 1864.0 56.0 DNF Relationship re-identify reIdentifyRelationship 44.0 855.0 47.0 823.5 40.0 950.5 49.0 885.0 44.0 DNF Relationship delete deleteRelationship 40.0 398.0 40.0 407.0 39.0 466.0 47.0 434.0 41.0 DNF Entity delete deleteEntity 45.0 785.0 45.0 824.0 43.0 1054.0 55.0 886.0 48.0 DNF Entity restore restoreEntity 39.0 809.5 39.0 871.0 37.0 1091.0 45.0 874.0 40.0 DNF Relationship restore restoreRelationship 37.0 395.0 39.0 401.0 36.0 517.0 43.0 443.0 36.0 DNF Relationship purge purgeRelationship 32.0 146.0 32.0 194.0 30.0 210.0 39.0 202.0 33.0 DNF ... purgeRelationshipReferenceCopy 23.0 118.0 24.0 116.0 22.0 126.0 27.0 117.0 24.0 DNF Entity purge purgeEntity 40.0 271.0 40.0 381.0 40.0 433.5 52.0 416.0 45.0 DNF ... purgeEntityReferenceCopy 24.0 271.0 24.0 259.0 24.0 277.0 29.0 253.0 26.0 DNF","title":"XTDB vs JanusGraph"},{"location":"connectors/repository/xtdb/performance/#reproducibility","text":"","title":"Reproducibility"},{"location":"connectors/repository/xtdb/performance/#re-running-the-tests","text":"Two Helm charts are provided, that were used to automate the execution of these suites against the XTDB repository connector: The Helm chart used to execute the CTS suite The Helm chart used to execute the PTS suite These use a default configuration for the XTDB repository where Lucene is used as a text index and RocksDB is used for all persistence: index store, document store and transaction log. No additional tuning of any parameters (XTDB or RocksDB) is applied: they use all of their default settings.","title":"Re-running the tests"},{"location":"connectors/repository/xtdb/performance/#data-points","text":"The cts/results directory in the code repository for the connector contains results of running the suites against the XTDB connector. For each test suite execution, you will find the following details: openmetadata_cts_summary.json - a summary of the results of each profile Description of the k8s environment deployment - details of the deployed components used for the test configmap.yaml - details of the variables used within the components of the test The OMAG Server configurations: omag.server.[crux|xtdb].config - the configuration of the XTDB connector (proxy) omag.server.cts.config - the configuration of the test workbench The cohort registrations: cohort.coco.[crux|xtdb].local - the local XTDB connector (proxy) cohort registration information cohort.coco.[crux|xtdb].remote - the cohort members considered remote from the XTDB connector (proxy)'s perspective cohort.coco.cts.local - the local test Workbench cohort registration cohort.coco.cts.remote - the cohort members considered remote from the test Workbench's perspective Detailed results: pd.tar.gz - an archive containing the full detailed results of every profile tested tcd.tar.gz - an archive containing the full detailed results of every test case executed Jupyter Notebooks used to analyze the results: analyze-performance-results.ipynb - details about the environment, instance counts, and distribution of elapsed times per method, also illustrating how the results can be analyzed more deeply calculate-medians.ipynb - used to calculate the medians displayed in the table further below (to run either of these notebooks, you will need to first extract the pd.tar.gz file to have the JSON results files for analysis)","title":"Data points"},{"location":"connectors/repository/xtdb/upgrade/","text":"Upgrading the XTDB Connector \u00b6 The connector embeds its own persistence layer (storage) for metadata in XTDB. While we try to keep this underlying storage unchanged as much as possible to ease moving from one version of the connector to another, this is not always possible. It may therefore be necessary to occasionally migrate any pre-existing metadata stored in the embedded XTDB repository in order to make use of the latest features and performance benefits of a new version of the connector. Persistence layer version must be compatible with connector version To ensure the integrity of the metadata, the connector will validate that the version of the persistence matches the version the connector expects before even attempting to run -- if this validation fails, you will see an OMRS-XTDB-REPOSITORY-500-003 error in the audit log to indicate that you must first migrate the metadata before running this version of the connector. In other words: if migration is needed, the newer version of the connector will not allow you to run against an older set of metadata without first running the migration. Your only options will be to continue to use an older version of the connector (with which your pre-existing metadata is compatible), or to run this offline migration of your repository and then run the newer version of the connector. The migration itself runs outside the connector (while the connector is offline), in order to maximize the throughput of the in-place upgrade of the repository. The time it takes to run the migration naturally depends on a number of factors, such as the amount of pre-existing metadata that must be migrated and the specific changes needed by the upgrade. As a very approximate metric, we would expect the in-place upgrade to be capable of migrating 60-100 metadata instances (entities or relationships) per second. So 10 000 instances should take approximately 2 minutes. 1. Obtain migrator \u00b6 Start by downloading the XTDB repository migrator: Latest release Latest snapshot The migrator is egeria-connector-xtdb-migrator-{version}-jar-with-dependencies.jar 2. Configure repository \u00b6 Before running the migrator, define the configuration of your repository. The configuration must be defined in a JSON file, following XTDB's JSON configuration format . Take XTDB configuration from Egeria connector configuration The simplest way to ensure this matches the configuration used by your connector is to copy the xtdbConfig property from the request you POST to Egeria to configure your connector. Simply be certain to replace any relative paths with absolute paths to data to ensure the migrator can find the metadata. Example connector configuration in Egeria 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" }, \"configurationProperties\" : { \"xtdbConfig\" : { \"xtdb/index-store\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-index\" } }, \"xtdb/document-store\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-docs\" } }, \"xtdb/tx-log\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-tx\" } }, \"xtdb.lucene/lucene-store\" : { \"db-dir\" : \"data/servers/xtdb/lucene\" } } } } 3. Make a backup \u00b6 As the migration runs in-place, it is always a good practice to take a backup of your repository first. Different configurations will require different approaches to backup. If your configuration makes use of pluggable components that have their own backup utilities (Kafka, JDBC, etc) then you should follow the best practices for backing up those components themselves: e.g. from Apache Kafka or the database vendor. For pluggable components that persist their data directly to the filesystem (RocksDB, Lucene, LMDB, etc), you may be able to simply backup the files directly. Ensure connector is not running before taking backup In all cases, you should ensure that your connector is shutdown (not running), and that any data is appropriately quiesced prior to running the backup. Example filesystem backup For example, running this command when the persistence is using the example configuration above: tar cvf backup.tar .../data/servers/xtdb will backup all the files used by RocksDB and Lucene: a .../data/servers/xtdb a .../data/servers/xtdb/rdb-index a .../data/servers/xtdb/lucene a .../data/servers/xtdb/config a .../data/servers/xtdb/cohorts a .../data/servers/xtdb/rdb-tx a .../data/servers/xtdb/rdb-docs ... 4. Run the in-place upgrade \u00b6 Run the following command to execute the in-place upgrade: Execute the in-place upgrade java -jar egeria-connector-xtdb-migrator-*-jar-with-dependencies.jar config.json Where config.json is the file containing your repository's configuration. If you run the migrator and no migration is actually needed, the output will indicate that your repository is already at the necessary version to work with this version of the connector, and no migration is needed. You can simply proceed with running the connector. Example output when no migration is needed Starting a XTDB node using configuration: config.json SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\". SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. ... checking if migration is needed (xtdb.api.java.JXtdbNode@25c4bb06) This node is already at the latest version of the persistence layer -- no migration needed. If a migration is necessary, it will immediately begin to run. The output will indicate the existing version of the persistence layer, and the version that is expected by this version of the connector. If you are making a jump across several migrations, you may see this last line appear multiple times with different existing versions listed each time: the in-place upgrade sequentially applies the necessary migrations step-by-step. Example output when migration is required Starting a XTDB node using configuration: config.json SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\". SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. ... checking if migration is needed (xtdb.api.java.JXtdbNode@25c4bb06) The node is at version -1, while latest is 2 -- migrating... 5. Start the connector \u00b6 Once the previous (in-place upgrade) command completes, you should now be able to start your connector. See the instructions on configuring the connector for more details. Change log \u00b6 There should be no need to actually understand these details, as the connector (and migration) will handle them for you. However, for the interested reader, the following changes were made to the storage layer in the specified release: 2.9 \u00b6 InstanceAuditHeaderMapping no longer separates the type GUID and supertype GUIDs, but places all such information into a single vector (for improved search performance) RelationshipMapping no longer has separate properties for each entity proxy, but stores them as a vector: this retains their ordering, but allows relationships to be more efficiently searched from either related entity","title":"Upgrading the XTDB Connector"},{"location":"connectors/repository/xtdb/upgrade/#upgrading-the-xtdb-connector","text":"The connector embeds its own persistence layer (storage) for metadata in XTDB. While we try to keep this underlying storage unchanged as much as possible to ease moving from one version of the connector to another, this is not always possible. It may therefore be necessary to occasionally migrate any pre-existing metadata stored in the embedded XTDB repository in order to make use of the latest features and performance benefits of a new version of the connector. Persistence layer version must be compatible with connector version To ensure the integrity of the metadata, the connector will validate that the version of the persistence matches the version the connector expects before even attempting to run -- if this validation fails, you will see an OMRS-XTDB-REPOSITORY-500-003 error in the audit log to indicate that you must first migrate the metadata before running this version of the connector. In other words: if migration is needed, the newer version of the connector will not allow you to run against an older set of metadata without first running the migration. Your only options will be to continue to use an older version of the connector (with which your pre-existing metadata is compatible), or to run this offline migration of your repository and then run the newer version of the connector. The migration itself runs outside the connector (while the connector is offline), in order to maximize the throughput of the in-place upgrade of the repository. The time it takes to run the migration naturally depends on a number of factors, such as the amount of pre-existing metadata that must be migrated and the specific changes needed by the upgrade. As a very approximate metric, we would expect the in-place upgrade to be capable of migrating 60-100 metadata instances (entities or relationships) per second. So 10 000 instances should take approximately 2 minutes.","title":"Upgrading the XTDB Connector"},{"location":"connectors/repository/xtdb/upgrade/#1-obtain-migrator","text":"Start by downloading the XTDB repository migrator: Latest release Latest snapshot The migrator is egeria-connector-xtdb-migrator-{version}-jar-with-dependencies.jar","title":"1. Obtain migrator"},{"location":"connectors/repository/xtdb/upgrade/#2-configure-repository","text":"Before running the migrator, define the configuration of your repository. The configuration must be defined in a JSON file, following XTDB's JSON configuration format . Take XTDB configuration from Egeria connector configuration The simplest way to ensure this matches the configuration used by your connector is to copy the xtdbConfig property from the request you POST to Egeria to configure your connector. Simply be certain to replace any relative paths with absolute paths to data to ensure the migrator can find the metadata. Example connector configuration in Egeria 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" }, \"configurationProperties\" : { \"xtdbConfig\" : { \"xtdb/index-store\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-index\" } }, \"xtdb/document-store\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-docs\" } }, \"xtdb/tx-log\" : { \"kv-store\" : { \"xtdb/module\" : \"xtdb.rocksdb/->kv-store\" , \"db-dir\" : \"data/servers/xtdb/rdb-tx\" } }, \"xtdb.lucene/lucene-store\" : { \"db-dir\" : \"data/servers/xtdb/lucene\" } } } }","title":"2. Configure repository"},{"location":"connectors/repository/xtdb/upgrade/#3-make-a-backup","text":"As the migration runs in-place, it is always a good practice to take a backup of your repository first. Different configurations will require different approaches to backup. If your configuration makes use of pluggable components that have their own backup utilities (Kafka, JDBC, etc) then you should follow the best practices for backing up those components themselves: e.g. from Apache Kafka or the database vendor. For pluggable components that persist their data directly to the filesystem (RocksDB, Lucene, LMDB, etc), you may be able to simply backup the files directly. Ensure connector is not running before taking backup In all cases, you should ensure that your connector is shutdown (not running), and that any data is appropriately quiesced prior to running the backup. Example filesystem backup For example, running this command when the persistence is using the example configuration above: tar cvf backup.tar .../data/servers/xtdb will backup all the files used by RocksDB and Lucene: a .../data/servers/xtdb a .../data/servers/xtdb/rdb-index a .../data/servers/xtdb/lucene a .../data/servers/xtdb/config a .../data/servers/xtdb/cohorts a .../data/servers/xtdb/rdb-tx a .../data/servers/xtdb/rdb-docs ...","title":"3. Make a backup"},{"location":"connectors/repository/xtdb/upgrade/#4-run-the-in-place-upgrade","text":"Run the following command to execute the in-place upgrade: Execute the in-place upgrade java -jar egeria-connector-xtdb-migrator-*-jar-with-dependencies.jar config.json Where config.json is the file containing your repository's configuration. If you run the migrator and no migration is actually needed, the output will indicate that your repository is already at the necessary version to work with this version of the connector, and no migration is needed. You can simply proceed with running the connector. Example output when no migration is needed Starting a XTDB node using configuration: config.json SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\". SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. ... checking if migration is needed (xtdb.api.java.JXtdbNode@25c4bb06) This node is already at the latest version of the persistence layer -- no migration needed. If a migration is necessary, it will immediately begin to run. The output will indicate the existing version of the persistence layer, and the version that is expected by this version of the connector. If you are making a jump across several migrations, you may see this last line appear multiple times with different existing versions listed each time: the in-place upgrade sequentially applies the necessary migrations step-by-step. Example output when migration is required Starting a XTDB node using configuration: config.json SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\". SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. ... checking if migration is needed (xtdb.api.java.JXtdbNode@25c4bb06) The node is at version -1, while latest is 2 -- migrating...","title":"4. Run the in-place upgrade"},{"location":"connectors/repository/xtdb/upgrade/#5-start-the-connector","text":"Once the previous (in-place upgrade) command completes, you should now be able to start your connector. See the instructions on configuring the connector for more details.","title":"5. Start the connector"},{"location":"connectors/repository/xtdb/upgrade/#change-log","text":"There should be no need to actually understand these details, as the connector (and migration) will handle them for you. However, for the interested reader, the following changes were made to the storage layer in the specified release:","title":"Change log"},{"location":"connectors/repository/xtdb/upgrade/#29","text":"InstanceAuditHeaderMapping no longer separates the type GUID and supertype GUIDs, but places all such information into a single vector (for improved search performance) RelationshipMapping no longer has separate properties for each entity proxy, but stores them as a vector: this retains their ordering, but allows relationships to be more efficiently searched from either related entity","title":"2.9"},{"location":"education/open-metadata-labs/","text":"Open Metadata Labs \u00b6 The open metadata labs contain an interactive environment that allow you to experiment with different capabilities of ODPi Egeria. As such we often refer to them as Hands-on Labs . Each lab notebook describes a scenario from the Coco Pharmaceuticals case study, focusing on a challenge that one or more of the characters face and how they approached the solution. The calls to the Egeria APIs necessary to complete the challenge are encoded in the notebook so you can experiment with the APIs. These labs can be used for individual study, as part of a class and / or as the basis of a workbook for using Egeria within a specific organization. Running the Labs \u00b6 There are two main ways to set up the software to run these labs. These are listed below. They each create exactly the same environment that supports the labs. Using Kubernetes to run them in a flexible, self-contained environment - locally or in the cloud. Using your own local environment directly . Once the software is in place, you then go to the JupyterLab browser window (typically at http://localhost:8888/lab ) and begin with the read-me-first.ipynb lab notebook to familiarize yourself with the tutorial tools. This notebook will guide you to the rest of the labs. You can start running a notebook by simply double-clicking the filename in the left pane of the Jupyter interface.","title":"Open metadata labs"},{"location":"education/open-metadata-labs/#open-metadata-labs","text":"The open metadata labs contain an interactive environment that allow you to experiment with different capabilities of ODPi Egeria. As such we often refer to them as Hands-on Labs . Each lab notebook describes a scenario from the Coco Pharmaceuticals case study, focusing on a challenge that one or more of the characters face and how they approached the solution. The calls to the Egeria APIs necessary to complete the challenge are encoded in the notebook so you can experiment with the APIs. These labs can be used for individual study, as part of a class and / or as the basis of a workbook for using Egeria within a specific organization.","title":"Open Metadata Labs"},{"location":"education/open-metadata-labs/#running-the-labs","text":"There are two main ways to set up the software to run these labs. These are listed below. They each create exactly the same environment that supports the labs. Using Kubernetes to run them in a flexible, self-contained environment - locally or in the cloud. Using your own local environment directly . Once the software is in place, you then go to the JupyterLab browser window (typically at http://localhost:8888/lab ) and begin with the read-me-first.ipynb lab notebook to familiarize yourself with the tutorial tools. This notebook will guide you to the rest of the labs. You can start running a notebook by simply double-clicking the filename in the left pane of the Jupyter interface.","title":"Running the Labs"},{"location":"education/egeria-dojo/egeria-dojo-day-1-1-introduction/","text":"Egeria Introduction \u00b6 In this session, you will learn about the function and value of Egeria along with the key concepts and use cases it supports. Introductory presentation \u00b6 This session provides background information to the Egeria project using a presentation. Watch a video of the presentation: https://youtu.be/s249ofNoETY . The charts for the presentation are located here: https://github.com/odpi/data-governance/tree/master/workshops/may-2020/egeria-dojo-day-1-1-introduction.pptx . Test yourself \u00b6 Which of the following are part of the Open Metadata Manifesto : Metadata needs to be centralized so it can be managed. Maintenance of metadata must be automated. The availability of metadata management must become ubiquitous. Metadata access must become open and remotely accessible. Name 3 tools that could connect to Egeria. Name a metadata standard. Progress to Egeria Project Overview Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 1 introduction"},{"location":"education/egeria-dojo/egeria-dojo-day-1-1-introduction/#egeria-introduction","text":"In this session, you will learn about the function and value of Egeria along with the key concepts and use cases it supports.","title":"Egeria Introduction"},{"location":"education/egeria-dojo/egeria-dojo-day-1-1-introduction/#introductory-presentation","text":"This session provides background information to the Egeria project using a presentation. Watch a video of the presentation: https://youtu.be/s249ofNoETY . The charts for the presentation are located here: https://github.com/odpi/data-governance/tree/master/workshops/may-2020/egeria-dojo-day-1-1-introduction.pptx .","title":"Introductory presentation"},{"location":"education/egeria-dojo/egeria-dojo-day-1-1-introduction/#test-yourself","text":"Which of the following are part of the Open Metadata Manifesto : Metadata needs to be centralized so it can be managed. Maintenance of metadata must be automated. The availability of metadata management must become ubiquitous. Metadata access must become open and remotely accessible. Name 3 tools that could connect to Egeria. Name a metadata standard. Progress to Egeria Project Overview Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Test yourself"},{"location":"education/egeria-dojo/egeria-dojo-day-1-2-project-introduction/","text":"Egeria Project Introduction \u00b6 In this session, you will learn about the contents of the Egeria project. It will also describe the software to download in preparation for the next session. Project Resources \u00b6 Watch the project overview video: https://youtu.be/CN81aeSlWlU GitHub repositories \u00b6 GitHub is a public service for managing files - particularly files associated with a software project. Many open source projects use GitHub and egeria is no exception. All of the content for the Egeria project is stored in git repositories. For example, these web pages you are reading as part of the dojo are managed in Egeria's main git repository here . Each directory in the repository has a README.md file written in the Markdown standard . You can either click through on GitHub or link to the Content Organization that lists the directories with descriptions. Other resources \u00b6 The Egeria community love to collaborate on the work they do. Git and GitHub is an excellent way to exchange and manage files. In addition, the community runs public calls that anyone can join, as well as a number of slack channels. Details of the different ways the community operates is described in our Community Guide . Click on the link to the community guide to find out more. Test yourself \u00b6 Name three of the git repositories owned by the Egeria Project and describe what they do. Describe why the Egeria project is called \"egeria\". Log on to the ODPi slack service and post a message to the #egeria-dojo-live channel to say that you have got this far in the dojo. Downloads for next session \u00b6 It is time for a break now. However, if you want to save time, the next session makes use of Docker containers to run Egeria and Postman to issue REST API calls. The links below provide information on how to download these tools during the break. Docker Desktop Postman These download instructions will be presented again in the appropriate session so it is not a problem if you do not download them now. Now it is time to take a break before moving on to the next session. Progress to Running Egeria on your machine Step-by-Step Return to Egeria Overview Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 2 project introduction"},{"location":"education/egeria-dojo/egeria-dojo-day-1-2-project-introduction/#egeria-project-introduction","text":"In this session, you will learn about the contents of the Egeria project. It will also describe the software to download in preparation for the next session.","title":"Egeria Project Introduction"},{"location":"education/egeria-dojo/egeria-dojo-day-1-2-project-introduction/#project-resources","text":"Watch the project overview video: https://youtu.be/CN81aeSlWlU","title":"Project Resources"},{"location":"education/egeria-dojo/egeria-dojo-day-1-2-project-introduction/#github-repositories","text":"GitHub is a public service for managing files - particularly files associated with a software project. Many open source projects use GitHub and egeria is no exception. All of the content for the Egeria project is stored in git repositories. For example, these web pages you are reading as part of the dojo are managed in Egeria's main git repository here . Each directory in the repository has a README.md file written in the Markdown standard . You can either click through on GitHub or link to the Content Organization that lists the directories with descriptions.","title":"GitHub repositories"},{"location":"education/egeria-dojo/egeria-dojo-day-1-2-project-introduction/#other-resources","text":"The Egeria community love to collaborate on the work they do. Git and GitHub is an excellent way to exchange and manage files. In addition, the community runs public calls that anyone can join, as well as a number of slack channels. Details of the different ways the community operates is described in our Community Guide . Click on the link to the community guide to find out more.","title":"Other resources"},{"location":"education/egeria-dojo/egeria-dojo-day-1-2-project-introduction/#test-yourself","text":"Name three of the git repositories owned by the Egeria Project and describe what they do. Describe why the Egeria project is called \"egeria\". Log on to the ODPi slack service and post a message to the #egeria-dojo-live channel to say that you have got this far in the dojo.","title":"Test yourself"},{"location":"education/egeria-dojo/egeria-dojo-day-1-2-project-introduction/#downloads-for-next-session","text":"It is time for a break now. However, if you want to save time, the next session makes use of Docker containers to run Egeria and Postman to issue REST API calls. The links below provide information on how to download these tools during the break. Docker Desktop Postman These download instructions will be presented again in the appropriate session so it is not a problem if you do not download them now. Now it is time to take a break before moving on to the next session. Progress to Running Egeria on your machine Step-by-Step Return to Egeria Overview Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Downloads for next session"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-1-platform-set-up-prerequisites/","text":"Running Egeria prerequisites \u00b6 In this session, you will learn about the Open Metadata and Governance (OMAG) Server Platform that hosts many of the services provided by Egeria. However, before we get started there are some steps to prepare your machine. For this session you will need both Docker Desktop and Postman running on your machine. What the video for an overview of this session: https://youtu.be/jnxY2epKgzY Follow the links below to find out a little bit about these technologies and ensure the software is installed. Docker Desktop Postman Once these technologies are installed, work through the tutorials - starting with Docker to get the OMAG Server Platform running and then Postman to get ready to work with the platform and the servers running on top if it. Docker Tutorial Postman Tutorial At this point you should have Postman installed with the collections loaded, and Egeria's OMAG Server Platform running as a docker container. Test yourself \u00b6 What is the message from the OMAG Server Platform that says it is ready to process requests? How do you find out the version of Egeria running in an OMAG Server Platform? What is the url to view the Swagger UI page for the OMAG Server Platform? Progress to Configuring the platform Return to Platform set up and configuration Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 1 1 platform set up prerequisites"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-1-platform-set-up-prerequisites/#running-egeria-prerequisites","text":"In this session, you will learn about the Open Metadata and Governance (OMAG) Server Platform that hosts many of the services provided by Egeria. However, before we get started there are some steps to prepare your machine. For this session you will need both Docker Desktop and Postman running on your machine. What the video for an overview of this session: https://youtu.be/jnxY2epKgzY Follow the links below to find out a little bit about these technologies and ensure the software is installed. Docker Desktop Postman Once these technologies are installed, work through the tutorials - starting with Docker to get the OMAG Server Platform running and then Postman to get ready to work with the platform and the servers running on top if it. Docker Tutorial Postman Tutorial At this point you should have Postman installed with the collections loaded, and Egeria's OMAG Server Platform running as a docker container.","title":"Running Egeria prerequisites"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-1-platform-set-up-prerequisites/#test-yourself","text":"What is the message from the OMAG Server Platform that says it is ready to process requests? How do you find out the version of Egeria running in an OMAG Server Platform? What is the url to view the Swagger UI page for the OMAG Server Platform? Progress to Configuring the platform Return to Platform set up and configuration Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Test yourself"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-2-configuring-the-platform/","text":"Configuring the OMAG Server Platform \u00b6 In this session, you will learn how to set up the OMAG Server Platform. Watch this video to get an overview of this session: https://youtu.be/-YScFx0fQk0 . In the previous session you downloaded an application called Postman and loaded collections of pre-defined requests. This tool makes it easy to issue REST API requests to the OMAG Server Platform. Check that it is working by locating the Get Server Origin request in the Egeria-platform-services collection. When you click on that request in the left-hand list, a new tab opens and you can click on send to issue the request. You should see the same response as when you issues the platform origin request from Swagger earlier. Below is this response in Postman. If this does not work, then there is something wrong either in Postman or your platform. Check the URL string that was used in the request (shown in orange in the middle of the screen.) The screen shot below shows the error message when the egeria environment is not set. This can be fixed by setting it in the top right-hand dropdown. If the Egeria environment is not listed then you need to load the environment ( Postman tutorial ). If the baseURL variable is set to a different value to the server platform then Postman can not connect. In the screen capture below, you can see the baseURL is set to the default of https://localhost:9443 when it should be https://localhost:9443 because the platform is running in docker. Finally, if the OMAG Server Platform is not running the even though everything is set up correctly in Postman, it has nothing to connect to. Restart the platform ( Docker tutorial ). In last part of this session you will learn how to set up the OMAG Server Platform so that it is secure and determine the services and servers that are associated with the platform. Review the description of the OMAG Server Platform configuration: Configuring the OMAG Server Platform The link below takes you to a task description in the Egeria Administration User Guide. The user guide describes the REST API call(s) needed to complete the task. You can choose to type the request into postman, or use the requests already defined in the Egeria-admin-services-platform-configuration Postman collection. Add the Coco Pharmaceuticals platform security connector to the platform Try running the platform origin command again - it should fail with a security error. Change the user variable in the Egeria environment from me to garygeeke and rerun the request. It will work again because garygeeke is the user id of the Coco Pharmaceuticals IT infrastructure lead and has permission to run the platform commands. Finally, use the Egeria-admin-services-platform-configuration Postman collection to experiment with the different registered services and and known and active server requests. These are useful to know as we move to configure servers on the platform. This is the end of the session on the OMAG Server Platform. Progress to Configuring a metadata server on the platform Return to Platform set up and configuration Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 1 2 configuring the platform"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-2-configuring-the-platform/#configuring-the-omag-server-platform","text":"In this session, you will learn how to set up the OMAG Server Platform. Watch this video to get an overview of this session: https://youtu.be/-YScFx0fQk0 . In the previous session you downloaded an application called Postman and loaded collections of pre-defined requests. This tool makes it easy to issue REST API requests to the OMAG Server Platform. Check that it is working by locating the Get Server Origin request in the Egeria-platform-services collection. When you click on that request in the left-hand list, a new tab opens and you can click on send to issue the request. You should see the same response as when you issues the platform origin request from Swagger earlier. Below is this response in Postman. If this does not work, then there is something wrong either in Postman or your platform. Check the URL string that was used in the request (shown in orange in the middle of the screen.) The screen shot below shows the error message when the egeria environment is not set. This can be fixed by setting it in the top right-hand dropdown. If the Egeria environment is not listed then you need to load the environment ( Postman tutorial ). If the baseURL variable is set to a different value to the server platform then Postman can not connect. In the screen capture below, you can see the baseURL is set to the default of https://localhost:9443 when it should be https://localhost:9443 because the platform is running in docker. Finally, if the OMAG Server Platform is not running the even though everything is set up correctly in Postman, it has nothing to connect to. Restart the platform ( Docker tutorial ). In last part of this session you will learn how to set up the OMAG Server Platform so that it is secure and determine the services and servers that are associated with the platform. Review the description of the OMAG Server Platform configuration: Configuring the OMAG Server Platform The link below takes you to a task description in the Egeria Administration User Guide. The user guide describes the REST API call(s) needed to complete the task. You can choose to type the request into postman, or use the requests already defined in the Egeria-admin-services-platform-configuration Postman collection. Add the Coco Pharmaceuticals platform security connector to the platform Try running the platform origin command again - it should fail with a security error. Change the user variable in the Egeria environment from me to garygeeke and rerun the request. It will work again because garygeeke is the user id of the Coco Pharmaceuticals IT infrastructure lead and has permission to run the platform commands. Finally, use the Egeria-admin-services-platform-configuration Postman collection to experiment with the different registered services and and known and active server requests. These are useful to know as we move to configure servers on the platform. This is the end of the session on the OMAG Server Platform. Progress to Configuring a metadata server on the platform Return to Platform set up and configuration Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Configuring the OMAG Server Platform"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-3-configuring-a-server/","text":"Configuring a metadata server on the OMAG Server Platform \u00b6 The OMAG Server Platform is able to host one-to-many OMAG servers. An OMAG Server is responsible for supporting the integration of different types of technology. There are different types of OMAG Servers in Egeria. In this session you are going to learn how to set up particular type of OMAG server called a metadata server. Watch the overview of this session: https://youtu.be/c1g2vY_0mYs . Begin by understanding about the different types of OMAG Servers and what they are used for by following the link below: * Egeria's OMAG Servers In this first exercise you are going to use Postman to configure a simple metadata server called myMetadataServer . In the Postman Egeria Environment, update the variable called server from myServer to myMetadataServer . Using the Egeria-admin-services-server-configuration Postman collection and the instructions from the Admin services user guide on metadata servers create the configuration for myMetadataServer as follows. For each value, find the right REST API request in the Postman collection. Then look at where the values come from. Sometimes you will need to change the variable value in the Egeria Environment, sometimes you can type it directly into the request URL and other times, the request in Postman is just what you need. Each time you add a configuration value, retrieve the server's configuration to see how the effect of your requests are changing the server's configuration. local server URL root to https://localhost:19443 This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Confguration for Cohort Members/Set local server URL root . The specific documentation for this call is in the Admin Guide here . localServerType to Egeria Dojo Metadata Server (update the value in the request) This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set local server type . The specific documentation for this call is in the Admin Guide here . organizationName to your organization name (update the variable organization_name ). This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set organization name . The specific documentation for this call is in the Admin Guide here . localServerUserId to myMetadataServerUserId . This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set local server user Id . The specific documentation for this call is in the Admin Guide here . localServerPassword to myMetadataServerPassword This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set local server user password . The specific documentation for this call is in the Admin Guide here . maxPageSize - the maximum page size that can be set on requests to the server. The default value is 1000. This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set max page size . The specific documentation for this call is in the Admin Guide here . Add a graph-based local repository. This will store metadata in JanusGraph. This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Configuration for Cohort Members/Configuration for Metadata Access Points/Configuration for Metadata Servers/Enable the graph repository . The specific documentation for this call is in the Admin Guide here . Configure the Asset Owner Open Metadata Access Service (OMAS). URL name for this service is asset-owner . This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Configuration for Cohort Members/Configuration for Metadata Access Points/Enable a specific access service . The specific documentation for this call is in the Admin Guide here . Set up the Coco Pharmaceutical Server Security connector to provide authorization checks for inbound REST API calls. This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set Server Security Connection . The specific documentation for this call is in the Admin Guide here . Once the configuration is complete you are ready to move on to the next section. Test yourself \u00b6 What is the name of the place where a server's configuration is assembled? What determines where the server configuration is stored? What is the quickest way to discover what has recently changed in a server's configuration? Return to Platform set up and configuration Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 1 3 configuring a server"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-3-configuring-a-server/#configuring-a-metadata-server-on-the-omag-server-platform","text":"The OMAG Server Platform is able to host one-to-many OMAG servers. An OMAG Server is responsible for supporting the integration of different types of technology. There are different types of OMAG Servers in Egeria. In this session you are going to learn how to set up particular type of OMAG server called a metadata server. Watch the overview of this session: https://youtu.be/c1g2vY_0mYs . Begin by understanding about the different types of OMAG Servers and what they are used for by following the link below: * Egeria's OMAG Servers In this first exercise you are going to use Postman to configure a simple metadata server called myMetadataServer . In the Postman Egeria Environment, update the variable called server from myServer to myMetadataServer . Using the Egeria-admin-services-server-configuration Postman collection and the instructions from the Admin services user guide on metadata servers create the configuration for myMetadataServer as follows. For each value, find the right REST API request in the Postman collection. Then look at where the values come from. Sometimes you will need to change the variable value in the Egeria Environment, sometimes you can type it directly into the request URL and other times, the request in Postman is just what you need. Each time you add a configuration value, retrieve the server's configuration to see how the effect of your requests are changing the server's configuration. local server URL root to https://localhost:19443 This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Confguration for Cohort Members/Set local server URL root . The specific documentation for this call is in the Admin Guide here . localServerType to Egeria Dojo Metadata Server (update the value in the request) This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set local server type . The specific documentation for this call is in the Admin Guide here . organizationName to your organization name (update the variable organization_name ). This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set organization name . The specific documentation for this call is in the Admin Guide here . localServerUserId to myMetadataServerUserId . This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set local server user Id . The specific documentation for this call is in the Admin Guide here . localServerPassword to myMetadataServerPassword This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set local server user password . The specific documentation for this call is in the Admin Guide here . maxPageSize - the maximum page size that can be set on requests to the server. The default value is 1000. This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set max page size . The specific documentation for this call is in the Admin Guide here . Add a graph-based local repository. This will store metadata in JanusGraph. This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Configuration for Cohort Members/Configuration for Metadata Access Points/Configuration for Metadata Servers/Enable the graph repository . The specific documentation for this call is in the Admin Guide here . Configure the Asset Owner Open Metadata Access Service (OMAS). URL name for this service is asset-owner . This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Configuration for Cohort Members/Configuration for Metadata Access Points/Enable a specific access service . The specific documentation for this call is in the Admin Guide here . Set up the Coco Pharmaceutical Server Security connector to provide authorization checks for inbound REST API calls. This call is located in the Postman collection Egeria-admin-services-server-configuration in folder Configuring OMAG Servers/Set Server Security Connection . The specific documentation for this call is in the Admin Guide here . Once the configuration is complete you are ready to move on to the next section.","title":"Configuring a metadata server on the OMAG Server Platform"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-3-configuring-a-server/#test-yourself","text":"What is the name of the place where a server's configuration is assembled? What determines where the server configuration is stored? What is the quickest way to discover what has recently changed in a server's configuration? Return to Platform set up and configuration Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Test yourself"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-platform-set-up-and-configuration/","text":"Platform set up and configuration \u00b6 In this session, you will learn about the Open Metadata and Governance (OMAG) Server Platform that hosts many of the services provided by Egeria. There are three parts to this session. Click on the links in turn to find out more: Setting up prerequisites for running Egeria Configuring the OMAG Server Platform Configuring a server on the platform Once you have finished, take a break and then go on to the next section. Progress to Running metadata servers Return to Running Egeria on your machine - Step-by-Step Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 1 platform set up and configuration"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-1-platform-set-up-and-configuration/#platform-set-up-and-configuration","text":"In this session, you will learn about the Open Metadata and Governance (OMAG) Server Platform that hosts many of the services provided by Egeria. There are three parts to this session. Click on the links in turn to find out more: Setting up prerequisites for running Egeria Configuring the OMAG Server Platform Configuring a server on the platform Once you have finished, take a break and then go on to the next section. Progress to Running metadata servers Return to Running Egeria on your machine - Step-by-Step Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Platform set up and configuration"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-1-starting-the-server/","text":"Starting a server on the OMAG Server Platform \u00b6 In this session, you will learn how to start a server on the Open Metadata and Governance (OMAG) Server Platform. There are also optional advanced exercises in this session. Using Postman, and the Egeria-admin-services-operational Postman collection, start your server myMetadataServer . The documentation from the Admin Guide is shown below. Starting and Stopping OMAG Servers From Docker Desktop, look at the logs for your docker container to see the audit log messages. There are different type of audit log messages Diagnostic Guide Optional material \u00b6 Add the file audit log connector to your server configuration . Restart your server and then, from Docker Desktop, open the CLI and look at the log record files that have been created. The audit log destinations are configured using connections that define how to create an appropriate connector. Now link to the Developer Guide to understand more about connectors. Progress to Calling the server API Return to Running metadata servers Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 2 1 starting the server"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-1-starting-the-server/#starting-a-server-on-the-omag-server-platform","text":"In this session, you will learn how to start a server on the Open Metadata and Governance (OMAG) Server Platform. There are also optional advanced exercises in this session. Using Postman, and the Egeria-admin-services-operational Postman collection, start your server myMetadataServer . The documentation from the Admin Guide is shown below. Starting and Stopping OMAG Servers From Docker Desktop, look at the logs for your docker container to see the audit log messages. There are different type of audit log messages Diagnostic Guide","title":"Starting a server on the OMAG Server Platform"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-1-starting-the-server/#optional-material","text":"Add the file audit log connector to your server configuration . Restart your server and then, from Docker Desktop, open the CLI and look at the log record files that have been created. The audit log destinations are configured using connections that define how to create an appropriate connector. Now link to the Developer Guide to understand more about connectors. Progress to Calling the server API Return to Running metadata servers Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Optional material"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-2-calling-server-api/","text":"Calling the metadata server API \u00b6 In this session, you will learn some of the API calls that are possible on the metadata server. For this exercise, you will be using the following Postman collections: * Egeria-repository-services-local-repository * Egeria-asset-owner-omas The aim is to show the differences between the fine-grained repository services APIs and the courser-grained, but more specialized access services APIs. Start with the the Asset Owner OMAS interface and add a CSV file. This returns a list of assets it has created, one for the directory and one for the filename. Retrieve these assets using the Now use the repository service API to see how these assets are stored. What are the differences? Later on today, you will have a change to work with the Open Metadata Labs that provide a lot more explanation on the APIs and their differences. The purpose of this exercise was to giver you direct experience of the REST APIs. Progress to Working with prepared content Return to Running metadata servers Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 2 2 calling server api"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-2-calling-server-api/#calling-the-metadata-server-api","text":"In this session, you will learn some of the API calls that are possible on the metadata server. For this exercise, you will be using the following Postman collections: * Egeria-repository-services-local-repository * Egeria-asset-owner-omas The aim is to show the differences between the fine-grained repository services APIs and the courser-grained, but more specialized access services APIs. Start with the the Asset Owner OMAS interface and add a CSV file. This returns a list of assets it has created, one for the directory and one for the filename. Retrieve these assets using the Now use the repository service API to see how these assets are stored. What are the differences? Later on today, you will have a change to work with the Open Metadata Labs that provide a lot more explanation on the APIs and their differences. The purpose of this exercise was to giver you direct experience of the REST APIs. Progress to Working with prepared content Return to Running metadata servers Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Calling the metadata server API"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-3-working-with-archives/","text":"Working with prepared content \u00b6 In this session, you will learn about open metadata archives and how they can be used to load prepared content such as glossaries or standard models into a metadata server. First read about Open Metadata Archives . Egeria has a number of pre-built content packs in the content-packs directory on GitHub - Click to link to it Using Postman, try to create a new request that loads this archive. The format of the REST API is: POST {{baseURL}}/open-metadata/admin-services/users/{{user}}/servers/{{server}}/instance/open-metadata-archives/file Where the filename is a TEXT request body. This is the file name you need to specify https://raw.githubusercontent.com/odpi/egeria/master/content-packs/CloudInformationModel.json` When you execute the request, look at the logs in Docker Desktop to see any errors or to watch the archive load. The Open Metadata Labs has a specific lab for working with this archive and through that you will get a chance to query its content. Test yourself \u00b6 What is the message identifier of the Audit Log message produced when an element is loaded from an archive? Progress to Creating a second server and connecting via a cohort Return to Running metadata servers Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 2 3 working with archives"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-3-working-with-archives/#working-with-prepared-content","text":"In this session, you will learn about open metadata archives and how they can be used to load prepared content such as glossaries or standard models into a metadata server. First read about Open Metadata Archives . Egeria has a number of pre-built content packs in the content-packs directory on GitHub - Click to link to it Using Postman, try to create a new request that loads this archive. The format of the REST API is: POST {{baseURL}}/open-metadata/admin-services/users/{{user}}/servers/{{server}}/instance/open-metadata-archives/file Where the filename is a TEXT request body. This is the file name you need to specify https://raw.githubusercontent.com/odpi/egeria/master/content-packs/CloudInformationModel.json` When you execute the request, look at the logs in Docker Desktop to see any errors or to watch the archive load. The Open Metadata Labs has a specific lab for working with this archive and through that you will get a chance to query its content.","title":"Working with prepared content"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-3-working-with-archives/#test-yourself","text":"What is the message identifier of the Audit Log message produced when an element is loaded from an archive? Progress to Creating a second server and connecting via a cohort Return to Running metadata servers Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Test yourself"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-4-second-server/","text":"Creating a second server and connecting via a cohort \u00b6 Metadata servers can exchange metadata via open metadata repository cohorts. In this session you will learn how to connect two servers via a cohort. But first you need to create a second server. The docker image that you have been using is isolated in a container. This is good as far as it goes but is no help when you want to connect it to other servers. For this next exercise, we are going to use docker-compose to run a set of docker containers with different technologies. Watch video showing docker compose and the open metadata labs: https://youtu.be/nuRKPfRDKEc Before you move forward, shut down your egeria docker container using the docker desktop to save cycles on your machine. You can delete it if you do not want it any more. Set up environment \u00b6 Now download the latest version of Egeria from GitHub in a new directory on your machine. This is a direct copy of the latest content from GitHub. From within the egeria/open-metadata-resources/open-metadata-deployment/compose/tutorials directory, run the command: $ docker-compose -f ./egeria-tutorial.yaml up You may need to wait while some containers are downloaded . They will then be started, which will likely take less than a minute. Once you see the following lines: core_1 | Thu Sep 26 19:33:54 GMT 2019 OMAG server platform ready for configuration datalake_1 | Thu Sep 26 19:33:55 GMT 2019 OMAG server platform ready for configuration dev_1 | Thu Sep 26 19:33:56 GMT 2019 OMAG server platform ready for configuration factory_1 | Thu Sep 26 19:33:57 GMT 2019 OMAG server platform ready for configuration or activity has subsided (as there are many log entries output), your self-contained environment should be ready. Repeat the previous server configuration exercise twice - once to create a server called server1 and again to create a server called server 2 . Connect the Servers via a Cohort \u00b6 Once you have 2 servers configured, add configuration to each of them to connect them via a cohort. First read about Open Metadata Repository Cohorts . Then * Set up the event bus defaults * Connect then together by adding cohort configuration to each server. Start both servers and view their logs via the Docker Desktop - you should see that they are communicating. Now use the commands in the Egeria-repository-services-metadata-highway to query information about the cohort from each server's perspective. Return to Running metadata servers Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 2 4 second server"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-4-second-server/#creating-a-second-server-and-connecting-via-a-cohort","text":"Metadata servers can exchange metadata via open metadata repository cohorts. In this session you will learn how to connect two servers via a cohort. But first you need to create a second server. The docker image that you have been using is isolated in a container. This is good as far as it goes but is no help when you want to connect it to other servers. For this next exercise, we are going to use docker-compose to run a set of docker containers with different technologies. Watch video showing docker compose and the open metadata labs: https://youtu.be/nuRKPfRDKEc Before you move forward, shut down your egeria docker container using the docker desktop to save cycles on your machine. You can delete it if you do not want it any more.","title":"Creating a second server and connecting via a cohort"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-4-second-server/#set-up-environment","text":"Now download the latest version of Egeria from GitHub in a new directory on your machine. This is a direct copy of the latest content from GitHub. From within the egeria/open-metadata-resources/open-metadata-deployment/compose/tutorials directory, run the command: $ docker-compose -f ./egeria-tutorial.yaml up You may need to wait while some containers are downloaded . They will then be started, which will likely take less than a minute. Once you see the following lines: core_1 | Thu Sep 26 19:33:54 GMT 2019 OMAG server platform ready for configuration datalake_1 | Thu Sep 26 19:33:55 GMT 2019 OMAG server platform ready for configuration dev_1 | Thu Sep 26 19:33:56 GMT 2019 OMAG server platform ready for configuration factory_1 | Thu Sep 26 19:33:57 GMT 2019 OMAG server platform ready for configuration or activity has subsided (as there are many log entries output), your self-contained environment should be ready. Repeat the previous server configuration exercise twice - once to create a server called server1 and again to create a server called server 2 .","title":"Set up environment"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-4-second-server/#connect-the-servers-via-a-cohort","text":"Once you have 2 servers configured, add configuration to each of them to connect them via a cohort. First read about Open Metadata Repository Cohorts . Then * Set up the event bus defaults * Connect then together by adding cohort configuration to each server. Start both servers and view their logs via the Docker Desktop - you should see that they are communicating. Now use the commands in the Egeria-repository-services-metadata-highway to query information about the cohort from each server's perspective. Return to Running metadata servers Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Connect the Servers via a Cohort"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-running-metadata-servers/","text":"Running Metadata Servers \u00b6 In this session, you will learn how to work with a metadata server on the OMAG Server Platform. There are four parts to this section. The links below take you to the content: However, before embarking on the session, you can watch this video showing docker compose and the open metadata labs: https://youtu.be/nuRKPfRDKEc . This will give you an overview of process. Then follow along with the exercises below to try this out for yourself. Starting a server Calling the server API Working with prepared content Creating a second server and connecting via a cohort Take a break and then go onto the last section. This introduces new types of servers that work with the metadata server. Progress to Running metadata ecosystems Return to Running Egeria on your machine - Step-by-Step Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 2 running metadata servers"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-2-running-metadata-servers/#running-metadata-servers","text":"In this session, you will learn how to work with a metadata server on the OMAG Server Platform. There are four parts to this section. The links below take you to the content: However, before embarking on the session, you can watch this video showing docker compose and the open metadata labs: https://youtu.be/nuRKPfRDKEc . This will give you an overview of process. Then follow along with the exercises below to try this out for yourself. Starting a server Calling the server API Working with prepared content Creating a second server and connecting via a cohort Take a break and then go onto the last section. This introduces new types of servers that work with the metadata server. Progress to Running metadata ecosystems Return to Running Egeria on your machine - Step-by-Step Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Running Metadata Servers"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-1-running-ui/","text":"Running User Interfaces (UIs) \u00b6 In this session, you will learn about the user interfaces provided by Egeria. Egeria has two User Interfaces in development at the moment, each focused at different types of organization. The EgeriaUIPlatform provides a user interface for a mature organization that has already invested in a metadata capability and is using Egeria to integrate tools into their metadata repository plus add advanced features. The second UI makes use of view servers and a thin presentation server. It is multi-tenant and is focused on supporting all aspects of an organization's metadata integration and governance needs. Since these capabilities are still in development, this session will be a demonstration of the two UIs we have. At a later date, the dojo will be updated to include exercises where you can run them yourselves. Watch the presentation and demo: https://youtu.be/gVNbqKjwH94 Progress to Running governance servers Return to Running metadata ecosystems Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 3 1 running ui"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-1-running-ui/#running-user-interfaces-uis","text":"In this session, you will learn about the user interfaces provided by Egeria. Egeria has two User Interfaces in development at the moment, each focused at different types of organization. The EgeriaUIPlatform provides a user interface for a mature organization that has already invested in a metadata capability and is using Egeria to integrate tools into their metadata repository plus add advanced features. The second UI makes use of view servers and a thin presentation server. It is multi-tenant and is focused on supporting all aspects of an organization's metadata integration and governance needs. Since these capabilities are still in development, this session will be a demonstration of the two UIs we have. At a later date, the dojo will be updated to include exercises where you can run them yourselves. Watch the presentation and demo: https://youtu.be/gVNbqKjwH94 Progress to Running governance servers Return to Running metadata ecosystems Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Running User Interfaces (UIs)"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-2-running-governance-servers/","text":"Running governance servers \u00b6 In this session, you will learn about a new type of OMAG Server called the Governance Server. The governance server makes active use of open metadata in third party technologies and the open metadata cohorts. They are divided into two main groups: * the governance servers that host a governance engine. The governance engine is performing some sort of governance operation such as metadata discovery or stewardship. * the governance servers that exchange metadata between third party technologies and the open metadata ecosystem. Click on the link below to dive into more detail: Overview of the Governance Servers Test yourself \u00b6 How many different types of integration patterns can an integration daemon support? Which type of governance server runs a discovery engine ? What types of OMAG Servers does a governance server connect to and why? Next steps \u00b6 Much of today's dojo has been about the infrastructure of Egeria so that you have enough knowledge to set up and run the platform and then experiment with it to learn more. The final session in the Dojo today is to use Kubernetes and the lab hands on environment to run a mixture of OMAG Server types and experience the types of use cases that the Egeria Technology supports. Progress to Kubernetes and Lab Notebooks Return to Running metadata ecosystems Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 3 2 running governance servers"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-2-running-governance-servers/#running-governance-servers","text":"In this session, you will learn about a new type of OMAG Server called the Governance Server. The governance server makes active use of open metadata in third party technologies and the open metadata cohorts. They are divided into two main groups: * the governance servers that host a governance engine. The governance engine is performing some sort of governance operation such as metadata discovery or stewardship. * the governance servers that exchange metadata between third party technologies and the open metadata ecosystem. Click on the link below to dive into more detail: Overview of the Governance Servers","title":"Running governance servers"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-2-running-governance-servers/#test-yourself","text":"How many different types of integration patterns can an integration daemon support? Which type of governance server runs a discovery engine ? What types of OMAG Servers does a governance server connect to and why?","title":"Test yourself"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-2-running-governance-servers/#next-steps","text":"Much of today's dojo has been about the infrastructure of Egeria so that you have enough knowledge to set up and run the platform and then experiment with it to learn more. The final session in the Dojo today is to use Kubernetes and the lab hands on environment to run a mixture of OMAG Server types and experience the types of use cases that the Egeria Technology supports. Progress to Kubernetes and Lab Notebooks Return to Running metadata ecosystems Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Next steps"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-3-kubernetes-and-labs/","text":"Kubernetes and lab notebooks \u00b6 The final session in day one of the Egeria Dojo is to use our Kubernetes helm charts to set up the infrastructure for Egeria's hands on labs. These labs attempt to show a rich metadata environment in action, allowing you to experiment with different concepts and APIs. First, go to you Docker Desktop and shut down all of your docker containers that were started by docker-compose (your laptop will thank you for that.) Now go to the Lab Infrastructure tutorial and follow the instructions for setting up the lab environment using Kubernetes. Once it is running, go to the Open Metadata Labs instructions to start the first lab notebook. There is more material to run in the Open metadata Labs than can be done in 30 minutes. The purpose of this session is to ensure that you can set up the environment so you can run it at you leisure when every you want to. In addition, these labs (like everything else in Egeria) is evolving rapidly so it is worth checking back from time to time to see what is new. Return to Running metadata ecosystems Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 3 3 kubernetes and labs"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-3-kubernetes-and-labs/#kubernetes-and-lab-notebooks","text":"The final session in day one of the Egeria Dojo is to use our Kubernetes helm charts to set up the infrastructure for Egeria's hands on labs. These labs attempt to show a rich metadata environment in action, allowing you to experiment with different concepts and APIs. First, go to you Docker Desktop and shut down all of your docker containers that were started by docker-compose (your laptop will thank you for that.) Now go to the Lab Infrastructure tutorial and follow the instructions for setting up the lab environment using Kubernetes. Once it is running, go to the Open Metadata Labs instructions to start the first lab notebook. There is more material to run in the Open metadata Labs than can be done in 30 minutes. The purpose of this session is to ensure that you can set up the environment so you can run it at you leisure when every you want to. In addition, these labs (like everything else in Egeria) is evolving rapidly so it is worth checking back from time to time to see what is new. Return to Running metadata ecosystems Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Kubernetes and lab notebooks"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-running-metadata-ecosystems/","text":"Running metadata ecosystems \u00b6 Metadata servers store and maintain metadata. In this next session, you will learn how to actively capture metadata and make use of it to manage your data and IT landscape. Click on the links to get to the session content: Running the User Interface (UI) Running Governance Servers Kubernetes and lab notebooks Return to Running Egeria on your machine - Step-by-Step Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 3 running metadata ecosystems"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-3-running-metadata-ecosystems/#running-metadata-ecosystems","text":"Metadata servers store and maintain metadata. In this next session, you will learn how to actively capture metadata and make use of it to manage your data and IT landscape. Click on the links to get to the session content: Running the User Interface (UI) Running Governance Servers Kubernetes and lab notebooks Return to Running Egeria on your machine - Step-by-Step Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Running metadata ecosystems"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-running-egeria/","text":"Running Egeria on your machine - Step-by-Step \u00b6 In this session, you will be guided on how to set up Egeria on your machine to perform a variety of use cases. There are four main ways to run Egeria on your machine: * Download the Egeria repository from GitHub, build it and run the resulting image. * Download the Egeria docker image and run it as a standalone container using docker desktop. * Download the Egeria repository and use the docker-compose scripts to run egeria with a supporting cast of other technologies. * Download the Egeria repository and use the kubernetes helm charts to run egeria with a supporting cast of other technologies. This is in addition to the different ways that developers run Egeria when they are testing their contributions. Each of these methods has different benefits and costs. During the next two days you will have the opportunity to try each of these approaches so you can understand their pros and cons to make the best choice for your organization. Click on the links below in turn to access each part of this session. Don't forget to take your breaks. There is a lot of content to get through. Platform set up and configuration Running metadata servers Running metadata ecosystems Congratulations, you have completed the final step in the largest session in the dojo. There is one more short section to go and you have completed Day 1. Progress to Participating in the community Return to Egeria Project Introduction Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 3 running egeria"},{"location":"education/egeria-dojo/egeria-dojo-day-1-3-running-egeria/#running-egeria-on-your-machine-step-by-step","text":"In this session, you will be guided on how to set up Egeria on your machine to perform a variety of use cases. There are four main ways to run Egeria on your machine: * Download the Egeria repository from GitHub, build it and run the resulting image. * Download the Egeria docker image and run it as a standalone container using docker desktop. * Download the Egeria repository and use the docker-compose scripts to run egeria with a supporting cast of other technologies. * Download the Egeria repository and use the kubernetes helm charts to run egeria with a supporting cast of other technologies. This is in addition to the different ways that developers run Egeria when they are testing their contributions. Each of these methods has different benefits and costs. During the next two days you will have the opportunity to try each of these approaches so you can understand their pros and cons to make the best choice for your organization. Click on the links below in turn to access each part of this session. Don't forget to take your breaks. There is a lot of content to get through. Platform set up and configuration Running metadata servers Running metadata ecosystems Congratulations, you have completed the final step in the largest session in the dojo. There is one more short section to go and you have completed Day 1. Progress to Participating in the community Return to Egeria Project Introduction Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Running Egeria on your machine - Step-by-Step"},{"location":"education/egeria-dojo/egeria-dojo-day-1-4-participating-in-the-community/","text":"Participating in the Egeria Community \u00b6 In this session, you will learn about the resources to help you participate effectively in the Egeria community. Watch the video of this session: https://youtu.be/UJ7to5aG2oc . Mind set \u00b6 Egeria is an open source project. This means its most important asset is the community that it draws together to collaborate. It is only through this community that new ideas and content are contributed, and the results deployed into organization to help them operate more effectively. This community is stronger if it consists of individuals from different organizations and backgrounds. This means we need a respectful and inclusive culture to allow a diverse range of people to participate. This culture is reflected in the Code of Conduct that every participant must adhere to. Within the community, contributors are focused on making the contributions that are meaningful to them, or their employer. Beyond conforming to the rules of the community, they are not required to make changes requested by people and organizations outside of the community. Contributions are incorporated into the project at the discretion of the maintainers. For large changes, typically the maintainers look for consensus within the community before incorporating it. This means the only way to influence the progress of the project is to join the community, build a reputation as a valuable member of the community and then either influence other contributors, or make the contribution yourself. Getting connected \u00b6 The processes used by the community are documented in the Community Guide . This includes information about how to join the community and participate. Raising your status in the community \u00b6 The Egeria community has three special roles that you can work towards: Egeria Contributor - someone who has made multiple quality contributions to the community. Egeria Maintainer - an experienced Egeria contributor who is willing to help in the management of the community and the project contents. Egeria Project Leader - individual who is elected by the maintainers to lead the Egeria project. These roles are described in the Operations Guide . Egeria badges \u00b6 To recognise individuals who are either contributors or maintainers on the Egeria project, we are able to award Acclaim badges . Test yourself \u00b6 Using the material from the code of conduct and community guide answer the following questions. What time is the weekly community call in your local timezone? What are the principle communication mechanisms used by the Egeria community? Who nominates an individual to be officially recognized as an Egeria Contributor? To which foundation does the ODPi belong? Give two examples of unacceptable behavior when participating in the community. End of Day 1 \u00b6 Congratulations you have completed all of the sessions in Day 1 of the Egeria Dojo. Day 2 covers the information that you need to become and Egeria Contributor . Day 3 covers additional information for advocates and those wishing to become Egeria Maintainers . Progress to Dojo Overview to see the content for day 2. Return to Running Egeria on your machine Step-by-Step License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 1 4 participating in the community"},{"location":"education/egeria-dojo/egeria-dojo-day-1-4-participating-in-the-community/#participating-in-the-egeria-community","text":"In this session, you will learn about the resources to help you participate effectively in the Egeria community. Watch the video of this session: https://youtu.be/UJ7to5aG2oc .","title":"Participating in the Egeria Community"},{"location":"education/egeria-dojo/egeria-dojo-day-1-4-participating-in-the-community/#mind-set","text":"Egeria is an open source project. This means its most important asset is the community that it draws together to collaborate. It is only through this community that new ideas and content are contributed, and the results deployed into organization to help them operate more effectively. This community is stronger if it consists of individuals from different organizations and backgrounds. This means we need a respectful and inclusive culture to allow a diverse range of people to participate. This culture is reflected in the Code of Conduct that every participant must adhere to. Within the community, contributors are focused on making the contributions that are meaningful to them, or their employer. Beyond conforming to the rules of the community, they are not required to make changes requested by people and organizations outside of the community. Contributions are incorporated into the project at the discretion of the maintainers. For large changes, typically the maintainers look for consensus within the community before incorporating it. This means the only way to influence the progress of the project is to join the community, build a reputation as a valuable member of the community and then either influence other contributors, or make the contribution yourself.","title":"Mind set"},{"location":"education/egeria-dojo/egeria-dojo-day-1-4-participating-in-the-community/#getting-connected","text":"The processes used by the community are documented in the Community Guide . This includes information about how to join the community and participate.","title":"Getting connected"},{"location":"education/egeria-dojo/egeria-dojo-day-1-4-participating-in-the-community/#raising-your-status-in-the-community","text":"The Egeria community has three special roles that you can work towards: Egeria Contributor - someone who has made multiple quality contributions to the community. Egeria Maintainer - an experienced Egeria contributor who is willing to help in the management of the community and the project contents. Egeria Project Leader - individual who is elected by the maintainers to lead the Egeria project. These roles are described in the Operations Guide .","title":"Raising your status in the community"},{"location":"education/egeria-dojo/egeria-dojo-day-1-4-participating-in-the-community/#egeria-badges","text":"To recognise individuals who are either contributors or maintainers on the Egeria project, we are able to award Acclaim badges .","title":"Egeria badges"},{"location":"education/egeria-dojo/egeria-dojo-day-1-4-participating-in-the-community/#test-yourself","text":"Using the material from the code of conduct and community guide answer the following questions. What time is the weekly community call in your local timezone? What are the principle communication mechanisms used by the Egeria community? Who nominates an individual to be officially recognized as an Egeria Contributor? To which foundation does the ODPi belong? Give two examples of unacceptable behavior when participating in the community.","title":"Test yourself"},{"location":"education/egeria-dojo/egeria-dojo-day-1-4-participating-in-the-community/#end-of-day-1","text":"Congratulations you have completed all of the sessions in Day 1 of the Egeria Dojo. Day 2 covers the information that you need to become and Egeria Contributor . Day 3 covers additional information for advocates and those wishing to become Egeria Maintainers . Progress to Dojo Overview to see the content for day 2. Return to Running Egeria on your machine Step-by-Step License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"End of Day 1"},{"location":"education/egeria-dojo/egeria-dojo-day-2-1-open-source-philosophy/","text":"Open source philosophy \u00b6 In this session, you will learn about the way that open source projects and ecosystems work in general, and Egeria specifically. This will include a check list of items to verify before you start contributing to Egeria. Watch the video: https://youtu.be/-1YM8Nj51qg The presentation is here: https://github.com/odpi/data-governance/tree/master/workshops/may-2020 Progress to Tools for Contributors Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 2 1 open source philosophy"},{"location":"education/egeria-dojo/egeria-dojo-day-2-1-open-source-philosophy/#open-source-philosophy","text":"In this session, you will learn about the way that open source projects and ecosystems work in general, and Egeria specifically. This will include a check list of items to verify before you start contributing to Egeria. Watch the video: https://youtu.be/-1YM8Nj51qg The presentation is here: https://github.com/odpi/data-governance/tree/master/workshops/may-2020 Progress to Tools for Contributors Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Open source philosophy"},{"location":"education/egeria-dojo/egeria-dojo-day-2-2-tools-for-contributors/","text":"Tools for Contributors \u00b6 In this session, you will learn about the tools that many of the maintainers and contributors use when they are working on Egeria. With the exception of tools that are embedded on our processes, such as Git and Maven, you are not required to use the same tools. However, if you are using the same tools and you get stuck then the Egeria community is more likely to be able to help. Watch the video for a quick tour of the tools: https://youtu.be/k0cszugBiQg . Then browse the material below ... Session Content \u00b6 Follow the links to learn about the tools used to contribute to Egeria: Markdown - for web pages and documentation Git and GitHub - for managing Egeria's content IntelliJ - IDE that is popular with the Egeria community Maven - build tool Postman - REST API test tool HTTPie and Curl - Command line HTTP request tools Test yourself \u00b6 Once you have reviewed details of the tools try to answer these questions: What is the command to create a clean complete build of Egeria? How long does the complete build of Egeria take? What is the difference between a fork and a clone? What is the Postman collection used for? Which version of IntelliJ do you need to build contributions for Egeria? What are the different parts of the REST API call? What is the format of responses from REST API calls? This is the end of the Tools for Contributors Session. Progress to Contributing to Egeria - Step-by-Step Return to Open Source Philosophy Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 2 2 tools for contributors"},{"location":"education/egeria-dojo/egeria-dojo-day-2-2-tools-for-contributors/#tools-for-contributors","text":"In this session, you will learn about the tools that many of the maintainers and contributors use when they are working on Egeria. With the exception of tools that are embedded on our processes, such as Git and Maven, you are not required to use the same tools. However, if you are using the same tools and you get stuck then the Egeria community is more likely to be able to help. Watch the video for a quick tour of the tools: https://youtu.be/k0cszugBiQg . Then browse the material below ...","title":"Tools for Contributors"},{"location":"education/egeria-dojo/egeria-dojo-day-2-2-tools-for-contributors/#session-content","text":"Follow the links to learn about the tools used to contribute to Egeria: Markdown - for web pages and documentation Git and GitHub - for managing Egeria's content IntelliJ - IDE that is popular with the Egeria community Maven - build tool Postman - REST API test tool HTTPie and Curl - Command line HTTP request tools","title":"Session Content"},{"location":"education/egeria-dojo/egeria-dojo-day-2-2-tools-for-contributors/#test-yourself","text":"Once you have reviewed details of the tools try to answer these questions: What is the command to create a clean complete build of Egeria? How long does the complete build of Egeria take? What is the difference between a fork and a clone? What is the Postman collection used for? Which version of IntelliJ do you need to build contributions for Egeria? What are the different parts of the REST API call? What is the format of responses from REST API calls? This is the end of the Tools for Contributors Session. Progress to Contributing to Egeria - Step-by-Step Return to Open Source Philosophy Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Test yourself"},{"location":"education/egeria-dojo/egeria-dojo-day-2-3-contribution-to-egeria/","text":"Making a contribution to Egeria - Step-by-Step \u00b6 In this session, you will be guided on how to make a simple change to the Egeria project. This change is to add a new file to the egeria-dojo-postcards directory and link to it in the README.md file of the same directory. There are two videos for this session: How to make a contribution: https://youtu.be/vdHRtuIYwoE Pull Requests and testing: https://youtu.be/pMODYyPJ1b4 The Steps \u00b6 To create your own contribution, click on each step and complete the tasks described: Review the developer guidelines to understand the requirements for an Egeria contribution. Log on to GitHub . Create a Git Issue . Every contribution begins with a git issue . This describes the changes that you plan to make. The more detail that you provide, the better the maintainers will understand your contribution and be able to process it faster. Create a fork and clone of the git repository to bring the Egeria code onto your machine. Create a new git branch to contain your change. Load Egeria into your IDE so that you can see the project contents. Build Egeria so it is ready to run. The link assumes you are using IntelliJ. If you prefer working with the command line try this link Create your contribution - typically using the IDE. You need to create a new markdown file, add your message to the file and then add a link to the README.md file. Both of these files should use Markdown and include license and copyright statements top and bottom of the file just like this file: License File Example . (There is more information on licences in the Developer Guidelines .) Test your changes to make sure your new function works and nothing else has broken. Since this is a document change, there should be no impact on the code - so running these tests is to check that nothing has changed by accident. Add and commit changes to Git . As you commit your changes, make sure they are signed (see Why the DCO? ). Initiate the request to include your changes into the master branch of Egeria. Once the PR is in place, GitHub will check the DCOs for you commits, and then run a full build on Java 8 and Java 11. The Egeria maintainers will review your contribution and may ask ask you to make changes to it. When it is acceptable, they will merge it into master and your contribution is complete. Progress to Types of Contribution Return to Tools for Contributors Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 2 3 contribution to egeria"},{"location":"education/egeria-dojo/egeria-dojo-day-2-3-contribution-to-egeria/#making-a-contribution-to-egeria-step-by-step","text":"In this session, you will be guided on how to make a simple change to the Egeria project. This change is to add a new file to the egeria-dojo-postcards directory and link to it in the README.md file of the same directory. There are two videos for this session: How to make a contribution: https://youtu.be/vdHRtuIYwoE Pull Requests and testing: https://youtu.be/pMODYyPJ1b4","title":"Making a contribution to Egeria - Step-by-Step"},{"location":"education/egeria-dojo/egeria-dojo-day-2-3-contribution-to-egeria/#the-steps","text":"To create your own contribution, click on each step and complete the tasks described: Review the developer guidelines to understand the requirements for an Egeria contribution. Log on to GitHub . Create a Git Issue . Every contribution begins with a git issue . This describes the changes that you plan to make. The more detail that you provide, the better the maintainers will understand your contribution and be able to process it faster. Create a fork and clone of the git repository to bring the Egeria code onto your machine. Create a new git branch to contain your change. Load Egeria into your IDE so that you can see the project contents. Build Egeria so it is ready to run. The link assumes you are using IntelliJ. If you prefer working with the command line try this link Create your contribution - typically using the IDE. You need to create a new markdown file, add your message to the file and then add a link to the README.md file. Both of these files should use Markdown and include license and copyright statements top and bottom of the file just like this file: License File Example . (There is more information on licences in the Developer Guidelines .) Test your changes to make sure your new function works and nothing else has broken. Since this is a document change, there should be no impact on the code - so running these tests is to check that nothing has changed by accident. Add and commit changes to Git . As you commit your changes, make sure they are signed (see Why the DCO? ). Initiate the request to include your changes into the master branch of Egeria. Once the PR is in place, GitHub will check the DCOs for you commits, and then run a full build on Java 8 and Java 11. The Egeria maintainers will review your contribution and may ask ask you to make changes to it. When it is acceptable, they will merge it into master and your contribution is complete. Progress to Types of Contribution Return to Tools for Contributors Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"The Steps"},{"location":"education/egeria-dojo/egeria-dojo-day-2-4-types-of-contribution/","text":"Types of contribution \u00b6 In this session, you will learn about the different types of contribution and how much knowledge of Egeria is required to complete one. The diagram below shows the different types of contribution. We have used the same color scheme as the dojo sessions to give you a view on how hard each one is. The video describe each type of contribution with pointers to the design information you need to make a contribution of that type. https://youtu.be/_nnoQGk84bk Progress to Becoming a contributor Return to Contributing to Egeria - Step-by-Step Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 2 4 types of contribution"},{"location":"education/egeria-dojo/egeria-dojo-day-2-4-types-of-contribution/#types-of-contribution","text":"In this session, you will learn about the different types of contribution and how much knowledge of Egeria is required to complete one. The diagram below shows the different types of contribution. We have used the same color scheme as the dojo sessions to give you a view on how hard each one is. The video describe each type of contribution with pointers to the design information you need to make a contribution of that type. https://youtu.be/_nnoQGk84bk Progress to Becoming a contributor Return to Contributing to Egeria - Step-by-Step Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Types of contribution"},{"location":"education/egeria-dojo/egeria-dojo-day-2-5-becoming-a-contributor/","text":"Becoming an Egeria contributor \u00b6 In this session, you will learn about how to be recognized as an Egeria Contributor by the Egeria community. Watch the video to find out more: https://youtu.be/e3pEXZ6iatE What does it mean to be recognized as an Egeria contributor? \u00b6 An Egeria Contributor is someone who has made multiple quality contributions to the Egeria community. This role is described in the Operations Guide . Egeria badges \u00b6 To recognise individuals who are established contributors to the Egeria project, the Egeria community is able to award Acclaim badges . Test yourself \u00b6 Using the material from the Egeria operations guide answer the following questions. How many contributors are listed for the Egeria project? What is the DCO? How often do the maintainers create a release of Egeria? End of Day 2 \u00b6 Congratulations you have completed all of the sessions in Day 2 of the Egeria Dojo. Day 3 covers additional information for advocates and those wishing to become Egeria Maintainers . Progress to Dojo Overview to see the content for day 3. Return to Running Egeria on your machine Step-by-Step License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 2 5 becoming a contributor"},{"location":"education/egeria-dojo/egeria-dojo-day-2-5-becoming-a-contributor/#becoming-an-egeria-contributor","text":"In this session, you will learn about how to be recognized as an Egeria Contributor by the Egeria community. Watch the video to find out more: https://youtu.be/e3pEXZ6iatE","title":"Becoming an Egeria contributor"},{"location":"education/egeria-dojo/egeria-dojo-day-2-5-becoming-a-contributor/#what-does-it-mean-to-be-recognized-as-an-egeria-contributor","text":"An Egeria Contributor is someone who has made multiple quality contributions to the Egeria community. This role is described in the Operations Guide .","title":"What does it mean to be recognized as an Egeria contributor?"},{"location":"education/egeria-dojo/egeria-dojo-day-2-5-becoming-a-contributor/#egeria-badges","text":"To recognise individuals who are established contributors to the Egeria project, the Egeria community is able to award Acclaim badges .","title":"Egeria badges"},{"location":"education/egeria-dojo/egeria-dojo-day-2-5-becoming-a-contributor/#test-yourself","text":"Using the material from the Egeria operations guide answer the following questions. How many contributors are listed for the Egeria project? What is the DCO? How often do the maintainers create a release of Egeria?","title":"Test yourself"},{"location":"education/egeria-dojo/egeria-dojo-day-2-5-becoming-a-contributor/#end-of-day-2","text":"Congratulations you have completed all of the sessions in Day 2 of the Egeria Dojo. Day 3 covers additional information for advocates and those wishing to become Egeria Maintainers . Progress to Dojo Overview to see the content for day 3. Return to Running Egeria on your machine Step-by-Step License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"End of Day 2"},{"location":"education/egeria-dojo/egeria-dojo-day-3-1-becoming-an-advocate/","text":"Becoming an advocate \u00b6 In this session, you will learn about how to become an advocate for the Egeria technology. Watch the video to hear about being an Egeria advocates from the experts: https://youtu.be/zmr7H6Tk5BM Progress to Becoming a maintainer Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 3 1 becoming an advocate"},{"location":"education/egeria-dojo/egeria-dojo-day-3-1-becoming-an-advocate/#becoming-an-advocate","text":"In this session, you will learn about how to become an advocate for the Egeria technology. Watch the video to hear about being an Egeria advocates from the experts: https://youtu.be/zmr7H6Tk5BM Progress to Becoming a maintainer Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Becoming an advocate"},{"location":"education/egeria-dojo/egeria-dojo-day-3-2-becoming-a-maintainer/","text":"Becoming a maintainer \u00b6 In this session, you will learn useful tips on building a reputation that will help you to be recognized as an Egeria Maintainer. Listen to Egeria's maintainers talking about their experiences on being a maintainer on Egeria. https://youtu.be/BQf48I6pFf8 Further information \u00b6 Requirements for being a maintainer is described in Egeria's Operation Guide . Note : a maintainer on Egeria is equivalent to a \"committer\" in the Apache Software Foundation (ASF) . Progress to Egeria Architecture and Philosophy - the deep stuff Return to Becoming an advocate Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 3 2 becoming a maintainer"},{"location":"education/egeria-dojo/egeria-dojo-day-3-2-becoming-a-maintainer/#becoming-a-maintainer","text":"In this session, you will learn useful tips on building a reputation that will help you to be recognized as an Egeria Maintainer. Listen to Egeria's maintainers talking about their experiences on being a maintainer on Egeria. https://youtu.be/BQf48I6pFf8","title":"Becoming a maintainer"},{"location":"education/egeria-dojo/egeria-dojo-day-3-2-becoming-a-maintainer/#further-information","text":"Requirements for being a maintainer is described in Egeria's Operation Guide . Note : a maintainer on Egeria is equivalent to a \"committer\" in the Apache Software Foundation (ASF) . Progress to Egeria Architecture and Philosophy - the deep stuff Return to Becoming an advocate Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Further information"},{"location":"education/egeria-dojo/egeria-dojo-day-3-3-egeria-architecture/","text":"Egeria architecture and philosophy - the deep stuff \u00b6 In this session, you will learn about the Egeria architecture, history and approach. Watch this video to understand Egeria's architecture principles and how they manifest themselves in the project's design and implementation. https://youtu.be/n-Xm8_WIyBM The charts for this session are stored in the data-governance git repository . Progress to the Egeria Social Return to Becoming a maintainer Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 3 3 egeria architecture"},{"location":"education/egeria-dojo/egeria-dojo-day-3-3-egeria-architecture/#egeria-architecture-and-philosophy-the-deep-stuff","text":"In this session, you will learn about the Egeria architecture, history and approach. Watch this video to understand Egeria's architecture principles and how they manifest themselves in the project's design and implementation. https://youtu.be/n-Xm8_WIyBM The charts for this session are stored in the data-governance git repository . Progress to the Egeria Social Return to Becoming a maintainer Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria architecture and philosophy - the deep stuff"},{"location":"education/egeria-dojo/egeria-dojo-day-3-4-egeria-social/","text":"Egeria Social \u00b6 Congratulations you have made it through the dojo. If you are attending a live version of the Dojo, this is the time to join the other participants and other members of the Egeria community in an informal and open discussion. Perhaps this is a time to start the conversation on what you would like to contribute to the project? Even if you are doing the dojo as a self-study exercise, now is a time to reflect on your next steps. Here are some suggestions: * If there are errors in the dojo - or missing explanations - then please consider contributing some improvements. * Block time in your calendar for the community calls. * Arrange to give a presentation to your colleagues on how Egeria could benefit your organization. * Raise an issue on GitHub and get working on your next contribution. If you would like to contribute, but are not sure what would be valuable, ask for advice on the #egeria-project slack channel. We look forward to working with you in the future. Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria dojo day 3 4 egeria social"},{"location":"education/egeria-dojo/egeria-dojo-day-3-4-egeria-social/#egeria-social","text":"Congratulations you have made it through the dojo. If you are attending a live version of the Dojo, this is the time to join the other participants and other members of the Egeria community in an informal and open discussion. Perhaps this is a time to start the conversation on what you would like to contribute to the project? Even if you are doing the dojo as a self-study exercise, now is a time to reflect on your next steps. Here are some suggestions: * If there are errors in the dojo - or missing explanations - then please consider contributing some improvements. * Block time in your calendar for the community calls. * Arrange to give a presentation to your colleagues on how Egeria could benefit your organization. * Raise an issue on GitHub and get working on your next contribution. If you would like to contribute, but are not sure what would be valuable, ask for advice on the #egeria-project slack channel. We look forward to working with you in the future. Return to Dojo Overview License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Egeria Social"},{"location":"education/egeria-dojo/overview/","text":"The Egeria Dojo \u00b6 The Egeria Dojo is an intensive course to help you learn about Egeria. It is designed as a 3 day effort, although, since it is self-study you can dip in and out of it as time permits. The objectives of the three day are as follows: Day 1 : Learning about setting up and running Egeria on you own machine. Day 2 : Learning how to make a contribution to Egeria Day 3 : Learning how to become either an advocate or a maintainer The sessions are color-coded like ski runs. As you progress through the dojo, the colors of the sessions show how advanced your knowledge is becoming. The schedule also includes estimated times needed to complete each session as well as breaks to give your mind a rest from time to time. Also within the sessions are links to videos of the live sessions run in May 2020. These videos are consolidated into single playlist on YouTube here: https://www.youtube.com/playlist?list=PLhfwwk2gl_5Y7ZE8kHjGKyuIEZMQ5Hkfp Day 1 \u00b6 After completing day 1 of the Egeria dojo you should feel comfortable with setting up and running the Egeria technology. It includes sessions on the prerequisite technology that Egeria uses, how to configure Egeria, how to start and stop various capabilities and well as diagnosing any problems you may come across. Day 1 Overview Links to content * Egeria Introduction * Egeria Project Introduction * Running Egeria on your Machine - Step-by-Step * Participating in the Community Day 2 \u00b6 Day 2 of the Egeria dojo is all about making changes to the Egeria project. This may be to add code, documentation or samples. You will have an opportunity to add a new file to the Egeria project and take it all the way through the process to update Egeria's git repository. Day 2 Overview Links to content: * Open Source Philosophy * Tools for Contributors * Making a contribution - Step-by-Step * Types of Contribution * Becoming a Contributor Day 3 \u00b6 Day 3 prepares you to become an Egeria professional - either as an advocate of the technology or a maintainer. It goes much deeper into the philosophy, design and processes of the project. Day 3 Overview Links to content: * Becoming an advocate * Becoming a maintainer * Egeria architecture and philosophy (the deep stuff) * Egeria social Video Links \u00b6 On 26th-28th May 2020, the Egeria community ran three live sessions walking through the dojo. The videos are from these sessions. Watch a video describing the Dojo Link to the YouTube play list for all of the recorded dojo sessions . Return to Tutorials Menu License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Overview"},{"location":"education/egeria-dojo/overview/#the-egeria-dojo","text":"The Egeria Dojo is an intensive course to help you learn about Egeria. It is designed as a 3 day effort, although, since it is self-study you can dip in and out of it as time permits. The objectives of the three day are as follows: Day 1 : Learning about setting up and running Egeria on you own machine. Day 2 : Learning how to make a contribution to Egeria Day 3 : Learning how to become either an advocate or a maintainer The sessions are color-coded like ski runs. As you progress through the dojo, the colors of the sessions show how advanced your knowledge is becoming. The schedule also includes estimated times needed to complete each session as well as breaks to give your mind a rest from time to time. Also within the sessions are links to videos of the live sessions run in May 2020. These videos are consolidated into single playlist on YouTube here: https://www.youtube.com/playlist?list=PLhfwwk2gl_5Y7ZE8kHjGKyuIEZMQ5Hkfp","title":"The Egeria Dojo"},{"location":"education/egeria-dojo/overview/#day-1","text":"After completing day 1 of the Egeria dojo you should feel comfortable with setting up and running the Egeria technology. It includes sessions on the prerequisite technology that Egeria uses, how to configure Egeria, how to start and stop various capabilities and well as diagnosing any problems you may come across. Day 1 Overview Links to content * Egeria Introduction * Egeria Project Introduction * Running Egeria on your Machine - Step-by-Step * Participating in the Community","title":"Day 1"},{"location":"education/egeria-dojo/overview/#day-2","text":"Day 2 of the Egeria dojo is all about making changes to the Egeria project. This may be to add code, documentation or samples. You will have an opportunity to add a new file to the Egeria project and take it all the way through the process to update Egeria's git repository. Day 2 Overview Links to content: * Open Source Philosophy * Tools for Contributors * Making a contribution - Step-by-Step * Types of Contribution * Becoming a Contributor","title":"Day 2"},{"location":"education/egeria-dojo/overview/#day-3","text":"Day 3 prepares you to become an Egeria professional - either as an advocate of the technology or a maintainer. It goes much deeper into the philosophy, design and processes of the project. Day 3 Overview Links to content: * Becoming an advocate * Becoming a maintainer * Egeria architecture and philosophy (the deep stuff) * Egeria social","title":"Day 3"},{"location":"education/egeria-dojo/overview/#video-links","text":"On 26th-28th May 2020, the Egeria community ran three live sessions walking through the dojo. The videos are from these sessions. Watch a video describing the Dojo Link to the YouTube play list for all of the recorded dojo sessions . Return to Tutorials Menu License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Video Links"},{"location":"education/planned-webinars/overview/","text":"Planned Egeria Webinars \u00b6 For the webinars being planned see page https://wiki.lfaidata.foundation/display/EG/Egeria+Webinar+program Please check the calendar has the latest confirmed Webinar information Return to Git Repository Home Page","title":"Planned Webinars"},{"location":"education/planned-webinars/overview/#planned-egeria-webinars","text":"For the webinars being planned see page https://wiki.lfaidata.foundation/display/EG/Egeria+Webinar+program Please check the calendar has the latest confirmed Webinar information Return to Git Repository Home Page","title":"Planned Egeria Webinars"},{"location":"education/previous-webinars/","text":"Previous Egeria Webinars \u00b6 Webinars on open metadata and governance are run on a regular basis, there was a break during the pandemic. Each webinar focuses on a specific audience or issue. The material for our webinars is stored below along with links to the recordings. Value of Egeria - October 2021 Visualising a metadata eco system - September 2021 Building a governed data lake with Egeria - June 2020 Building a Data Catalog with Egeria - April 2020 Egeria virtual metadata show - March 2020 (Three days of topics relating to Egeria from ING, IBM and SAS). New Approaches to Managing Access to Sensitive Data - December 2019 Managing data privacy - July 2018 Metadata standards - April 2018 Free your metadata - October 2017 Return to Git Repository Home Page","title":"Previous Webinars"},{"location":"education/previous-webinars/#previous-egeria-webinars","text":"Webinars on open metadata and governance are run on a regular basis, there was a break during the pandemic. Each webinar focuses on a specific audience or issue. The material for our webinars is stored below along with links to the recordings. Value of Egeria - October 2021 Visualising a metadata eco system - September 2021 Building a governed data lake with Egeria - June 2020 Building a Data Catalog with Egeria - April 2020 Egeria virtual metadata show - March 2020 (Three days of topics relating to Egeria from ING, IBM and SAS). New Approaches to Managing Access to Sensitive Data - December 2019 Managing data privacy - July 2018 Metadata standards - April 2018 Free your metadata - October 2017 Return to Git Repository Home Page","title":"Previous Egeria Webinars"},{"location":"education/previous-webinars/april-2018/","text":"Open Metadata Standards \u00b6 Date: 26th April 2018 This presentation provides a description of the open metadata standards associated with exchanging metadata across a cohort. It is still accurate except for the chart that describes Apache Atlas as the reference implementation for open metadata. The reference implementation has moved to the ODPi Egeria project . Presentations Day 1 Day 2 Day 3 YouTube Video: Return to Webinar list","title":"Index"},{"location":"education/previous-webinars/april-2018/#open-metadata-standards","text":"Date: 26th April 2018 This presentation provides a description of the open metadata standards associated with exchanging metadata across a cohort. It is still accurate except for the chart that describes Apache Atlas as the reference implementation for open metadata. The reference implementation has moved to the ODPi Egeria project . Presentations Day 1 Day 2 Day 3 YouTube Video: Return to Webinar list","title":"Open Metadata Standards"},{"location":"education/previous-webinars/april-2020/","text":"Webinar - Building a data catalog with Egeria \u00b6 Date: 28th April 2020 The Building a data catalog with Egeria webinar covers the different APIs and services that support the creation and maintenance of a catalog of data assets. This catalog helps an organization find and use data and related assets effectively. Presentation YouTube Video: Return to Webinar list","title":"Index"},{"location":"education/previous-webinars/april-2020/#webinar-building-a-data-catalog-with-egeria","text":"Date: 28th April 2020 The Building a data catalog with Egeria webinar covers the different APIs and services that support the creation and maintenance of a catalog of data assets. This catalog helps an organization find and use data and related assets effectively. Presentation YouTube Video: Return to Webinar list","title":"Webinar - Building a data catalog with Egeria"},{"location":"education/previous-webinars/december-2019/","text":"Webinar - New Approaches to Managing Access to Sensitive Data \u00b6 Date: 6th December 2010 What happens when you need your data scientist to repeatedly work with your most valuable and sensitive data? How do you prevent them from seeing more than they need whilst ensuring that they have a productive and enabling work environment. In this webinar we look at 3 different approaches to managing secure access to data sets that include the most personal and sensitive data. In each approach we use increasing automated means to create selective access to an employee data set that includes correlated personal, performance and financial information. The technology involved is all open source and includes ODPi Egeria and Palisade. Together they will change the way you think about access control. Presentation YouTube Video: Return to Webinar list","title":"Index"},{"location":"education/previous-webinars/december-2019/#webinar-new-approaches-to-managing-access-to-sensitive-data","text":"Date: 6th December 2010 What happens when you need your data scientist to repeatedly work with your most valuable and sensitive data? How do you prevent them from seeing more than they need whilst ensuring that they have a productive and enabling work environment. In this webinar we look at 3 different approaches to managing secure access to data sets that include the most personal and sensitive data. In each approach we use increasing automated means to create selective access to an employee data set that includes correlated personal, performance and financial information. The technology involved is all open source and includes ODPi Egeria and Palisade. Together they will change the way you think about access control. Presentation YouTube Video: Return to Webinar list","title":"Webinar - New Approaches to Managing Access to Sensitive Data"},{"location":"education/previous-webinars/july-2018/","text":"Managing Privacy \u00b6 Date: 12th July 2018 There is increasing public awareness about the issues of data privacy. Individuals are concerned with how data about themselves is used in digital services, such as websites, and mobile apps. In this webinar we will be discussing how an organization that offers digital services can manage data about individuals so that their privacy is respected and the organization is compliant with new regulations on data privacy such as the EU General Data Protection Regulation (GDPR). You will learn: The life cycle of a digital service as it is developed, sold, enhanced and used. This life cycle breaks the work into six stages. Each stage describes the roles and the activities involved to ensure data privacy. The types of artifacts that need to be collected about a digital service and the methods used to develop it. How these artifacts link together in an open metadata repository (data catalog). Finally we will demonstrate the ODPi's data privacy pack that provides documentation and open metadata definitions for a privacy program. The ODPi's data privacy pack is the first open source initiative for data privacy. It is being developed by a team of cross-industry, multi-vendor data privacy experts. Join the call to find out more and maybe join the team to build your skills and share your expertise. Presentation YouTube Video: Return to Webinar list","title":"Index"},{"location":"education/previous-webinars/july-2018/#managing-privacy","text":"Date: 12th July 2018 There is increasing public awareness about the issues of data privacy. Individuals are concerned with how data about themselves is used in digital services, such as websites, and mobile apps. In this webinar we will be discussing how an organization that offers digital services can manage data about individuals so that their privacy is respected and the organization is compliant with new regulations on data privacy such as the EU General Data Protection Regulation (GDPR). You will learn: The life cycle of a digital service as it is developed, sold, enhanced and used. This life cycle breaks the work into six stages. Each stage describes the roles and the activities involved to ensure data privacy. The types of artifacts that need to be collected about a digital service and the methods used to develop it. How these artifacts link together in an open metadata repository (data catalog). Finally we will demonstrate the ODPi's data privacy pack that provides documentation and open metadata definitions for a privacy program. The ODPi's data privacy pack is the first open source initiative for data privacy. It is being developed by a team of cross-industry, multi-vendor data privacy experts. Join the call to find out more and maybe join the team to build your skills and share your expertise. Presentation YouTube Video: Return to Webinar list","title":"Managing Privacy"},{"location":"education/previous-webinars/june-2020/","text":"Webinar - Building a governed data lake with Egeria \u00b6 Date: 2nd June 2020 Data lakes provide a flexible environment for managing many types of data at scale. In this presentation, we will cover how open metadata can increase the effectiveness and protection of the data lake and avoid it running into a mighty data swamp. Presentation YouTube Video: Return to Webinar list","title":"Index"},{"location":"education/previous-webinars/june-2020/#webinar-building-a-governed-data-lake-with-egeria","text":"Date: 2nd June 2020 Data lakes provide a flexible environment for managing many types of data at scale. In this presentation, we will cover how open metadata can increase the effectiveness and protection of the data lake and avoid it running into a mighty data swamp. Presentation YouTube Video: Return to Webinar list","title":"Webinar - Building a governed data lake with Egeria"},{"location":"education/previous-webinars/march-2020/","text":"Egeria Virtual Metadata Show \u00b6 Date: 24th \u2013 26th March Find out how metadata can enable enterprise-wide knowledge and understanding for all data assets in an organization. Get the latest information on the Egeria Open Metadata exchange standard and capabilities, that makes it possible for any tool or application repository to share metadata in real-time. Day 1 Why Egeria is an open source project \u2013 John Mertic (Linux Foundation) The Egeria Journey so far \u2013 Maryna Strelchuk (ING Bank) Design Lineage - ING Bank Perspective Q&A Day 2 Metadata essentials for the data driven organisation - Mandy Chessell (IBM) Everything Metadata - Chris Replogle (SAS) How to adopt the Egeria Framework Q&A Day 3 Lightening Talks 3pm Supporting ethical AI Industry Models and Business Glossaries Egeria and Cloud Pak\u2019s Egeria driving Enterprise API's Q&A why is Egeria an open source project Day 1 presentation Day 2 presentation Day 3 presentation YouTube Day 1 Video: Link to video YouTube Day 2 Video: Link to video YouTube Day 3 Video: Return to Webinar list","title":"Index"},{"location":"education/previous-webinars/march-2020/#egeria-virtual-metadata-show","text":"Date: 24th \u2013 26th March Find out how metadata can enable enterprise-wide knowledge and understanding for all data assets in an organization. Get the latest information on the Egeria Open Metadata exchange standard and capabilities, that makes it possible for any tool or application repository to share metadata in real-time. Day 1 Why Egeria is an open source project \u2013 John Mertic (Linux Foundation) The Egeria Journey so far \u2013 Maryna Strelchuk (ING Bank) Design Lineage - ING Bank Perspective Q&A Day 2 Metadata essentials for the data driven organisation - Mandy Chessell (IBM) Everything Metadata - Chris Replogle (SAS) How to adopt the Egeria Framework Q&A Day 3 Lightening Talks 3pm Supporting ethical AI Industry Models and Business Glossaries Egeria and Cloud Pak\u2019s Egeria driving Enterprise API's Q&A why is Egeria an open source project Day 1 presentation Day 2 presentation Day 3 presentation YouTube Day 1 Video: Link to video YouTube Day 2 Video: Link to video YouTube Day 3 Video: Return to Webinar list","title":"Egeria Virtual Metadata Show"},{"location":"education/previous-webinars/october-2017/","text":"Webinar - Free your metadata \u00b6 A definition of metadata and why it is essential to your organization. Presentation YouTube Video: Return to Webinar list","title":"Index"},{"location":"education/previous-webinars/october-2017/#webinar-free-your-metadata","text":"A definition of metadata and why it is essential to your organization. Presentation YouTube Video: Return to Webinar list","title":"Webinar - Free your metadata"},{"location":"education/previous-webinars/october-2021/","text":"The Value of Egeria \u00b6 Date: 4th October 2021 Presenter: Mandy Chessell This session is for people wanting to understand the value of Egeria in enabling data centric, metadata driven integration. The session will start with the core Egeria constructs, including entities, explaining the principles behind why they are as they are. The session will go through the layers and aspects of the Egeria architecture, at each stage talking about the applicability to solving real world problems. By the end of the session you should have awareness of the parts of Egeria at a high level; why they have been implemented that way and the value that each piece brings. Link to event advertising Link to recording on YouTube TBA Presentation \u00b6 Return to Webinar list","title":"Index"},{"location":"education/previous-webinars/october-2021/#the-value-of-egeria","text":"Date: 4th October 2021 Presenter: Mandy Chessell This session is for people wanting to understand the value of Egeria in enabling data centric, metadata driven integration. The session will start with the core Egeria constructs, including entities, explaining the principles behind why they are as they are. The session will go through the layers and aspects of the Egeria architecture, at each stage talking about the applicability to solving real world problems. By the end of the session you should have awareness of the parts of Egeria at a high level; why they have been implemented that way and the value that each piece brings. Link to event advertising Link to recording on YouTube TBA Presentation","title":"The Value of Egeria"},{"location":"education/previous-webinars/october-2021/#_1","text":"Return to Webinar list","title":""},{"location":"education/previous-webinars/september-2021/","text":"Visualising a Metadata Ecosystem \u00b6 Date: 13th September 2021 Presenter: David Radley The session is for people looking to understand the metadata across their ecosystem in terms of the Egeria open types and instances using visualisations in the Egeria React User Interface. Understanding the types is important knowledge when developing connectors and new APIs like OMAS\u2019s. This session will also show how metadata instances can be explored at a low level. This will be contrasted with an exploration of semantic data that is based on the Subject Area Open Metadata Access Service (OMAS). Link to event advertising Presentation YouTube Video: Return to Webinar list","title":"Index"},{"location":"education/previous-webinars/september-2021/#visualising-a-metadata-ecosystem","text":"Date: 13th September 2021 Presenter: David Radley The session is for people looking to understand the metadata across their ecosystem in terms of the Egeria open types and instances using visualisations in the Egeria React User Interface. Understanding the types is important knowledge when developing connectors and new APIs like OMAS\u2019s. This session will also show how metadata instances can be explored at a low level. This will be contrasted with an exploration of semantic data that is based on the Subject Area Open Metadata Access Service (OMAS). Link to event advertising Presentation YouTube Video: Return to Webinar list","title":"Visualising a Metadata Ecosystem"},{"location":"education/tutorials/docker-tutorial/","text":"Docker tutorial \u00b6 This tutorial explains how to use the Egeria Docker Image published to the docker catalog at https://hub.docker.com/r/odpi/egeria . Egeria's docker image includes the Egeria install image. When the image is started using docker, a new egeria docker container is created. As it starts up, an instance of the Egeria runtime - that is the OMAG Server Platform - is started at port https 9443. This container can be incorporated into larger container orchestration environments or used standalone. This tutorial describes how to use it standalone. The Open Metadata Labs use this container with either the docker-compose or Kubernetes container services to create a complete open metadata solution. Link to Hands-on Labs Infrastructure Guide to learn more. Working with Egeria's docker image \u00b6 If docker is new to you and you don't have it installed, link to the article on docker in the developer tools . This provides an overview of docker and installation instructions for Docker Desktop. Once the docker desktop is installed, start the docker desktop application. It may take a little while to complete its start up so check it is running before continuing. For example, on macOS, the docker desktop can be found on the Launchpad . Once it is running, the docker whale icon appears on the top menu bar. Clicking on the docker whale icon reveals a menu and the status of the desk top is visible. This menu is used to shutdown docker at the end of the dojo. Downloading the egeria docker image \u00b6 The command to download Egeria's docker image is docker pull odpi/egeria . This is issued from a command/terminal window in the directory where you want the container to be copied to. If you see the following response, then the docker runtime is not installed properly on your machine. $ docker pull odpi/egeria -bash: docker: command not found If all is well, the image downloads. Notice it is pulling the latest master build by default. $ docker pull odpi/egeria Using default tag: latest latest: Pulling from odpi/egeria e7c96db7181b: Pull complete f910a506b6cb: Pull complete b6abafe80f63: Pull complete a83b87485b54: Pull complete 10d9ee7d5688: Pull complete 9558171b7a95: Pull complete Digest: sha256:18451a4676a6688e03f284f887ba5be7026c17805ee0b919ed02cb131621d45b Status: Downloaded newer image for odpi/egeria:latest docker.io/odpi/egeria:latest $ To check it will run, try the docker run --publish 19443:9443 odpi/egeria . This will start the image as a new docker container. As the container initializes it starts a single copy of the OMAG Server Platform . The OMAG Server Platform is the Egeria runtime platform where the Egeria REST services run. The --publish 19443:9443 parameter maps the 9443 port inside the docker that the OMAG Server Platform has registered with to port 19443 You should see the server logo come up and finally a message OMAG server platform ready for more configuration . This message means it has successfully started. Once you can see that it has started, use Control-C to stop it. $ docker run --publish 19443 :9443 odpi/egeria Picked up JAVA_TOOL_OPTIONS: ODPi Egeria ____ __ ___ ___ ______ _____ ____ _ _ ___ / __ \\ / | / // | / ____/ / ___/ ___ ____ _ __ ___ ____ / _ \\ / / __ / / / _ /__ ____ _ _ / / / // / | _/ // / | | / / __ \\_ _ \\ / _ \\ / __/ | | / // _ \\ / __/ / /_/ // // | / _ \\ / /_ / | / _// || | / /_/ // / / // ___ | / /_/ / ___/ // __// / | | / // __// / / __ // // / \\ / /_ / _// / // / / / / / \\_ ___//_/ /_//_/ | _ | \\_ ___/ /____/ \\_ __//_/ | ___/ \\_ __//_/ /_/ /_/ \\_ _/ \\/ /___//_/ \\_ _//_/ /_/ /_/ :: Powered by Spring Boot ( v2.3.0.RELEASE ) :: 10 :12:28.047 [ main ] INFO o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port ( s ) : 9443 ( https ) 10 :12:41.688 [ main ] INFO o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port ( s ) : 9443 ( https ) with context path '' Thu Jun 04 10 :12:32 BST 2020 No OMAG servers listed in startup configuration Thu Jun 04 10 :12:41 BST 2020 OMAG server platform ready for more configuration ^C $ Working with the Docker Desktop Dashboard \u00b6 The docker desktop dashboard makes it easy to control your docker containers. It is started from the docker desktop menu. Select the Dashboard option. You will see something like this: Each time a new docker container is created, it is given a generated name. In the example above the name is gifted-lovelace which is a great tribute to Ada Lovelace . You can see that the container is not running ( EXITED ) because you stopped it earlier with Control-C . Hover your mouse pointer over the container entry and some options appear. The triangular \"START\" button is to start the container running again and the Bin/Trash can is to delete your container. Press the \"START\" button to start your container again. When the container is running, more options are available to you when you hover the mouse over the container entry. The first symbol is the \"OPEN IN BROWSER\" option. Click on it and your browser opens. You should see an error displayed: Update the URL as follows: and press enter. After a few moments, Egeria's Swagger page should open. This is an automatically generated page that describes the REST APIs of Egeria's OMAG Server Platform. There is more information on swagger in the Developer's tools pages . Page down until you see the \"Platform Services\". The platform services provide support for administrators running Egeria. Click on the angle bracket on the right hand end of the entry and the list of REST API operations is displayed. Now click on the first blue entry for platform origin. Then press the Try it Out button. and enter garygeeke in the userId field and then the Execute button. You can see that through the Swagger UI it is possible to try out different REST requests and make sure the platform is operating correctly. The platform origin request is particularly useful for verifying what version of the OMAG Server Platform is running. The Swagger UI is useful for ad hoc testing. However, later in the Dojo we will cover a tool called Postman that provides a more powerful testing experience. So back to the Docker Desktop. The second option on the docker desktop is \"CLI\". This opens the Terminal/Command window inside the docker container . You are in the home directory of the OMAG Server Platform. This contains the contents of the egeria install image. It is also the home directory of the OMAG Server Platform which is where it will write its files. Type ls to list the files. $ ls LICENSE clients server utilities NOTICE conformance-suite user-interface $ Only the files from the install image are present because we have not asked the OMAG Server Platform to do anything yet. However, as we configure servers and run them, you will see new files appearing. You can check back here from time to time to see the files accumulating. If you delete this container then all of the files that the OMAG Server Platform created are lost. (If you want to know more about the egeria install image, see the Installing Egeria Tutorial .) The third button on the docker desktop is the \"STOP\" button and the fourth button is \"RESTART\". If you just need to test these buttons, remember to ensure that the docker container is running when you have finished because it is needed for the rest of the session. The final button is \"DELETE\". As described above, it deletes the container and uoi need to start again with docker run --publish 19443:9443 odpi/egeria . If you now click on the whitespace of the container's entry, a new section opens up with 3 tabs. \"Logs\" shows the console logs. Each new run of the container appends new log information to the end of this console. \"Inspect\" shows the settings for the container. \"Stats\" shows the resource usage of the container. ... and that is all you need to know about docker. Congratulations, you are familiar enough with running docker containers to continue with the Egeria Dojo . Return to Egeria Dojo Link to other tutorials Link to Hands on labs there this docker image is used as part of the suite of containers that supports the lab infrastructure . License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Docker tutorial"},{"location":"education/tutorials/docker-tutorial/#docker-tutorial","text":"This tutorial explains how to use the Egeria Docker Image published to the docker catalog at https://hub.docker.com/r/odpi/egeria . Egeria's docker image includes the Egeria install image. When the image is started using docker, a new egeria docker container is created. As it starts up, an instance of the Egeria runtime - that is the OMAG Server Platform - is started at port https 9443. This container can be incorporated into larger container orchestration environments or used standalone. This tutorial describes how to use it standalone. The Open Metadata Labs use this container with either the docker-compose or Kubernetes container services to create a complete open metadata solution. Link to Hands-on Labs Infrastructure Guide to learn more.","title":"Docker tutorial"},{"location":"education/tutorials/docker-tutorial/#working-with-egerias-docker-image","text":"If docker is new to you and you don't have it installed, link to the article on docker in the developer tools . This provides an overview of docker and installation instructions for Docker Desktop. Once the docker desktop is installed, start the docker desktop application. It may take a little while to complete its start up so check it is running before continuing. For example, on macOS, the docker desktop can be found on the Launchpad . Once it is running, the docker whale icon appears on the top menu bar. Clicking on the docker whale icon reveals a menu and the status of the desk top is visible. This menu is used to shutdown docker at the end of the dojo.","title":"Working with Egeria's docker image"},{"location":"education/tutorials/docker-tutorial/#downloading-the-egeria-docker-image","text":"The command to download Egeria's docker image is docker pull odpi/egeria . This is issued from a command/terminal window in the directory where you want the container to be copied to. If you see the following response, then the docker runtime is not installed properly on your machine. $ docker pull odpi/egeria -bash: docker: command not found If all is well, the image downloads. Notice it is pulling the latest master build by default. $ docker pull odpi/egeria Using default tag: latest latest: Pulling from odpi/egeria e7c96db7181b: Pull complete f910a506b6cb: Pull complete b6abafe80f63: Pull complete a83b87485b54: Pull complete 10d9ee7d5688: Pull complete 9558171b7a95: Pull complete Digest: sha256:18451a4676a6688e03f284f887ba5be7026c17805ee0b919ed02cb131621d45b Status: Downloaded newer image for odpi/egeria:latest docker.io/odpi/egeria:latest $ To check it will run, try the docker run --publish 19443:9443 odpi/egeria . This will start the image as a new docker container. As the container initializes it starts a single copy of the OMAG Server Platform . The OMAG Server Platform is the Egeria runtime platform where the Egeria REST services run. The --publish 19443:9443 parameter maps the 9443 port inside the docker that the OMAG Server Platform has registered with to port 19443 You should see the server logo come up and finally a message OMAG server platform ready for more configuration . This message means it has successfully started. Once you can see that it has started, use Control-C to stop it. $ docker run --publish 19443 :9443 odpi/egeria Picked up JAVA_TOOL_OPTIONS: ODPi Egeria ____ __ ___ ___ ______ _____ ____ _ _ ___ / __ \\ / | / // | / ____/ / ___/ ___ ____ _ __ ___ ____ / _ \\ / / __ / / / _ /__ ____ _ _ / / / // / | _/ // / | | / / __ \\_ _ \\ / _ \\ / __/ | | / // _ \\ / __/ / /_/ // // | / _ \\ / /_ / | / _// || | / /_/ // / / // ___ | / /_/ / ___/ // __// / | | / // __// / / __ // // / \\ / /_ / _// / // / / / / / \\_ ___//_/ /_//_/ | _ | \\_ ___/ /____/ \\_ __//_/ | ___/ \\_ __//_/ /_/ /_/ \\_ _/ \\/ /___//_/ \\_ _//_/ /_/ /_/ :: Powered by Spring Boot ( v2.3.0.RELEASE ) :: 10 :12:28.047 [ main ] INFO o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port ( s ) : 9443 ( https ) 10 :12:41.688 [ main ] INFO o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port ( s ) : 9443 ( https ) with context path '' Thu Jun 04 10 :12:32 BST 2020 No OMAG servers listed in startup configuration Thu Jun 04 10 :12:41 BST 2020 OMAG server platform ready for more configuration ^C $","title":"Downloading the egeria docker image"},{"location":"education/tutorials/docker-tutorial/#working-with-the-docker-desktop-dashboard","text":"The docker desktop dashboard makes it easy to control your docker containers. It is started from the docker desktop menu. Select the Dashboard option. You will see something like this: Each time a new docker container is created, it is given a generated name. In the example above the name is gifted-lovelace which is a great tribute to Ada Lovelace . You can see that the container is not running ( EXITED ) because you stopped it earlier with Control-C . Hover your mouse pointer over the container entry and some options appear. The triangular \"START\" button is to start the container running again and the Bin/Trash can is to delete your container. Press the \"START\" button to start your container again. When the container is running, more options are available to you when you hover the mouse over the container entry. The first symbol is the \"OPEN IN BROWSER\" option. Click on it and your browser opens. You should see an error displayed: Update the URL as follows: and press enter. After a few moments, Egeria's Swagger page should open. This is an automatically generated page that describes the REST APIs of Egeria's OMAG Server Platform. There is more information on swagger in the Developer's tools pages . Page down until you see the \"Platform Services\". The platform services provide support for administrators running Egeria. Click on the angle bracket on the right hand end of the entry and the list of REST API operations is displayed. Now click on the first blue entry for platform origin. Then press the Try it Out button. and enter garygeeke in the userId field and then the Execute button. You can see that through the Swagger UI it is possible to try out different REST requests and make sure the platform is operating correctly. The platform origin request is particularly useful for verifying what version of the OMAG Server Platform is running. The Swagger UI is useful for ad hoc testing. However, later in the Dojo we will cover a tool called Postman that provides a more powerful testing experience. So back to the Docker Desktop. The second option on the docker desktop is \"CLI\". This opens the Terminal/Command window inside the docker container . You are in the home directory of the OMAG Server Platform. This contains the contents of the egeria install image. It is also the home directory of the OMAG Server Platform which is where it will write its files. Type ls to list the files. $ ls LICENSE clients server utilities NOTICE conformance-suite user-interface $ Only the files from the install image are present because we have not asked the OMAG Server Platform to do anything yet. However, as we configure servers and run them, you will see new files appearing. You can check back here from time to time to see the files accumulating. If you delete this container then all of the files that the OMAG Server Platform created are lost. (If you want to know more about the egeria install image, see the Installing Egeria Tutorial .) The third button on the docker desktop is the \"STOP\" button and the fourth button is \"RESTART\". If you just need to test these buttons, remember to ensure that the docker container is running when you have finished because it is needed for the rest of the session. The final button is \"DELETE\". As described above, it deletes the container and uoi need to start again with docker run --publish 19443:9443 odpi/egeria . If you now click on the whitespace of the container's entry, a new section opens up with 3 tabs. \"Logs\" shows the console logs. Each new run of the container appends new log information to the end of this console. \"Inspect\" shows the settings for the container. \"Stats\" shows the resource usage of the container. ... and that is all you need to know about docker. Congratulations, you are familiar enough with running docker containers to continue with the Egeria Dojo . Return to Egeria Dojo Link to other tutorials Link to Hands on labs there this docker image is used as part of the suite of containers that supports the lab infrastructure . License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Working with the Docker Desktop Dashboard"},{"location":"education/tutorials/installing-egeria-tutorial/","text":"Installing ODPi Egeria \u00b6 The egeria build process creates the distribution files for Egeria in the open-metadata-distribution module. The assemblies are located from the egeria build directory as follows: $ cd open-metadata-distribution/open-metadata-assemblies/target $ ls ls archive-tmp egeria-3.3-SNAPSHOT-sources.tar.gz egeria-3.3-SNAPSHOT-distribution maven-archiver egeria-3.3-SNAPSHOT-distribution.tar.gz open-metadata-assemblies-3.3-SNAPSHOT.jar egeria-3.3-SNAPSHOT-omag-server rat.txt egeria-3.3-SNAPSHOT-omag-server.tar.gz The name of the files is determined by the release level of the code that you downloaded from GitHub . In this example, the release is egeria-3.3-SNAPSHOT . Create a directory for the install and copy the tar file into it. The two commands shown below create an install directory at the same level in the file system as the egeria build library and then copies the egeria distribution file into it. $ mkdir ../../../../egeria-install $ cp egeria*-distribution.tar.gz ../../../../egeria-install These next commands change to the new directory and lists its contents. $ cd ../../../../egeria-install $ ls egeria-3.3-SNAPSHOT-distribution.tar.gz It is now possible to unpack the tar file. $ tar -xf egeria-3.3-SNAPSHOT-distribution.tar.gz $ ls egeria-3.3-SNAPSHOT-distribution.tar.gz egeria-omag-3.3-SNAPSHOT A new directory is created called egeria-omag-3.3-SNAPSHOT . Change to this new directory and list its contents as shown below. $ cd egeria-omag-3.3-SNAPSHOT $ ls LICENSE clients server NOTICE conformance-suite user-interface Under server is a directory for the OMAG Server Platform that is used to run open metadata and governance services. Change to the OMAG server platform's directory. $ cd server/omag-server* $ resources server-chassis-spring-3.3-SNAPSHOT.jar This means you have completed this tutorial and are ready to choose the next step. Return to Egeria Dojo License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Installing egeria tutorial"},{"location":"education/tutorials/installing-egeria-tutorial/#installing-odpi-egeria","text":"The egeria build process creates the distribution files for Egeria in the open-metadata-distribution module. The assemblies are located from the egeria build directory as follows: $ cd open-metadata-distribution/open-metadata-assemblies/target $ ls ls archive-tmp egeria-3.3-SNAPSHOT-sources.tar.gz egeria-3.3-SNAPSHOT-distribution maven-archiver egeria-3.3-SNAPSHOT-distribution.tar.gz open-metadata-assemblies-3.3-SNAPSHOT.jar egeria-3.3-SNAPSHOT-omag-server rat.txt egeria-3.3-SNAPSHOT-omag-server.tar.gz The name of the files is determined by the release level of the code that you downloaded from GitHub . In this example, the release is egeria-3.3-SNAPSHOT . Create a directory for the install and copy the tar file into it. The two commands shown below create an install directory at the same level in the file system as the egeria build library and then copies the egeria distribution file into it. $ mkdir ../../../../egeria-install $ cp egeria*-distribution.tar.gz ../../../../egeria-install These next commands change to the new directory and lists its contents. $ cd ../../../../egeria-install $ ls egeria-3.3-SNAPSHOT-distribution.tar.gz It is now possible to unpack the tar file. $ tar -xf egeria-3.3-SNAPSHOT-distribution.tar.gz $ ls egeria-3.3-SNAPSHOT-distribution.tar.gz egeria-omag-3.3-SNAPSHOT A new directory is created called egeria-omag-3.3-SNAPSHOT . Change to this new directory and list its contents as shown below. $ cd egeria-omag-3.3-SNAPSHOT $ ls LICENSE clients server NOTICE conformance-suite user-interface Under server is a directory for the OMAG Server Platform that is used to run open metadata and governance services. Change to the OMAG server platform's directory. $ cd server/omag-server* $ resources server-chassis-spring-3.3-SNAPSHOT.jar This means you have completed this tutorial and are ready to choose the next step. Return to Egeria Dojo License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Installing ODPi Egeria"},{"location":"education/tutorials/omag-client-tutorial/","text":"OMAG Client Libraries Tutorial \u00b6","title":"Omag client tutorial"},{"location":"education/tutorials/omag-client-tutorial/#omag-client-libraries-tutorial","text":"","title":"OMAG Client Libraries Tutorial"},{"location":"education/tutorials/overview/","text":"Learning about Egeria \u00b6 Egeria is a big project tackling a complex problem. The Egeria Dojo provides guided learning to help you get up to speed quickly with different topics. It has 3 parts: Learn how to set up and run Egeria on you own machine. Learn how to make a contribution to Egeria Learn how to become either an advocate or a maintainer It is organized so you can work through it as an intensive 3 day course, or work at you own pace, dipping in and out as the interest takes you. In addition, there are the Hands on Labs . These provide an interactive environment that allow you to experiment with different capabilities of Egeria. Learn more about the Egeria Dojo Link to the Hands on Labs","title":"Overview"},{"location":"education/tutorials/overview/#learning-about-egeria","text":"Egeria is a big project tackling a complex problem. The Egeria Dojo provides guided learning to help you get up to speed quickly with different topics. It has 3 parts: Learn how to set up and run Egeria on you own machine. Learn how to make a contribution to Egeria Learn how to become either an advocate or a maintainer It is organized so you can work through it as an intensive 3 day course, or work at you own pace, dipping in and out as the interest takes you. In addition, there are the Hands on Labs . These provide an interactive environment that allow you to experiment with different capabilities of Egeria. Learn more about the Egeria Dojo Link to the Hands on Labs","title":"Learning about Egeria"},{"location":"education/tutorials/postman-tutorial/","text":"Postman \u00b6 Postman provides an interactive application for issuing REST API calls to a server. If Postman is new to you, and you do not have it installed, link to the Postman page in the developer tools for installation instructions. Once Postman is installed, start up the application. You should see a user interface something like this: The beauty of Postman is that it supports collections of environments and requests. This means we can pre-can descriptions and implementations of different requests to Egeria that can be widely shared. Importing the Egeria Environment \u00b6 A Postman environment provides a set of common variable that can be used in request definitions to make them adaptable to different deployment environments. The Egeria Environment is located on GitHub at this location: https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-resources/open-metadata-samples/postman-rest-samples/Egeria.postman_environment.json Copy the link and then click on Postman's Import menu option (top left): . Select Import from Link and paste the URL of the environment file in the URL box. Check that the Egeria environment is selected in the top left dropdown: If you click on the \"eye\" shaped icon, you can see the current values. Make sure you have an OMAG Server Platform running and set the values for your platform in the CURRENT VALUE column. For example, if you are running the OMAG Server Platform in either a docker container or kubernetes, the baseURL variable will probably need to be changed to https://localhost:18080 . These values can be changed at any time when you are using Postman so you can direct requests to different servers and switch users issuing the requests. Importing the Egeria Request Collections \u00b6 The Egeria community are continually building new Postman request collections as new APIs are added to the platform. The most popular collections are for the platform and administration services. We will also use the collections from the repository services and asset owner OMAS . These collections are located in GitHub at the following locations: https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/platform-services/Egeria-platform-services.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/admin-services/Egeria-admin-services-platform-configuration.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/admin-services/Egeria-admin-services-server-configuration.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/admin-services/Egeria-admin-services-operational.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/repository-services/Egeria-repository-services-audit-log.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/repository-services/Egeria-repository-services-local-repository.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/repository-services/Egeria-repository-services-metadata-highway.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/access-services/asset-owner/Egeria-asset-owner-omas.postman_collection.json Using the import option again, load each of these collections in turn. You will see them populate the left-hand menu. Next steps \u00b6 With the collections loaded, you are ready to return to the Egeria Dojo to learn more about the OMAG Server Platform. Alternatively you can use the collections to test existing function, or modify them to test new function. Instructions for contributing new Postman collections are located in the developer-resources .","title":"Postman tutorial"},{"location":"education/tutorials/postman-tutorial/#postman","text":"Postman provides an interactive application for issuing REST API calls to a server. If Postman is new to you, and you do not have it installed, link to the Postman page in the developer tools for installation instructions. Once Postman is installed, start up the application. You should see a user interface something like this: The beauty of Postman is that it supports collections of environments and requests. This means we can pre-can descriptions and implementations of different requests to Egeria that can be widely shared.","title":"Postman"},{"location":"education/tutorials/postman-tutorial/#importing-the-egeria-environment","text":"A Postman environment provides a set of common variable that can be used in request definitions to make them adaptable to different deployment environments. The Egeria Environment is located on GitHub at this location: https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-resources/open-metadata-samples/postman-rest-samples/Egeria.postman_environment.json Copy the link and then click on Postman's Import menu option (top left): . Select Import from Link and paste the URL of the environment file in the URL box. Check that the Egeria environment is selected in the top left dropdown: If you click on the \"eye\" shaped icon, you can see the current values. Make sure you have an OMAG Server Platform running and set the values for your platform in the CURRENT VALUE column. For example, if you are running the OMAG Server Platform in either a docker container or kubernetes, the baseURL variable will probably need to be changed to https://localhost:18080 . These values can be changed at any time when you are using Postman so you can direct requests to different servers and switch users issuing the requests.","title":"Importing the Egeria Environment"},{"location":"education/tutorials/postman-tutorial/#importing-the-egeria-request-collections","text":"The Egeria community are continually building new Postman request collections as new APIs are added to the platform. The most popular collections are for the platform and administration services. We will also use the collections from the repository services and asset owner OMAS . These collections are located in GitHub at the following locations: https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/platform-services/Egeria-platform-services.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/admin-services/Egeria-admin-services-platform-configuration.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/admin-services/Egeria-admin-services-server-configuration.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/admin-services/Egeria-admin-services-operational.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/repository-services/Egeria-repository-services-audit-log.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/repository-services/Egeria-repository-services-local-repository.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/repository-services/Egeria-repository-services-metadata-highway.postman_collection.json https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-implementation/access-services/asset-owner/Egeria-asset-owner-omas.postman_collection.json Using the import option again, load each of these collections in turn. You will see them populate the left-hand menu.","title":"Importing the Egeria Request Collections"},{"location":"education/tutorials/postman-tutorial/#next-steps","text":"With the collections loaded, you are ready to return to the Egeria Dojo to learn more about the OMAG Server Platform. Alternatively you can use the collections to test existing function, or modify them to test new function. Instructions for contributing new Postman collections are located in the developer-resources .","title":"Next steps"},{"location":"education/tutorials/running-samples-tutorial/","text":"Running the samples \u00b6","title":"Running samples tutorial"},{"location":"education/tutorials/running-samples-tutorial/#running-the-samples","text":"","title":"Running the samples"},{"location":"education/tutorials/testing-egeria-tutorial/","text":"Testing Egeria \u00b6","title":"Testing egeria tutorial"},{"location":"education/tutorials/testing-egeria-tutorial/#testing-egeria","text":"","title":"Testing Egeria"},{"location":"education/tutorials/working-with-connectors-tutorial/","text":"Working with connectors \u00b6 A connector is a client library for accessing an asset . ODPi Egeria provides a framework called the Open Connector Framework ( OCF ) for writing, configuring and using connectors. Typically a connector is written to support a specific type of asset. It has two main APIs: An API for working with the asset itself An API for retrieving metadata","title":"Working with connectors tutorial"},{"location":"education/tutorials/working-with-connectors-tutorial/#working-with-connectors","text":"A connector is a client library for accessing an asset . ODPi Egeria provides a framework called the Open Connector Framework ( OCF ) for writing, configuring and using connectors. Typically a connector is written to support a specific type of asset. It has two main APIs: An API for working with the asset itself An API for retrieving metadata","title":"Working with connectors"},{"location":"education/tutorials/building-egeria-tutorial/overview/","text":"Downloading and Building Egeria Tutorial \u00b6 Egeria is an open source project that is delivered both as source code as well as Maven Central Repository libraries. This tutorial will guide you through the process of downloading the ODPi Egeria source code from GitHub and building it so that you can run it on your local machine. Once you have downloaded Egeria , you can also use Kubernetes to start the lab infrastructure for the Hands-on Labs . This does not require you to build Egeria. Already lost, or are the instructions below not detailed enough? Check out the Egeria Dojo , or consider jumping straight to the Hands-on Labs , which provide a pre-built environment for you and guided instructions on how to use different APIs. Prerequisite Technology for Building Egeria \u00b6 You will need a Java Development Kit (JDK) installed on your machine in order to build Egeria. There are various JDKs available, and you may even have one pre-installed on your system. You can check if java is already installed by running the command java -version from the command-line. Java can be installed by: Downloading the OpenJDK 11 (LTS) HotSpot JVM from Adoptium . Running the installer that is downloaded. Maven is the tool used to run the Egeria build. You can check if Maven installed by running the command mvn --version from the command-line. Ensure you are using version 3.5.0 or higher in order to build Egeria. Maven can be installed: On MacOS, by first installing the HomeBrew package manager and then running brew install maven from the command-line. On Linux operating systems, by using your distribution's package manager ( yum install maven , apt-get install maven , etc). On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for Linux. Git is an open source version control system used to store and manage Egeria's files. You need it installed on your machine to work with Egeria's git repositories stored on GitHub . You can check whether it is installed on your system by running git --version from the command-line. Tutorial tasks \u00b6 Downloading the Egeria source from GitHub Building the Egeria source with Apache Maven Downloading the Egeria Source from GitHub \u00b6 The Egeria source is extracted from GitHub using the following git command: $ git clone https://github.com/odpi/egeria.git Cloning into 'egeria' ... remote: Enumerating objects: 38 , done . remote: Counting objects: 100 % ( 38 /38 ) , done . remote: Compressing objects: 100 % ( 24 /24 ) , done . remote: Total 50419 ( delta 8 ) , reused 29 ( delta 7 ) , pack-reused 50381 Receiving objects: 100 % ( 50419 /50419 ) , 36 .35 MiB | 5 .23 MiB/s, done . Resolving deltas: 100 % ( 31704 /31704 ) , done . Checking out files: 100 % ( 6669 /6669 ) , done . A new directory has been created with the ODPi Egeria source code. Change to the egeria directory. $ cd egeria You are now ready to build the egeria source . Alternatively you can use Kubernetes to set up the infrastructure to run the Open Metadata Labs . If you are working on the Dojo return to Day 1 Building the Egeria Source \u00b6 When you download the egeria source from GitHub a new directory called egeria is created that contains all of the source and the build scripts. The build scripts use Apache Maven to ensure the software is built in the correct order. If you change into the egeria directory, you will see a file called pom.xml . This is the file that controls the build. Issue the following command from the egeria directory. $ mvn clean install The build can take 15-30 minutes depending on the speed and load on your machine. However eventually you will see the message: [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 14:54 min [INFO] Finished at: 2020-01-29T09:33:17Z [INFO] Final Memory: 171M/3510M [INFO] ------------------------------------------------------------------------ Process finished with exit code 0 This means you have completed this tutorial and are ready to choose the next step . What next? \u00b6 Run the hands on labs to get experience with using Egeria or Learn about installing Egeria in your own environment or Jump to the Egeria dojo to learn how to make a contribution to Egeria Return to Egeria Dojo License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Overview"},{"location":"education/tutorials/building-egeria-tutorial/overview/#downloading-and-building-egeria-tutorial","text":"Egeria is an open source project that is delivered both as source code as well as Maven Central Repository libraries. This tutorial will guide you through the process of downloading the ODPi Egeria source code from GitHub and building it so that you can run it on your local machine. Once you have downloaded Egeria , you can also use Kubernetes to start the lab infrastructure for the Hands-on Labs . This does not require you to build Egeria. Already lost, or are the instructions below not detailed enough? Check out the Egeria Dojo , or consider jumping straight to the Hands-on Labs , which provide a pre-built environment for you and guided instructions on how to use different APIs.","title":"Downloading and Building Egeria Tutorial"},{"location":"education/tutorials/building-egeria-tutorial/overview/#prerequisite-technology-for-building-egeria","text":"You will need a Java Development Kit (JDK) installed on your machine in order to build Egeria. There are various JDKs available, and you may even have one pre-installed on your system. You can check if java is already installed by running the command java -version from the command-line. Java can be installed by: Downloading the OpenJDK 11 (LTS) HotSpot JVM from Adoptium . Running the installer that is downloaded. Maven is the tool used to run the Egeria build. You can check if Maven installed by running the command mvn --version from the command-line. Ensure you are using version 3.5.0 or higher in order to build Egeria. Maven can be installed: On MacOS, by first installing the HomeBrew package manager and then running brew install maven from the command-line. On Linux operating systems, by using your distribution's package manager ( yum install maven , apt-get install maven , etc). On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for Linux. Git is an open source version control system used to store and manage Egeria's files. You need it installed on your machine to work with Egeria's git repositories stored on GitHub . You can check whether it is installed on your system by running git --version from the command-line.","title":"Prerequisite Technology for Building Egeria"},{"location":"education/tutorials/building-egeria-tutorial/overview/#tutorial-tasks","text":"Downloading the Egeria source from GitHub Building the Egeria source with Apache Maven","title":"Tutorial tasks"},{"location":"education/tutorials/building-egeria-tutorial/overview/#downloading-the-egeria-source-from-github","text":"The Egeria source is extracted from GitHub using the following git command: $ git clone https://github.com/odpi/egeria.git Cloning into 'egeria' ... remote: Enumerating objects: 38 , done . remote: Counting objects: 100 % ( 38 /38 ) , done . remote: Compressing objects: 100 % ( 24 /24 ) , done . remote: Total 50419 ( delta 8 ) , reused 29 ( delta 7 ) , pack-reused 50381 Receiving objects: 100 % ( 50419 /50419 ) , 36 .35 MiB | 5 .23 MiB/s, done . Resolving deltas: 100 % ( 31704 /31704 ) , done . Checking out files: 100 % ( 6669 /6669 ) , done . A new directory has been created with the ODPi Egeria source code. Change to the egeria directory. $ cd egeria You are now ready to build the egeria source . Alternatively you can use Kubernetes to set up the infrastructure to run the Open Metadata Labs . If you are working on the Dojo return to Day 1","title":"Downloading the Egeria Source from GitHub"},{"location":"education/tutorials/building-egeria-tutorial/overview/#building-the-egeria-source","text":"When you download the egeria source from GitHub a new directory called egeria is created that contains all of the source and the build scripts. The build scripts use Apache Maven to ensure the software is built in the correct order. If you change into the egeria directory, you will see a file called pom.xml . This is the file that controls the build. Issue the following command from the egeria directory. $ mvn clean install The build can take 15-30 minutes depending on the speed and load on your machine. However eventually you will see the message: [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 14:54 min [INFO] Finished at: 2020-01-29T09:33:17Z [INFO] Final Memory: 171M/3510M [INFO] ------------------------------------------------------------------------ Process finished with exit code 0 This means you have completed this tutorial and are ready to choose the next step .","title":"Building the Egeria Source"},{"location":"education/tutorials/building-egeria-tutorial/overview/#what-next","text":"Run the hands on labs to get experience with using Egeria or Learn about installing Egeria in your own environment or Jump to the Egeria dojo to learn how to make a contribution to Egeria Return to Egeria Dojo License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"What next?"},{"location":"education/tutorials/building-egeria-tutorial/task-building-egeria-source/","text":"Building the Egeria Source \u00b6 When you download the egeria source from GitHub a new directory called egeria is created that contains all of the source and the build scripts. The build scripts use Apache Maven to ensure the software is built in the correct order. If you change into the egeria directory, you will see a file called pom.xml . This is the file that controls the build. Issue the following command from the egeria directory. $ mvn clean install The build can take 15-30 minutes depending on the speed and load on your machine. However eventually you will see the message: [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 14:54 min [INFO] Finished at: 2020-01-29T09:33:17Z [INFO] Final Memory: 171M/3510M [INFO] ------------------------------------------------------------------------ Process finished with exit code 0 This means you have completed this tutorial and are ready to choose the next step .","title":"Task building egeria source"},{"location":"education/tutorials/building-egeria-tutorial/task-building-egeria-source/#building-the-egeria-source","text":"When you download the egeria source from GitHub a new directory called egeria is created that contains all of the source and the build scripts. The build scripts use Apache Maven to ensure the software is built in the correct order. If you change into the egeria directory, you will see a file called pom.xml . This is the file that controls the build. Issue the following command from the egeria directory. $ mvn clean install The build can take 15-30 minutes depending on the speed and load on your machine. However eventually you will see the message: [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 14:54 min [INFO] Finished at: 2020-01-29T09:33:17Z [INFO] Final Memory: 171M/3510M [INFO] ------------------------------------------------------------------------ Process finished with exit code 0 This means you have completed this tutorial and are ready to choose the next step .","title":"Building the Egeria Source"},{"location":"education/tutorials/building-egeria-tutorial/task-downloading-egeria-source/","text":"Downloading the Egeria Source from GitHub \u00b6 The Egeria source is extracted from GitHub using the following git command: $ git clone https://github.com/odpi/egeria.git Cloning into 'egeria' ... remote: Enumerating objects: 38 , done . remote: Counting objects: 100 % ( 38 /38 ) , done . remote: Compressing objects: 100 % ( 24 /24 ) , done . remote: Total 50419 ( delta 8 ) , reused 29 ( delta 7 ) , pack-reused 50381 Receiving objects: 100 % ( 50419 /50419 ) , 36 .35 MiB | 5 .23 MiB/s, done . Resolving deltas: 100 % ( 31704 /31704 ) , done . Checking out files: 100 % ( 6669 /6669 ) , done . A new directory has been created with the ODPi Egeria source code. Change to the egeria directory. $ cd egeria You are now ready to build the egeria source . Alternatively you can use Kubernetes to set up the infrastructure to run the Open Metadata Labs . If you are working on the Dojo return to Day 1 Return to Egeria Dojo Return to Building Egeria Tutorial Link to Running the lab infrastructure using Kubernetes License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task downloading egeria source"},{"location":"education/tutorials/building-egeria-tutorial/task-downloading-egeria-source/#downloading-the-egeria-source-from-github","text":"The Egeria source is extracted from GitHub using the following git command: $ git clone https://github.com/odpi/egeria.git Cloning into 'egeria' ... remote: Enumerating objects: 38 , done . remote: Counting objects: 100 % ( 38 /38 ) , done . remote: Compressing objects: 100 % ( 24 /24 ) , done . remote: Total 50419 ( delta 8 ) , reused 29 ( delta 7 ) , pack-reused 50381 Receiving objects: 100 % ( 50419 /50419 ) , 36 .35 MiB | 5 .23 MiB/s, done . Resolving deltas: 100 % ( 31704 /31704 ) , done . Checking out files: 100 % ( 6669 /6669 ) , done . A new directory has been created with the ODPi Egeria source code. Change to the egeria directory. $ cd egeria You are now ready to build the egeria source . Alternatively you can use Kubernetes to set up the infrastructure to run the Open Metadata Labs . If you are working on the Dojo return to Day 1 Return to Egeria Dojo Return to Building Egeria Tutorial Link to Running the lab infrastructure using Kubernetes License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Downloading the Egeria Source from GitHub"},{"location":"education/tutorials/building-egeria-tutorial/task-installing-egeria/","text":"Installing Egeria \u00b6 The egeria build process creates the distribution files for Egeria in the open-metadata-distribution module. The assemblies are located from the egeria build directory as follows: $ cd open-metadata-distribution/open-metadata-assemblies/target $ ls ls archive-tmp egeria-3.3-SNAPSHOT-sources.tar.gz egeria-3.3-SNAPSHOT-distribution maven-archiver egeria-3.3-SNAPSHOT-distribution.tar.gz open-metadata-assemblies-3.3-SNAPSHOT.jar egeria-3.3-SNAPSHOT-omag-server rat.txt egeria-3.3-SNAPSHOT-omag-server.tar.gz The name of the files is determined by the release level of the code that you downloaded from GitHub . In this example, the release is egeria-3.3-SNAPSHOT . Create a directory for the install and copy the tar file into it. The two commands shown below create an install directory at the same level in the file system as the egeria build library and then copies the egeria distribution file into it. $ mkdir ../../../../egeria-install $ cp egeria*-distribution.tar.gz ../../../../egeria-install These next commands change to the new directory and lists its contents. $ cd ../../../../egeria-install $ ls egeria-3.3-SNAPSHOT-distribution.tar.gz It is now possible to unpack the tar file. $ tar -xf egeria-3.3-SNAPSHOT-distribution.tar.gz $ ls egeria-3.3-SNAPSHOT-distribution.tar.gz egeria-omag-3.3-SNAPSHOT A new directory is created called egeria-omag-3.3-SNAPSHOT . Change to this new directory and list its contents as shown below. $ cd egeria-omag-3.3-SNAPSHOT $ ls LICENSE clients server NOTICE conformance-suite user-interface Under server is a directory for the OMAG Server Platform that is used to run open metadata and governance services. Change to the OMAG server platform's directory. $ cd server $ ls $ resources server-chassis-spring-3.3-SNAPSHOT.jar This is the end of the Downloading and Building ODPi Egeria Tutorial . You are now ready to learn about the OMAG Server Platform .","title":"Task installing egeria"},{"location":"education/tutorials/building-egeria-tutorial/task-installing-egeria/#installing-egeria","text":"The egeria build process creates the distribution files for Egeria in the open-metadata-distribution module. The assemblies are located from the egeria build directory as follows: $ cd open-metadata-distribution/open-metadata-assemblies/target $ ls ls archive-tmp egeria-3.3-SNAPSHOT-sources.tar.gz egeria-3.3-SNAPSHOT-distribution maven-archiver egeria-3.3-SNAPSHOT-distribution.tar.gz open-metadata-assemblies-3.3-SNAPSHOT.jar egeria-3.3-SNAPSHOT-omag-server rat.txt egeria-3.3-SNAPSHOT-omag-server.tar.gz The name of the files is determined by the release level of the code that you downloaded from GitHub . In this example, the release is egeria-3.3-SNAPSHOT . Create a directory for the install and copy the tar file into it. The two commands shown below create an install directory at the same level in the file system as the egeria build library and then copies the egeria distribution file into it. $ mkdir ../../../../egeria-install $ cp egeria*-distribution.tar.gz ../../../../egeria-install These next commands change to the new directory and lists its contents. $ cd ../../../../egeria-install $ ls egeria-3.3-SNAPSHOT-distribution.tar.gz It is now possible to unpack the tar file. $ tar -xf egeria-3.3-SNAPSHOT-distribution.tar.gz $ ls egeria-3.3-SNAPSHOT-distribution.tar.gz egeria-omag-3.3-SNAPSHOT A new directory is created called egeria-omag-3.3-SNAPSHOT . Change to this new directory and list its contents as shown below. $ cd egeria-omag-3.3-SNAPSHOT $ ls LICENSE clients server NOTICE conformance-suite user-interface Under server is a directory for the OMAG Server Platform that is used to run open metadata and governance services. Change to the OMAG server platform's directory. $ cd server $ ls $ resources server-chassis-spring-3.3-SNAPSHOT.jar This is the end of the Downloading and Building ODPi Egeria Tutorial . You are now ready to learn about the OMAG Server Platform .","title":"Installing Egeria"},{"location":"education/tutorials/git-and-git-hub-tutorial/further-git-tips/","text":"Additional git tips \u00b6 If you are working locally, and realise you have accidentally been making changes on master instead of another branch: $ git stash $ git checkout -b correct-branch $ git stash pop Messed up your master branch? $ git checkout master $ git fetch upstream $ git reset --hard HEAD $ git push Correct your last commit $ git commit --amend -s -m \"New commit message\" View recent changes $ git log View recent changes in a prettier way: $ git log --pretty = format: \"%h %ad | %s%d [%an]\" --graph --date = short Take a fix you have pushed to a different branch (perhaps a top-level pom change, or something else you need) and apply it to your current branch: $ git cherry-pick <commit-id> Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Further git tips"},{"location":"education/tutorials/git-and-git-hub-tutorial/further-git-tips/#additional-git-tips","text":"If you are working locally, and realise you have accidentally been making changes on master instead of another branch: $ git stash $ git checkout -b correct-branch $ git stash pop Messed up your master branch? $ git checkout master $ git fetch upstream $ git reset --hard HEAD $ git push Correct your last commit $ git commit --amend -s -m \"New commit message\" View recent changes $ git log View recent changes in a prettier way: $ git log --pretty = format: \"%h %ad | %s%d [%an]\" --graph --date = short Take a fix you have pushed to a different branch (perhaps a top-level pom change, or something else you need) and apply it to your current branch: $ git cherry-pick <commit-id> Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Additional git tips"},{"location":"education/tutorials/git-and-git-hub-tutorial/overview/","text":"Git and GitHub Tutorial \u00b6 This tutorial covers common tasks associated with using Git and GitHub to work with the Egeria content and make a contribution. For an overview of Git and GitHub see developer-resources/tools . General Tasks \u00b6 Getting a GitHub user log in - This is required to add anything - even a comment to the Egeria project. Creating an Issue on GitHub - Issues are used by developers to describe a contribution. They are also used by consumers of Egeria to request help with function they think is not working. Downloading Egeria to build and run - If you do not want to make changes to Egeria, but want to build the distribution file to run it natively on your machine. Then follow this task. If you want to be able to make changes to Egeria and contribute them back to the community, then follow the developer tasks. Developer Tasks \u00b6 The tasks below describe how to use Git and GitHub to create a contribution to the Egeria project. The development process using Git and GitHub is illustrated in Figure 1. Figure 1: Git and GitHub development flow The tasks below step through this process Installing Git on your local Machine Creating a Fork and a Clone Creating a Branch in a git repository Adding your changes to a git repository Adding your contribution to Egeria In addition, these are further tips for using Git. Return to Egeria Dojo License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Overview"},{"location":"education/tutorials/git-and-git-hub-tutorial/overview/#git-and-github-tutorial","text":"This tutorial covers common tasks associated with using Git and GitHub to work with the Egeria content and make a contribution. For an overview of Git and GitHub see developer-resources/tools .","title":"Git and GitHub Tutorial"},{"location":"education/tutorials/git-and-git-hub-tutorial/overview/#general-tasks","text":"Getting a GitHub user log in - This is required to add anything - even a comment to the Egeria project. Creating an Issue on GitHub - Issues are used by developers to describe a contribution. They are also used by consumers of Egeria to request help with function they think is not working. Downloading Egeria to build and run - If you do not want to make changes to Egeria, but want to build the distribution file to run it natively on your machine. Then follow this task. If you want to be able to make changes to Egeria and contribute them back to the community, then follow the developer tasks.","title":"General Tasks"},{"location":"education/tutorials/git-and-git-hub-tutorial/overview/#developer-tasks","text":"The tasks below describe how to use Git and GitHub to create a contribution to the Egeria project. The development process using Git and GitHub is illustrated in Figure 1. Figure 1: Git and GitHub development flow The tasks below step through this process Installing Git on your local Machine Creating a Fork and a Clone Creating a Branch in a git repository Adding your changes to a git repository Adding your contribution to Egeria In addition, these are further tips for using Git. Return to Egeria Dojo License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Developer Tasks"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-adding-changes-to-git/","text":"Adding your changes to you git clone \u00b6 Once you have completed your contribution, you are ready to add it to your git clone. Most development work is done on your local clone with occasional calls to GitHub to synchronize with its versions of the repository. Figure 1: Local development process using git Issue the git status command in a Terminal/Command window to verify all of your changes are included. This will list any new files and files that have been changed, but not yet included in the git clone. Use git add to add all of the files you want included. For example: $ git status On branch example-branch Untracked files: ( use \"git add <file>...\" to include in what will be committed ) new-file.java $ git add new-file.java $ git status On branch example-branch Changes to be committed: ( use \"git reset HEAD <file>...\" to unstage ) new file: new-file.java Now you are ready to complete your contribution . Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task adding changes to git"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-adding-changes-to-git/#adding-your-changes-to-you-git-clone","text":"Once you have completed your contribution, you are ready to add it to your git clone. Most development work is done on your local clone with occasional calls to GitHub to synchronize with its versions of the repository. Figure 1: Local development process using git Issue the git status command in a Terminal/Command window to verify all of your changes are included. This will list any new files and files that have been changed, but not yet included in the git clone. Use git add to add all of the files you want included. For example: $ git status On branch example-branch Untracked files: ( use \"git add <file>...\" to include in what will be committed ) new-file.java $ git add new-file.java $ git status On branch example-branch Changes to be committed: ( use \"git reset HEAD <file>...\" to unstage ) new file: new-file.java Now you are ready to complete your contribution . Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding your changes to you git clone"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-a-fork-and-clone/","text":"Creating a fork and a clone \u00b6 The git repositories for Egeria are read only to everyone except the Egeria Maintainers . This is to protect the content from accidental or malicious damage. However, anyone wanting to make a contribution needs editing access to the repositories to make the change and test it. This is achieved with the git fork and git clone . Forking \u00b6 Forking creates your own version of the egeria git repository that is linked back to the original. Figure 1 illustrates the forking process. Figure 1: Forking an Egeria git repository To create your fork, from your browser, navigate to the Egeria GitHub URL , and logging into the github UI with a your GitHub id . You will then see a 'Fork' button at the top right, and should click this to create your own fork to work with Egeria. This only needs to be done once. Cloning \u00b6 Once you have your fork, you need to create a copy of the repository on your local machine. This copy is called a clone . You create a clone each time you are starting a significant piece of work. Figure 2 illustrates the cloning process. Figure 2: Cloning an Egeria git repository To create a clone on your machine enter the following in a new directory from a terminal/command window. Replace USER with your GitHub userId. $ git clone https://github.com/USER/egeria.git $ cd egeria The git clone command creates a new directory called egeria containing the Egeria content. You should also set the upstream repository to connect your clone to the main Egeria repository: $ git remote add upstream https://github.com/odpi/egeria.git Now you are ready to create a branch for your changes . Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools Further details of GitHub's fork and pull model , Further details on the fork command. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task creating a fork and clone"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-a-fork-and-clone/#creating-a-fork-and-a-clone","text":"The git repositories for Egeria are read only to everyone except the Egeria Maintainers . This is to protect the content from accidental or malicious damage. However, anyone wanting to make a contribution needs editing access to the repositories to make the change and test it. This is achieved with the git fork and git clone .","title":"Creating a fork and a clone"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-a-fork-and-clone/#forking","text":"Forking creates your own version of the egeria git repository that is linked back to the original. Figure 1 illustrates the forking process. Figure 1: Forking an Egeria git repository To create your fork, from your browser, navigate to the Egeria GitHub URL , and logging into the github UI with a your GitHub id . You will then see a 'Fork' button at the top right, and should click this to create your own fork to work with Egeria. This only needs to be done once.","title":"Forking"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-a-fork-and-clone/#cloning","text":"Once you have your fork, you need to create a copy of the repository on your local machine. This copy is called a clone . You create a clone each time you are starting a significant piece of work. Figure 2 illustrates the cloning process. Figure 2: Cloning an Egeria git repository To create a clone on your machine enter the following in a new directory from a terminal/command window. Replace USER with your GitHub userId. $ git clone https://github.com/USER/egeria.git $ cd egeria The git clone command creates a new directory called egeria containing the Egeria content. You should also set the upstream repository to connect your clone to the main Egeria repository: $ git remote add upstream https://github.com/odpi/egeria.git Now you are ready to create a branch for your changes . Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools Further details of GitHub's fork and pull model , Further details on the fork command. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Cloning"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-an-issue-on-git-hub/","text":"Creating an Issue on GitHub \u00b6 Every contribution begins with a git issue . Go to GitHub and click on the second tab marked Issues . \u00b6 Click in the new issue green button on the top right hand side and a form for a new issue is displayed. \u00b6 Enter a meaningful title and description. This will help the maintainers understand your contribution and speed up the process to include it. If you are participating on the dojo you can use a title of Create my postcard file for Egeria Dojo and description of This is a change to Egeria that is part of the Egeria Dojo session [ Making a contribution to Egeria - Step-by-Step ]( https://egeria.odpi.org/open-metadata-resources/open-metadata-tutorials/egeria-dojo/egeria-dojo-day-2-3-contribution-to-egeria.html ). It will create a new markdown file in `open-metadata-resources/open-metadata-tutorials/egeria-dojo/egeria-dojo-postcards` and link it to the readme. Notice that it is possible to use Markdown tags to create highlights and links to content to explain what you are doing. When you are happy with your text, click on Submit new Issue . A new issue is created and assigned a new number - #3091 in this example. Make a note of this issue number because you will need it later. Now you are ready to work on your contribution . Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task creating an issue on git hub"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-an-issue-on-git-hub/#creating-an-issue-on-github","text":"Every contribution begins with a git issue . Go to GitHub and click on the second tab marked Issues .","title":"Creating an Issue on GitHub"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-an-issue-on-git-hub/#_1","text":"Click in the new issue green button on the top right hand side and a form for a new issue is displayed.","title":""},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-an-issue-on-git-hub/#_2","text":"Enter a meaningful title and description. This will help the maintainers understand your contribution and speed up the process to include it. If you are participating on the dojo you can use a title of Create my postcard file for Egeria Dojo and description of This is a change to Egeria that is part of the Egeria Dojo session [ Making a contribution to Egeria - Step-by-Step ]( https://egeria.odpi.org/open-metadata-resources/open-metadata-tutorials/egeria-dojo/egeria-dojo-day-2-3-contribution-to-egeria.html ). It will create a new markdown file in `open-metadata-resources/open-metadata-tutorials/egeria-dojo/egeria-dojo-postcards` and link it to the readme. Notice that it is possible to use Markdown tags to create highlights and links to content to explain what you are doing. When you are happy with your text, click on Submit new Issue . A new issue is created and assigned a new number - #3091 in this example. Make a note of this issue number because you will need it later. Now you are ready to work on your contribution . Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":""},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-git-branches/","text":"Creating a branch for your work \u00b6 Once you have a clone of the git repository there is one more step before you can begin developing. Most development work is done on your local clone with occasional calls to GitHub to synchronize with its versions of the repository. Figure 1: Local development process using git The top level branch (copy) of a git repository is called master . It is recommended not to make any changes directly to master but just to use it for reference and as a basis for branching. It is also recommended to create a new branch for each distinct set of changes. This keeps the commit history pushed to Egeria clean, and makes reviews of the code much easier for the maintainers. Since GitHub manages the introduction of new content on a branch basis it is also a way to be able to easily rework, by updating a change later before it has been incorporated back into the main Egeria code. First update your copy of master in your clone and push to your GitHub fork. $ git checkout master $ git pull upstream master $ git push Once you have the latest code on your machine, create a branch for your changes. The commands below set up a branch called \"example-branch\" based off of master, and also push it back to your personal fork: $ git checkout -b example-branch master $ git push origin example-branch When you create your own branch, use a name that describes that the branch is for as you will use it for all changes you are collecting together to push as one group to Egeria. This name will be publicly visible too once you start pushing your changes to Egeria so keep it clean :). You can also see that 'origin' will point to your GitHub fork, whilst 'upstream' points to the Egeria master branch: $ git remote -v origin https://github.com/USER/egeria ( fetch ) origin https://github.com/USER/egeria ( push ) upstream https://github.com/odpi/egeria.git ( fetch ) upstream https://github.com/odpi/egeria.git ( push ) Now you can make your changes to the content. Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task creating git branches"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-creating-git-branches/#creating-a-branch-for-your-work","text":"Once you have a clone of the git repository there is one more step before you can begin developing. Most development work is done on your local clone with occasional calls to GitHub to synchronize with its versions of the repository. Figure 1: Local development process using git The top level branch (copy) of a git repository is called master . It is recommended not to make any changes directly to master but just to use it for reference and as a basis for branching. It is also recommended to create a new branch for each distinct set of changes. This keeps the commit history pushed to Egeria clean, and makes reviews of the code much easier for the maintainers. Since GitHub manages the introduction of new content on a branch basis it is also a way to be able to easily rework, by updating a change later before it has been incorporated back into the main Egeria code. First update your copy of master in your clone and push to your GitHub fork. $ git checkout master $ git pull upstream master $ git push Once you have the latest code on your machine, create a branch for your changes. The commands below set up a branch called \"example-branch\" based off of master, and also push it back to your personal fork: $ git checkout -b example-branch master $ git push origin example-branch When you create your own branch, use a name that describes that the branch is for as you will use it for all changes you are collecting together to push as one group to Egeria. This name will be publicly visible too once you start pushing your changes to Egeria so keep it clean :). You can also see that 'origin' will point to your GitHub fork, whilst 'upstream' points to the Egeria master branch: $ git remote -v origin https://github.com/USER/egeria ( fetch ) origin https://github.com/USER/egeria ( push ) upstream https://github.com/odpi/egeria.git ( fetch ) upstream https://github.com/odpi/egeria.git ( push ) Now you can make your changes to the content. Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Creating a branch for your work"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-getting-git-hub-id/","text":"Getting a GitHub Id \u00b6 Although all of the git repositories on GitHub are public, it is necessary to have a GitHub id to work with the Egeria content. Creating a GitHub account can be done from the top of the GitHub home page . Select the Sign up option. Once you have created your account then sign in. Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task getting git hub id"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-getting-git-hub-id/#getting-a-github-id","text":"Although all of the git repositories on GitHub are public, it is necessary to have a GitHub id to work with the Egeria content. Creating a GitHub account can be done from the top of the GitHub home page . Select the Sign up option. Once you have created your account then sign in. Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Getting a GitHub Id"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-git-pull-push-pr/","text":"Adding your contribution to Egeria's Git repositories \u00b6 Once you have prepared a contribution and these changes are added to your clone, you are ready to commit the changes and push them to your clone on GitHub. Figure 1: Pushing changes to GitHub Below is the command to commit your changes. Make sure to use the -s option to sign your changes (see Why the DCO? ) and the -m option to provide a useful commit message. In the message you can make use of special strings to directly link to GitHub issues. By doing this others following the issue will see the commits to your fork easily so can track the work going on even before you submit to the egeria repository. It is also essential to push the changes from your local machine up to GitHub ready for the next step. $ git commit -s -m 'Best code change ever as per Issue #1433' $ git push If you think there is ongoing work in a similar area to that of your changes, you may find it useful to pull the latest master code prior to completing your changes. $ git pull upstream master Figure 2: Pulling latest changes from master and then making any necessary changes to merge conflicts, and commit/push as above. Creating a pull request \u00b6 Pull requests are created on GitHub, so go to your browser window. The easiest way to create a pull request is by navigating to your local fork of the Egeria repository eg. https://github.com/USER/egeria , selecting your working branch, and clicking on 'pull request'. Add an explanation and links to any GitHub Issues that are relevant to your change, and then submit the pull request. GitHub automatically validates that you have signed all of your commits and that any code builds. The Egeria maintainers will then review and if all is well, it will be merged into the master branch and you have officially made a successful contribution to the project. Congratulations :). Further changes can be done using the same branch, and will be added to the same pull request automatically until the pull request is merged into master. Cleaning up \u00b6 Once all work has been completed, including changes appearing in master, only then can your temporary branch be deleted: $ git branch -d example-branch $ git push -d origin example-branch You may need to use -D if not all changes are merged, but check carefully! Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task git pull push pr"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-git-pull-push-pr/#adding-your-contribution-to-egerias-git-repositories","text":"Once you have prepared a contribution and these changes are added to your clone, you are ready to commit the changes and push them to your clone on GitHub. Figure 1: Pushing changes to GitHub Below is the command to commit your changes. Make sure to use the -s option to sign your changes (see Why the DCO? ) and the -m option to provide a useful commit message. In the message you can make use of special strings to directly link to GitHub issues. By doing this others following the issue will see the commits to your fork easily so can track the work going on even before you submit to the egeria repository. It is also essential to push the changes from your local machine up to GitHub ready for the next step. $ git commit -s -m 'Best code change ever as per Issue #1433' $ git push If you think there is ongoing work in a similar area to that of your changes, you may find it useful to pull the latest master code prior to completing your changes. $ git pull upstream master Figure 2: Pulling latest changes from master and then making any necessary changes to merge conflicts, and commit/push as above.","title":"Adding your contribution to Egeria's Git repositories"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-git-pull-push-pr/#creating-a-pull-request","text":"Pull requests are created on GitHub, so go to your browser window. The easiest way to create a pull request is by navigating to your local fork of the Egeria repository eg. https://github.com/USER/egeria , selecting your working branch, and clicking on 'pull request'. Add an explanation and links to any GitHub Issues that are relevant to your change, and then submit the pull request. GitHub automatically validates that you have signed all of your commits and that any code builds. The Egeria maintainers will then review and if all is well, it will be merged into the master branch and you have officially made a successful contribution to the project. Congratulations :). Further changes can be done using the same branch, and will be added to the same pull request automatically until the pull request is merged into master.","title":"Creating a pull request"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-git-pull-push-pr/#cleaning-up","text":"Once all work has been completed, including changes appearing in master, only then can your temporary branch be deleted: $ git branch -d example-branch $ git push -d origin example-branch You may need to use -D if not all changes are merged, but check carefully! Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Cleaning up"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-installing-git/","text":"Installing Git on your local machine \u00b6 Git is an open source version control system used to store and manage Egeria's files. You need it installed on your machine to work with Egeria's git repositories stored on GitHub . You can check whether it is installed on your system by running git --version from the command-line. Git can be installed: On MacOS, as part of the Xcode suite (running git --version will prompt you to install it if it is not already installed). On Linux operating systems, by using your distribution's package manager ( yum install git , apt-get install git , etc). On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for Linux. Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task installing git"},{"location":"education/tutorials/git-and-git-hub-tutorial/task-installing-git/#installing-git-on-your-local-machine","text":"Git is an open source version control system used to store and manage Egeria's files. You need it installed on your machine to work with Egeria's git repositories stored on GitHub . You can check whether it is installed on your system by running git --version from the command-line. Git can be installed: On MacOS, as part of the Xcode suite (running git --version will prompt you to install it if it is not already installed). On Linux operating systems, by using your distribution's package manager ( yum install git , apt-get install git , etc). On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for Linux. Return to Git and GitHub Tutorial Return to Egeria Dojo - Making a contribution step by step Link to Git/GitHub overview in developer-resources/tools License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Installing Git on your local machine"},{"location":"education/tutorials/intellij-tutorial/overview/","text":"IntelliJ IDEA tutorial \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Overview"},{"location":"education/tutorials/intellij-tutorial/overview/#intellij-idea-tutorial","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"IntelliJ IDEA tutorial"},{"location":"education/tutorials/intellij-tutorial/task-building-egeria-in-intellij/","text":"Building Egeria in IntelliJ IDEA \u00b6 Maven is accessed from a sidebar menu in IntelliJ. When you click on the Maven label, a panel opens with the list of modules in Egeria is displayed. To build the whole project, select the M button at the top of the maven panel. Then a dialog box opens. Enter mvn clean install . Then the build kicks off. The full build can take about 15 minutes. It is worth doing a full build before committing a change. However it is also possible to build a single module. Goto the maven sidebar panel and find the module you are interested in. Open up the content for the module and then the lifecycle folder. Double-click on install and the build of that module starts. Using maven rather than using the IntelliJ build? \u00b6 While you are working on code in IntelliJ, it will be continuously rebuilding your code so that it is discovering syntax other coding errors as you type. This is useful in getting a first pass of your code. However, IntelliJ does not understand the egeria structure - only Maven does, so the Maven build is important to to verify your changes are OK at the project level. Return to Dojo Day 2 Return to Developer Tools Return to IntelliJ tutorial License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task building egeria in intellij"},{"location":"education/tutorials/intellij-tutorial/task-building-egeria-in-intellij/#building-egeria-in-intellij-idea","text":"Maven is accessed from a sidebar menu in IntelliJ. When you click on the Maven label, a panel opens with the list of modules in Egeria is displayed. To build the whole project, select the M button at the top of the maven panel. Then a dialog box opens. Enter mvn clean install . Then the build kicks off. The full build can take about 15 minutes. It is worth doing a full build before committing a change. However it is also possible to build a single module. Goto the maven sidebar panel and find the module you are interested in. Open up the content for the module and then the lifecycle folder. Double-click on install and the build of that module starts.","title":"Building Egeria in IntelliJ IDEA"},{"location":"education/tutorials/intellij-tutorial/task-building-egeria-in-intellij/#using-maven-rather-than-using-the-intellij-build","text":"While you are working on code in IntelliJ, it will be continuously rebuilding your code so that it is discovering syntax other coding errors as you type. This is useful in getting a first pass of your code. However, IntelliJ does not understand the egeria structure - only Maven does, so the Maven build is important to to verify your changes are OK at the project level. Return to Dojo Day 2 Return to Developer Tools Return to IntelliJ tutorial License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Using maven rather than using the IntelliJ build?"},{"location":"education/tutorials/intellij-tutorial/task-creating-content-with-intellij/","text":"Creating content with IntelliJ IDEA \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task creating content with intellij"},{"location":"education/tutorials/intellij-tutorial/task-creating-content-with-intellij/#creating-content-with-intellij-idea","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Creating content with IntelliJ IDEA"},{"location":"education/tutorials/intellij-tutorial/task-loading-egeria-into-intellij/","text":"Loading Egeria into IntelliJ IDEA \u00b6 Once you have a branch of your git repository you can load egeria into IntelliJ. Go to the File menu and select Open Then select the top-level directory that was created when you cloned the git repository. IntelliJ will then start reading the git repository and creating a project. This may take a few minutes so be patient. Return to Dojo Day 2 Return to Developer Tools Return to IntelliJ tutorial License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Task loading egeria into intellij"},{"location":"education/tutorials/intellij-tutorial/task-loading-egeria-into-intellij/#loading-egeria-into-intellij-idea","text":"Once you have a branch of your git repository you can load egeria into IntelliJ. Go to the File menu and select Open Then select the top-level directory that was created when you cloned the git repository. IntelliJ will then start reading the git repository and creating a project. This may take a few minutes so be patient. Return to Dojo Day 2 Return to Developer Tools Return to IntelliJ tutorial License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Loading Egeria into IntelliJ IDEA"},{"location":"education/tutorials/lab-infrastructure-guide/building/","text":"Building and developing Egeria \u00b6 These technologies are needed in order to build and develop Egeria. If you simply want to try out and explore Egeria, or if you find yourself lost in all of these technologies, choose one of the self-contained environments instead. Supported Platforms \u00b6 Egeria currently supports building on *nix, Linux & Linux-like operating systems such as MacOS. Our official build pipelines are based on x86_64 architecture, but it is expected other architectures would build ok, subject to the availablility of the required tools and interpreters/jvms/runtimes ie Java, Python, Docker/containerd/k8s etc. On Windows, you should use Windows Subsystem for Linux Version 2 or above, and install a Linux distribution such as Ubuntu. This avoids issues we have seen with path seperators, symbolic links, slow I/O performance, long pathnames. Some IDEs such as JetBrains IntelliJ and Microsoft VisualCode will run the GUI in Windows natively, and then use a linux environment (via WSL2 - which uses a real Linux kernel) to perform build and execution Git \u00b6 Git is an open source version control system. It is what we use to: track changes to the underlying Egeria code as the project evolves track issues and enhancements, and link these back to the code changes that resolve them collaborate on and review the issues, enhancements and code changes As a result, it gives us a definitive source for the latest and greatest source code for Egeria itself, its history, and the rationale behind various decisions that are made over time. In our Downloading Egeria from GitHub tutorial , when you are asked to do a git clone https://github.com/odpi/egeria.git , what you are telling your own computer to do is to create a local copy of our source code repository. It is this local copy that you can then use (locally) to build Egeria itself. You can check whether it is installed on your system by running git --version from the command-line. Git can be installed: On MacOS, as part of the Xcode suite (running git --version will prompt you to install it if it is not already installed). On Linux operating systems, by using your distribution's package manager ( yum install git , apt-get install git , etc). On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for Linux. Interested to learn more? GitHub provides some great introductory guides . Java \u00b6 Because Egeria is written in Java, you will need a Java Development Kit ( JDK ) installed in order to build Egeria. The JDK can also act as the runtime environment ( JRE ) mentioned in running Egeria natively . There are various JDKs available, and you may even have one pre-installed on your system. You can check by running the command java -version from the command-line. Java can be installed by: Downloading the OpenJDK 11 (LTS) HotSpot JVM from Adoptium . Running the installer that is downloaded. Apache Maven \u00b6 Apache Maven is a tool to describe and manage the technical aspects of a software project. For example, it can be used to define various dependencies a project like Egeria has on other pre-existing software projects or libraries. This information can then be used during the build process to ensure that all of the necessary software is bundled together. When you are asked to run mvn clean install in the Building the Egeria Source tutorial , you are instructing Maven to go through the Egeria source code and build the project: including all of these external libraries and dependencies (including downloading them automatically, when needed). You can check if Maven installed by running the command mvn --version from the command-line. Maven can be installed: On MacOS, by first installing the HomeBrew package manager and then running brew install maven from the command-line. On Linux operating systems, by using your distribution's package manager ( yum install maven , apt-get install maven , etc). On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for Linux. Ensure you are using version 3.5.0 or higher in order to build Egeria.","title":"Building"},{"location":"education/tutorials/lab-infrastructure-guide/building/#building-and-developing-egeria","text":"These technologies are needed in order to build and develop Egeria. If you simply want to try out and explore Egeria, or if you find yourself lost in all of these technologies, choose one of the self-contained environments instead.","title":"Building and developing Egeria"},{"location":"education/tutorials/lab-infrastructure-guide/building/#supported-platforms","text":"Egeria currently supports building on *nix, Linux & Linux-like operating systems such as MacOS. Our official build pipelines are based on x86_64 architecture, but it is expected other architectures would build ok, subject to the availablility of the required tools and interpreters/jvms/runtimes ie Java, Python, Docker/containerd/k8s etc. On Windows, you should use Windows Subsystem for Linux Version 2 or above, and install a Linux distribution such as Ubuntu. This avoids issues we have seen with path seperators, symbolic links, slow I/O performance, long pathnames. Some IDEs such as JetBrains IntelliJ and Microsoft VisualCode will run the GUI in Windows natively, and then use a linux environment (via WSL2 - which uses a real Linux kernel) to perform build and execution","title":"Supported Platforms"},{"location":"education/tutorials/lab-infrastructure-guide/building/#git","text":"Git is an open source version control system. It is what we use to: track changes to the underlying Egeria code as the project evolves track issues and enhancements, and link these back to the code changes that resolve them collaborate on and review the issues, enhancements and code changes As a result, it gives us a definitive source for the latest and greatest source code for Egeria itself, its history, and the rationale behind various decisions that are made over time. In our Downloading Egeria from GitHub tutorial , when you are asked to do a git clone https://github.com/odpi/egeria.git , what you are telling your own computer to do is to create a local copy of our source code repository. It is this local copy that you can then use (locally) to build Egeria itself. You can check whether it is installed on your system by running git --version from the command-line. Git can be installed: On MacOS, as part of the Xcode suite (running git --version will prompt you to install it if it is not already installed). On Linux operating systems, by using your distribution's package manager ( yum install git , apt-get install git , etc). On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for Linux. Interested to learn more? GitHub provides some great introductory guides .","title":"Git"},{"location":"education/tutorials/lab-infrastructure-guide/building/#java","text":"Because Egeria is written in Java, you will need a Java Development Kit ( JDK ) installed in order to build Egeria. The JDK can also act as the runtime environment ( JRE ) mentioned in running Egeria natively . There are various JDKs available, and you may even have one pre-installed on your system. You can check by running the command java -version from the command-line. Java can be installed by: Downloading the OpenJDK 11 (LTS) HotSpot JVM from Adoptium . Running the installer that is downloaded.","title":"Java"},{"location":"education/tutorials/lab-infrastructure-guide/building/#apache-maven","text":"Apache Maven is a tool to describe and manage the technical aspects of a software project. For example, it can be used to define various dependencies a project like Egeria has on other pre-existing software projects or libraries. This information can then be used during the build process to ensure that all of the necessary software is bundled together. When you are asked to run mvn clean install in the Building the Egeria Source tutorial , you are instructing Maven to go through the Egeria source code and build the project: including all of these external libraries and dependencies (including downloading them automatically, when needed). You can check if Maven installed by running the command mvn --version from the command-line. Maven can be installed: On MacOS, by first installing the HomeBrew package manager and then running brew install maven from the command-line. On Linux operating systems, by using your distribution's package manager ( yum install maven , apt-get install maven , etc). On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for Linux. Ensure you are using version 3.5.0 or higher in order to build Egeria.","title":"Apache Maven"},{"location":"education/tutorials/lab-infrastructure-guide/overview/","text":"Guide to Running Egeria for the Hands on Labs \u00b6 There are a number of approaches to running the environment used in the hands on labs . If you only want to get the environment running for the hands on labs: Running Egeria in a self-contained environment using Kubernetes . If you want to learn more about setting up egeria and its related technologies, then this is the option for you ... Running the Egeria ecosystem natively . Further information \u00b6 If you are entirely new to technologies like Git, Java, Maven, Kafka, ZooKeeper, Jupyter, Docker, Kubernetes, Helm, etc the Egeria Dojo provides self-paced education that covers these technologies in the context of Egeria.","title":"Overview"},{"location":"education/tutorials/lab-infrastructure-guide/overview/#guide-to-running-egeria-for-the-hands-on-labs","text":"There are a number of approaches to running the environment used in the hands on labs . If you only want to get the environment running for the hands on labs: Running Egeria in a self-contained environment using Kubernetes . If you want to learn more about setting up egeria and its related technologies, then this is the option for you ... Running the Egeria ecosystem natively .","title":"Guide to Running Egeria for the Hands on Labs"},{"location":"education/tutorials/lab-infrastructure-guide/overview/#further-information","text":"If you are entirely new to technologies like Git, Java, Maven, Kafka, ZooKeeper, Jupyter, Docker, Kubernetes, Helm, etc the Egeria Dojo provides self-paced education that covers these technologies in the context of Egeria.","title":"Further information"},{"location":"education/tutorials/lab-infrastructure-guide/running-kubernetes/","text":"Running Egeria in a self-contained environment using Kubernetes \u00b6 With this approach, you do not need to download, install, configure and understand all of the underlying components that Egeria itself uses. Intro & Setting up Kubernetes & Helm Installing the Coco Pharmaceuticals lab chart","title":"Running kubernetes"},{"location":"education/tutorials/lab-infrastructure-guide/running-kubernetes/#running-egeria-in-a-self-contained-environment-using-kubernetes","text":"With this approach, you do not need to download, install, configure and understand all of the underlying components that Egeria itself uses. Intro & Setting up Kubernetes & Helm Installing the Coco Pharmaceuticals lab chart","title":"Running Egeria in a self-contained environment using Kubernetes"},{"location":"education/tutorials/lab-infrastructure-guide/running-natively/","text":"Running Egeria natively \u00b6 These technologies are what Egeria itself uses to operate. They are included when using the self-contained environments, but they can also be installed and run natively (directly) on your system. Just be aware that running them natively on your system will require the additional effort of downloading, installing, configuring and operating each one -- which the self-contained environments largely take care of for you. To make use of the latest Egeria software, you will likely also need to be familiar with how to build Egeria in order to use it natively. Follow the OMAG Server Platform tutorial for instructions on how to set up and run a platform yourself. You need to start four OMAG Server Platforms at the following URLs - remembering to use the -Dserver.port=nnnn option: https://localhost:9443 https://localhost:9444 https://localhost:9445 https://localhost:9446 Java \u00b6 Java is a relatively mature object-oriented programming language that was originally designed to be able to easily run programs across a number of different computer systems. The Egeria project itself is primarily written in Java, and therefore a Java Runtime Environment ( JRE ) is the most basic component needed in order to run Egeria. You can either run such an environment directly on your system, or you can use one of the options below to run a self-contained environment on top of your system. You can check if you have a JRE available by running the command java -version from the command-line. If not, and you prefer to run it directly rather than via one of the options outlined below, Java can be installed by: Downloading the OpenJDK JRE or JDK from AdoptOpenJDK . Java 11 is required. Hotspot is tested, J9 should work. Running the installer that is downloaded. Alternatively you may wish to install from your package manager such as 'homebrew' on MacOS. Apache Kafka \u00b6 Apache Kafka is used by Egeria as an event bus. There is a QuickStart Guide provided by Kafka itself covering installation and basic usage. For the tutorials, the Kafka server needs to be running a PLAINTEXT listener on localhost:9092 . From the directory where Kafka is installed, check the config/server.properties file so that the listeners and advertised.listeners are setup as follows: listeners=PLAINTEXT://localhost:9092 advertised.listeners=PLAINTEXT://localhost:5092 To restart Kafka after making this update, change into Kafka's bin directory and issue the following commands: $ ./zookeeper-server-start.sh ../config/zookeeper.properties & $ ./kafka-server-start.sh ../config/server.properties & You may alternatively wish to install kafka/zookeeper using a package manager such as 'homebrew' on MacOS. Apache ZooKeeper \u00b6 Apache ZooKeeper is used by Apache Kafka for maintaining certain configuration information. It is therefore typically a pre-requisite to using Apache Kafka. The QuickStart Guide provided by Kafka itself includes quick-and-dirty instructions on running a minimal ZooKeeper server necessary for Kafka's use. For more detailed information, you will want to read the ZooKeeper Getting Started Guide . Jupyter \u00b6 Project Jupyter provides tools for interactive computing. In particular, we use Jupyter Notebooks to provide an interactive tutorial that shows rich instructions, allows you to run code, and to see the output all in the same interface. Our notebooks are found under open-metadata-resources/open-metadata-labs/ - either start jupyter with this as the current directory, or navigate to it in the web ui. (this is automatic when using the other execution options). Help \u00b6 For additional help refer to our slack channels at http://slack.lfai.foundation","title":"Running natively"},{"location":"education/tutorials/lab-infrastructure-guide/running-natively/#running-egeria-natively","text":"These technologies are what Egeria itself uses to operate. They are included when using the self-contained environments, but they can also be installed and run natively (directly) on your system. Just be aware that running them natively on your system will require the additional effort of downloading, installing, configuring and operating each one -- which the self-contained environments largely take care of for you. To make use of the latest Egeria software, you will likely also need to be familiar with how to build Egeria in order to use it natively. Follow the OMAG Server Platform tutorial for instructions on how to set up and run a platform yourself. You need to start four OMAG Server Platforms at the following URLs - remembering to use the -Dserver.port=nnnn option: https://localhost:9443 https://localhost:9444 https://localhost:9445 https://localhost:9446","title":"Running Egeria natively"},{"location":"education/tutorials/lab-infrastructure-guide/running-natively/#java","text":"Java is a relatively mature object-oriented programming language that was originally designed to be able to easily run programs across a number of different computer systems. The Egeria project itself is primarily written in Java, and therefore a Java Runtime Environment ( JRE ) is the most basic component needed in order to run Egeria. You can either run such an environment directly on your system, or you can use one of the options below to run a self-contained environment on top of your system. You can check if you have a JRE available by running the command java -version from the command-line. If not, and you prefer to run it directly rather than via one of the options outlined below, Java can be installed by: Downloading the OpenJDK JRE or JDK from AdoptOpenJDK . Java 11 is required. Hotspot is tested, J9 should work. Running the installer that is downloaded. Alternatively you may wish to install from your package manager such as 'homebrew' on MacOS.","title":"Java"},{"location":"education/tutorials/lab-infrastructure-guide/running-natively/#apache-kafka","text":"Apache Kafka is used by Egeria as an event bus. There is a QuickStart Guide provided by Kafka itself covering installation and basic usage. For the tutorials, the Kafka server needs to be running a PLAINTEXT listener on localhost:9092 . From the directory where Kafka is installed, check the config/server.properties file so that the listeners and advertised.listeners are setup as follows: listeners=PLAINTEXT://localhost:9092 advertised.listeners=PLAINTEXT://localhost:5092 To restart Kafka after making this update, change into Kafka's bin directory and issue the following commands: $ ./zookeeper-server-start.sh ../config/zookeeper.properties & $ ./kafka-server-start.sh ../config/server.properties & You may alternatively wish to install kafka/zookeeper using a package manager such as 'homebrew' on MacOS.","title":"Apache Kafka"},{"location":"education/tutorials/lab-infrastructure-guide/running-natively/#apache-zookeeper","text":"Apache ZooKeeper is used by Apache Kafka for maintaining certain configuration information. It is therefore typically a pre-requisite to using Apache Kafka. The QuickStart Guide provided by Kafka itself includes quick-and-dirty instructions on running a minimal ZooKeeper server necessary for Kafka's use. For more detailed information, you will want to read the ZooKeeper Getting Started Guide .","title":"Apache ZooKeeper"},{"location":"education/tutorials/lab-infrastructure-guide/running-natively/#jupyter","text":"Project Jupyter provides tools for interactive computing. In particular, we use Jupyter Notebooks to provide an interactive tutorial that shows rich instructions, allows you to run code, and to see the output all in the same interface. Our notebooks are found under open-metadata-resources/open-metadata-labs/ - either start jupyter with this as the current directory, or navigate to it in the web ui. (this is automatic when using the other execution options).","title":"Jupyter"},{"location":"education/tutorials/lab-infrastructure-guide/running-natively/#help","text":"For additional help refer to our slack channels at http://slack.lfai.foundation","title":"Help"},{"location":"education/tutorials/omag-server-tutorial/overview/","text":"OMAG Server Platform Tutorial \u00b6 The Open Metadata and Governance ( OMAG ) Server Platform is a flexible server platform that can run many different types of open metadata and governance services. Objectives \u00b6 At the end of this tutorial you will be able to perform the following tasks. Starting the OMAG Server Platform Using the Administration Services to: Configure open metadata and governance services in OMAG servers . Start up the configured services. Make calls to the running services. Shutdown running services. Remove the configuration for open metadata and governance services. Prerequisite Tasks \u00b6 Download and build ODPi Egeria Familiarize yourself with the Postman test tool Tutorial Tasks \u00b6 Starting the OMAG Server Platform Creating Configuration Documents Activating Logical OMAG Servers in the OMAG Server Platform Calling the Open Metadata and Governance APIs Digging Deeper \u00b6 Changing the OMAG Server Platform's network address Running the Egeria samples to understand more about the different Egeria APIs. Calling the OMAG Clients from Java to understand how to call Egeria APIs from your code. Running the Open Metadata Conformance Suite to understand how a technology/software product can demonstrate its conformance to the Egeria standards.","title":"Overview"},{"location":"education/tutorials/omag-server-tutorial/overview/#omag-server-platform-tutorial","text":"The Open Metadata and Governance ( OMAG ) Server Platform is a flexible server platform that can run many different types of open metadata and governance services.","title":"OMAG Server Platform Tutorial"},{"location":"education/tutorials/omag-server-tutorial/overview/#objectives","text":"At the end of this tutorial you will be able to perform the following tasks. Starting the OMAG Server Platform Using the Administration Services to: Configure open metadata and governance services in OMAG servers . Start up the configured services. Make calls to the running services. Shutdown running services. Remove the configuration for open metadata and governance services.","title":"Objectives"},{"location":"education/tutorials/omag-server-tutorial/overview/#prerequisite-tasks","text":"Download and build ODPi Egeria Familiarize yourself with the Postman test tool","title":"Prerequisite Tasks"},{"location":"education/tutorials/omag-server-tutorial/overview/#tutorial-tasks","text":"Starting the OMAG Server Platform Creating Configuration Documents Activating Logical OMAG Servers in the OMAG Server Platform Calling the Open Metadata and Governance APIs","title":"Tutorial Tasks"},{"location":"education/tutorials/omag-server-tutorial/overview/#digging-deeper","text":"Changing the OMAG Server Platform's network address Running the Egeria samples to understand more about the different Egeria APIs. Calling the OMAG Clients from Java to understand how to call Egeria APIs from your code. Running the Open Metadata Conformance Suite to understand how a technology/software product can demonstrate its conformance to the Egeria standards.","title":"Digging Deeper"},{"location":"education/tutorials/omag-server-tutorial/task-calling-omag-apis/","text":"Calling Open Metadata and Governance Services \u00b6","title":"Task calling omag apis"},{"location":"education/tutorials/omag-server-tutorial/task-calling-omag-apis/#calling-open-metadata-and-governance-services","text":"","title":"Calling Open Metadata and Governance Services"},{"location":"education/tutorials/omag-server-tutorial/task-changing-the-omag-server-network-address/","text":"Changing the OMAG Server Platform's Network Address \u00b6 By default the OMAG Server Platform registers with the network using https://localhost:9443 . This is ok for testing, or where you only want to run one instance of the OMAG Server Platform on a single machine, but for many situations it is not sufficient. This tutorial covers changing the network address. The OMAG Server Platform's installation directory there is the Java Archive (Jar) file for the OMAG server platform and a resources directory. $ ls resources server-chassis-spring-3.3-SNAPSHOT.jar Change to the resources directory and you will see the banner.txt file that is displayed when the OMAG server platform starts up along with the application.properties file. $ cd resources $ ls application.properties banner.txt The application.properties file provides a means to add configuration to the Spring Boot Server Chassis that acts as a base for the OMAG Server Platform. $ cat application.properties # SPDX-License-Identifier: Apache-2.0 # Copyright Contributors to the ODPi Egeria project. strict.ssl = true ################################################ ### Logging ################################################ logging.level.root = OFF Edit the application.properties file and add server.address=https://localhost:9444 to the file: # SPDX-License-Identifier: Apache-2.0 # Copyright Contributors to the ODPi Egeria project. strict.ssl=true ################################################ ### Logging ################################################ logging.level.root=OFF server.address=https://localhost:9444 Start the OMAG server platform again and issue the following REST call to check the server is running with the new server address. $ curl --insecure -X GET https://localhost:9444/open-metadata/platform-services/users/test/server-platform/origin Egeria OMAG Server Platform","title":"Task changing the omag server network address"},{"location":"education/tutorials/omag-server-tutorial/task-changing-the-omag-server-network-address/#changing-the-omag-server-platforms-network-address","text":"By default the OMAG Server Platform registers with the network using https://localhost:9443 . This is ok for testing, or where you only want to run one instance of the OMAG Server Platform on a single machine, but for many situations it is not sufficient. This tutorial covers changing the network address. The OMAG Server Platform's installation directory there is the Java Archive (Jar) file for the OMAG server platform and a resources directory. $ ls resources server-chassis-spring-3.3-SNAPSHOT.jar Change to the resources directory and you will see the banner.txt file that is displayed when the OMAG server platform starts up along with the application.properties file. $ cd resources $ ls application.properties banner.txt The application.properties file provides a means to add configuration to the Spring Boot Server Chassis that acts as a base for the OMAG Server Platform. $ cat application.properties # SPDX-License-Identifier: Apache-2.0 # Copyright Contributors to the ODPi Egeria project. strict.ssl = true ################################################ ### Logging ################################################ logging.level.root = OFF Edit the application.properties file and add server.address=https://localhost:9444 to the file: # SPDX-License-Identifier: Apache-2.0 # Copyright Contributors to the ODPi Egeria project. strict.ssl=true ################################################ ### Logging ################################################ logging.level.root=OFF server.address=https://localhost:9444 Start the OMAG server platform again and issue the following REST call to check the server is running with the new server address. $ curl --insecure -X GET https://localhost:9444/open-metadata/platform-services/users/test/server-platform/origin Egeria OMAG Server Platform","title":"Changing the OMAG Server Platform's Network Address"},{"location":"education/tutorials/omag-server-tutorial/task-creating-configuration-documents/","text":"Creating configuration documents for the OMAG Server Platform \u00b6 The OMAG server platform provides a software platform for running OMAG Servers . Each OMAG Server supports selected open metadata and governance services based on its configuration. When the OMAG server platform is first started , there are no OMAG Servers running inside it. However there are three sets of Administration Service APIs active. Server Origin - for discovering the source of the OMAG server platform. (This was used in the previous task .) Configuration Services - for creating configuration documents. Operational Services - for starting and stopping OMAG Servers in the OMAG server platform using the configuration documents. What is a configuration document? \u00b6 A configuration document provides the configuration properties for an OMAG server. It includes: * Basic properties of the OMAG server. * Defaults to use when configuring the subsystems of the OMAG server. * Configuration for selected subsystems within the OMAG server. The subsystems selected and configured determine which open metadata and governance services are supported by the OMAG server. Configuration documents are created using the OMAG server platform configuration services. In order to experiment with these services, this tutorial uses the Postman test tool. This is a tool that enables you to type in REST API calls and execute them against the OMAG server platform. There is also a postman collection located at: https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-resources/open-metadata-tutorials/omag-server-tutorial/resources/omag-server-platform-tutorial.postman_collection.json It can be downloaded and imported into postman to support this tutorial. (see Import button top left of the Postman user interface). This tutorial will also use curl commands to illustrate calls to the administration services as well as refer to the pre-canned calls in the postman collection. Creating the configuration document \u00b6 Before there is a configuration document, requesting the server configuration creates and returns a default document. The command is: GET {serverURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/configuration where: * {serverURLRoot} is the host name and port number of the OMAG server platform (eg https://localhost:9443). * {adminUserId} is the user id of the administrator making the calls. * {serverName} is the name of the OMAG server that is being configured. Try the following command (this is request 2. in Postman): GET https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/configuration The response is in JSON format and contains the following information: { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"28aeb916-5029-4d6a-aa96-392196859916\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Open Metadata and Governance Server\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 } } The localServerId property is a unique identifier given to the server and is used internally to improve the performance of its interaction with external components such as Apache Kafka. The localServerName is the name of the OMAG server supplied on the command. The localServerType , localServerURL , localServerUserId and maxPageSize are set to their default values and can be changed. For example, try the following command (this is request 3. in Postman): POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/server-type?typeName=\"Standalone Metadata Repository\" Then query the configuration again (this is request 4. in Postman): { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Standalone Metadata Repository\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"auditTrail\" : [ \"Tue Feb 05 13:12:50 GMT 2019 garygeeke updated configuration for local server type name to Standalone Metadata Repository.\" ] } } Notice that the localServerType has changed and an audit trail has also appeared. This allows you to keep track of the changes being made to the configuration document. The next command configures in type of metadata repository (this is request 5. in Postman). In this example, we are using a simple in-memory repository which is useful for testing. POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/local-repository/mode/in-memory-repository This has added the configuration for the local repository using default values. If you query the configuration again (this is request 6. in Postman) you see: { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Standalone Metadata Repository\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"repositoryServicesConfig\" : { \"class\" : \"RepositoryServicesConfig\" , \"auditLogConnections\" : [ { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5390bf3e-6b38-4eda-b34a-de55ac4252a7\" , \"qualifiedName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"displayName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"description\" : \"OMRS default audit log connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"4afac741-3dcc-4c60-a4ca-a6dede994e3f\" , \"qualifiedName\" : \"Console Audit Log Store Connector\" , \"displayName\" : \"Console Audit Log Store Connector\" , \"description\" : \"Connector supports logging of audit log messages to stdout.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.auditlogstore.console.ConsoleAuditLogStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"836efeae-ab34-4425-89f0-6adf2faa1f2e\" , \"qualifiedName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"displayName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"description\" : \"OMRS default audit log endpoint.\" , \"address\" : \"cocoMDS1.auditlog\" } } ], \"localRepositoryConfig\" : { \"class\" : \"LocalRepositoryConfig\" , \"metadataCollectionId\" : \"ad405dc2-1361-48f8-9ea2-538bd43db1b0\" , \"localRepositoryLocalConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6a3c07b0-0e04-42dc-bcc6-392609bf1d02\" , \"qualifiedName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"displayName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"description\" : \"OMRS default in memory local repository connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"65cc9091-757f-4bcd-b937-426160be8bc2\" , \"qualifiedName\" : \"OMRS In Memory Repository Connector\" , \"displayName\" : \"OMRS In Memory Repository Connector\" , \"description\" : \"OMRS Repository Connector that uses an in-memory store.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.inmemory.repositoryconnector.InMemoryOMRSRepositoryConnectorProvider\" } }, \"localRepositoryRemoteConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"75ea56d1-656c-43fb-bc0c-9d35c5553b9e\" , \"qualifiedName\" : \"OMRS REST API Repository Connector\" , \"displayName\" : \"OMRS REST API Repository Connector\" , \"description\" : \"OMRS Repository Connector that calls the repository services REST API of a remote server.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/servers/cocoMDS1\" } }, \"eventsToSaveRule\" : \"ALL\" , \"eventsToSendRule\" : \"ALL\" } }, \"auditTrail\" : [ \"Tue Feb 05 13:12:50 GMT 2019 garygeeke updated configuration for local server type name to Standalone Metadata Repository.\" , \"Tue Feb 05 14:58:28 GMT 2019 garygeeke updated configuration for the local repository.\" ] } } Finally in this exercise, use the following command to enable the Open Metadata Access Services (OMASs) that provide the domain specific open metadata and governance APIs. The access services provide both REST APIs and event-based interaction. As such they need information about an event bus. The command below (this is request 7. in Postman) sets up configuration properties about the event bus. These properties are embedded in the configuration for each access service. POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/event-bus?topicURLRoot=egeriaTopics When the configuration is next queried (this is request 8. in Postman), the event bus details are stored in the configuration document. { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Standalone Metadata Repository\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"eventBusConfig\" : { \"class\" : \"EventBusConfig\" , \"topicURLRoot\" : \"egeriaTopics\" }, \"repositoryServicesConfig\" : { \"class\" : \"RepositoryServicesConfig\" , \"auditLogConnections\" : [ { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5390bf3e-6b38-4eda-b34a-de55ac4252a7\" , \"qualifiedName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"displayName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"description\" : \"OMRS default audit log connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"4afac741-3dcc-4c60-a4ca-a6dede994e3f\" , \"qualifiedName\" : \"Console Audit Log Store Connector\" , \"displayName\" : \"Console Audit Log Store Connector\" , \"description\" : \"Connector supports logging of audit log messages to stdout.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.auditlogstore.console.ConsoleAuditLogStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"836efeae-ab34-4425-89f0-6adf2faa1f2e\" , \"qualifiedName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"displayName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"description\" : \"OMRS default audit log endpoint.\" , \"address\" : \"cocoMDS1.auditlog\" } } ], \"localRepositoryConfig\" : { \"class\" : \"LocalRepositoryConfig\" , \"metadataCollectionId\" : \"ad405dc2-1361-48f8-9ea2-538bd43db1b0\" , \"localRepositoryLocalConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6a3c07b0-0e04-42dc-bcc6-392609bf1d02\" , \"qualifiedName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"displayName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"description\" : \"OMRS default in memory local repository connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"65cc9091-757f-4bcd-b937-426160be8bc2\" , \"qualifiedName\" : \"OMRS In Memory Repository Connector\" , \"displayName\" : \"OMRS In Memory Repository Connector\" , \"description\" : \"OMRS Repository Connector that uses an in-memory store.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.inmemory.repositoryconnector.InMemoryOMRSRepositoryConnectorProvider\" } }, \"localRepositoryRemoteConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"75ea56d1-656c-43fb-bc0c-9d35c5553b9e\" , \"qualifiedName\" : \"OMRS REST API Repository Connector\" , \"displayName\" : \"OMRS REST API Repository Connector\" , \"description\" : \"OMRS Repository Connector that calls the repository services REST API of a remote server.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/servers/cocoMDS1\" } }, \"eventsToSaveRule\" : \"ALL\" , \"eventsToSendRule\" : \"ALL\" } }, \"auditTrail\" : [ \"Tue Feb 05 13:12:50 GMT 2019 garygeeke updated configuration for local server type name to Standalone Metadata Repository.\" , \"Tue Feb 05 14:58:28 GMT 2019 garygeeke updated configuration for the local repository.\" , \"Tue Feb 05 15:13:45 GMT 2019 garygeeke updated configuration for default event bus.\" ] } } The last command creates the configuration for the access services (this is request 9. in Postman): POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/access-services which results in the final configuration (this is request 10. in Postman). { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Standalone Metadata Repository\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"eventBusConfig\" : { \"class\" : \"EventBusConfig\" , \"topicURLRoot\" : \"egeriaTopics\" }, \"accessServicesConfig\" : [ { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1021 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.dataengine.server.admin.DataEngineAdmin\" , \"accessServiceName\" : \"Data Engine\" , \"accessServiceDescription\" : \"Create processes for lineage\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-engine/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"14475820-7356-4b14-a560-128b4f6bdf87\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"25629bf5-e8f0-4f47-ac43-2dee3ba2439c\" , \"qualifiedName\" : \"open-metadata.access-services.Data Engine.inTopic\" , \"displayName\" : \"open-metadata.access-services.Data Engine.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Data Engine.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"84689e40-b83a-4a8e-b172-e628ded4c77b\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"0b2e8a73-0c58-44fe-8b8e-e07b3f78592d\" , \"qualifiedName\" : \"open-metadata.access-services.Data Engine.outTopic\" , \"displayName\" : \"open-metadata.access-services.Data Engine.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Data Engine.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1020 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.subjectarea.admin.SubjectAreaAdmin\" , \"accessServiceName\" : \"Subject Area\" , \"accessServiceDescription\" : \"Document knowledge about a subject area\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/subject-area/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"96780526-2d8e-4334-9bfa-1dd86896913c\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"c2643840-8225-4c9b-84b6-4ab0b2a9a80a\" , \"qualifiedName\" : \"open-metadata.access-services.Subject Area.inTopic\" , \"displayName\" : \"open-metadata.access-services.Subject Area.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Subject Area.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"82279a05-9310-4600-a03a-9dc70a41600f\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"2235fdb0-84d6-4efe-b914-9035dbe74083\" , \"qualifiedName\" : \"open-metadata.access-services.Subject Area.outTopic\" , \"displayName\" : \"open-metadata.access-services.Subject Area.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Subject Area.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1008 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.governanceengine.admin.GovernanceEngineAdmin\" , \"accessServiceName\" : \"Governance Engine\" , \"accessServiceDescription\" : \"Set up an operational governance engine\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-engine/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"4f83087c-bd1c-455f-b809-1938cab03ecd\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"a0ba0eea-738f-4b0c-adc2-3d832e43ca72\" , \"qualifiedName\" : \"open-metadata.access-services.Governance Engine.inTopic\" , \"displayName\" : \"open-metadata.access-services.Governance Engine.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"84036aea-5055-427a-aa3d-ad3fa0aef255\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"98f58323-b97c-4e7b-82f6-d804449a4d81\" , \"qualifiedName\" : \"open-metadata.access-services.Governance Engine.outTopic\" , \"displayName\" : \"open-metadata.access-services.Governance Engine.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1009 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.governanceprogram.admin.GovernanceProgramAdmin\" , \"accessServiceName\" : \"Governance Program\" , \"accessServiceDescription\" : \"Manage the governance program\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-program/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6bba6aa3-308e-41a3-bf01-51ef65028e60\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"aad59e1e-20e4-4a9b-982a-f8b939dc580a\" , \"qualifiedName\" : \"open-metadata.access-services.Governance Program.inTopic\" , \"displayName\" : \"open-metadata.access-services.Governance Program.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Program.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6d5a04c3-e216-42b0-9479-71ce4461e86d\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"dccb1ef2-ae92-4ed9-9619-537c9cf4e05d\" , \"qualifiedName\" : \"open-metadata.access-services.Governance Program.outTopic\" , \"displayName\" : \"open-metadata.access-services.Governance Program.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Program.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1014 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.informationview.admin.InformationViewAdmin\" , \"accessServiceName\" : \"Information View\" , \"accessServiceDescription\" : \"Support information virtualization and data set definitions\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/information-view/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"b7718cc6-da6a-4a9f-8f76-c5d4579f1c34\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"87628694-8c85-46eb-aae2-0c834e915e00\" , \"qualifiedName\" : \"open-metadata.access-services.Information View.inTopic\" , \"displayName\" : \"open-metadata.access-services.Information View.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"826c314e-856d-4b2b-bcf1-0d11285a7610\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"fccd511a-86f1-4748-b580-78afd9a0b166\" , \"qualifiedName\" : \"open-metadata.access-services.Information View.outTopic\" , \"displayName\" : \"open-metadata.access-services.Information View.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1001 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.assetconsumer.admin.AssetConsumerAdmin\" , \"accessServiceName\" : \"Asset Consumer\" , \"accessServiceDescription\" : \"Access assets through connectors\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-consumer/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5d034bb8-133b-4dc8-b0db-712ae8a032d6\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"148e6940-9dff-47c6-9762-662559b3bec7\" , \"qualifiedName\" : \"open-metadata.access-services.Asset Consumer.inTopic\" , \"displayName\" : \"open-metadata.access-services.Asset Consumer.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"c46fd6be-4377-4ef8-8ce4-82aa30a9f3bd\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6ca034c7-523e-4b30-a7dc-f1359c287ea0\" , \"qualifiedName\" : \"open-metadata.access-services.Asset Consumer.outTopic\" , \"displayName\" : \"open-metadata.access-services.Asset Consumer.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1004 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.connectedasset.admin.ConnectedAssetAdmin\" , \"accessServiceName\" : \"Connected Asset\" , \"accessServiceDescription\" : \"Understand an asset\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/connected-asset/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"2214b4ad-d1b8-4fd4-942c-4a5552688e91\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"fabfa203-ca60-4036-90e5-de5d695ef8f1\" , \"qualifiedName\" : \"open-metadata.access-services.Connected Asset.inTopic\" , \"displayName\" : \"open-metadata.access-services.Connected Asset.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Connected Asset.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"9c3332ce-b065-49dc-b22e-432277627cde\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"e7bf76b4-4214-460f-ad8f-12a0ecb63e44\" , \"qualifiedName\" : \"open-metadata.access-services.Connected Asset.outTopic\" , \"displayName\" : \"open-metadata.access-services.Connected Asset.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Connected Asset.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1000 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservice.assetcatalog.admin.AssetCatalogAdmin\" , \"accessServiceName\" : \"Asset Catalog\" , \"accessServiceDescription\" : \"Search and understand your assets\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-catalog/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5f6dc495-2b31-4ca0-8196-bb34a14e020b\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"338b6ea6-cd1e-4896-ab1a-568da8477903\" , \"qualifiedName\" : \"open-metadata.access-services.Asset Catalog.inTopic\" , \"displayName\" : \"open-metadata.access-services.Asset Catalog.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Catalog.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"55a9dbb0-f756-4180-82d5-9b8c35af5fb0\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"dab48064-6204-49bf-bf30-a66b0e353d36\" , \"qualifiedName\" : \"open-metadata.access-services.Asset Catalog.outTopic\" , \"displayName\" : \"open-metadata.access-services.Asset Catalog.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Catalog.outTopic\" } } } ], \"repositoryServicesConfig\" : { \"class\" : \"RepositoryServicesConfig\" , \"auditLogConnections\" : [ { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5390bf3e-6b38-4eda-b34a-de55ac4252a7\" , \"qualifiedName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"displayName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"description\" : \"OMRS default audit log connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"4afac741-3dcc-4c60-a4ca-a6dede994e3f\" , \"qualifiedName\" : \"Console Audit Log Store Connector\" , \"displayName\" : \"Console Audit Log Store Connector\" , \"description\" : \"Connector supports logging of audit log messages to stdout.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.auditlogstore.console.ConsoleAuditLogStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"836efeae-ab34-4425-89f0-6adf2faa1f2e\" , \"qualifiedName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"displayName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"description\" : \"OMRS default audit log endpoint.\" , \"address\" : \"cocoMDS1.auditlog\" } } ], \"localRepositoryConfig\" : { \"class\" : \"LocalRepositoryConfig\" , \"metadataCollectionId\" : \"ad405dc2-1361-48f8-9ea2-538bd43db1b0\" , \"localRepositoryLocalConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6a3c07b0-0e04-42dc-bcc6-392609bf1d02\" , \"qualifiedName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"displayName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"description\" : \"OMRS default in memory local repository connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"65cc9091-757f-4bcd-b937-426160be8bc2\" , \"qualifiedName\" : \"OMRS In Memory Repository Connector\" , \"displayName\" : \"OMRS In Memory Repository Connector\" , \"description\" : \"OMRS Repository Connector that uses an in-memory store.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.inmemory.repositoryconnector.InMemoryOMRSRepositoryConnectorProvider\" } }, \"localRepositoryRemoteConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"75ea56d1-656c-43fb-bc0c-9d35c5553b9e\" , \"qualifiedName\" : \"OMRS REST API Repository Connector\" , \"displayName\" : \"OMRS REST API Repository Connector\" , \"description\" : \"OMRS Repository Connector that calls the repository services REST API of a remote server.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/servers/cocoMDS1\" } }, \"eventsToSaveRule\" : \"ALL\" , \"eventsToSendRule\" : \"ALL\" }, \"enterpriseAccessConfig\" : { \"class\" : \"EnterpriseAccessConfig\" , \"enterpriseMetadataCollectionName\" : \"cocoMDS1 Enterprise Metadata Collection\" , \"enterpriseMetadataCollectionId\" : \"95af03a9-ac18-4dbb-8b3a-4782429e5f77\" , \"enterpriseOMRSTopicConnection\" : { \"class\" : \"VirtualConnection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"82f9c664-e59d-484c-a8f3-17088c23a2f3\" , \"elementTypeName\" : \"VirtualConnection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A connector for a virtual resource that needs to retrieve data from multiple places.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"2084ee90-717b-49a1-938e-8f9d49567b8e\" , \"qualifiedName\" : \"EnterpriseTopicConnector.Server.cocoMDS1\" , \"displayName\" : \"EnterpriseTopicConnector.Server.cocoMDS1\" , \"description\" : \"OMRS default enterprise topic connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"c3cc7a9c-4fe2-4383-85c3-1e94df45e2da\" , \"qualifiedName\" : \"org.odpi.openmetadata.repositoryservices.connectors.omrstopic.OMRSTopicProvider\" , \"displayName\" : \"OMRSTopicProvider\" , \"description\" : \"ConnectorType for OMRSTopicProvider\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.repositoryservices.connectors.omrstopic.OMRSTopicProvider\" }, \"embeddedConnections\" : [ { \"class\" : \"EmbeddedConnection\" , \"displayName\" : \"Enterprise OMRS Events\" , \"embeddedConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"d2224d17-d55d-4029-b841-7b37f2fa3df3\" , \"qualifiedName\" : \"Enterprise OMRS Events\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"Enterprise OMRS Events\" , \"description\" : \"Enterprise OMRS Events\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"ed8e682b-2fec-4403-b551-02f8c46322ef\" , \"qualifiedName\" : \"In Memory Open Metadata Topic Connector\" , \"displayName\" : \"In Memory Open Metadata Topic Connector\" , \"description\" : \"In Memory Open Metadata Topic Connector supports string based events over an in memory event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.inmemory.InMemoryOpenMetadataTopicProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"2f858351-eb06-4824-805c-6f0bb56a4923\" , \"qualifiedName\" : \"open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic\" , \"displayName\" : \"open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic\" , \"description\" : \"Enterprise OMRS Events\" , \"address\" : \"cocoMDS1.open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic\" } } } ] }, \"enterpriseOMRSTopicProtocolVersion\" : \"V1\" } }, \"auditTrail\" : [ \"Tue Feb 05 13:12:50 GMT 2019 garygeeke updated configuration for local server type name to Standalone Metadata Repository.\" , \"Tue Feb 05 14:58:28 GMT 2019 garygeeke updated configuration for the local repository.\" , \"Tue Feb 05 15:13:45 GMT 2019 garygeeke updated configuration for default event bus.\" , \"Tue Feb 05 15:49:07 GMT 2019 garygeeke updated configuration for access services.\" , \"Tue Feb 05 15:49:07 GMT 2019 garygeeke updated configuration for enterprise repository services (used by access services).\" ] } } You have probably noticed how quickly the configuration document grew into a complex structure. The commands you used made use of all of the configuration default values. There are other configuration services that enable you to customize the configuration document to adapt it to specific environment. However, the defaults provide a good starting point. Further reading \u00b6 The contents of this tutorial cover a very simple OMAG server configuration. For guidance on configuring more complex OMAG servers see: Administration Services User Guide For instructions on how to set up two OMAG Servers using in memory repositories that are exchanging metadata over Apache Kafka , see: In Memory Repository Demo Next steps \u00b6 With the configuration document in place, you are ready to start the OMAG Server .","title":"Task creating configuration documents"},{"location":"education/tutorials/omag-server-tutorial/task-creating-configuration-documents/#creating-configuration-documents-for-the-omag-server-platform","text":"The OMAG server platform provides a software platform for running OMAG Servers . Each OMAG Server supports selected open metadata and governance services based on its configuration. When the OMAG server platform is first started , there are no OMAG Servers running inside it. However there are three sets of Administration Service APIs active. Server Origin - for discovering the source of the OMAG server platform. (This was used in the previous task .) Configuration Services - for creating configuration documents. Operational Services - for starting and stopping OMAG Servers in the OMAG server platform using the configuration documents.","title":"Creating configuration documents for the OMAG Server Platform"},{"location":"education/tutorials/omag-server-tutorial/task-creating-configuration-documents/#what-is-a-configuration-document","text":"A configuration document provides the configuration properties for an OMAG server. It includes: * Basic properties of the OMAG server. * Defaults to use when configuring the subsystems of the OMAG server. * Configuration for selected subsystems within the OMAG server. The subsystems selected and configured determine which open metadata and governance services are supported by the OMAG server. Configuration documents are created using the OMAG server platform configuration services. In order to experiment with these services, this tutorial uses the Postman test tool. This is a tool that enables you to type in REST API calls and execute them against the OMAG server platform. There is also a postman collection located at: https://raw.githubusercontent.com/odpi/egeria/master/open-metadata-resources/open-metadata-tutorials/omag-server-tutorial/resources/omag-server-platform-tutorial.postman_collection.json It can be downloaded and imported into postman to support this tutorial. (see Import button top left of the Postman user interface). This tutorial will also use curl commands to illustrate calls to the administration services as well as refer to the pre-canned calls in the postman collection.","title":"What is a configuration document?"},{"location":"education/tutorials/omag-server-tutorial/task-creating-configuration-documents/#creating-the-configuration-document","text":"Before there is a configuration document, requesting the server configuration creates and returns a default document. The command is: GET {serverURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/configuration where: * {serverURLRoot} is the host name and port number of the OMAG server platform (eg https://localhost:9443). * {adminUserId} is the user id of the administrator making the calls. * {serverName} is the name of the OMAG server that is being configured. Try the following command (this is request 2. in Postman): GET https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/configuration The response is in JSON format and contains the following information: { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"28aeb916-5029-4d6a-aa96-392196859916\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Open Metadata and Governance Server\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 } } The localServerId property is a unique identifier given to the server and is used internally to improve the performance of its interaction with external components such as Apache Kafka. The localServerName is the name of the OMAG server supplied on the command. The localServerType , localServerURL , localServerUserId and maxPageSize are set to their default values and can be changed. For example, try the following command (this is request 3. in Postman): POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/server-type?typeName=\"Standalone Metadata Repository\" Then query the configuration again (this is request 4. in Postman): { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Standalone Metadata Repository\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"auditTrail\" : [ \"Tue Feb 05 13:12:50 GMT 2019 garygeeke updated configuration for local server type name to Standalone Metadata Repository.\" ] } } Notice that the localServerType has changed and an audit trail has also appeared. This allows you to keep track of the changes being made to the configuration document. The next command configures in type of metadata repository (this is request 5. in Postman). In this example, we are using a simple in-memory repository which is useful for testing. POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/local-repository/mode/in-memory-repository This has added the configuration for the local repository using default values. If you query the configuration again (this is request 6. in Postman) you see: { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Standalone Metadata Repository\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"repositoryServicesConfig\" : { \"class\" : \"RepositoryServicesConfig\" , \"auditLogConnections\" : [ { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5390bf3e-6b38-4eda-b34a-de55ac4252a7\" , \"qualifiedName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"displayName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"description\" : \"OMRS default audit log connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"4afac741-3dcc-4c60-a4ca-a6dede994e3f\" , \"qualifiedName\" : \"Console Audit Log Store Connector\" , \"displayName\" : \"Console Audit Log Store Connector\" , \"description\" : \"Connector supports logging of audit log messages to stdout.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.auditlogstore.console.ConsoleAuditLogStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"836efeae-ab34-4425-89f0-6adf2faa1f2e\" , \"qualifiedName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"displayName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"description\" : \"OMRS default audit log endpoint.\" , \"address\" : \"cocoMDS1.auditlog\" } } ], \"localRepositoryConfig\" : { \"class\" : \"LocalRepositoryConfig\" , \"metadataCollectionId\" : \"ad405dc2-1361-48f8-9ea2-538bd43db1b0\" , \"localRepositoryLocalConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6a3c07b0-0e04-42dc-bcc6-392609bf1d02\" , \"qualifiedName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"displayName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"description\" : \"OMRS default in memory local repository connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"65cc9091-757f-4bcd-b937-426160be8bc2\" , \"qualifiedName\" : \"OMRS In Memory Repository Connector\" , \"displayName\" : \"OMRS In Memory Repository Connector\" , \"description\" : \"OMRS Repository Connector that uses an in-memory store.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.inmemory.repositoryconnector.InMemoryOMRSRepositoryConnectorProvider\" } }, \"localRepositoryRemoteConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"75ea56d1-656c-43fb-bc0c-9d35c5553b9e\" , \"qualifiedName\" : \"OMRS REST API Repository Connector\" , \"displayName\" : \"OMRS REST API Repository Connector\" , \"description\" : \"OMRS Repository Connector that calls the repository services REST API of a remote server.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/servers/cocoMDS1\" } }, \"eventsToSaveRule\" : \"ALL\" , \"eventsToSendRule\" : \"ALL\" } }, \"auditTrail\" : [ \"Tue Feb 05 13:12:50 GMT 2019 garygeeke updated configuration for local server type name to Standalone Metadata Repository.\" , \"Tue Feb 05 14:58:28 GMT 2019 garygeeke updated configuration for the local repository.\" ] } } Finally in this exercise, use the following command to enable the Open Metadata Access Services (OMASs) that provide the domain specific open metadata and governance APIs. The access services provide both REST APIs and event-based interaction. As such they need information about an event bus. The command below (this is request 7. in Postman) sets up configuration properties about the event bus. These properties are embedded in the configuration for each access service. POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/event-bus?topicURLRoot=egeriaTopics When the configuration is next queried (this is request 8. in Postman), the event bus details are stored in the configuration document. { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Standalone Metadata Repository\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"eventBusConfig\" : { \"class\" : \"EventBusConfig\" , \"topicURLRoot\" : \"egeriaTopics\" }, \"repositoryServicesConfig\" : { \"class\" : \"RepositoryServicesConfig\" , \"auditLogConnections\" : [ { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5390bf3e-6b38-4eda-b34a-de55ac4252a7\" , \"qualifiedName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"displayName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"description\" : \"OMRS default audit log connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"4afac741-3dcc-4c60-a4ca-a6dede994e3f\" , \"qualifiedName\" : \"Console Audit Log Store Connector\" , \"displayName\" : \"Console Audit Log Store Connector\" , \"description\" : \"Connector supports logging of audit log messages to stdout.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.auditlogstore.console.ConsoleAuditLogStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"836efeae-ab34-4425-89f0-6adf2faa1f2e\" , \"qualifiedName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"displayName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"description\" : \"OMRS default audit log endpoint.\" , \"address\" : \"cocoMDS1.auditlog\" } } ], \"localRepositoryConfig\" : { \"class\" : \"LocalRepositoryConfig\" , \"metadataCollectionId\" : \"ad405dc2-1361-48f8-9ea2-538bd43db1b0\" , \"localRepositoryLocalConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6a3c07b0-0e04-42dc-bcc6-392609bf1d02\" , \"qualifiedName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"displayName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"description\" : \"OMRS default in memory local repository connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"65cc9091-757f-4bcd-b937-426160be8bc2\" , \"qualifiedName\" : \"OMRS In Memory Repository Connector\" , \"displayName\" : \"OMRS In Memory Repository Connector\" , \"description\" : \"OMRS Repository Connector that uses an in-memory store.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.inmemory.repositoryconnector.InMemoryOMRSRepositoryConnectorProvider\" } }, \"localRepositoryRemoteConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"75ea56d1-656c-43fb-bc0c-9d35c5553b9e\" , \"qualifiedName\" : \"OMRS REST API Repository Connector\" , \"displayName\" : \"OMRS REST API Repository Connector\" , \"description\" : \"OMRS Repository Connector that calls the repository services REST API of a remote server.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/servers/cocoMDS1\" } }, \"eventsToSaveRule\" : \"ALL\" , \"eventsToSendRule\" : \"ALL\" } }, \"auditTrail\" : [ \"Tue Feb 05 13:12:50 GMT 2019 garygeeke updated configuration for local server type name to Standalone Metadata Repository.\" , \"Tue Feb 05 14:58:28 GMT 2019 garygeeke updated configuration for the local repository.\" , \"Tue Feb 05 15:13:45 GMT 2019 garygeeke updated configuration for default event bus.\" ] } } The last command creates the configuration for the access services (this is request 9. in Postman): POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/access-services which results in the final configuration (this is request 10. in Postman). { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"localServerId\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" , \"localServerName\" : \"cocoMDS1\" , \"localServerType\" : \"Standalone Metadata Repository\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"eventBusConfig\" : { \"class\" : \"EventBusConfig\" , \"topicURLRoot\" : \"egeriaTopics\" }, \"accessServicesConfig\" : [ { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1021 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.dataengine.server.admin.DataEngineAdmin\" , \"accessServiceName\" : \"Data Engine\" , \"accessServiceDescription\" : \"Create processes for lineage\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-engine/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"14475820-7356-4b14-a560-128b4f6bdf87\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"25629bf5-e8f0-4f47-ac43-2dee3ba2439c\" , \"qualifiedName\" : \"open-metadata.access-services.Data Engine.inTopic\" , \"displayName\" : \"open-metadata.access-services.Data Engine.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Data Engine.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"84689e40-b83a-4a8e-b172-e628ded4c77b\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"0b2e8a73-0c58-44fe-8b8e-e07b3f78592d\" , \"qualifiedName\" : \"open-metadata.access-services.Data Engine.outTopic\" , \"displayName\" : \"open-metadata.access-services.Data Engine.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Data Engine.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1020 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.subjectarea.admin.SubjectAreaAdmin\" , \"accessServiceName\" : \"Subject Area\" , \"accessServiceDescription\" : \"Document knowledge about a subject area\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/subject-area/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"96780526-2d8e-4334-9bfa-1dd86896913c\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"c2643840-8225-4c9b-84b6-4ab0b2a9a80a\" , \"qualifiedName\" : \"open-metadata.access-services.Subject Area.inTopic\" , \"displayName\" : \"open-metadata.access-services.Subject Area.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Subject Area.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"82279a05-9310-4600-a03a-9dc70a41600f\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"2235fdb0-84d6-4efe-b914-9035dbe74083\" , \"qualifiedName\" : \"open-metadata.access-services.Subject Area.outTopic\" , \"displayName\" : \"open-metadata.access-services.Subject Area.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Subject Area.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1008 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.governanceengine.admin.GovernanceEngineAdmin\" , \"accessServiceName\" : \"Governance Engine\" , \"accessServiceDescription\" : \"Set up an operational governance engine\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-engine/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"4f83087c-bd1c-455f-b809-1938cab03ecd\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"a0ba0eea-738f-4b0c-adc2-3d832e43ca72\" , \"qualifiedName\" : \"open-metadata.access-services.Governance Engine.inTopic\" , \"displayName\" : \"open-metadata.access-services.Governance Engine.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"84036aea-5055-427a-aa3d-ad3fa0aef255\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"98f58323-b97c-4e7b-82f6-d804449a4d81\" , \"qualifiedName\" : \"open-metadata.access-services.Governance Engine.outTopic\" , \"displayName\" : \"open-metadata.access-services.Governance Engine.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1009 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.governanceprogram.admin.GovernanceProgramAdmin\" , \"accessServiceName\" : \"Governance Program\" , \"accessServiceDescription\" : \"Manage the governance program\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-program/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6bba6aa3-308e-41a3-bf01-51ef65028e60\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"aad59e1e-20e4-4a9b-982a-f8b939dc580a\" , \"qualifiedName\" : \"open-metadata.access-services.Governance Program.inTopic\" , \"displayName\" : \"open-metadata.access-services.Governance Program.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Program.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6d5a04c3-e216-42b0-9479-71ce4461e86d\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"dccb1ef2-ae92-4ed9-9619-537c9cf4e05d\" , \"qualifiedName\" : \"open-metadata.access-services.Governance Program.outTopic\" , \"displayName\" : \"open-metadata.access-services.Governance Program.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Program.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1014 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.informationview.admin.InformationViewAdmin\" , \"accessServiceName\" : \"Information View\" , \"accessServiceDescription\" : \"Support information virtualization and data set definitions\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/information-view/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"b7718cc6-da6a-4a9f-8f76-c5d4579f1c34\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"87628694-8c85-46eb-aae2-0c834e915e00\" , \"qualifiedName\" : \"open-metadata.access-services.Information View.inTopic\" , \"displayName\" : \"open-metadata.access-services.Information View.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"826c314e-856d-4b2b-bcf1-0d11285a7610\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"fccd511a-86f1-4748-b580-78afd9a0b166\" , \"qualifiedName\" : \"open-metadata.access-services.Information View.outTopic\" , \"displayName\" : \"open-metadata.access-services.Information View.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1001 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.assetconsumer.admin.AssetConsumerAdmin\" , \"accessServiceName\" : \"Asset Consumer\" , \"accessServiceDescription\" : \"Access assets through connectors\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-consumer/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5d034bb8-133b-4dc8-b0db-712ae8a032d6\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"148e6940-9dff-47c6-9762-662559b3bec7\" , \"qualifiedName\" : \"open-metadata.access-services.Asset Consumer.inTopic\" , \"displayName\" : \"open-metadata.access-services.Asset Consumer.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"c46fd6be-4377-4ef8-8ce4-82aa30a9f3bd\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6ca034c7-523e-4b30-a7dc-f1359c287ea0\" , \"qualifiedName\" : \"open-metadata.access-services.Asset Consumer.outTopic\" , \"displayName\" : \"open-metadata.access-services.Asset Consumer.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1004 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservices.connectedasset.admin.ConnectedAssetAdmin\" , \"accessServiceName\" : \"Connected Asset\" , \"accessServiceDescription\" : \"Understand an asset\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/connected-asset/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"2214b4ad-d1b8-4fd4-942c-4a5552688e91\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"fabfa203-ca60-4036-90e5-de5d695ef8f1\" , \"qualifiedName\" : \"open-metadata.access-services.Connected Asset.inTopic\" , \"displayName\" : \"open-metadata.access-services.Connected Asset.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Connected Asset.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"9c3332ce-b065-49dc-b22e-432277627cde\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"e7bf76b4-4214-460f-ad8f-12a0ecb63e44\" , \"qualifiedName\" : \"open-metadata.access-services.Connected Asset.outTopic\" , \"displayName\" : \"open-metadata.access-services.Connected Asset.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Connected Asset.outTopic\" } } }, { \"class\" : \"AccessServiceConfig\" , \"accessServiceId\" : 1000 , \"accessServiceAdminClass\" : \"org.odpi.openmetadata.accessservice.assetcatalog.admin.AssetCatalogAdmin\" , \"accessServiceName\" : \"Asset Catalog\" , \"accessServiceDescription\" : \"Search and understand your assets\" , \"accessServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-catalog/\" , \"accessServiceOperationalStatus\" : \"ENABLED\" , \"accessServiceInTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5f6dc495-2b31-4ca0-8196-bb34a14e020b\" , \"qualifiedName\" : \"InTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"InTopic\" , \"description\" : \"InTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"338b6ea6-cd1e-4896-ab1a-568da8477903\" , \"qualifiedName\" : \"open-metadata.access-services.Asset Catalog.inTopic\" , \"displayName\" : \"open-metadata.access-services.Asset Catalog.inTopic\" , \"description\" : \"InTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Catalog.inTopic\" } }, \"accessServiceOutTopic\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"55a9dbb0-f756-4180-82d5-9b8c35af5fb0\" , \"qualifiedName\" : \"OutTopic\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"OutTopic\" , \"description\" : \"OutTopic\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"3851e8d0-e343-400c-82cb-3918fed81da6\" , \"qualifiedName\" : \"Kafka Open Metadata Topic Connector\" , \"displayName\" : \"Kafka Open Metadata Topic Connector\" , \"description\" : \"Kafka Open Metadata Topic Connector supports string based events over an Apache Kafka event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.kafka.KafkaOpenMetadataTopicProvider\" , \"recognizedAdditionalProperties\" : [ \"producer\" , \"consumer\" , \"local.server.id\" ] }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"dab48064-6204-49bf-bf30-a66b0e353d36\" , \"qualifiedName\" : \"open-metadata.access-services.Asset Catalog.outTopic\" , \"displayName\" : \"open-metadata.access-services.Asset Catalog.outTopic\" , \"description\" : \"OutTopic\" , \"address\" : \"egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Catalog.outTopic\" } } } ], \"repositoryServicesConfig\" : { \"class\" : \"RepositoryServicesConfig\" , \"auditLogConnections\" : [ { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"5390bf3e-6b38-4eda-b34a-de55ac4252a7\" , \"qualifiedName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"displayName\" : \"DefaultAuditLog.Connection.cocoMDS1\" , \"description\" : \"OMRS default audit log connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"4afac741-3dcc-4c60-a4ca-a6dede994e3f\" , \"qualifiedName\" : \"Console Audit Log Store Connector\" , \"displayName\" : \"Console Audit Log Store Connector\" , \"description\" : \"Connector supports logging of audit log messages to stdout.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.auditlogstore.console.ConsoleAuditLogStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"836efeae-ab34-4425-89f0-6adf2faa1f2e\" , \"qualifiedName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"displayName\" : \"DefaultAuditLog.Endpoint.cocoMDS1.auditlog\" , \"description\" : \"OMRS default audit log endpoint.\" , \"address\" : \"cocoMDS1.auditlog\" } } ], \"localRepositoryConfig\" : { \"class\" : \"LocalRepositoryConfig\" , \"metadataCollectionId\" : \"ad405dc2-1361-48f8-9ea2-538bd43db1b0\" , \"localRepositoryLocalConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"6a3c07b0-0e04-42dc-bcc6-392609bf1d02\" , \"qualifiedName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"displayName\" : \"DefaultInMemoryRepository.Connection.cocoMDS1\" , \"description\" : \"OMRS default in memory local repository connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"65cc9091-757f-4bcd-b937-426160be8bc2\" , \"qualifiedName\" : \"OMRS In Memory Repository Connector\" , \"displayName\" : \"OMRS In Memory Repository Connector\" , \"description\" : \"OMRS Repository Connector that uses an in-memory store.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.inmemory.repositoryconnector.InMemoryOMRSRepositoryConnectorProvider\" } }, \"localRepositoryRemoteConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"75ea56d1-656c-43fb-bc0c-9d35c5553b9e\" , \"qualifiedName\" : \"OMRS REST API Repository Connector\" , \"displayName\" : \"OMRS REST API Repository Connector\" , \"description\" : \"OMRS Repository Connector that calls the repository services REST API of a remote server.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"displayName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/servers/cocoMDS1\" } }, \"eventsToSaveRule\" : \"ALL\" , \"eventsToSendRule\" : \"ALL\" }, \"enterpriseAccessConfig\" : { \"class\" : \"EnterpriseAccessConfig\" , \"enterpriseMetadataCollectionName\" : \"cocoMDS1 Enterprise Metadata Collection\" , \"enterpriseMetadataCollectionId\" : \"95af03a9-ac18-4dbb-8b3a-4782429e5f77\" , \"enterpriseOMRSTopicConnection\" : { \"class\" : \"VirtualConnection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"82f9c664-e59d-484c-a8f3-17088c23a2f3\" , \"elementTypeName\" : \"VirtualConnection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A connector for a virtual resource that needs to retrieve data from multiple places.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"2084ee90-717b-49a1-938e-8f9d49567b8e\" , \"qualifiedName\" : \"EnterpriseTopicConnector.Server.cocoMDS1\" , \"displayName\" : \"EnterpriseTopicConnector.Server.cocoMDS1\" , \"description\" : \"OMRS default enterprise topic connection.\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"c3cc7a9c-4fe2-4383-85c3-1e94df45e2da\" , \"qualifiedName\" : \"org.odpi.openmetadata.repositoryservices.connectors.omrstopic.OMRSTopicProvider\" , \"displayName\" : \"OMRSTopicProvider\" , \"description\" : \"ConnectorType for OMRSTopicProvider\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.repositoryservices.connectors.omrstopic.OMRSTopicProvider\" }, \"embeddedConnections\" : [ { \"class\" : \"EmbeddedConnection\" , \"displayName\" : \"Enterprise OMRS Events\" , \"embeddedConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"d2224d17-d55d-4029-b841-7b37f2fa3df3\" , \"qualifiedName\" : \"Enterprise OMRS Events\" , \"configurationProperties\" : { \"local.server.id\" : \"2a73902e-e691-43cc-b422-23b6b42992e2\" }, \"displayName\" : \"Enterprise OMRS Events\" , \"description\" : \"Enterprise OMRS Events\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"LOCAL_COHORT\" }, \"guid\" : \"ed8e682b-2fec-4403-b551-02f8c46322ef\" , \"qualifiedName\" : \"In Memory Open Metadata Topic Connector\" , \"displayName\" : \"In Memory Open Metadata Topic Connector\" , \"description\" : \"In Memory Open Metadata Topic Connector supports string based events over an in memory event bus.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.eventbus.topic.inmemory.InMemoryOpenMetadataTopicProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"type\" : { \"class\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"2f858351-eb06-4824-805c-6f0bb56a4923\" , \"qualifiedName\" : \"open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic\" , \"displayName\" : \"open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic\" , \"description\" : \"Enterprise OMRS Events\" , \"address\" : \"cocoMDS1.open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic\" } } } ] }, \"enterpriseOMRSTopicProtocolVersion\" : \"V1\" } }, \"auditTrail\" : [ \"Tue Feb 05 13:12:50 GMT 2019 garygeeke updated configuration for local server type name to Standalone Metadata Repository.\" , \"Tue Feb 05 14:58:28 GMT 2019 garygeeke updated configuration for the local repository.\" , \"Tue Feb 05 15:13:45 GMT 2019 garygeeke updated configuration for default event bus.\" , \"Tue Feb 05 15:49:07 GMT 2019 garygeeke updated configuration for access services.\" , \"Tue Feb 05 15:49:07 GMT 2019 garygeeke updated configuration for enterprise repository services (used by access services).\" ] } } You have probably noticed how quickly the configuration document grew into a complex structure. The commands you used made use of all of the configuration default values. There are other configuration services that enable you to customize the configuration document to adapt it to specific environment. However, the defaults provide a good starting point.","title":"Creating the configuration document"},{"location":"education/tutorials/omag-server-tutorial/task-creating-configuration-documents/#further-reading","text":"The contents of this tutorial cover a very simple OMAG server configuration. For guidance on configuring more complex OMAG servers see: Administration Services User Guide For instructions on how to set up two OMAG Servers using in memory repositories that are exchanging metadata over Apache Kafka , see: In Memory Repository Demo","title":"Further reading"},{"location":"education/tutorials/omag-server-tutorial/task-creating-configuration-documents/#next-steps","text":"With the configuration document in place, you are ready to start the OMAG Server .","title":"Next steps"},{"location":"education/tutorials/omag-server-tutorial/task-starting-omag-server/","text":"Activating OMAG servers in the OMAG server platform \u00b6 Once you have created a configuration document for an OMAG server it is started in the OMAG Server Platform using the following command (this is request 11. in Postman). POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/instance The response from the command lists the subsystems that have been activated in the OMAG server: { \"class\" : \"VoidResponse\" , \"relatedHTTPCode\" : 200 , \"successMessage\" : \"Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 is running the following services: [Repository Services, Data Engine OMAS, Subject Area OMAS, Governance Engine OMAS, Governance Program OMAS, Information View OMAS, Asset Consumer OMAS, Connected Asset OMAS, Asset Catalog OMAS]\" } The window where your OMAG server platform is running will show the start up messages, something like this (note this is from an older version where we used Java 8): /Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home/bin/java -Dserver.port=9443 ... ____ __ ___ ___ ______ _____ ____ _ _ ___ / __ \\ / |/ // | / ____/ / ___/ ___ ____ _ __ ___ ____ / _ \\ / / __ / / / _ /__ ____ _ _ / / / // /|_/ // /| | / / __ \\__ \\ / _ \\ / __/| | / // _ \\ / __/ / /_/ // // | / _\\ / /_ / | / _// || | / /_/ // / / // ___ |/ /_/ / ___/ // __// / | |/ // __// / / __ // // / \\ / /_ / _// / // / / / / / \\____//_/ /_//_/ |_|\\____/ /____/ \\___//_/ |___/ \\___//_/ /_/ /_/ \\__/\\//___//_/ \\__//_/ /_/ /_/ :: Powered by Spring Boot (v2.1.2.RELEASE) :: 16:13:18.047 [main] INFO o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9443 (https) 16:13:41.688 [main] INFO o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9443 (https) with context path '' Tue Feb 05 16:14:20 GMT 2019 2020 No OMAG servers listed in startup configuration Tue Feb 05 16:14:20 GMT 2019 OMAG server platform ready for more configuration Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0001 The Open Metadata Repository Services (OMRS) is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0002 Enterprise access through the Enterprise Repository Services is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0003 The local repository is initializing with metadata collection named cocoMDS1 with an id of ad405dc2-1361-48f8-9ea2-538bd43db1b0 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0030 The local repository outbound event manager is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0050 The Open Metadata Repository Services (OMRS) is about to process open metadata archive Open Metadata Types Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called object with a unique identifier of 1c4b21f4-0b67-41a7-a6ed-2af185eb9b3b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called boolean with a unique identifier of 3863f010-611c-41fe-aaae-5d4d427f863b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called byte with a unique identifier of 6b7d410a-2e8a-4d12-981a-a806449f9bdb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called char with a unique identifier of b0abebe5-cf85-4065-86ad-f3c6360ed9c7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called short with a unique identifier of 8e95b966-ab60-46d4-a03f-40c5a1ba6c2a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called int with a unique identifier of 7fc49104-fd3a-46c8-b6bf-f16b6074cd35 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called long with a unique identifier of 33a91510-92ee-4825-9f49-facd7a6f9db6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called float with a unique identifier of 52aeb769-37b7-4b30-b949-ddc7dcebcfa2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called double with a unique identifier of e13572e8-25c3-4994-acb6-2ea66c95812e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called biginteger with a unique identifier of 8aa56e52-1076-4e0d-9b66-3873a1ed7392 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called bigdecimal with a unique identifier of d5c8ad9f-8fee-4a64-80b3-63ce1e47f6bb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called string with a unique identifier of b34a64b9-554a-42b1-8f8a-7d5c2339f9c4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called date with a unique identifier of 1bef35ca-d4f9-48db-87c2-afce4649362d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called map<string,string> with a unique identifier of 005c7c14-ac84-4136-beed-959401b041f8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called map<string,boolean> with a unique identifier of 8fa603dd-c2c5-43fc-8ff4-92141f2414ab and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called map<string,int> with a unique identifier of 8fa603dd-c2c5-43fc-8ff4-92141f2414ac and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called map<string,long> with a unique identifier of 8fa603dd-c2c5-43fc-8ff4-92141f2414ae and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called array<string> with a unique identifier of 0428b5d3-f824-459c-b7f5-f8151de59707 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called array<int> with a unique identifier of 0103fe10-98b0-4910-8ee0-21d529f7ff6d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetOwnerType with a unique identifier of 9548390c-69f5-4dc6-950d-6feeee257b56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaType with a unique identifier of 9548390c-69f5-4dc6-950d-6fdffb257b56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaUsage with a unique identifier of c6861a72-7485-48c9-8040-876f6c342b61 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called KeyPattern with a unique identifier of 8904df8f-1aca-4de8-9abd-1ef2aadba300 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Endianness with a unique identifier of e5612c3a-49bd-4148-8f67-cfdf145d5fd8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OperationalStatus with a unique identifier of 24e1e33e-9250-4a6c-8b07-05c7adec3a1d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ServerAssetUse with a unique identifier of 09439481-9489-467c-9ae5-178a6e0b6b5a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContactMethodType with a unique identifier of 30e7d8cd-df01-46e8-9247-a24c5650910d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OrderBy with a unique identifier of 1d412439-4272-4a7e-a940-1065f889fc56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ToDoStatus with a unique identifier of 7197ea39-334d-403f-a70b-d40231092df7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CommunityMembershipType with a unique identifier of b0ef45bf-d12b-4b6f-add6-59c14648d750 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called StarRating with a unique identifier of 77fea3ef-6ec1-4223-8408-38567e9d3c93 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CommentType with a unique identifier of 06d5032e-192a-4f77-ade1-a4b97926e867 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CrowdSourcingRole with a unique identifier of 0ded50c2-17cc-4ecf-915e-908e66dbb27f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermRelationshipStatus with a unique identifier of 42282652-7d60-435e-ad3e-7cfe5291bcc7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ActivityType with a unique identifier of af7e403d-9865-4ebb-8c1a-1fd57b4f4bca and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermAssignmentStatus with a unique identifier of c8fe36ac-369f-4799-af75-46b9c1343ab3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDomain with a unique identifier of baa31998-f3cb-47b0-9123-674a701e87bc and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceClassificationStatus with a unique identifier of cc540586-ac7c-41ba-8cc1-4da694a6a8e4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConfidentialityLevel with a unique identifier of ecb48ca2-4d29-4de9-99a1-bc4db9816d68 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConfidenceLevel with a unique identifier of ae846797-d88a-4421-ad9a-318bf7c1fe6f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RetentionBasis with a unique identifier of de79bf78-ecb0-4fd0-978f-ecc2cb4ff6c7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CriticalityLevel with a unique identifier of 22bcbf49-83e1-4432-b008-e09a8f842a1e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called BusinessCapabilityType with a unique identifier of fb7c40cf-8d95-48ff-ba8b-e22bff6f5a91 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassAssignmentStatus with a unique identifier of 2611892f-0527-478f-8843-a3aa2b9abb47 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnnotationStatus with a unique identifier of 71187df6-ef66-4f88-bc03-cd3c7f925165 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Referenceable with a unique identifier of a32316b8-dc8c-48c5-b12b-71c1b2a080bf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Asset with a unique identifier of 896d14c2-7522-4f6c-8519-757711943fe6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Infrastructure with a unique identifier of c19746ac-b3ec-49ce-af4b-83348fc55e07 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Process with a unique identifier of d8f33bd7-afa9-4a11-a8c7-07dcec83c050 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataSet with a unique identifier of 1449911c-4f44-4c22-abc0-7540154feefb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalReference with a unique identifier of af536f20-062b-48ef-9c31-1ddd05b04c56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelatedMedia with a unique identifier of 747f8b86-fe7c-4c9b-ba75-979e093cc307 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalId with a unique identifier of 7c8f8c2c-cc48-429e-8a21-a1f1851ccdb0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PropertyFacet with a unique identifier of 6403a704-aad6-41c2-8e08-b9525c006f85 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Location with a unique identifier of 3e09cb2b-5f15-4fd2-b004-fe0146ad8628 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ITInfrastructure with a unique identifier of 151e6dd1-54a0-4b7f-a072-85caa09d1dda and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Host with a unique identifier of 1abd16db-5b8a-4fd9-aee5-205db3febe99 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OperatingPlatform with a unique identifier of bd96a997-8d78-42f6-adf7-8239bc98501c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostCluster with a unique identifier of 9794f42f-4c9f-4fe6-be84-261f0a7de890 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called VirtualContainer with a unique identifier of e2393236-100f-4ac0-a5e6-ce4e96c521e7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerPlatform with a unique identifier of ba7c7884-32ce-4991-9c41-9778f1fec6aa and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServer with a unique identifier of aa7c7884-32ce-4991-9c41-9778f1fec6aa and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Endpoint with a unique identifier of dbc20663-d705-4ff0-8424-80c262c6b8e7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerCapability with a unique identifier of fe30a033-8f86-4d17-8986-e6166fa24177 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Application with a unique identifier of 58280f3c-9d63-4eae-9509-3f223872fb25 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Engine with a unique identifier of 3566527f-b1bd-4e7a-873e-a3e04d5f2a14 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Network with a unique identifier of e0430f59-f021-411a-9d81-883e1ff3f6f6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NetworkGateway with a unique identifier of 9bbae94d-e109-4c96-b072-4f97123f04fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ActorProfile with a unique identifier of 5a2f38dc-d69d-4a6f-ad26-ac86f118fa35 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called UserIdentity with a unique identifier of fbe95779-1f3c-4ac6-aa9d-24963ff16282 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContactDetails with a unique identifier of 79296df8-645a-4ef7-a011-912d1cdcf75a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Person with a unique identifier of ac406bf8-e53e-49f1-9088-2af28bbbd285 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContributionRecord with a unique identifier of ac406bf8-e53e-49f1-9088-2af28cccd285 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PersonRole with a unique identifier of ac406bf8-e53e-49f1-9088-2af28bcbd285 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Team with a unique identifier of 36db26d5-aba2-439b-bc15-d62d373c5db6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamLeader with a unique identifier of 36db26d5-abb2-439b-bc15-d62d373c5db6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamMember with a unique identifier of 46db26d5-abb2-538b-bc15-d62d373c5db6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ITProfile with a unique identifier of 81394f85-6008-465b-926e-b3fae4668937 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Collection with a unique identifier of 347005ba-2b35-4670-b5a7-12c9ebed0cf7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Project with a unique identifier of 0799569f-0c16-4a1f-86d9-e2e89568f7fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectManager with a unique identifier of 0798569f-0c16-4a1f-86d9-e2e89568f7fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Meeting with a unique identifier of 6bf90c79-32f4-47ad-959c-8fff723fe744 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ToDo with a unique identifier of 93dbc58d-c826-4bc2-b36f-195148d46f86 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Community with a unique identifier of fbd42379-f6c3-4f08-b6f7-378565cda993 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CommunityMember with a unique identifier of fbd42379-f6c3-4f09-b6f7-378565cda993 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Rating with a unique identifier of 7299d721-d17f-4562-8286-bcd451814478 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Comment with a unique identifier of 1a226073-9c84-40e4-a422-fbddb9b84278 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Like with a unique identifier of deaa5ca0-47a0-483d-b943-d91c76744e01 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called InformalTag with a unique identifier of ba846a7b-2955-40bf-952b-2793ceca090a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PrivateTag with a unique identifier of 9b3f5443-2475-4522-bfda-8f1f17e9a6c3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NoteEntry with a unique identifier of 2a84d94c-ac6f-4be1-a72a-07dcec7b1fe3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NoteLog with a unique identifier of 646727c7-9ad4-46fa-b660-265489ad96c6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Connection with a unique identifier of 114e9f8f-5ff3-4c32-bd37-a7eb42712253 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConnectorType with a unique identifier of 954421eb-33a6-462d-a8ca-b5709a1bd0d4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called VirtualConnection with a unique identifier of 82f9c664-e59d-484c-a8f3-17088c23a2f3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataStore with a unique identifier of 30756d0b-362b-4bfa-a0de-fce6a8f47b47 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedAPI with a unique identifier of 7dbb3e63-138f-49f1-97b4-66313871fc14 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedSoftwareComponent with a unique identifier of 486af62c-dcfd-4859-ab24-eab2e380ecfd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called FileFolder with a unique identifier of 229ed5cc-de31-45fc-beb4-9919fd247398 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataFile with a unique identifier of 10752b4a-4b5d-4519-9eae-fdd6d162122f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaFile with a unique identifier of c5ce5499-9582-42ea-936c-9771fbd475f8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaCollection with a unique identifier of 0075d603-1627-41c5-8cae-f5458d1247fe and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Document with a unique identifier of b463827c-c0a0-4cfb-a2b2-ddc63746ded4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DocumentStore with a unique identifier of 37156790-feac-4e1a-a42e-88858ae6f8e1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphStore with a unique identifier of 86de3633-eec8-4bf9-aad1-e92df1ca2024 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SubscriberList with a unique identifier of 69751093-35f9-42b1-944b-ba6251ff513d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Topic with a unique identifier of 29100f49-338e-4361-b05d-7e4e8e818325 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LogFile with a unique identifier of ff4c8484-9127-464a-97fc-99579d5bc429 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedDatabaseSchema with a unique identifier of eab811ec-556a-45f1-9091-bc7ac8face0f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Database with a unique identifier of 0921c83f-b2db-4086-a52c-0d10e52ca078 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EnterpriseAccessLayer with a unique identifier of 39444bf9-638e-4124-a5f9-1b8f3e1b008b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CohortMember with a unique identifier of 42063797-a78a-4720-9353-52026c75f667 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataRepositoryCohort with a unique identifier of 43e7dca2-c7b4-4cdf-a1ea-c9d4f7093893 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataCollection with a unique identifier of ea3b15af-ed0e-44f7-91e4-bdb299dd4976 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataRepository with a unique identifier of c40397bd-eab0-4b2e-bffb-e7fa0f93a5a9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CohortRegistryStore with a unique identifier of 2bfdcd0d-68bb-42c3-ae75-e9fb6c3dff70 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called KeystoreFile with a unique identifier of 17bee904-5b35-4c81-ac63-871c615424a2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called KeyStoreCollection with a unique identifier of 979d97dd-6782-4648-8e2a-8982994533e6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReferenceCodeTable with a unique identifier of 201f48c5-4e4b-41dc-9c5f-0bc9742190cf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReferenceCodeMappingTable with a unique identifier of 9c6ec0c6-0b26-4414-bffe-089144323213 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called InformationView with a unique identifier of 68d7b905-6438-43be-88cf-5de027b4aaaf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Form with a unique identifier of 8078e3d1-0c63-4ace-aafa-68498b39ccd6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedReport with a unique identifier of e9077f4f-955b-4d7b-b1f7-12ee769ff0c3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Glossary with a unique identifier of 36f66863-9726-4b41-97ee-714fd0dc6fe4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalGlossaryLink with a unique identifier of 183d2935-a950-4d74-b246-eac3664b5a9d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GlossaryCategory with a unique identifier of e507485b-9b5a-44c9-8a28-6967f7ff3672 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GlossaryTerm with a unique identifier of 0db3e6ec-f5ef-4d75-ae38-b7ee6fd6ec0a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ControlledGlossaryTerm with a unique identifier of c04e29b2-2d66-48fc-a20d-e59895de6040 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDefinition with a unique identifier of 578a3500-9ad3-45fe-8ada-e4e9572c37c8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceOfficer with a unique identifier of 578a3510-9ad3-45fe-8ada-e4e9572c37c8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDriver with a unique identifier of c403c109-7b6b-48cd-8eee-df445b258b33 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceStrategy with a unique identifier of 3c34f121-07a6-4e95-a07d-9b0ef17b7bbf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Regulation with a unique identifier of e3c4293d-8846-4500-b0c0-197d73aba8b0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernancePolicy with a unique identifier of a7defa41-9cfa-4be5-9059-359022bb016d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernancePrinciple with a unique identifier of 3b7d1325-ec2c-44cb-8db0-ce207beb78cf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceObligation with a unique identifier of 0cec20d3-aa29-41b7-96ea-1c544ed32537 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceApproach with a unique identifier of 2d03ec9d-bd6b-4be9-8e17-95a7ecdbaa67 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceControl with a unique identifier of c794985e-a10b-4b6c-9dc2-6b2e0a2901d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TechnicalControl with a unique identifier of d8f6eb5b-36f0-49bd-9b25-bf16f370d1ec and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OrganizationalControl with a unique identifier of befa1458-79b8-446a-b813-536700e60fa8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceZone with a unique identifier of 290a192b-42a7-449a-935a-269ca62cfdac and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceRule with a unique identifier of 8f954380-12ce-4a2d-97c6-9ebe250fecf8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceProcess with a unique identifier of b68b5d9d-6b79-4f3a-887f-ec0f81c54aea and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NamingStandardRule with a unique identifier of 52505b06-98a5-481f-8a32-db9b02afabfc and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NamingStandardRuleSet with a unique identifier of ba70f506-1f81-4890-bb4f-1cb1d99c939e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Organization with a unique identifier of 50a61105-35be-4ee3-8b99-bdd958ed0685 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called BusinessCapability with a unique identifier of 7cc6bcb2-b573-4719-9412-cf6c3f4bbb15 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceResponsibility with a unique identifier of 89a76b24-deb8-45bf-9304-a578a610326f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceProcedure with a unique identifier of 69055d10-51dc-4c2b-b21f-d76fad3f8ef3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectCharter with a unique identifier of f96b5a32-42c1-4a74-8f77-70a81cec783d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceRole with a unique identifier of de2d7f2e-1759-44e3-b8a6-8af53e8fb0ee and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetOwner with a unique identifier of ac406bf8-e53e-49f1-9088-2af28eeee285 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceMetric with a unique identifier of 9ada8e7b-823c-40f7-adf8-f164aabda77e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LicenseType with a unique identifier of 046a049d-5f80-4e5b-b0ae-f3cf6009b513 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CertificationType with a unique identifier of 97f9ffc9-e2f7-4557-ac12-925257345eea and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaElement with a unique identifier of 718d4244-8559-49ed-ad5a-10e5c305a656 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaType with a unique identifier of 5bd4a3e7-d22d-4a3d-a115-066ee8e0754f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PrimitiveSchemaType with a unique identifier of f0f75fba-9136-4082-8352-0ad74f3c36ed and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ImplementationSnippet with a unique identifier of 49990755-2faa-4a62-a1f3-9124b9c73df4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaAttribute with a unique identifier of 1a5e159b-913a-43b1-95fe-04433b25fca9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ComplexSchemaType with a unique identifier of 786a6199-0ce8-47bf-b006-9ace1c5510e4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called StructSchemaType with a unique identifier of a13b409f-fd67-4506-8d94-14dfafd250a4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called BoundedSchemaType with a unique identifier of 77133161-37a9-43f5-aaa3-fd6d7ff92fdb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ArraySchemaType with a unique identifier of ba8d29d2-a8a4-41f3-b29f-91ad924dd944 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SetSchemaType with a unique identifier of b2605d2d-10cd-443c-b3e8-abf15fb051f0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaLinkElement with a unique identifier of 67e08705-2d2a-4df6-9239-1818161a41e0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MapSchemaType with a unique identifier of bd4c85d0-d471-4cd2-a193-33b0387a19fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DerivedSchemaAttribute with a unique identifier of cf21abfe-655a-47ba-b9b6-f73394745c80 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TabularSchemaType with a unique identifier of 248975ec-8019-4b8a-9caf-084c8b724233 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TabularColumnType with a unique identifier of a7392281-348d-48a4-bad7-f9742d7696fe and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TabularColumn with a unique identifier of d81a0425-4e9b-4f31-bc1c-e18c3566da10 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DocumentSchemaType with a unique identifier of 33da99cd-8d04-490c-9457-c58908da7794 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DocumentSchemaAttribute with a unique identifier of b5cefb7e-b198-485f-a1d7-8e661012499b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SimpleDocumentType with a unique identifier of 42cfccbf-cc68-4980-8c31-0faf1ee002d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called StructDocumentType with a unique identifier of f6245c25-8f73-45eb-8fb5-fa17a5f27649 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ArrayDocumentType with a unique identifier of ddd29c67-db9a-45ff-92aa-6d17a12a8ee2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SetDocumentType with a unique identifier of 67228a7a-9d8d-4fa7-b217-17474f1f4ac6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MapDocumentType with a unique identifier of b0f09598-ceb6-415b-befc-563ecadd5727 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ObjectSchemaType with a unique identifier of 6920fda1-7c07-47c7-84f1-9fb044ae153e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ObjectAttribute with a unique identifier of ccb408c0-582e-4a3a-a926-7082d53bb669 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphSchemaType with a unique identifier of 983c5e72-801b-4e42-bc51-f109527f2317 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphVertex with a unique identifier of 1252ce12-540c-4724-ad70-f70940956de0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphEdge with a unique identifier of d4104eb3-4f2d-4d83-aca7-e58dd8d5e0b1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalDBSchemaType with a unique identifier of f20f5f45-1afb-41c1-9a09-34d8812626a4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalTableType with a unique identifier of 1321bcc0-dc6a-48ed-9ca6-0c6f934b0b98 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalTable with a unique identifier of ce7e72b8-396a-4013-8688-f9d973067425 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalColumn with a unique identifier of aa8d5470-6dbc-4648-9e2f-045e5df9d2f9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalColumnType with a unique identifier of f0438d80-6eb9-4fac-bcc1-5efee5babcfc and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DerivedRelationalColumn with a unique identifier of a9f7d15d-b797-450a-8d56-1ba55490c019 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EventSet with a unique identifier of bead9aa4-214a-4596-8036-aa78395bbfb1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EventType with a unique identifier of 8bc88aba-d7e4-4334-957f-cfe8e8eadc32 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APISchemaType with a unique identifier of b46cddb3-9864-4c5d-8a49-266b3fc95cb8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIOperation with a unique identifier of f1c0af19-2729-4fac-996e-a7badff3c21c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClass with a unique identifier of 6bc727dc-e855-4979-8736-78ac3cfcd32f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OpenDiscoveryEngine with a unique identifier of be650674-790b-487a-a619-0a9002488055 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OpenDiscoveryService with a unique identifier of 2f278dfc-4640-4714-b34b-303e84e4fc40 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OpenDiscoveryPipeline with a unique identifier of 081abe00-740e-4143-b0d5-a1f55450fc22 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OpenDiscoveryAnalysisReport with a unique identifier of acc7cbc8-09c3-472b-87dd-f78459323dcb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Annotation with a unique identifier of 6cea5b53-558c-48f1-8191-11d48db29fb4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnnotationReview with a unique identifier of b893d6fc-642a-454b-beaf-809ee4dd876a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaAnalysisAnnotation with a unique identifier of 3c5aa68b-d562-4b04-b189-c7b7f0bf2ced and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataField with a unique identifier of 3c5bbc8b-d562-4b04-b189-c7b7f0bf2cea and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataFieldAnnotation with a unique identifier of 72ed6de6-79d9-4e7d-aefc-b969382fc4b0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataProfileAnnotation with a unique identifier of bff1f694-afd0-4829-ab11-50a9fbaf2f5f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataProfileLogAnnotation with a unique identifier of 368e6fb3-7323-4f81-a723-5182491594bd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassAnnotation with a unique identifier of 0c8a3673-04ef-406f-899d-e88de67f6176 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SemanticAnnotation with a unique identifier of 0b494819-28be-4604-b238-3af20963eea6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ClassificationAnnotation with a unique identifier of 23e8287f-5c7e-4e03-8bd3-471fc7fc029c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called QualityAnnotation with a unique identifier of 72e6473d-4ce0-4609-80a4-e6e949a7f520 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationshipAdviceAnnotation with a unique identifier of 740f07dc-4ee8-4c2a-baba-efb55c73eb68 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataSourceMeasurementAnnotation with a unique identifier of c85bea73-d7af-46d7-8a7e-cb745910b1df and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataSourcePhysicalStatusAnnotation with a unique identifier of e9ba276e-6d9f-4999-a5a9-9ddaaabfae23 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RequestForAction with a unique identifier of f45765a9-f3ae-4686-983f-602c348e020d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MobileAsset with a unique identifier of b25fb90d-8fa2-4aa9-b884-ff0a6351a697 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called FixedLocation with a unique identifier of bc111963-80c7-444f-9715-946c03142dd2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SecureLocation with a unique identifier of e7b563c0-fcdd-4ba7-a046-eecf5c4638b8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CyberLocation with a unique identifier of f9ec3633-8ac8-480b-aa6d-5e674b9e1b17 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ApplicationServer with a unique identifier of 19196efb-2706-47bf-8e51-e8ba5b36d033 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Webserver with a unique identifier of d13e1cc5-bb7e-41ec-8233-9647fbf92a19 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called WorkflowEngine with a unique identifier of 37a6d212-7c4a-4a82-b4e2-601d4358381c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReportingEngine with a unique identifier of e07eefaa-16e0-46cf-ad54-bed47fb15812 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnalyticsEngine with a unique identifier of 1a0dc6f6-7980-42f5-98bd-51e56543a07e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataMovementEngine with a unique identifier of d2ed6621-9d99-4fe8-843a-b28d816cf888 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataVirtualizationEngine with a unique identifier of 03e25cd0-03d7-4d96-b28b-eed671824ed6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CloudProvider with a unique identifier of a2bfdd08-d0a8-49db-bc97-7f2406281046 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CloudPlatform with a unique identifier of 1b8f8511-e606-4f65-86d3-84891706ad12 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CloudTenant with a unique identifier of 1b8f8522-e606-4f65-86d3-84891706ad12 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CloudService with a unique identifier of 337e7b1a-ad4b-4818-aa3e-0ff3307b2fbe and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Folder with a unique identifier of 3c0fa687-8a63-4c8e-8bda-ede9c78be6c7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Set with a unique identifier of 3947f08d-7412-4022-81fc-344a20dfbb26 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Task with a unique identifier of 2312b668-3670-4845-a140-ef88d5a6db0c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Campaign with a unique identifier of 41437629-8609-49ef-8930-8c435c912572 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataStoreEncoding with a unique identifier of f08e48b5-6b66-40f5-8ff6-c2bfe527330b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RequestResponseInterface with a unique identifier of 14a29330-e830-4343-a41e-d57e2cec82f8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ListenerInterface with a unique identifier of 4099d2ed-2a5e-4c44-8443-9de4e378a4ba and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PublisherInterface with a unique identifier of 4fdedcd5-b186-4bee-887a-02fa29a10750 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called FileSystem with a unique identifier of cab5ba1d-cfd3-4fca-857d-c07711fc4157 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContentManager with a unique identifier of fa4df7b5-cb6d-475c-889e-8f3b7ca564d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NotificationManager with a unique identifier of 3e7502a7-396a-4737-a106-378c9c94c105 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DatabaseServer with a unique identifier of 6bb58cc9-ed9e-4f75-b2f2-6d308554eb52 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataServer with a unique identifier of 74a256ad-4022-4518-a446-c65fe082d4d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RepositoryProxy with a unique identifier of ae81c35e-7078-46f0-9b2c-afc99accf3ec and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Taxonomy with a unique identifier of 37116c51-e6c9-4c37-942e-35d48c8c69a0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CanonicalVocabulary with a unique identifier of 33ad3da2-0910-47be-83f1-daee018a4c05 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SubjectArea with a unique identifier of 480e6993-35c5-433a-b50b-0f5c4063fb5d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ActivityDescription with a unique identifier of 317f0e52-1548-41e6-b90c-6ae5e6c53fed and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AbstractConcept with a unique identifier of 9d725a07-4abf-4939-a268-419d200b69c2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataValue with a unique identifier of ab253e31-3d8a-45a7-8592-24329a189b9e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContextDefinition with a unique identifier of 54f9f41a-3871-4650-825d-59a41de01330 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SpineObject with a unique identifier of a41ee152-de1e-4533-8535-2f8b37897cac and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SpineAttribute with a unique identifier of ccb749ba-34ec-4f71-8755-4d8b383c34c3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ObjectIdentifier with a unique identifier of 3d1e4389-27de-44fa-8df4-d57bfaf809ea and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GlossaryProject with a unique identifier of 43be51a9-2d19-4044-b399-3ba36af10929 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceProject with a unique identifier of 37142317-4125-4046-9514-71dc5031563f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Confidentiality with a unique identifier of 742ddb7d-9a4a-4eb5-8ac2-1d69953bd2b6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Confidence with a unique identifier of 25d8f8d5-2998-4983-b9ef-265f58732965 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Retention with a unique identifier of 83dbcdf2-9445-45d7-bb24-9fa661726553 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Criticality with a unique identifier of d46d211a-bd22-40d5-b642-87b4954a167e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PrimeWord with a unique identifier of 3ea1ea66-8923-4662-8628-0bacef3e9c5f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ClassWord with a unique identifier of feac4bd9-37d9-4437-82f6-618ce3e2793e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NamingConventionRule with a unique identifier of dfc70bed-7e8b-4060-910c-59c7473f23a3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceMeasurementsResultsDataSet with a unique identifier of 789f2e89-accd-4489-8eca-dc43b432c022 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExceptionLogFile with a unique identifier of 4756a6da-e0c2-4e81-b9ab-99df2f735eec and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AuditLogFile with a unique identifier of 109d6d13-a3cf-4687-a0c1-c3802dc6b3a2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExceptionBacklog with a unique identifier of b3eceea3-aa02-4d84-8f11-da4953e64b5f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AuditLog with a unique identifier of 449be034-6cc8-4f1b-859f-a8b9ff8ee7a1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MeteringLog with a unique identifier of 161b37c9-1d51-433b-94ce-5a760a198236 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called StewardshipServer with a unique identifier of eaaeaa31-6f8b-4ed5-88fe-422ed3733158 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDaemon with a unique identifier of 7815f222-529d-4902-8f0b-e37cbc779885 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ControlPoint with a unique identifier of acf8b73e-3545-435d-ba16-fbfae060dd28 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called VerificationPoint with a unique identifier of 12d78c95-3879-466d-883f-b71f6477a741 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EnforcementPoint with a unique identifier of f4ce104e-7430-4c30-863d-60f6af6394d9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PrimaryKey with a unique identifier of b239d832-50bd-471b-b17a-15a335fc7f40 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalView with a unique identifier of 4814bec8-482d-463d-8376-160b0358e129 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProcessInput with a unique identifier of 9a6583c4-7419-4d5a-a6e5-26b0033fa349 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProcessOutput with a unique identifier of 8920eada-9b05-4368-b511-b8506a4bef4b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalReferenceLink with a unique identifier of 7d818a67-ab45-481c-bc28-f6b1caf12f06 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaReference with a unique identifier of 1353400f-b0ab-4ab9-ab09-3045dd8a7140 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalIdScope with a unique identifier of 8c5b1415-2d1f-4190-ba6c-1fdd47f03269 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalIdLink with a unique identifier of 28ab0381-c662-4b6d-b787-5d77208de126 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReferenceableFacet with a unique identifier of 58c87647-ada9-4c90-a3c3-a40ace46b1f7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NestedLocation with a unique identifier of f82a96c2-95a3-4223-88c0-9cbf2882b772 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AdjacentLocation with a unique identifier of 017d0518-fc25-4e5e-985e-491d91e61e17 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetLocation with a unique identifier of bc236b62-d0e6-4c5c-93a1-3a35c3dba7b1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostLocation with a unique identifier of f3066075-9611-4886-9244-32cc6eb07ea9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostOperatingPlatform with a unique identifier of b9179df5-6e23-4581-a8b0-2919e6322b12 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostClusterMember with a unique identifier of 1a1c3933-a583-4b0c-9e42-c3691296a8e0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedVirtualContainer with a unique identifier of 4b981d89-e356-4d9b-8f17-b3a8d5a86676 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerPlatformDeployment with a unique identifier of b909eb3b-5205-4180-9f63-122a65b30738 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerDeployment with a unique identifier of d909eb3b-5205-4180-9f63-122a65b30738 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ServerEndpoint with a unique identifier of 2b8bfab4-8023-4611-9833-82a0dc95f187 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerSupportedCapability with a unique identifier of 8b7d7da5-0668-4174-a43b-8f8c6c068dd0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ServerAssetUse with a unique identifier of 92b75926-8e9a-46c7-9d98-89009f622397 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RuntimeForProcess with a unique identifier of f6b5cf4f-7b88-47df-aeb0-d80d28ba1ec1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostNetwork with a unique identifier of f2bd7401-c064-41ac-862c-e5bcdc98fa1e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NetworkGatewayLink with a unique identifier of 5bece460-1fa6-41fb-a29f-fdaf65ec8ce3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContactThrough with a unique identifier of 6cb9af43-184e-4dfa-854a-1572bcf0fe75 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProfileIdentity with a unique identifier of 01664609-e777-4079-b543-6baffe910ff1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PersonRoleAppointment with a unique identifier of 4a316abe-bcce-4d11-ad5a-4bfb4079b80b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PersonalContribution with a unique identifier of 4a316abe-eeee-4d11-ad5a-4bfb4079b80b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Peer with a unique identifier of 4a316abe-bccd-4d11-ad5a-4bfb4079b80b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamLeadership with a unique identifier of 5ebc4fb2-b62a-4269-8f18-e9237a2119ca and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamMembership with a unique identifier of 1ebc4fb2-b62a-4269-8f18-e9237a2119ca and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamStructure with a unique identifier of 5ebc4fb2-b62a-4269-8f18-e9237a2229ca and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CollectionMembership with a unique identifier of 5cabb76a-e25b-4bb5-8b93-768bbac005af and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ResourceList with a unique identifier of 73cf5658-6a73-4ebc-8f4d-44fdfac0b437 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectHierarchy with a unique identifier of 8f1134f6-b9fe-4971-bc57-6e1b8b302b55 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectDependency with a unique identifier of 5b6a56f1-68e2-4e10-85f0-fda47a4263fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectTeam with a unique identifier of 746875af-2e41-4d1f-864b-35265df1d5dc and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectScope with a unique identifier of bc63ac45-b4d0-4fba-b583-92859de77dd8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectManagement with a unique identifier of ac63ac45-a4d0-4fba-b583-92859de77dd8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Meetings with a unique identifier of a05f918e-e7e2-419d-8016-5b37406df63a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ToDoSource with a unique identifier of a0b7ba50-4c97-4b76-9a7d-c6a00e1be646 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Actions with a unique identifier of aca1277b-bf1c-42f5-9b3b-fbc2c9047325 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ActionAssignment with a unique identifier of af2b5fab-8f83-4a2b-b749-1e6219f61f79 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CommunityMembership with a unique identifier of 7c7da1a3-01b3-473e-972e-606eff0cb112 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedRating with a unique identifier of 0aaad9e9-9cc5-4ad8-bc2e-c1099bab6344 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedComment with a unique identifier of 0d90501b-bf29-4621-a207-0c8c953bdac9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedLike with a unique identifier of e2509715-a606-415d-a995-61d00503dad4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AcceptedAnswer with a unique identifier of ecf1a3ca-adc5-4747-82cf-10ec590c5c69 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedTag with a unique identifier of 4b1641c4-3d1a-4213-86b2-d6968b6c65ab and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Contributor with a unique identifier of 4db83564-b200-4956-94a4-c95a5c30e65a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedNoteLog with a unique identifier of 4f798c0c-6769-4a2d-b489-d2714d89e0a4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedNoteLogEntry with a unique identifier of 38edecc6-f385-4574-8144-524a44e3e712 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConnectionEndpoint with a unique identifier of 887a7132-d6bc-4b92-a483-e80b60c86fb2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConnectionConnectorType with a unique identifier of e542cfc1-0b4b-42b9-9921-f0a5a88aaf96 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EmbeddedConnection with a unique identifier of eb6dfdd2-8c6f-4f0d-a17d-f6ce4799f64f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConnectionToAsset with a unique identifier of e777d660-8dbe-453e-8b83-903771f054c0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataContentForDataSet with a unique identifier of b827683c-2924-4df3-a92d-7be1888e23c0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIEndpoint with a unique identifier of de5b9501-3ad4-4803-a8b2-e311c72a4336 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called FolderHierarchy with a unique identifier of 48ac9028-45dd-495d-b3e1-622685b54a01 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NestedFile with a unique identifier of 4cb88900-1446-4eb6-acea-29cd9da45e63 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LinkedFile with a unique identifier of 970a3405-fde1-4039-8249-9aa5f56d5151 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GroupedMedia with a unique identifier of 7d881574-461d-475c-ab44-077451528cb8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LinkedMedia with a unique identifier of cee3a190-fc8d-4e53-908a-f1b9689581e0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TopicSubscribers with a unique identifier of bc91a28c-afb9-41a7-8eb2-fc8b5271fe9e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataCohortPeer with a unique identifier of 954cdba1-3d69-4db1-bf0e-d59fd2c25a27 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CohortMemberMetadataCollection with a unique identifier of 8b9dd3ea-057b-4709-9b42-f16098523907 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternallySourcedGlossary with a unique identifier of 7786a39c-436b-4538-acc7-d595b5856add and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CategoryAnchor with a unique identifier of c628938e-815e-47db-8d1c-59bb2e84e028 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CategoryHierarchyLink with a unique identifier of 71e4b6fb-3412-4193-aff3-a16eccd87e8e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LibraryCategoryReference with a unique identifier of 3da21cc9-3cdc-4d87-89b5-c501740f00b2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermAnchor with a unique identifier of 1d43d661-bdc7-4a91-a996-3239b8f82e56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermCategorization with a unique identifier of 696a81f5-ac60-46c7-b9fd-6979a1e7ad27 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LibraryTermReference with a unique identifier of 38c346e4-ddd2-42ef-b4aa-55d53c078d22 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelatedTerm with a unique identifier of b1161696-e563-4cf9-9fd9-c0c76e47d063 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Synonym with a unique identifier of 74f4094d-dba2-4ad9-874e-d422b69947e2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Antonym with a unique identifier of ea5e126a-a8fa-4a43-bcfa-309a98aa0185 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PreferredTerm with a unique identifier of 8ac8f9de-9cdd-4103-8a33-4cb204b78c2a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReplacementTerm with a unique identifier of 3bac5f35-328b-4bbd-bfc9-3b3c9ba5e0ed and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Translation with a unique identifier of 6ae42e95-efc5-4256-bfa8-801140a29d2a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ISARelationship with a unique identifier of 50fab7c7-68bc-452f-b8eb-ec76829cac85 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ValidValue with a unique identifier of 707a156b-e579-4482-89a5-de5889da1971 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called UsedInContext with a unique identifier of 2dc524d2-e29f-4186-9081-72ea956c75de and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SemanticAssignment with a unique identifier of e6670973-645f-441a-bec7-6f5570345b92 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermHASARelationship with a unique identifier of d67f16d1-5348-419e-ba38-b0bb6fe4ad6c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermISATypeOFRelationship with a unique identifier of d5d588c3-46c9-420c-adff-6031802a7e51 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermTYPEDBYRelationship with a unique identifier of 669e8aa4-c671-4ee7-8d03-f37d09b9d006 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernancePost with a unique identifier of 4c4d1d0c-a9fc-4305-8b71-4e691c0f9ae0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernancePolicyLink with a unique identifier of 0c42c999-4cac-4da4-afab-0e381f3a818e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceResponse with a unique identifier of 8845990e-7fd9-4b79-a19d-6c4730dadd6b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceImplementation with a unique identifier of 787eaf46-7cf2-4096-8d6e-671a0819d57e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceControlLink with a unique identifier of 806933fb-7925-439b-9876-922a960d2ba1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ZoneGovernance with a unique identifier of 4c4d1d9c-a9fc-4305-8b71-4e891c0f9ae0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceRuleImplementation with a unique identifier of e701a5c8-c1ba-4b75-8257-e0a6569eda48 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceProcessImplementation with a unique identifier of a5a7b08a-73fd-4026-a9dd-d0fe55bea8a4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OrganizationalCapability with a unique identifier of 47f0ad39-db77-41b0-b406-36b1598e0ba7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ResponsibilityStaffContact with a unique identifier of 49f2ecb5-6bf7-4324-9824-ac98d595c404 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called BusinessCapabilityControls with a unique identifier of b5de932a-738c-4c69-b852-09fec2b9c678 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectCharterLink with a unique identifier of f081808d-545a-41cb-a9aa-c4f074a16c78 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceRoleAssignment with a unique identifier of cb10c107-b7af-475d-aab0-d78b8297b982 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceResponsibilityAssignment with a unique identifier of cb15c107-b7af-475d-aab0-d78b8297b982 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDefinitionMetric with a unique identifier of e076fbb3-54f5-46b8-8f1e-a7cb7e792673 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceResults with a unique identifier of 89c3c695-9e8d-4660-9f44-ed971fd55f88 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called License with a unique identifier of 35e53b7f-2312-4d66-ae90-2d4cb47901ee and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Certification with a unique identifier of 390559eb-6a0c-4dd7-bc95-b9074caffa7f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RegulationCertificationType with a unique identifier of be12ff15-0721-4a7e-8c98-334eaa884bdf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetSchemaType with a unique identifier of 815b004d-73c6-4728-9dd9-536f4fe803cd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaTypeImplementation with a unique identifier of 6aab4ec6-f0c6-4c40-9f50-ac02a3483358 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttributeForSchema with a unique identifier of 86b176a2-015c-44a6-8106-54d5d69ba661 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaAttributeType with a unique identifier of 2d955049-e59b-45dd-8e62-cde1add59f9e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LinkedType with a unique identifier of 292125f7-5660-4533-a48a-478c5611922e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaLinkToType with a unique identifier of db9583c5-4690-41e5-a580-b4e30a0242d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MapFromElementType with a unique identifier of 6189d444-2da4-4cd7-9332-e48a1c340b44 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MapToElementType with a unique identifier of 8b9856b3-451e-45fc-afc7-fddefd81a73a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaQueryImplementation with a unique identifier of e5d7025d-8b4f-43c7-bcae-1047d650b94a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphEdgeLink with a unique identifier of 503b4221-71c8-4ba9-8f3d-6a035b27971c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ForeignKey with a unique identifier of 3cd4e0e7-fdbf-47a6-ae88-d4b3205e0c07 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIOperations with a unique identifier of 03737169-ceb5-45f0-84f0-21c5929945af and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIHeader with a unique identifier of e8fb46d1-5f75-481b-aa66-f43ad44e2cc6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIRequest with a unique identifier of 4ab3b466-31bd-48ea-8aa2-75623476f2e2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIResponse with a unique identifier of e8001de2-1bb1-442b-a66f-9addc3641eae and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassHierarchy with a unique identifier of 6b947ccc-1a70-4785-9ca3-d6326bc51291 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassComposition with a unique identifier of 767fb343-4699-49c1-a0f8-af6da78505f8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassAssignment with a unique identifier of 4df37335-7f0c-4ced-82df-3b2fd07be1bd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SupportedDiscoveryService with a unique identifier of dff45aeb-c65e-428c-9ab3-d756bc5d8dbb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveryServiceImplementation with a unique identifier of dd2bf14c-9fff-49c2-b29a-1636f4e92672 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetDiscoveryService with a unique identifier of 38713b9e-8561-4a74-a1ba-d50b2facc4c2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveryEngineReport with a unique identifier of 2c318c3a-5dc2-42cd-a933-0087d852f67f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveryInvocationReport with a unique identifier of 1744d72b-903d-4273-9229-de20372a17e2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetDiscoveryReport with a unique identifier of 7eded424-f176-4258-9ae6-138a46b2845f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveredAnnotation with a unique identifier of 51d386a3-3857-42e3-a3df-14a6cad08b93 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnnotationExtension with a unique identifier of 605aaa6d-682e-405c-964b-ca6aaa94be1b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnnotationReviewLink with a unique identifier of 5d3c2fb7-fa04-4d77-83cb-fd9216a07769 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaTypeDefinition with a unique identifier of 60f2d263-e24d-4f20-8c0d-b5e24648cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveredDataField with a unique identifier of 60f2d263-e24d-4f20-8c0d-b5e22222cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaAttributeDefinition with a unique identifier of 60f1e263-e24d-4f20-8c0d-b5e21232cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveredNestedDataField with a unique identifier of 60f2d263-e24d-4f20-8c0d-b5e12356cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassDefinition with a unique identifier of 51a2d263-e24d-4f20-8c0d-b5e12356cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataFieldAnalysis with a unique identifier of 833e849d-eda2-40bb-9e6b-c3ca0b56d581 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataProfileLogFile with a unique identifier of 75026fac-f9e5-4da8-9ad1-e9c68d47f577 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationshipAnnotation with a unique identifier of 73510abd-49e6-4097-ba4b-23bd3ef15baa and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0053 The Open Metadata Repository Services (OMRS) has loaded 412 types and 0 instances from open metadata archive Open Metadata Types Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0031 The local repository outbound event manager is starting with 0 type definition event consumer(s) and 0 instance event consumer(s) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0032 The local repository outbound event manager is sending out the 412 type definition events that were generated and buffered during server initialization Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0007 The Open Metadata Repository Services (OMRS) has initialized Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Data Engine open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Data Engine open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-DATA-ENGINE-0001 The Data Engine Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-DATA-ENGINE-0002 The Data Engine Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Subject Area open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Subject Area open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-SUBJECT-AREA-0001 The Subject Area Open Metadata Access Service (OMAS) is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-SUBJECT-AREA-0002 The Subject Area Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-SUBJECT-AREA-0003 The Subject Area Open Metadata Access Service (OMAS) is initialized Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Governance Engine open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Governance Engine open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-ENGINE-0001 The Governance Engine Open Metadata Access Service (OMAS) is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0001 Connecting to Apache Kafka Topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic with a server identifier of 2a73902e-e691-43cc-b422-23b6b42992e2 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0003 The properties passed to the Apache Kafka Consumer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic are: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.partition.fetch.bytes=10485760, auto.commit.interval.ms=1000, bootstrap.servers=localhost:9092, group.id=2a73902e-e691-43cc-b422-23b6b42992e2, enable.auto.commit=true, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, session.timeout.ms=30000} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0002 The properties passed to the Apache Kafka Producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic are: {retries=1, bootstrap.servers=localhost:9092, linger.ms=0, acks=all, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=33554432, batch.size=16384, key.serializer=org.apache.kafka.common.serialization.StringSerializer} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0010 The Apache Kafka producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic is starting up with 0 buffered messages Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-ENGINE-0002 The Governance Engine Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server instance cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-ENGINE-0003 The Governance Engine Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Governance Program open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Governance Program open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-PROGRAM-0001 The Governance Program Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-PROGRAM-0002 The Governance Program Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-PROGRAM-0003 The Governance Program Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Information View open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Information View open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0001 The Information View Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0002 The Information View Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0003 The Information View Open Metadata Access Service (OMAS) is registering a listener with the Information View In topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0001 Connecting to Apache Kafka Topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic with a server identifier of 2a73902e-e691-43cc-b422-23b6b42992e2 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0003 The properties passed to the Apache Kafka Consumer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic are: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.partition.fetch.bytes=10485760, auto.commit.interval.ms=1000, bootstrap.servers=localhost:9092, group.id=2a73902e-e691-43cc-b422-23b6b42992e2, enable.auto.commit=true, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, session.timeout.ms=30000} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0002 The properties passed to the Apache Kafka Producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic are: {retries=1, bootstrap.servers=localhost:9092, linger.ms=0, acks=all, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=33554432, batch.size=16384, key.serializer=org.apache.kafka.common.serialization.StringSerializer} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0010 The Apache Kafka producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic is starting up with 0 buffered messages Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0004 The Information View Open Metadata Access Service (OMAS) is registering a publisher with the Information View Out topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0001 Connecting to Apache Kafka Topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic with a server identifier of 2a73902e-e691-43cc-b422-23b6b42992e2 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0003 The properties passed to the Apache Kafka Consumer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic are: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.partition.fetch.bytes=10485760, auto.commit.interval.ms=1000, bootstrap.servers=localhost:9092, group.id=2a73902e-e691-43cc-b422-23b6b42992e2, enable.auto.commit=true, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, session.timeout.ms=30000} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0002 The properties passed to the Apache Kafka Producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic are: {retries=1, bootstrap.servers=localhost:9092, linger.ms=0, acks=all, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=33554432, batch.size=16384, key.serializer=org.apache.kafka.common.serialization.StringSerializer} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0010 The Apache Kafka producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic is starting up with 0 buffered messages Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0005 The Information View Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Asset Consumer open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Asset Consumer open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CONSUMER-0001 The Asset Consumer Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CONSUMER-0002 The Asset Consumer Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0001 Connecting to Apache Kafka Topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic with a server identifier of 2a73902e-e691-43cc-b422-23b6b42992e2 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0003 The properties passed to the Apache Kafka Consumer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic are: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.partition.fetch.bytes=10485760, auto.commit.interval.ms=1000, bootstrap.servers=localhost:9092, group.id=2a73902e-e691-43cc-b422-23b6b42992e2, enable.auto.commit=true, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, session.timeout.ms=30000} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0002 The properties passed to the Apache Kafka Producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic are: {retries=1, bootstrap.servers=localhost:9092, linger.ms=0, acks=all, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=33554432, batch.size=16384, key.serializer=org.apache.kafka.common.serialization.StringSerializer} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CONSUMER-0003 The Asset Consumer Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0010 The Apache Kafka producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic is starting up with 0 buffered messages Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Connected Asset open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Connected Asset open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-CONNECTED-ASSET-0001 The Connected Asset Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-CONNECTED-ASSET-0002 The Connected Asset Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-CONNECTED-ASSET-0003 The Connected Asset Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Asset Catalog open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Asset Catalog open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CATALOG-0001 The Asset Catalog Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CATALOG-0003 The Asset Catalog Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0019 The OMRS Topic Connector EnterpriseTopicConnector.Server.cocoMDS1 has registered with an event bus connector connected to topic cocoMDS1.open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0020 The OMRS Topic Connector EnterpriseTopicConnector.Server.cocoMDS1 is ready to send and receive events Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic cocoMDS1.open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic has started Further reading \u00b6 The contents of this tutorial covered a single OMAG server. For instructions on how to set up two OMAG Servers using in memory repositories that are exchanging metadata over Apache Kafka , see: In Memory Repository Demo Next steps \u00b6 Now the OMAG Server is running you are ready to start calling the open metadata and governance services .","title":"Task starting omag server"},{"location":"education/tutorials/omag-server-tutorial/task-starting-omag-server/#activating-omag-servers-in-the-omag-server-platform","text":"Once you have created a configuration document for an OMAG server it is started in the OMAG Server Platform using the following command (this is request 11. in Postman). POST https://localhost:9443/open-metadata/admin-services/users/garygeeke/servers/cocoMDS1/instance The response from the command lists the subsystems that have been activated in the OMAG server: { \"class\" : \"VoidResponse\" , \"relatedHTTPCode\" : 200 , \"successMessage\" : \"Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 is running the following services: [Repository Services, Data Engine OMAS, Subject Area OMAS, Governance Engine OMAS, Governance Program OMAS, Information View OMAS, Asset Consumer OMAS, Connected Asset OMAS, Asset Catalog OMAS]\" } The window where your OMAG server platform is running will show the start up messages, something like this (note this is from an older version where we used Java 8): /Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home/bin/java -Dserver.port=9443 ... ____ __ ___ ___ ______ _____ ____ _ _ ___ / __ \\ / |/ // | / ____/ / ___/ ___ ____ _ __ ___ ____ / _ \\ / / __ / / / _ /__ ____ _ _ / / / // /|_/ // /| | / / __ \\__ \\ / _ \\ / __/| | / // _ \\ / __/ / /_/ // // | / _\\ / /_ / | / _// || | / /_/ // / / // ___ |/ /_/ / ___/ // __// / | |/ // __// / / __ // // / \\ / /_ / _// / // / / / / / \\____//_/ /_//_/ |_|\\____/ /____/ \\___//_/ |___/ \\___//_/ /_/ /_/ \\__/\\//___//_/ \\__//_/ /_/ /_/ :: Powered by Spring Boot (v2.1.2.RELEASE) :: 16:13:18.047 [main] INFO o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9443 (https) 16:13:41.688 [main] INFO o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9443 (https) with context path '' Tue Feb 05 16:14:20 GMT 2019 2020 No OMAG servers listed in startup configuration Tue Feb 05 16:14:20 GMT 2019 OMAG server platform ready for more configuration Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0001 The Open Metadata Repository Services (OMRS) is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0002 Enterprise access through the Enterprise Repository Services is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0003 The local repository is initializing with metadata collection named cocoMDS1 with an id of ad405dc2-1361-48f8-9ea2-538bd43db1b0 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0030 The local repository outbound event manager is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0050 The Open Metadata Repository Services (OMRS) is about to process open metadata archive Open Metadata Types Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called object with a unique identifier of 1c4b21f4-0b67-41a7-a6ed-2af185eb9b3b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called boolean with a unique identifier of 3863f010-611c-41fe-aaae-5d4d427f863b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called byte with a unique identifier of 6b7d410a-2e8a-4d12-981a-a806449f9bdb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called char with a unique identifier of b0abebe5-cf85-4065-86ad-f3c6360ed9c7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called short with a unique identifier of 8e95b966-ab60-46d4-a03f-40c5a1ba6c2a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called int with a unique identifier of 7fc49104-fd3a-46c8-b6bf-f16b6074cd35 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called long with a unique identifier of 33a91510-92ee-4825-9f49-facd7a6f9db6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called float with a unique identifier of 52aeb769-37b7-4b30-b949-ddc7dcebcfa2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called double with a unique identifier of e13572e8-25c3-4994-acb6-2ea66c95812e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called biginteger with a unique identifier of 8aa56e52-1076-4e0d-9b66-3873a1ed7392 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called bigdecimal with a unique identifier of d5c8ad9f-8fee-4a64-80b3-63ce1e47f6bb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called string with a unique identifier of b34a64b9-554a-42b1-8f8a-7d5c2339f9c4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called date with a unique identifier of 1bef35ca-d4f9-48db-87c2-afce4649362d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called map<string,string> with a unique identifier of 005c7c14-ac84-4136-beed-959401b041f8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called map<string,boolean> with a unique identifier of 8fa603dd-c2c5-43fc-8ff4-92141f2414ab and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called map<string,int> with a unique identifier of 8fa603dd-c2c5-43fc-8ff4-92141f2414ac and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called map<string,long> with a unique identifier of 8fa603dd-c2c5-43fc-8ff4-92141f2414ae and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called array<string> with a unique identifier of 0428b5d3-f824-459c-b7f5-f8151de59707 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called array<int> with a unique identifier of 0103fe10-98b0-4910-8ee0-21d529f7ff6d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetOwnerType with a unique identifier of 9548390c-69f5-4dc6-950d-6feeee257b56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaType with a unique identifier of 9548390c-69f5-4dc6-950d-6fdffb257b56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaUsage with a unique identifier of c6861a72-7485-48c9-8040-876f6c342b61 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called KeyPattern with a unique identifier of 8904df8f-1aca-4de8-9abd-1ef2aadba300 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Endianness with a unique identifier of e5612c3a-49bd-4148-8f67-cfdf145d5fd8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OperationalStatus with a unique identifier of 24e1e33e-9250-4a6c-8b07-05c7adec3a1d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ServerAssetUse with a unique identifier of 09439481-9489-467c-9ae5-178a6e0b6b5a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContactMethodType with a unique identifier of 30e7d8cd-df01-46e8-9247-a24c5650910d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OrderBy with a unique identifier of 1d412439-4272-4a7e-a940-1065f889fc56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ToDoStatus with a unique identifier of 7197ea39-334d-403f-a70b-d40231092df7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CommunityMembershipType with a unique identifier of b0ef45bf-d12b-4b6f-add6-59c14648d750 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called StarRating with a unique identifier of 77fea3ef-6ec1-4223-8408-38567e9d3c93 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CommentType with a unique identifier of 06d5032e-192a-4f77-ade1-a4b97926e867 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CrowdSourcingRole with a unique identifier of 0ded50c2-17cc-4ecf-915e-908e66dbb27f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermRelationshipStatus with a unique identifier of 42282652-7d60-435e-ad3e-7cfe5291bcc7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ActivityType with a unique identifier of af7e403d-9865-4ebb-8c1a-1fd57b4f4bca and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermAssignmentStatus with a unique identifier of c8fe36ac-369f-4799-af75-46b9c1343ab3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDomain with a unique identifier of baa31998-f3cb-47b0-9123-674a701e87bc and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceClassificationStatus with a unique identifier of cc540586-ac7c-41ba-8cc1-4da694a6a8e4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConfidentialityLevel with a unique identifier of ecb48ca2-4d29-4de9-99a1-bc4db9816d68 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConfidenceLevel with a unique identifier of ae846797-d88a-4421-ad9a-318bf7c1fe6f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RetentionBasis with a unique identifier of de79bf78-ecb0-4fd0-978f-ecc2cb4ff6c7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CriticalityLevel with a unique identifier of 22bcbf49-83e1-4432-b008-e09a8f842a1e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called BusinessCapabilityType with a unique identifier of fb7c40cf-8d95-48ff-ba8b-e22bff6f5a91 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassAssignmentStatus with a unique identifier of 2611892f-0527-478f-8843-a3aa2b9abb47 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnnotationStatus with a unique identifier of 71187df6-ef66-4f88-bc03-cd3c7f925165 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Referenceable with a unique identifier of a32316b8-dc8c-48c5-b12b-71c1b2a080bf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Asset with a unique identifier of 896d14c2-7522-4f6c-8519-757711943fe6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Infrastructure with a unique identifier of c19746ac-b3ec-49ce-af4b-83348fc55e07 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Process with a unique identifier of d8f33bd7-afa9-4a11-a8c7-07dcec83c050 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataSet with a unique identifier of 1449911c-4f44-4c22-abc0-7540154feefb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalReference with a unique identifier of af536f20-062b-48ef-9c31-1ddd05b04c56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelatedMedia with a unique identifier of 747f8b86-fe7c-4c9b-ba75-979e093cc307 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalId with a unique identifier of 7c8f8c2c-cc48-429e-8a21-a1f1851ccdb0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PropertyFacet with a unique identifier of 6403a704-aad6-41c2-8e08-b9525c006f85 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Location with a unique identifier of 3e09cb2b-5f15-4fd2-b004-fe0146ad8628 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ITInfrastructure with a unique identifier of 151e6dd1-54a0-4b7f-a072-85caa09d1dda and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Host with a unique identifier of 1abd16db-5b8a-4fd9-aee5-205db3febe99 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OperatingPlatform with a unique identifier of bd96a997-8d78-42f6-adf7-8239bc98501c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostCluster with a unique identifier of 9794f42f-4c9f-4fe6-be84-261f0a7de890 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called VirtualContainer with a unique identifier of e2393236-100f-4ac0-a5e6-ce4e96c521e7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerPlatform with a unique identifier of ba7c7884-32ce-4991-9c41-9778f1fec6aa and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServer with a unique identifier of aa7c7884-32ce-4991-9c41-9778f1fec6aa and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Endpoint with a unique identifier of dbc20663-d705-4ff0-8424-80c262c6b8e7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerCapability with a unique identifier of fe30a033-8f86-4d17-8986-e6166fa24177 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Application with a unique identifier of 58280f3c-9d63-4eae-9509-3f223872fb25 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Engine with a unique identifier of 3566527f-b1bd-4e7a-873e-a3e04d5f2a14 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Network with a unique identifier of e0430f59-f021-411a-9d81-883e1ff3f6f6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NetworkGateway with a unique identifier of 9bbae94d-e109-4c96-b072-4f97123f04fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ActorProfile with a unique identifier of 5a2f38dc-d69d-4a6f-ad26-ac86f118fa35 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called UserIdentity with a unique identifier of fbe95779-1f3c-4ac6-aa9d-24963ff16282 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContactDetails with a unique identifier of 79296df8-645a-4ef7-a011-912d1cdcf75a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Person with a unique identifier of ac406bf8-e53e-49f1-9088-2af28bbbd285 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContributionRecord with a unique identifier of ac406bf8-e53e-49f1-9088-2af28cccd285 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PersonRole with a unique identifier of ac406bf8-e53e-49f1-9088-2af28bcbd285 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Team with a unique identifier of 36db26d5-aba2-439b-bc15-d62d373c5db6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamLeader with a unique identifier of 36db26d5-abb2-439b-bc15-d62d373c5db6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamMember with a unique identifier of 46db26d5-abb2-538b-bc15-d62d373c5db6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ITProfile with a unique identifier of 81394f85-6008-465b-926e-b3fae4668937 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Collection with a unique identifier of 347005ba-2b35-4670-b5a7-12c9ebed0cf7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Project with a unique identifier of 0799569f-0c16-4a1f-86d9-e2e89568f7fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectManager with a unique identifier of 0798569f-0c16-4a1f-86d9-e2e89568f7fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Meeting with a unique identifier of 6bf90c79-32f4-47ad-959c-8fff723fe744 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ToDo with a unique identifier of 93dbc58d-c826-4bc2-b36f-195148d46f86 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Community with a unique identifier of fbd42379-f6c3-4f08-b6f7-378565cda993 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CommunityMember with a unique identifier of fbd42379-f6c3-4f09-b6f7-378565cda993 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Rating with a unique identifier of 7299d721-d17f-4562-8286-bcd451814478 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Comment with a unique identifier of 1a226073-9c84-40e4-a422-fbddb9b84278 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Like with a unique identifier of deaa5ca0-47a0-483d-b943-d91c76744e01 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called InformalTag with a unique identifier of ba846a7b-2955-40bf-952b-2793ceca090a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PrivateTag with a unique identifier of 9b3f5443-2475-4522-bfda-8f1f17e9a6c3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NoteEntry with a unique identifier of 2a84d94c-ac6f-4be1-a72a-07dcec7b1fe3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NoteLog with a unique identifier of 646727c7-9ad4-46fa-b660-265489ad96c6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Connection with a unique identifier of 114e9f8f-5ff3-4c32-bd37-a7eb42712253 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConnectorType with a unique identifier of 954421eb-33a6-462d-a8ca-b5709a1bd0d4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called VirtualConnection with a unique identifier of 82f9c664-e59d-484c-a8f3-17088c23a2f3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataStore with a unique identifier of 30756d0b-362b-4bfa-a0de-fce6a8f47b47 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedAPI with a unique identifier of 7dbb3e63-138f-49f1-97b4-66313871fc14 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedSoftwareComponent with a unique identifier of 486af62c-dcfd-4859-ab24-eab2e380ecfd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called FileFolder with a unique identifier of 229ed5cc-de31-45fc-beb4-9919fd247398 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataFile with a unique identifier of 10752b4a-4b5d-4519-9eae-fdd6d162122f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaFile with a unique identifier of c5ce5499-9582-42ea-936c-9771fbd475f8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaCollection with a unique identifier of 0075d603-1627-41c5-8cae-f5458d1247fe and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Document with a unique identifier of b463827c-c0a0-4cfb-a2b2-ddc63746ded4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DocumentStore with a unique identifier of 37156790-feac-4e1a-a42e-88858ae6f8e1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphStore with a unique identifier of 86de3633-eec8-4bf9-aad1-e92df1ca2024 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SubscriberList with a unique identifier of 69751093-35f9-42b1-944b-ba6251ff513d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Topic with a unique identifier of 29100f49-338e-4361-b05d-7e4e8e818325 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LogFile with a unique identifier of ff4c8484-9127-464a-97fc-99579d5bc429 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedDatabaseSchema with a unique identifier of eab811ec-556a-45f1-9091-bc7ac8face0f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Database with a unique identifier of 0921c83f-b2db-4086-a52c-0d10e52ca078 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EnterpriseAccessLayer with a unique identifier of 39444bf9-638e-4124-a5f9-1b8f3e1b008b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CohortMember with a unique identifier of 42063797-a78a-4720-9353-52026c75f667 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataRepositoryCohort with a unique identifier of 43e7dca2-c7b4-4cdf-a1ea-c9d4f7093893 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataCollection with a unique identifier of ea3b15af-ed0e-44f7-91e4-bdb299dd4976 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataRepository with a unique identifier of c40397bd-eab0-4b2e-bffb-e7fa0f93a5a9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CohortRegistryStore with a unique identifier of 2bfdcd0d-68bb-42c3-ae75-e9fb6c3dff70 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called KeystoreFile with a unique identifier of 17bee904-5b35-4c81-ac63-871c615424a2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called KeyStoreCollection with a unique identifier of 979d97dd-6782-4648-8e2a-8982994533e6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReferenceCodeTable with a unique identifier of 201f48c5-4e4b-41dc-9c5f-0bc9742190cf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReferenceCodeMappingTable with a unique identifier of 9c6ec0c6-0b26-4414-bffe-089144323213 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called InformationView with a unique identifier of 68d7b905-6438-43be-88cf-5de027b4aaaf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Form with a unique identifier of 8078e3d1-0c63-4ace-aafa-68498b39ccd6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedReport with a unique identifier of e9077f4f-955b-4d7b-b1f7-12ee769ff0c3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Glossary with a unique identifier of 36f66863-9726-4b41-97ee-714fd0dc6fe4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalGlossaryLink with a unique identifier of 183d2935-a950-4d74-b246-eac3664b5a9d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GlossaryCategory with a unique identifier of e507485b-9b5a-44c9-8a28-6967f7ff3672 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GlossaryTerm with a unique identifier of 0db3e6ec-f5ef-4d75-ae38-b7ee6fd6ec0a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ControlledGlossaryTerm with a unique identifier of c04e29b2-2d66-48fc-a20d-e59895de6040 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDefinition with a unique identifier of 578a3500-9ad3-45fe-8ada-e4e9572c37c8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceOfficer with a unique identifier of 578a3510-9ad3-45fe-8ada-e4e9572c37c8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDriver with a unique identifier of c403c109-7b6b-48cd-8eee-df445b258b33 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceStrategy with a unique identifier of 3c34f121-07a6-4e95-a07d-9b0ef17b7bbf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Regulation with a unique identifier of e3c4293d-8846-4500-b0c0-197d73aba8b0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernancePolicy with a unique identifier of a7defa41-9cfa-4be5-9059-359022bb016d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernancePrinciple with a unique identifier of 3b7d1325-ec2c-44cb-8db0-ce207beb78cf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceObligation with a unique identifier of 0cec20d3-aa29-41b7-96ea-1c544ed32537 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceApproach with a unique identifier of 2d03ec9d-bd6b-4be9-8e17-95a7ecdbaa67 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceControl with a unique identifier of c794985e-a10b-4b6c-9dc2-6b2e0a2901d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TechnicalControl with a unique identifier of d8f6eb5b-36f0-49bd-9b25-bf16f370d1ec and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OrganizationalControl with a unique identifier of befa1458-79b8-446a-b813-536700e60fa8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceZone with a unique identifier of 290a192b-42a7-449a-935a-269ca62cfdac and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceRule with a unique identifier of 8f954380-12ce-4a2d-97c6-9ebe250fecf8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceProcess with a unique identifier of b68b5d9d-6b79-4f3a-887f-ec0f81c54aea and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NamingStandardRule with a unique identifier of 52505b06-98a5-481f-8a32-db9b02afabfc and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NamingStandardRuleSet with a unique identifier of ba70f506-1f81-4890-bb4f-1cb1d99c939e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Organization with a unique identifier of 50a61105-35be-4ee3-8b99-bdd958ed0685 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called BusinessCapability with a unique identifier of 7cc6bcb2-b573-4719-9412-cf6c3f4bbb15 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceResponsibility with a unique identifier of 89a76b24-deb8-45bf-9304-a578a610326f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceProcedure with a unique identifier of 69055d10-51dc-4c2b-b21f-d76fad3f8ef3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectCharter with a unique identifier of f96b5a32-42c1-4a74-8f77-70a81cec783d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceRole with a unique identifier of de2d7f2e-1759-44e3-b8a6-8af53e8fb0ee and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetOwner with a unique identifier of ac406bf8-e53e-49f1-9088-2af28eeee285 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceMetric with a unique identifier of 9ada8e7b-823c-40f7-adf8-f164aabda77e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LicenseType with a unique identifier of 046a049d-5f80-4e5b-b0ae-f3cf6009b513 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CertificationType with a unique identifier of 97f9ffc9-e2f7-4557-ac12-925257345eea and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaElement with a unique identifier of 718d4244-8559-49ed-ad5a-10e5c305a656 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaType with a unique identifier of 5bd4a3e7-d22d-4a3d-a115-066ee8e0754f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PrimitiveSchemaType with a unique identifier of f0f75fba-9136-4082-8352-0ad74f3c36ed and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ImplementationSnippet with a unique identifier of 49990755-2faa-4a62-a1f3-9124b9c73df4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaAttribute with a unique identifier of 1a5e159b-913a-43b1-95fe-04433b25fca9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ComplexSchemaType with a unique identifier of 786a6199-0ce8-47bf-b006-9ace1c5510e4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called StructSchemaType with a unique identifier of a13b409f-fd67-4506-8d94-14dfafd250a4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called BoundedSchemaType with a unique identifier of 77133161-37a9-43f5-aaa3-fd6d7ff92fdb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ArraySchemaType with a unique identifier of ba8d29d2-a8a4-41f3-b29f-91ad924dd944 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SetSchemaType with a unique identifier of b2605d2d-10cd-443c-b3e8-abf15fb051f0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaLinkElement with a unique identifier of 67e08705-2d2a-4df6-9239-1818161a41e0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MapSchemaType with a unique identifier of bd4c85d0-d471-4cd2-a193-33b0387a19fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DerivedSchemaAttribute with a unique identifier of cf21abfe-655a-47ba-b9b6-f73394745c80 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TabularSchemaType with a unique identifier of 248975ec-8019-4b8a-9caf-084c8b724233 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TabularColumnType with a unique identifier of a7392281-348d-48a4-bad7-f9742d7696fe and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TabularColumn with a unique identifier of d81a0425-4e9b-4f31-bc1c-e18c3566da10 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DocumentSchemaType with a unique identifier of 33da99cd-8d04-490c-9457-c58908da7794 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DocumentSchemaAttribute with a unique identifier of b5cefb7e-b198-485f-a1d7-8e661012499b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SimpleDocumentType with a unique identifier of 42cfccbf-cc68-4980-8c31-0faf1ee002d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called StructDocumentType with a unique identifier of f6245c25-8f73-45eb-8fb5-fa17a5f27649 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ArrayDocumentType with a unique identifier of ddd29c67-db9a-45ff-92aa-6d17a12a8ee2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SetDocumentType with a unique identifier of 67228a7a-9d8d-4fa7-b217-17474f1f4ac6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MapDocumentType with a unique identifier of b0f09598-ceb6-415b-befc-563ecadd5727 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ObjectSchemaType with a unique identifier of 6920fda1-7c07-47c7-84f1-9fb044ae153e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ObjectAttribute with a unique identifier of ccb408c0-582e-4a3a-a926-7082d53bb669 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphSchemaType with a unique identifier of 983c5e72-801b-4e42-bc51-f109527f2317 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphVertex with a unique identifier of 1252ce12-540c-4724-ad70-f70940956de0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphEdge with a unique identifier of d4104eb3-4f2d-4d83-aca7-e58dd8d5e0b1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalDBSchemaType with a unique identifier of f20f5f45-1afb-41c1-9a09-34d8812626a4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalTableType with a unique identifier of 1321bcc0-dc6a-48ed-9ca6-0c6f934b0b98 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalTable with a unique identifier of ce7e72b8-396a-4013-8688-f9d973067425 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalColumn with a unique identifier of aa8d5470-6dbc-4648-9e2f-045e5df9d2f9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalColumnType with a unique identifier of f0438d80-6eb9-4fac-bcc1-5efee5babcfc and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DerivedRelationalColumn with a unique identifier of a9f7d15d-b797-450a-8d56-1ba55490c019 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EventSet with a unique identifier of bead9aa4-214a-4596-8036-aa78395bbfb1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EventType with a unique identifier of 8bc88aba-d7e4-4334-957f-cfe8e8eadc32 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APISchemaType with a unique identifier of b46cddb3-9864-4c5d-8a49-266b3fc95cb8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIOperation with a unique identifier of f1c0af19-2729-4fac-996e-a7badff3c21c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClass with a unique identifier of 6bc727dc-e855-4979-8736-78ac3cfcd32f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OpenDiscoveryEngine with a unique identifier of be650674-790b-487a-a619-0a9002488055 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OpenDiscoveryService with a unique identifier of 2f278dfc-4640-4714-b34b-303e84e4fc40 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OpenDiscoveryPipeline with a unique identifier of 081abe00-740e-4143-b0d5-a1f55450fc22 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OpenDiscoveryAnalysisReport with a unique identifier of acc7cbc8-09c3-472b-87dd-f78459323dcb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Annotation with a unique identifier of 6cea5b53-558c-48f1-8191-11d48db29fb4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnnotationReview with a unique identifier of b893d6fc-642a-454b-beaf-809ee4dd876a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaAnalysisAnnotation with a unique identifier of 3c5aa68b-d562-4b04-b189-c7b7f0bf2ced and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataField with a unique identifier of 3c5bbc8b-d562-4b04-b189-c7b7f0bf2cea and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataFieldAnnotation with a unique identifier of 72ed6de6-79d9-4e7d-aefc-b969382fc4b0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataProfileAnnotation with a unique identifier of bff1f694-afd0-4829-ab11-50a9fbaf2f5f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataProfileLogAnnotation with a unique identifier of 368e6fb3-7323-4f81-a723-5182491594bd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassAnnotation with a unique identifier of 0c8a3673-04ef-406f-899d-e88de67f6176 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SemanticAnnotation with a unique identifier of 0b494819-28be-4604-b238-3af20963eea6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ClassificationAnnotation with a unique identifier of 23e8287f-5c7e-4e03-8bd3-471fc7fc029c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called QualityAnnotation with a unique identifier of 72e6473d-4ce0-4609-80a4-e6e949a7f520 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationshipAdviceAnnotation with a unique identifier of 740f07dc-4ee8-4c2a-baba-efb55c73eb68 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataSourceMeasurementAnnotation with a unique identifier of c85bea73-d7af-46d7-8a7e-cb745910b1df and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataSourcePhysicalStatusAnnotation with a unique identifier of e9ba276e-6d9f-4999-a5a9-9ddaaabfae23 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RequestForAction with a unique identifier of f45765a9-f3ae-4686-983f-602c348e020d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MobileAsset with a unique identifier of b25fb90d-8fa2-4aa9-b884-ff0a6351a697 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called FixedLocation with a unique identifier of bc111963-80c7-444f-9715-946c03142dd2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SecureLocation with a unique identifier of e7b563c0-fcdd-4ba7-a046-eecf5c4638b8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CyberLocation with a unique identifier of f9ec3633-8ac8-480b-aa6d-5e674b9e1b17 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ApplicationServer with a unique identifier of 19196efb-2706-47bf-8e51-e8ba5b36d033 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Webserver with a unique identifier of d13e1cc5-bb7e-41ec-8233-9647fbf92a19 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called WorkflowEngine with a unique identifier of 37a6d212-7c4a-4a82-b4e2-601d4358381c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReportingEngine with a unique identifier of e07eefaa-16e0-46cf-ad54-bed47fb15812 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnalyticsEngine with a unique identifier of 1a0dc6f6-7980-42f5-98bd-51e56543a07e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataMovementEngine with a unique identifier of d2ed6621-9d99-4fe8-843a-b28d816cf888 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataVirtualizationEngine with a unique identifier of 03e25cd0-03d7-4d96-b28b-eed671824ed6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CloudProvider with a unique identifier of a2bfdd08-d0a8-49db-bc97-7f2406281046 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CloudPlatform with a unique identifier of 1b8f8511-e606-4f65-86d3-84891706ad12 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CloudTenant with a unique identifier of 1b8f8522-e606-4f65-86d3-84891706ad12 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CloudService with a unique identifier of 337e7b1a-ad4b-4818-aa3e-0ff3307b2fbe and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Folder with a unique identifier of 3c0fa687-8a63-4c8e-8bda-ede9c78be6c7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Set with a unique identifier of 3947f08d-7412-4022-81fc-344a20dfbb26 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Task with a unique identifier of 2312b668-3670-4845-a140-ef88d5a6db0c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Campaign with a unique identifier of 41437629-8609-49ef-8930-8c435c912572 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataStoreEncoding with a unique identifier of f08e48b5-6b66-40f5-8ff6-c2bfe527330b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RequestResponseInterface with a unique identifier of 14a29330-e830-4343-a41e-d57e2cec82f8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ListenerInterface with a unique identifier of 4099d2ed-2a5e-4c44-8443-9de4e378a4ba and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PublisherInterface with a unique identifier of 4fdedcd5-b186-4bee-887a-02fa29a10750 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called FileSystem with a unique identifier of cab5ba1d-cfd3-4fca-857d-c07711fc4157 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContentManager with a unique identifier of fa4df7b5-cb6d-475c-889e-8f3b7ca564d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NotificationManager with a unique identifier of 3e7502a7-396a-4737-a106-378c9c94c105 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DatabaseServer with a unique identifier of 6bb58cc9-ed9e-4f75-b2f2-6d308554eb52 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataServer with a unique identifier of 74a256ad-4022-4518-a446-c65fe082d4d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RepositoryProxy with a unique identifier of ae81c35e-7078-46f0-9b2c-afc99accf3ec and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Taxonomy with a unique identifier of 37116c51-e6c9-4c37-942e-35d48c8c69a0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CanonicalVocabulary with a unique identifier of 33ad3da2-0910-47be-83f1-daee018a4c05 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SubjectArea with a unique identifier of 480e6993-35c5-433a-b50b-0f5c4063fb5d and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ActivityDescription with a unique identifier of 317f0e52-1548-41e6-b90c-6ae5e6c53fed and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AbstractConcept with a unique identifier of 9d725a07-4abf-4939-a268-419d200b69c2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataValue with a unique identifier of ab253e31-3d8a-45a7-8592-24329a189b9e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContextDefinition with a unique identifier of 54f9f41a-3871-4650-825d-59a41de01330 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SpineObject with a unique identifier of a41ee152-de1e-4533-8535-2f8b37897cac and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SpineAttribute with a unique identifier of ccb749ba-34ec-4f71-8755-4d8b383c34c3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ObjectIdentifier with a unique identifier of 3d1e4389-27de-44fa-8df4-d57bfaf809ea and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GlossaryProject with a unique identifier of 43be51a9-2d19-4044-b399-3ba36af10929 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceProject with a unique identifier of 37142317-4125-4046-9514-71dc5031563f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Confidentiality with a unique identifier of 742ddb7d-9a4a-4eb5-8ac2-1d69953bd2b6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Confidence with a unique identifier of 25d8f8d5-2998-4983-b9ef-265f58732965 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Retention with a unique identifier of 83dbcdf2-9445-45d7-bb24-9fa661726553 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Criticality with a unique identifier of d46d211a-bd22-40d5-b642-87b4954a167e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PrimeWord with a unique identifier of 3ea1ea66-8923-4662-8628-0bacef3e9c5f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ClassWord with a unique identifier of feac4bd9-37d9-4437-82f6-618ce3e2793e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NamingConventionRule with a unique identifier of dfc70bed-7e8b-4060-910c-59c7473f23a3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceMeasurementsResultsDataSet with a unique identifier of 789f2e89-accd-4489-8eca-dc43b432c022 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExceptionLogFile with a unique identifier of 4756a6da-e0c2-4e81-b9ab-99df2f735eec and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AuditLogFile with a unique identifier of 109d6d13-a3cf-4687-a0c1-c3802dc6b3a2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExceptionBacklog with a unique identifier of b3eceea3-aa02-4d84-8f11-da4953e64b5f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AuditLog with a unique identifier of 449be034-6cc8-4f1b-859f-a8b9ff8ee7a1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MeteringLog with a unique identifier of 161b37c9-1d51-433b-94ce-5a760a198236 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called StewardshipServer with a unique identifier of eaaeaa31-6f8b-4ed5-88fe-422ed3733158 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDaemon with a unique identifier of 7815f222-529d-4902-8f0b-e37cbc779885 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ControlPoint with a unique identifier of acf8b73e-3545-435d-ba16-fbfae060dd28 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called VerificationPoint with a unique identifier of 12d78c95-3879-466d-883f-b71f6477a741 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EnforcementPoint with a unique identifier of f4ce104e-7430-4c30-863d-60f6af6394d9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PrimaryKey with a unique identifier of b239d832-50bd-471b-b17a-15a335fc7f40 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationalView with a unique identifier of 4814bec8-482d-463d-8376-160b0358e129 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProcessInput with a unique identifier of 9a6583c4-7419-4d5a-a6e5-26b0033fa349 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProcessOutput with a unique identifier of 8920eada-9b05-4368-b511-b8506a4bef4b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalReferenceLink with a unique identifier of 7d818a67-ab45-481c-bc28-f6b1caf12f06 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MediaReference with a unique identifier of 1353400f-b0ab-4ab9-ab09-3045dd8a7140 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalIdScope with a unique identifier of 8c5b1415-2d1f-4190-ba6c-1fdd47f03269 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternalIdLink with a unique identifier of 28ab0381-c662-4b6d-b787-5d77208de126 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReferenceableFacet with a unique identifier of 58c87647-ada9-4c90-a3c3-a40ace46b1f7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NestedLocation with a unique identifier of f82a96c2-95a3-4223-88c0-9cbf2882b772 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AdjacentLocation with a unique identifier of 017d0518-fc25-4e5e-985e-491d91e61e17 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetLocation with a unique identifier of bc236b62-d0e6-4c5c-93a1-3a35c3dba7b1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostLocation with a unique identifier of f3066075-9611-4886-9244-32cc6eb07ea9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostOperatingPlatform with a unique identifier of b9179df5-6e23-4581-a8b0-2919e6322b12 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostClusterMember with a unique identifier of 1a1c3933-a583-4b0c-9e42-c3691296a8e0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DeployedVirtualContainer with a unique identifier of 4b981d89-e356-4d9b-8f17-b3a8d5a86676 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerPlatformDeployment with a unique identifier of b909eb3b-5205-4180-9f63-122a65b30738 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerDeployment with a unique identifier of d909eb3b-5205-4180-9f63-122a65b30738 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ServerEndpoint with a unique identifier of 2b8bfab4-8023-4611-9833-82a0dc95f187 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SoftwareServerSupportedCapability with a unique identifier of 8b7d7da5-0668-4174-a43b-8f8c6c068dd0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ServerAssetUse with a unique identifier of 92b75926-8e9a-46c7-9d98-89009f622397 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RuntimeForProcess with a unique identifier of f6b5cf4f-7b88-47df-aeb0-d80d28ba1ec1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called HostNetwork with a unique identifier of f2bd7401-c064-41ac-862c-e5bcdc98fa1e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NetworkGatewayLink with a unique identifier of 5bece460-1fa6-41fb-a29f-fdaf65ec8ce3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ContactThrough with a unique identifier of 6cb9af43-184e-4dfa-854a-1572bcf0fe75 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProfileIdentity with a unique identifier of 01664609-e777-4079-b543-6baffe910ff1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PersonRoleAppointment with a unique identifier of 4a316abe-bcce-4d11-ad5a-4bfb4079b80b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PersonalContribution with a unique identifier of 4a316abe-eeee-4d11-ad5a-4bfb4079b80b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Peer with a unique identifier of 4a316abe-bccd-4d11-ad5a-4bfb4079b80b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamLeadership with a unique identifier of 5ebc4fb2-b62a-4269-8f18-e9237a2119ca and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamMembership with a unique identifier of 1ebc4fb2-b62a-4269-8f18-e9237a2119ca and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TeamStructure with a unique identifier of 5ebc4fb2-b62a-4269-8f18-e9237a2229ca and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CollectionMembership with a unique identifier of 5cabb76a-e25b-4bb5-8b93-768bbac005af and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ResourceList with a unique identifier of 73cf5658-6a73-4ebc-8f4d-44fdfac0b437 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectHierarchy with a unique identifier of 8f1134f6-b9fe-4971-bc57-6e1b8b302b55 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectDependency with a unique identifier of 5b6a56f1-68e2-4e10-85f0-fda47a4263fd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectTeam with a unique identifier of 746875af-2e41-4d1f-864b-35265df1d5dc and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectScope with a unique identifier of bc63ac45-b4d0-4fba-b583-92859de77dd8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectManagement with a unique identifier of ac63ac45-a4d0-4fba-b583-92859de77dd8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Meetings with a unique identifier of a05f918e-e7e2-419d-8016-5b37406df63a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ToDoSource with a unique identifier of a0b7ba50-4c97-4b76-9a7d-c6a00e1be646 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Actions with a unique identifier of aca1277b-bf1c-42f5-9b3b-fbc2c9047325 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ActionAssignment with a unique identifier of af2b5fab-8f83-4a2b-b749-1e6219f61f79 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CommunityMembership with a unique identifier of 7c7da1a3-01b3-473e-972e-606eff0cb112 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedRating with a unique identifier of 0aaad9e9-9cc5-4ad8-bc2e-c1099bab6344 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedComment with a unique identifier of 0d90501b-bf29-4621-a207-0c8c953bdac9 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedLike with a unique identifier of e2509715-a606-415d-a995-61d00503dad4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AcceptedAnswer with a unique identifier of ecf1a3ca-adc5-4747-82cf-10ec590c5c69 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedTag with a unique identifier of 4b1641c4-3d1a-4213-86b2-d6968b6c65ab and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Contributor with a unique identifier of 4db83564-b200-4956-94a4-c95a5c30e65a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedNoteLog with a unique identifier of 4f798c0c-6769-4a2d-b489-d2714d89e0a4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttachedNoteLogEntry with a unique identifier of 38edecc6-f385-4574-8144-524a44e3e712 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConnectionEndpoint with a unique identifier of 887a7132-d6bc-4b92-a483-e80b60c86fb2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConnectionConnectorType with a unique identifier of e542cfc1-0b4b-42b9-9921-f0a5a88aaf96 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called EmbeddedConnection with a unique identifier of eb6dfdd2-8c6f-4f0d-a17d-f6ce4799f64f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ConnectionToAsset with a unique identifier of e777d660-8dbe-453e-8b83-903771f054c0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataContentForDataSet with a unique identifier of b827683c-2924-4df3-a92d-7be1888e23c0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIEndpoint with a unique identifier of de5b9501-3ad4-4803-a8b2-e311c72a4336 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called FolderHierarchy with a unique identifier of 48ac9028-45dd-495d-b3e1-622685b54a01 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called NestedFile with a unique identifier of 4cb88900-1446-4eb6-acea-29cd9da45e63 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LinkedFile with a unique identifier of 970a3405-fde1-4039-8249-9aa5f56d5151 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GroupedMedia with a unique identifier of 7d881574-461d-475c-ab44-077451528cb8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LinkedMedia with a unique identifier of cee3a190-fc8d-4e53-908a-f1b9689581e0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TopicSubscribers with a unique identifier of bc91a28c-afb9-41a7-8eb2-fc8b5271fe9e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MetadataCohortPeer with a unique identifier of 954cdba1-3d69-4db1-bf0e-d59fd2c25a27 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CohortMemberMetadataCollection with a unique identifier of 8b9dd3ea-057b-4709-9b42-f16098523907 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ExternallySourcedGlossary with a unique identifier of 7786a39c-436b-4538-acc7-d595b5856add and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CategoryAnchor with a unique identifier of c628938e-815e-47db-8d1c-59bb2e84e028 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called CategoryHierarchyLink with a unique identifier of 71e4b6fb-3412-4193-aff3-a16eccd87e8e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LibraryCategoryReference with a unique identifier of 3da21cc9-3cdc-4d87-89b5-c501740f00b2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermAnchor with a unique identifier of 1d43d661-bdc7-4a91-a996-3239b8f82e56 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermCategorization with a unique identifier of 696a81f5-ac60-46c7-b9fd-6979a1e7ad27 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LibraryTermReference with a unique identifier of 38c346e4-ddd2-42ef-b4aa-55d53c078d22 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelatedTerm with a unique identifier of b1161696-e563-4cf9-9fd9-c0c76e47d063 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Synonym with a unique identifier of 74f4094d-dba2-4ad9-874e-d422b69947e2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Antonym with a unique identifier of ea5e126a-a8fa-4a43-bcfa-309a98aa0185 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called PreferredTerm with a unique identifier of 8ac8f9de-9cdd-4103-8a33-4cb204b78c2a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ReplacementTerm with a unique identifier of 3bac5f35-328b-4bbd-bfc9-3b3c9ba5e0ed and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Translation with a unique identifier of 6ae42e95-efc5-4256-bfa8-801140a29d2a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ISARelationship with a unique identifier of 50fab7c7-68bc-452f-b8eb-ec76829cac85 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ValidValue with a unique identifier of 707a156b-e579-4482-89a5-de5889da1971 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called UsedInContext with a unique identifier of 2dc524d2-e29f-4186-9081-72ea956c75de and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SemanticAssignment with a unique identifier of e6670973-645f-441a-bec7-6f5570345b92 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermHASARelationship with a unique identifier of d67f16d1-5348-419e-ba38-b0bb6fe4ad6c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermISATypeOFRelationship with a unique identifier of d5d588c3-46c9-420c-adff-6031802a7e51 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called TermTYPEDBYRelationship with a unique identifier of 669e8aa4-c671-4ee7-8d03-f37d09b9d006 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernancePost with a unique identifier of 4c4d1d0c-a9fc-4305-8b71-4e691c0f9ae0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernancePolicyLink with a unique identifier of 0c42c999-4cac-4da4-afab-0e381f3a818e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceResponse with a unique identifier of 8845990e-7fd9-4b79-a19d-6c4730dadd6b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceImplementation with a unique identifier of 787eaf46-7cf2-4096-8d6e-671a0819d57e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceControlLink with a unique identifier of 806933fb-7925-439b-9876-922a960d2ba1 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ZoneGovernance with a unique identifier of 4c4d1d9c-a9fc-4305-8b71-4e891c0f9ae0 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceRuleImplementation with a unique identifier of e701a5c8-c1ba-4b75-8257-e0a6569eda48 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceProcessImplementation with a unique identifier of a5a7b08a-73fd-4026-a9dd-d0fe55bea8a4 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called OrganizationalCapability with a unique identifier of 47f0ad39-db77-41b0-b406-36b1598e0ba7 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ResponsibilityStaffContact with a unique identifier of 49f2ecb5-6bf7-4324-9824-ac98d595c404 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called BusinessCapabilityControls with a unique identifier of b5de932a-738c-4c69-b852-09fec2b9c678 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ProjectCharterLink with a unique identifier of f081808d-545a-41cb-a9aa-c4f074a16c78 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceRoleAssignment with a unique identifier of cb10c107-b7af-475d-aab0-d78b8297b982 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceResponsibilityAssignment with a unique identifier of cb15c107-b7af-475d-aab0-d78b8297b982 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceDefinitionMetric with a unique identifier of e076fbb3-54f5-46b8-8f1e-a7cb7e792673 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GovernanceResults with a unique identifier of 89c3c695-9e8d-4660-9f44-ed971fd55f88 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called License with a unique identifier of 35e53b7f-2312-4d66-ae90-2d4cb47901ee and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called Certification with a unique identifier of 390559eb-6a0c-4dd7-bc95-b9074caffa7f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RegulationCertificationType with a unique identifier of be12ff15-0721-4a7e-8c98-334eaa884bdf and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetSchemaType with a unique identifier of 815b004d-73c6-4728-9dd9-536f4fe803cd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaTypeImplementation with a unique identifier of 6aab4ec6-f0c6-4c40-9f50-ac02a3483358 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AttributeForSchema with a unique identifier of 86b176a2-015c-44a6-8106-54d5d69ba661 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaAttributeType with a unique identifier of 2d955049-e59b-45dd-8e62-cde1add59f9e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called LinkedType with a unique identifier of 292125f7-5660-4533-a48a-478c5611922e and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaLinkToType with a unique identifier of db9583c5-4690-41e5-a580-b4e30a0242d3 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MapFromElementType with a unique identifier of 6189d444-2da4-4cd7-9332-e48a1c340b44 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called MapToElementType with a unique identifier of 8b9856b3-451e-45fc-afc7-fddefd81a73a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaQueryImplementation with a unique identifier of e5d7025d-8b4f-43c7-bcae-1047d650b94a and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called GraphEdgeLink with a unique identifier of 503b4221-71c8-4ba9-8f3d-6a035b27971c and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called ForeignKey with a unique identifier of 3cd4e0e7-fdbf-47a6-ae88-d4b3205e0c07 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIOperations with a unique identifier of 03737169-ceb5-45f0-84f0-21c5929945af and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIHeader with a unique identifier of e8fb46d1-5f75-481b-aa66-f43ad44e2cc6 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIRequest with a unique identifier of 4ab3b466-31bd-48ea-8aa2-75623476f2e2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called APIResponse with a unique identifier of e8001de2-1bb1-442b-a66f-9addc3641eae and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassHierarchy with a unique identifier of 6b947ccc-1a70-4785-9ca3-d6326bc51291 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassComposition with a unique identifier of 767fb343-4699-49c1-a0f8-af6da78505f8 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassAssignment with a unique identifier of 4df37335-7f0c-4ced-82df-3b2fd07be1bd and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SupportedDiscoveryService with a unique identifier of dff45aeb-c65e-428c-9ab3-d756bc5d8dbb and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveryServiceImplementation with a unique identifier of dd2bf14c-9fff-49c2-b29a-1636f4e92672 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetDiscoveryService with a unique identifier of 38713b9e-8561-4a74-a1ba-d50b2facc4c2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveryEngineReport with a unique identifier of 2c318c3a-5dc2-42cd-a933-0087d852f67f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveryInvocationReport with a unique identifier of 1744d72b-903d-4273-9229-de20372a17e2 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AssetDiscoveryReport with a unique identifier of 7eded424-f176-4258-9ae6-138a46b2845f and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveredAnnotation with a unique identifier of 51d386a3-3857-42e3-a3df-14a6cad08b93 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnnotationExtension with a unique identifier of 605aaa6d-682e-405c-964b-ca6aaa94be1b and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called AnnotationReviewLink with a unique identifier of 5d3c2fb7-fa04-4d77-83cb-fd9216a07769 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaTypeDefinition with a unique identifier of 60f2d263-e24d-4f20-8c0d-b5e24648cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveredDataField with a unique identifier of 60f2d263-e24d-4f20-8c0d-b5e22222cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called SchemaAttributeDefinition with a unique identifier of 60f1e263-e24d-4f20-8c0d-b5e21232cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DiscoveredNestedDataField with a unique identifier of 60f2d263-e24d-4f20-8c0d-b5e12356cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataClassDefinition with a unique identifier of 51a2d263-e24d-4f20-8c0d-b5e12356cd54 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataFieldAnalysis with a unique identifier of 833e849d-eda2-40bb-9e6b-c3ca0b56d581 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called DataProfileLogFile with a unique identifier of 75026fac-f9e5-4da8-9ad1-e9c68d47f577 and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0301 The local server has added a new type called RelationshipAnnotation with a unique identifier of 73510abd-49e6-4097-ba4b-23bd3ef15baa and a version number of 1 from ODPi Egeria (OMRS) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0053 The Open Metadata Repository Services (OMRS) has loaded 412 types and 0 instances from open metadata archive Open Metadata Types Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0031 The local repository outbound event manager is starting with 0 type definition event consumer(s) and 0 instance event consumer(s) Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0032 The local repository outbound event manager is sending out the 412 type definition events that were generated and buffered during server initialization Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0007 The Open Metadata Repository Services (OMRS) has initialized Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Data Engine open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Data Engine open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-DATA-ENGINE-0001 The Data Engine Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-DATA-ENGINE-0002 The Data Engine Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Subject Area open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Subject Area open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-SUBJECT-AREA-0001 The Subject Area Open Metadata Access Service (OMAS) is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-SUBJECT-AREA-0002 The Subject Area Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-SUBJECT-AREA-0003 The Subject Area Open Metadata Access Service (OMAS) is initialized Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Governance Engine open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Governance Engine open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-ENGINE-0001 The Governance Engine Open Metadata Access Service (OMAS) is initializing Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0001 Connecting to Apache Kafka Topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic with a server identifier of 2a73902e-e691-43cc-b422-23b6b42992e2 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0003 The properties passed to the Apache Kafka Consumer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic are: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.partition.fetch.bytes=10485760, auto.commit.interval.ms=1000, bootstrap.servers=localhost:9092, group.id=2a73902e-e691-43cc-b422-23b6b42992e2, enable.auto.commit=true, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, session.timeout.ms=30000} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0002 The properties passed to the Apache Kafka Producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic are: {retries=1, bootstrap.servers=localhost:9092, linger.ms=0, acks=all, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=33554432, batch.size=16384, key.serializer=org.apache.kafka.common.serialization.StringSerializer} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0010 The Apache Kafka producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic is starting up with 0 buffered messages Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Governance Engine.outTopic has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-ENGINE-0002 The Governance Engine Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server instance cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-ENGINE-0003 The Governance Engine Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Governance Program open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Governance Program open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-PROGRAM-0001 The Governance Program Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-PROGRAM-0002 The Governance Program Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-GOVERNANCE-PROGRAM-0003 The Governance Program Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Information View open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Information View open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0001 The Information View Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0002 The Information View Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0003 The Information View Open Metadata Access Service (OMAS) is registering a listener with the Information View In topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0001 Connecting to Apache Kafka Topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic with a server identifier of 2a73902e-e691-43cc-b422-23b6b42992e2 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0003 The properties passed to the Apache Kafka Consumer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic are: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.partition.fetch.bytes=10485760, auto.commit.interval.ms=1000, bootstrap.servers=localhost:9092, group.id=2a73902e-e691-43cc-b422-23b6b42992e2, enable.auto.commit=true, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, session.timeout.ms=30000} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0002 The properties passed to the Apache Kafka Producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic are: {retries=1, bootstrap.servers=localhost:9092, linger.ms=0, acks=all, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=33554432, batch.size=16384, key.serializer=org.apache.kafka.common.serialization.StringSerializer} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0010 The Apache Kafka producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic is starting up with 0 buffered messages Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0004 The Information View Open Metadata Access Service (OMAS) is registering a publisher with the Information View Out topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.inTopic has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0001 Connecting to Apache Kafka Topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic with a server identifier of 2a73902e-e691-43cc-b422-23b6b42992e2 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0003 The properties passed to the Apache Kafka Consumer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic are: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.partition.fetch.bytes=10485760, auto.commit.interval.ms=1000, bootstrap.servers=localhost:9092, group.id=2a73902e-e691-43cc-b422-23b6b42992e2, enable.auto.commit=true, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, session.timeout.ms=30000} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0002 The properties passed to the Apache Kafka Producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic are: {retries=1, bootstrap.servers=localhost:9092, linger.ms=0, acks=all, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=33554432, batch.size=16384, key.serializer=org.apache.kafka.common.serialization.StringSerializer} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0010 The Apache Kafka producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic is starting up with 0 buffered messages Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Information View.outTopic has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-INFORMATION-VIEW-0005 The Information View Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Asset Consumer open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Asset Consumer open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CONSUMER-0001 The Asset Consumer Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CONSUMER-0002 The Asset Consumer Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0001 Connecting to Apache Kafka Topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic with a server identifier of 2a73902e-e691-43cc-b422-23b6b42992e2 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0003 The properties passed to the Apache Kafka Consumer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic are: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, max.partition.fetch.bytes=10485760, auto.commit.interval.ms=1000, bootstrap.servers=localhost:9092, group.id=2a73902e-e691-43cc-b422-23b6b42992e2, enable.auto.commit=true, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, session.timeout.ms=30000} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0002 The properties passed to the Apache Kafka Producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic are: {retries=1, bootstrap.servers=localhost:9092, linger.ms=0, acks=all, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=33554432, batch.size=16384, key.serializer=org.apache.kafka.common.serialization.StringSerializer} Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CONSUMER-0003 The Asset Consumer Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OCF-KAFKA-TOPIC-CONNECTOR-0010 The Apache Kafka producer for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic is starting up with 0 buffered messages Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic egeriaTopics.server.cocoMDS1.open-metadata.access-services.Asset Consumer.outTopic has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Connected Asset open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Connected Asset open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-CONNECTED-ASSET-0001 The Connected Asset Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-CONNECTED-ASSET-0002 The Connected Asset Open Metadata Access Service (OMAS) is registering a listener with the OMRS Topic for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-CONNECTED-ASSET-0003 The Connected Asset Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0040 An enterprise OMRS connector has been created for the Asset Catalog open metadata access service Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0041 The enterprise OMRS connector for the Asset Catalog open metadata access service has started Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CATALOG-0001 The Asset Catalog Open Metadata Access Service (OMAS) is initializing a new server instance Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMAS-ASSET-CATALOG-0003 The Asset Catalog Open Metadata Access Service (OMAS) has initialized a new instance for server cocoMDS1 Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0019 The OMRS Topic Connector EnterpriseTopicConnector.Server.cocoMDS1 has registered with an event bus connector connected to topic cocoMDS1.open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0020 The OMRS Topic Connector EnterpriseTopicConnector.Server.cocoMDS1 is ready to send and receive events Tue Feb 05 16:14:27 GMT 2019 cocoMDS1 OMRS-AUDIT-0015 The listener thread for an OMRS Topic Connector for topic cocoMDS1.open-metadata.repository-services.enterprise.cocoMDS1.OMRSTopic has started","title":"Activating OMAG servers in the OMAG server platform"},{"location":"education/tutorials/omag-server-tutorial/task-starting-omag-server/#further-reading","text":"The contents of this tutorial covered a single OMAG server. For instructions on how to set up two OMAG Servers using in memory repositories that are exchanging metadata over Apache Kafka , see: In Memory Repository Demo","title":"Further reading"},{"location":"education/tutorials/omag-server-tutorial/task-starting-omag-server/#next-steps","text":"Now the OMAG Server is running you are ready to start calling the open metadata and governance services .","title":"Next steps"},{"location":"education/tutorials/omag-server-tutorial/task-starting-the-omag-server-platform/","text":"Starting the OMAG Server Platform \u00b6 The OMAG Server Platform's installation directory contains a Java Archive (Jar) file for the server platform itself along with a directory of resources. $ ls resources server-chassis-spring-3.3-SNAPSHOT.jar The name of the Java Archive (Jar) file will depend on the release of ODPi Egeria that you have installed. In this example, the release is 3.3-SNAPSHOT . The OMAG Server Platform is started with the java command. Ensure you have a Java runtime at Version 8 (Update 151) or above installed on your machine. Check the version of Java you have with the command java -version (You can download Java from Adoptium and select OpenJDK 11 (LTS) and the HotSpot version for your operating system. You only need the JRE but select the JDK if you expect to also write some Java code.) Start the OMAG server platform as follows - the -Dserver.port option is needed if you want multiple instances running on different ports, as required by the tutorials. You should be in the main distribution directory as setup when installing the server. $ java -Dserver.port = 9443 -jar server/server-chassis-spring-3.3-SNAPSHOT.jar The OMAG server platform first displays this banner and then initializes itself. ODPi Egeria ____ __ ___ ___ ______ _____ ____ _ _ ___ / __ \\ / |/ // | / ____/ / ___/ ___ ____ _ __ ___ ____ / _ \\ / / __ / / / _ /__ ____ _ _ / / / // /|_/ // /| | / / __ \\__ \\ / _ \\ / __/| | / // _ \\ / __/ / /_/ // // | / _\\ / /_ / | / _// || | / /_/ // / / // ___ |/ /_/ / ___/ // __// / | |/ // __// / / __ // // / \\ / /_ / _// / // / / / / / \\____//_/ /_//_/ |_|\\____/ /____/ \\___//_/ |___/ \\___//_/ /_/ /_/ \\__/\\//___//_/ \\__//_/ /_/ /_/ :: Powered by Spring Boot (v2.1.2.RELEASE) :: When the initialization is complete, you will see this message: timestamp OMAG server platform ready for more configuration This means your OMAG server platform is running. If you get an error that the port is in use, check for any applications using the same port. Try the following command (replace 9443 accordingly if using a non standard port): $ curl --insecure -X GET https://localhost:9443/open-metadata/platform-services/users/test/server-platform/origin Egeria OMAG Server Platform This calls the OMAG server platform using a REST API call. The response Egeria OMAG Server Platform means the curl command communicated with a running OMAG server platform instance. The OMAG server platform has many REST APIs. Enter https://localhost:9443/swagger-ui.html into your browser to see the list of available REST APIs. Broadly speaking, the OMAG server platform supports * Administration services and * Open metadata and governance services. The administration services (the ones beginning config and operational ) are available all of the time the OMAG server platform is running. The open metadata and governance services are routed to the OMAG Servers running on the OMAG server platform. OMAG servers are started on the server platform using a configuration document . This configuration document is both configured and activated in the OMAG server platform using the administration services. Understanding how to create a configuration document using the administration services is the next task in this tutorial .","title":"Task starting the omag server platform"},{"location":"education/tutorials/omag-server-tutorial/task-starting-the-omag-server-platform/#starting-the-omag-server-platform","text":"The OMAG Server Platform's installation directory contains a Java Archive (Jar) file for the server platform itself along with a directory of resources. $ ls resources server-chassis-spring-3.3-SNAPSHOT.jar The name of the Java Archive (Jar) file will depend on the release of ODPi Egeria that you have installed. In this example, the release is 3.3-SNAPSHOT . The OMAG Server Platform is started with the java command. Ensure you have a Java runtime at Version 8 (Update 151) or above installed on your machine. Check the version of Java you have with the command java -version (You can download Java from Adoptium and select OpenJDK 11 (LTS) and the HotSpot version for your operating system. You only need the JRE but select the JDK if you expect to also write some Java code.) Start the OMAG server platform as follows - the -Dserver.port option is needed if you want multiple instances running on different ports, as required by the tutorials. You should be in the main distribution directory as setup when installing the server. $ java -Dserver.port = 9443 -jar server/server-chassis-spring-3.3-SNAPSHOT.jar The OMAG server platform first displays this banner and then initializes itself. ODPi Egeria ____ __ ___ ___ ______ _____ ____ _ _ ___ / __ \\ / |/ // | / ____/ / ___/ ___ ____ _ __ ___ ____ / _ \\ / / __ / / / _ /__ ____ _ _ / / / // /|_/ // /| | / / __ \\__ \\ / _ \\ / __/| | / // _ \\ / __/ / /_/ // // | / _\\ / /_ / | / _// || | / /_/ // / / // ___ |/ /_/ / ___/ // __// / | |/ // __// / / __ // // / \\ / /_ / _// / // / / / / / \\____//_/ /_//_/ |_|\\____/ /____/ \\___//_/ |___/ \\___//_/ /_/ /_/ \\__/\\//___//_/ \\__//_/ /_/ /_/ :: Powered by Spring Boot (v2.1.2.RELEASE) :: When the initialization is complete, you will see this message: timestamp OMAG server platform ready for more configuration This means your OMAG server platform is running. If you get an error that the port is in use, check for any applications using the same port. Try the following command (replace 9443 accordingly if using a non standard port): $ curl --insecure -X GET https://localhost:9443/open-metadata/platform-services/users/test/server-platform/origin Egeria OMAG Server Platform This calls the OMAG server platform using a REST API call. The response Egeria OMAG Server Platform means the curl command communicated with a running OMAG server platform instance. The OMAG server platform has many REST APIs. Enter https://localhost:9443/swagger-ui.html into your browser to see the list of available REST APIs. Broadly speaking, the OMAG server platform supports * Administration services and * Open metadata and governance services. The administration services (the ones beginning config and operational ) are available all of the time the OMAG server platform is running. The open metadata and governance services are routed to the OMAG Servers running on the OMAG server platform. OMAG servers are started on the server platform using a configuration document . This configuration document is both configured and activated in the OMAG server platform using the administration services. Understanding how to create a configuration document using the administration services is the next task in this tutorial .","title":"Starting the OMAG Server Platform"},{"location":"education/tutorials/omag-server-tutorial/task-working-with-postman/","text":"Working with Postman \u00b6 Postman is a test tool that allows you to type in calls to REST APIs . Basically a REST API is an application program interface (API) that uses HTTP requests to GET, PUT, POST and DELETE data. The call is made using a URL - just like requesting a web page from your browser. In fact, when you request a web page from your browser, the browser is issuing a GET HTTP request for the page. REST APIs for services such as the open metadata and governance services of ODPi Egeria use the full range of HTTP requests as follows: GET - retrieving simple structures. PUT - creating simple structures. POST - creating, updating, deleting complex structures and retrieving long lists of information with paging. DELETE - deleting simple structures. With Postman it is possible issue these HTTP requests and experiment with what they do. It also supports collections of requests. We use Postman collections in tutorials to illustrate the calls and save you typing in the full URLs (which can be quite long :). Egeria by default uses https:// requests with a self-signed certificate. Any PostMan users therefore will need to go into settings->general and turn off 'SSL certificate verification' or requests will fail. Postman is a free download with optional enterprise licenses for teams. It includes a wide variety of tutorials to help you go from novice to expert. Familiarity with Postman will help you get the most value from the Egeria tutorials.","title":"Task working with postman"},{"location":"education/tutorials/omag-server-tutorial/task-working-with-postman/#working-with-postman","text":"Postman is a test tool that allows you to type in calls to REST APIs . Basically a REST API is an application program interface (API) that uses HTTP requests to GET, PUT, POST and DELETE data. The call is made using a URL - just like requesting a web page from your browser. In fact, when you request a web page from your browser, the browser is issuing a GET HTTP request for the page. REST APIs for services such as the open metadata and governance services of ODPi Egeria use the full range of HTTP requests as follows: GET - retrieving simple structures. PUT - creating simple structures. POST - creating, updating, deleting complex structures and retrieving long lists of information with paging. DELETE - deleting simple structures. With Postman it is possible issue these HTTP requests and experiment with what they do. It also supports collections of requests. We use Postman collections in tutorials to illustrate the calls and save you typing in the full URLs (which can be quite long :). Egeria by default uses https:// requests with a self-signed certificate. Any PostMan users therefore will need to go into settings->general and turn off 'SSL certificate verification' or requests will fail. Postman is a free download with optional enterprise licenses for teams. It includes a wide variety of tutorials to help you go from novice to expert. Familiarity with Postman will help you get the most value from the Egeria tutorials.","title":"Working with Postman"},{"location":"features/","text":"Egeria features \u00b6 The Egeria features describe the value-add features that Egeria adds to its ability to synchronize metadata between different tools and catalogues.","title":"Index"},{"location":"features/#egeria-features","text":"The Egeria features describe the value-add features that Egeria adds to its ability to synchronize metadata between different tools and catalogues.","title":"Egeria features"},{"location":"features/anchor-management/overview/","text":"Anchors \u00b6 Anchors are Referenceable metadata entities that group other entities together. They act like containers. This means, for example, if the anchor entity is deleted then the entities anchored to this entity are also deleted. The value of establishing this grouping is to ensure that entities that have little meaning without their anchor entity are cleaned up properly and are not left to uselessly clutter the repository. For example, if a personal message is attached to a personal profile then that personal profile is its anchor. If the personal profile is deleted then the personal message is deleted too. Anchored entities are also bound by the visibility and security restrictions of their anchor. For example, Asset visibility is controlled by Governance Zones . An Asset is only visible through a service if it is a member of that service's supportedZones . Similarly authorization to perform specific operations on an Asset is granted by the Open Metadata Security Services . When a SchemaType is attached to an Asset, it is anchored to that Asset. Subsequent requests to read or update the SchemaType will result in visibility and authorization checks for the requesting user being made with respect to its Asset anchor. The anchor grouping is limited to particular types of metadata entities that are only meaningful in the context of their anchor entity. So not all metadata entities linked to an anchor are anchored to it. They have an independent existence and may be linked to many anchors, without obligation. For example, a personal profile may contain links to specific \"favorite\" Assets. When the personal profile is deleted, the assets are not effected - except that they loose their relationship to the personal profile. LatestChange and Anchors classification \u00b6 The LatestChange classification is attached to each anchor Referenceable. It is used to record the latest change to this anchor or any of the entities anchored to it. So for example, if a hierarchy of SchemaElements, or a hierarchy of Comments (all Referenceables) were anchored to an Asset (also a Referenceable), then the LatestChange classification goes on the Asset and records changes to any of these entities. This includes changing property values, attaching or detaching entities through relationships as well ans any changes to their classifications. Maintaining \"LatestChanges\" on Asset means that it is easier to monitor for changes affecting the Asset and any of its anchored entities. However it also means that it must be easy to located the Asset from any of the anchored entities when they change, even though they may not be directly connected. The Anchors classification makes it easier to find the anchor entity. It is attached to any entity anchored to a Referenceable. In the example above, Anchors would be on all of the SchemaElements and Comments. Anchors would contain the unique identifier (guid) of the anchor Referenceable. There is also the unique identifier (guid) of the SchemaType at the root of a schema structure and the unique identifier (guid) of the Comment at root of a comment tree to make it easier to process these elements as a group. Figure 1 shows an example Asset with a number of entities anchored to it. The entities that have the Anchors classification are those that are anchored to the Asset. This includes entities such as Ratings, Likes and Attachments (from the Open Discovery Framework ( ODF ) . It is worthwhile maintaining the Anchors classification because reads of and updates to the anchored entities will happen many times, and it is rare that an anchored entity will change its anchor during its life time. Figure 1: Examples of dependent entities that are anchored to an Asset If a GlossaryTerm, or InformalTag is attached to the Asset, they are not anchored to it. GlossaryTerms and InformalTags are independent entities. They are not anchored to the Asset and hence do not have an Anchors classification. Any change to these entities does not reflect in the LatestChange classification of the Asset. However, the act of attaching them to, or detaching them from the Asset is recorded in the Asset's LatestChange classification. Since the GlossaryTerm is also an anchor, when the GlossaryTerm and the Asset are linked together, this change is reflected in both of their LatestChange classifications because they are both Referenceable anchors. NoteLogs are Referenceables that can be attached to many other Referenceables. They can be set up either to be anchored with a single Referenceable or to be their own anchor to allow then to be attached to and detached from many Referenceables over its lifetime. For example, these are cases where the NoteLog is anchored to another Referenceable NoteLogs are used to support the personal blog linked off of the Personal Profile in Community Profile OMAS . Assets may have a NoteLog to record \"news\" for consumers such as planned maintenance and unexpected situations. Egeria uses the Anchors classification on a NoteLog to indicate that the NoteLog is tied to the Referenceable it is attached to. The presence of this classification would prevent it from being linked to another Referenceable. Figure 2 illustrates additional objects connecting to an asset that do not have the Anchors classification because they are not anchored to the Asset. Also notice there are two NoteLogs attached to the asset, one with the Anchors classification and one without. The one with the Anchors classification is anchored to the the Asset. The one without the Anchors classification is independent of the Asset. Figure 2: Examples of other types of entities that are linked to an Asset but not necessarily anchored there Further information \u00b6 Generic Handlers provide support for the Anchors and LatestChange classifications. Open Metadata Type definitions for LatestChange and Anchors classification Open Metadata security checks for Assets and Connections Governance Zones and Assets","title":"Anchor Management"},{"location":"features/anchor-management/overview/#anchors","text":"Anchors are Referenceable metadata entities that group other entities together. They act like containers. This means, for example, if the anchor entity is deleted then the entities anchored to this entity are also deleted. The value of establishing this grouping is to ensure that entities that have little meaning without their anchor entity are cleaned up properly and are not left to uselessly clutter the repository. For example, if a personal message is attached to a personal profile then that personal profile is its anchor. If the personal profile is deleted then the personal message is deleted too. Anchored entities are also bound by the visibility and security restrictions of their anchor. For example, Asset visibility is controlled by Governance Zones . An Asset is only visible through a service if it is a member of that service's supportedZones . Similarly authorization to perform specific operations on an Asset is granted by the Open Metadata Security Services . When a SchemaType is attached to an Asset, it is anchored to that Asset. Subsequent requests to read or update the SchemaType will result in visibility and authorization checks for the requesting user being made with respect to its Asset anchor. The anchor grouping is limited to particular types of metadata entities that are only meaningful in the context of their anchor entity. So not all metadata entities linked to an anchor are anchored to it. They have an independent existence and may be linked to many anchors, without obligation. For example, a personal profile may contain links to specific \"favorite\" Assets. When the personal profile is deleted, the assets are not effected - except that they loose their relationship to the personal profile.","title":"Anchors"},{"location":"features/anchor-management/overview/#latestchange-and-anchors-classification","text":"The LatestChange classification is attached to each anchor Referenceable. It is used to record the latest change to this anchor or any of the entities anchored to it. So for example, if a hierarchy of SchemaElements, or a hierarchy of Comments (all Referenceables) were anchored to an Asset (also a Referenceable), then the LatestChange classification goes on the Asset and records changes to any of these entities. This includes changing property values, attaching or detaching entities through relationships as well ans any changes to their classifications. Maintaining \"LatestChanges\" on Asset means that it is easier to monitor for changes affecting the Asset and any of its anchored entities. However it also means that it must be easy to located the Asset from any of the anchored entities when they change, even though they may not be directly connected. The Anchors classification makes it easier to find the anchor entity. It is attached to any entity anchored to a Referenceable. In the example above, Anchors would be on all of the SchemaElements and Comments. Anchors would contain the unique identifier (guid) of the anchor Referenceable. There is also the unique identifier (guid) of the SchemaType at the root of a schema structure and the unique identifier (guid) of the Comment at root of a comment tree to make it easier to process these elements as a group. Figure 1 shows an example Asset with a number of entities anchored to it. The entities that have the Anchors classification are those that are anchored to the Asset. This includes entities such as Ratings, Likes and Attachments (from the Open Discovery Framework ( ODF ) . It is worthwhile maintaining the Anchors classification because reads of and updates to the anchored entities will happen many times, and it is rare that an anchored entity will change its anchor during its life time. Figure 1: Examples of dependent entities that are anchored to an Asset If a GlossaryTerm, or InformalTag is attached to the Asset, they are not anchored to it. GlossaryTerms and InformalTags are independent entities. They are not anchored to the Asset and hence do not have an Anchors classification. Any change to these entities does not reflect in the LatestChange classification of the Asset. However, the act of attaching them to, or detaching them from the Asset is recorded in the Asset's LatestChange classification. Since the GlossaryTerm is also an anchor, when the GlossaryTerm and the Asset are linked together, this change is reflected in both of their LatestChange classifications because they are both Referenceable anchors. NoteLogs are Referenceables that can be attached to many other Referenceables. They can be set up either to be anchored with a single Referenceable or to be their own anchor to allow then to be attached to and detached from many Referenceables over its lifetime. For example, these are cases where the NoteLog is anchored to another Referenceable NoteLogs are used to support the personal blog linked off of the Personal Profile in Community Profile OMAS . Assets may have a NoteLog to record \"news\" for consumers such as planned maintenance and unexpected situations. Egeria uses the Anchors classification on a NoteLog to indicate that the NoteLog is tied to the Referenceable it is attached to. The presence of this classification would prevent it from being linked to another Referenceable. Figure 2 illustrates additional objects connecting to an asset that do not have the Anchors classification because they are not anchored to the Asset. Also notice there are two NoteLogs attached to the asset, one with the Anchors classification and one without. The one with the Anchors classification is anchored to the the Asset. The one without the Anchors classification is independent of the Asset. Figure 2: Examples of other types of entities that are linked to an Asset but not necessarily anchored there","title":"LatestChange and Anchors classification"},{"location":"features/anchor-management/overview/#further-information","text":"Generic Handlers provide support for the Anchors and LatestChange classifications. Open Metadata Type definitions for LatestChange and Anchors classification Open Metadata security checks for Assets and Connections Governance Zones and Assets","title":"Further information"},{"location":"features/cohort-operation/overview/","text":"Open Metadata Repository Cohort Operation \u00b6 An Open Metadata Repository Cohort (or more simply, just a cohort ) is a collection of servers sharing metadata using a peer-to-peer exchange. Once a server becomes a member of the cohort, it can share metadata with, and receive metadata from, any other member either through events, or through federated queries. Formation of a cohort \u00b6 Cohort membership is established dynamically. This is through the cohort topic(s) . First server \u00b6 To join an open metadata repository cohort, a server must integrate with the OMRS module. OMRS then manages the metadata exchange. When OMRS running inside the server is configured to join a cohort it first adds a registration event to the cohort topic(s). This event identifies the server, its metadata repository (if any) and its capabilities. Figure 1: The first server to join the cohort issues a registration request and waits for others to join. Subsequent servers \u00b6 When another server joins the cohort, it also adds its registration event to the cohort topic(s) and begins to receive the registration events from other members. The other members respond with re-registration events to ensure the new member has the latest information about the originator's capabilities. The exchange of registration information causes all members to verify that they have the latest information about their peers. This is maintained in their own cohort registry store so that they can reconfigure themselves on restart without needing the other members to resend their registration information. Figure 2: When another server joins the cohort they exchange registration information. Peer-to-peer operation \u00b6 Once the registration information is exchanged and stored in each member's cohort registry store, it is ready to issue federated queries across the cohort, and respond to requests for metadata from other members. These requests can both retrieve metadata and maintain metadata in the home metadata repository . The management of federated queries and the routing of maintenance requests is managed by OMRS 's enterprise repository services . The enterprise repository services are configured with the registration information from across the cohort at the same time as the cohort registry store is updated. This process is managed by the cohort registry . The registration information includes the URL Root and server name of the member. The federation capability in each member allows it to issue metadata create, update, delete and search requests to each and every member of the cohort. Figure 3: Once the registration is complete the cohort members can issue federated queries. Primary mechanism for accessing metadata This peer-to-peer operation and federated queries are the primary mechanism for accessing metadata, because the access services use federated queries for every request they make for metadata. Metadata exchange \u00b6 Once the cohort membership is established, the server begins publishing information using instance events about changes to the home metadata instances in their repository. These events can be used by other members to maintain a cache of reference copies of this metadata to improve availability of the metadata and retrieval performance. Updates to this metadata will, however, be automatically routed to the home repository by the enterprise repository services: Figure 4: Metadata can also be replicated through the cohort to allow caching for availability and performance. Metadata refresh A member may also request that metadata is \"refreshed\" across the cohort. The originator of the requested metadata then sends the latest version of this metadata to the rest of the cohort through the cohort topic. This mechanism is useful to seed the cache in a new member of the cohort and is invoked as a result of a federated query issued from any cohort member. Dynamic changes to types \u00b6 Finally, as type definitions (TypeDefs) are added and updated, the cohort members send out events to allow the other members to verify that this type does not conflict with any of their types. Any conflicts in the types causes audit log messages to be logged in all members, prompting action to resolve the conflicts. Figure 5: TypeDef validation. Leaving the cohort \u00b6 When an OMAG Server permanently leaves the cohort, it sends an unregistration request. This enables the other members to remove the parting member from their registries. Enabling cohort membership \u00b6 Egeria provides a number of pre-built cohort members . One of them, the repository proxy provides a simple way to integrate a third party server into a cohort by creating an OMRS Repository Connector and optional Event Mapper Connector to map between the third party APIs/events and the repository service's equivalents A more bespoke integration involves: Creating an OMRS repository connector and optional event mapper connector Designing how to configure the OMRS Services for your metadata repository. Typically, this is done by extending the existing administration services of the metadata repository, but Egeria also offers some pre-built administration services that can be used or modified. Plugging the OMRS and any administration services into the metadata repository's security module so that requests to the server can be secured against unauthorized access. Integrating the OMRS , administration and security capability into your product. There are different integration patterns available to help you choose the best approach for your product. Each method is optimized for specific use cases and so the metadata repository can only play a full role in the open metadata use cases if it supports all integration methods. These are: Support for an OMRS repository connector to allow open metadata API calls to the repository to create, query, update and delete metadata stored in the repository. The OMRS connectors support the Open Connector Framework ( OCF ) to provide a call interface to the metadata repositories. The OMRS Repository Connector API is a standard interface for all metadata repositories. This enables services such as the Enterprise OMRS Repository Connector to interact with 1 or many metadata repositories through the same interface. The connection configuration it passes to the OCF determines which type of OMRS connector is returned by the OCF . Support for the OMRS event notifications that are used to synchronize selective metadata between the metadata repositories. Cohort members \u00b6 A cohort member is an OMAG Server that is registered with at least one open metadata repository cohort. Management of a server's membership is handled by the cohort services . The exchange of metadata uses the Open Metadata Repository Services ( OMRS ) interfaces which gives fine-grained 1 metadata notifications and updates. During server start up, the repository services detect the configuration of at least one cohort and starts the metadata highway manager . The metadata highway manager creates a cohort manager for each cohort configuration. The cohort manager manages the initialization and shutdown of the server's connectivity to a cohort, including the management of the cohort registry . The server's metadata security connector provides fine-grained control on which metadata is sent, received and/or stored by the server. This level of control is necessary for metadata repositories that are managing specific collections of valuable objects such as Assets . The types of cohort members include: Metadata server Metadata access point Repository proxy Conformance test server Explore hands-on The administration hands-on lab called \"Understanding Cohort Configuration Lab\" provides an opportunity to query the cohort registries of cohort members as they exchange metadata for Coco Pharmaceuticals. Cohort registration \u00b6 Each repository in the cohort has a cohort registry that supports the registration of the metadata repositories across the cohort. Through the registration process, each cohort registry assembles a list of all members of the cohort. This is saved in the cohort registry store . The list of connections to the remote members of the cohort are passed to the OMRS Enterprise Connector Manager that in turn manages the configuration of the Enterprise OMRS Repository Connectors. The Enterprise OMRS Connector provides federated query support across the metadata cohort for the Open Metadata Access Services ( OMAS ) . When a metadata repository registers with the cohort registry , the administrator may either supply a unique server identifier, or ask the OMRS to generate one. This server identifier (the metadata collection id ) is used in the OMRS event notifications, and on OMRS repository connector calls to identify the location of the home copy of the metadata entities and to identify which repository is requesting a service or supports a particular function. Once the metadata repository has registered with the cohort registry , it is a member of the metadata repository cohort and can synchronize and share metadata with other repositories in the cohort through the cohort topic(s) . Registering with multiple cohorts A single metadata repository can register with multiple metadata cohorts as long as its server identifier is unique across all cohorts that it joins and it manages the posting of events to the appropriate OMRS topic for each cohort it registers with. This capability is useful for a metadata repository that is aggregating reference copies of metadata from multiple open metadata repository cohorts. Cohort registry \u00b6 The cohort registry resides in each cohort member . It is responsible for registering a member with a specific open metadata repository cohort and maintaining a list of the other members of this cohort. The registration process is managed by exchanging registry events over the cohort topic(s) . The cohort registry maintains its record of the membership of the cohort in a cohort registry store . You may want to see the OMRS metamodel for more details on the granularity of metadata exchange. \u21a9","title":"Cohort Operation"},{"location":"features/cohort-operation/overview/#open-metadata-repository-cohort-operation","text":"An Open Metadata Repository Cohort (or more simply, just a cohort ) is a collection of servers sharing metadata using a peer-to-peer exchange. Once a server becomes a member of the cohort, it can share metadata with, and receive metadata from, any other member either through events, or through federated queries.","title":"Open Metadata Repository Cohort Operation"},{"location":"features/cohort-operation/overview/#formation-of-a-cohort","text":"Cohort membership is established dynamically. This is through the cohort topic(s) .","title":"Formation of a cohort"},{"location":"features/cohort-operation/overview/#first-server","text":"To join an open metadata repository cohort, a server must integrate with the OMRS module. OMRS then manages the metadata exchange. When OMRS running inside the server is configured to join a cohort it first adds a registration event to the cohort topic(s). This event identifies the server, its metadata repository (if any) and its capabilities. Figure 1: The first server to join the cohort issues a registration request and waits for others to join.","title":"First server"},{"location":"features/cohort-operation/overview/#subsequent-servers","text":"When another server joins the cohort, it also adds its registration event to the cohort topic(s) and begins to receive the registration events from other members. The other members respond with re-registration events to ensure the new member has the latest information about the originator's capabilities. The exchange of registration information causes all members to verify that they have the latest information about their peers. This is maintained in their own cohort registry store so that they can reconfigure themselves on restart without needing the other members to resend their registration information. Figure 2: When another server joins the cohort they exchange registration information.","title":"Subsequent servers"},{"location":"features/cohort-operation/overview/#peer-to-peer-operation","text":"Once the registration information is exchanged and stored in each member's cohort registry store, it is ready to issue federated queries across the cohort, and respond to requests for metadata from other members. These requests can both retrieve metadata and maintain metadata in the home metadata repository . The management of federated queries and the routing of maintenance requests is managed by OMRS 's enterprise repository services . The enterprise repository services are configured with the registration information from across the cohort at the same time as the cohort registry store is updated. This process is managed by the cohort registry . The registration information includes the URL Root and server name of the member. The federation capability in each member allows it to issue metadata create, update, delete and search requests to each and every member of the cohort. Figure 3: Once the registration is complete the cohort members can issue federated queries. Primary mechanism for accessing metadata This peer-to-peer operation and federated queries are the primary mechanism for accessing metadata, because the access services use federated queries for every request they make for metadata.","title":"Peer-to-peer operation"},{"location":"features/cohort-operation/overview/#metadata-exchange","text":"Once the cohort membership is established, the server begins publishing information using instance events about changes to the home metadata instances in their repository. These events can be used by other members to maintain a cache of reference copies of this metadata to improve availability of the metadata and retrieval performance. Updates to this metadata will, however, be automatically routed to the home repository by the enterprise repository services: Figure 4: Metadata can also be replicated through the cohort to allow caching for availability and performance. Metadata refresh A member may also request that metadata is \"refreshed\" across the cohort. The originator of the requested metadata then sends the latest version of this metadata to the rest of the cohort through the cohort topic. This mechanism is useful to seed the cache in a new member of the cohort and is invoked as a result of a federated query issued from any cohort member.","title":"Metadata exchange"},{"location":"features/cohort-operation/overview/#dynamic-changes-to-types","text":"Finally, as type definitions (TypeDefs) are added and updated, the cohort members send out events to allow the other members to verify that this type does not conflict with any of their types. Any conflicts in the types causes audit log messages to be logged in all members, prompting action to resolve the conflicts. Figure 5: TypeDef validation.","title":"Dynamic changes to types"},{"location":"features/cohort-operation/overview/#leaving-the-cohort","text":"When an OMAG Server permanently leaves the cohort, it sends an unregistration request. This enables the other members to remove the parting member from their registries.","title":"Leaving the cohort"},{"location":"features/cohort-operation/overview/#enabling-cohort-membership","text":"Egeria provides a number of pre-built cohort members . One of them, the repository proxy provides a simple way to integrate a third party server into a cohort by creating an OMRS Repository Connector and optional Event Mapper Connector to map between the third party APIs/events and the repository service's equivalents A more bespoke integration involves: Creating an OMRS repository connector and optional event mapper connector Designing how to configure the OMRS Services for your metadata repository. Typically, this is done by extending the existing administration services of the metadata repository, but Egeria also offers some pre-built administration services that can be used or modified. Plugging the OMRS and any administration services into the metadata repository's security module so that requests to the server can be secured against unauthorized access. Integrating the OMRS , administration and security capability into your product. There are different integration patterns available to help you choose the best approach for your product. Each method is optimized for specific use cases and so the metadata repository can only play a full role in the open metadata use cases if it supports all integration methods. These are: Support for an OMRS repository connector to allow open metadata API calls to the repository to create, query, update and delete metadata stored in the repository. The OMRS connectors support the Open Connector Framework ( OCF ) to provide a call interface to the metadata repositories. The OMRS Repository Connector API is a standard interface for all metadata repositories. This enables services such as the Enterprise OMRS Repository Connector to interact with 1 or many metadata repositories through the same interface. The connection configuration it passes to the OCF determines which type of OMRS connector is returned by the OCF . Support for the OMRS event notifications that are used to synchronize selective metadata between the metadata repositories.","title":"Enabling cohort membership"},{"location":"features/cohort-operation/overview/#cohort-members","text":"A cohort member is an OMAG Server that is registered with at least one open metadata repository cohort. Management of a server's membership is handled by the cohort services . The exchange of metadata uses the Open Metadata Repository Services ( OMRS ) interfaces which gives fine-grained 1 metadata notifications and updates. During server start up, the repository services detect the configuration of at least one cohort and starts the metadata highway manager . The metadata highway manager creates a cohort manager for each cohort configuration. The cohort manager manages the initialization and shutdown of the server's connectivity to a cohort, including the management of the cohort registry . The server's metadata security connector provides fine-grained control on which metadata is sent, received and/or stored by the server. This level of control is necessary for metadata repositories that are managing specific collections of valuable objects such as Assets . The types of cohort members include: Metadata server Metadata access point Repository proxy Conformance test server Explore hands-on The administration hands-on lab called \"Understanding Cohort Configuration Lab\" provides an opportunity to query the cohort registries of cohort members as they exchange metadata for Coco Pharmaceuticals.","title":"Cohort members"},{"location":"features/cohort-operation/overview/#cohort-registration","text":"Each repository in the cohort has a cohort registry that supports the registration of the metadata repositories across the cohort. Through the registration process, each cohort registry assembles a list of all members of the cohort. This is saved in the cohort registry store . The list of connections to the remote members of the cohort are passed to the OMRS Enterprise Connector Manager that in turn manages the configuration of the Enterprise OMRS Repository Connectors. The Enterprise OMRS Connector provides federated query support across the metadata cohort for the Open Metadata Access Services ( OMAS ) . When a metadata repository registers with the cohort registry , the administrator may either supply a unique server identifier, or ask the OMRS to generate one. This server identifier (the metadata collection id ) is used in the OMRS event notifications, and on OMRS repository connector calls to identify the location of the home copy of the metadata entities and to identify which repository is requesting a service or supports a particular function. Once the metadata repository has registered with the cohort registry , it is a member of the metadata repository cohort and can synchronize and share metadata with other repositories in the cohort through the cohort topic(s) . Registering with multiple cohorts A single metadata repository can register with multiple metadata cohorts as long as its server identifier is unique across all cohorts that it joins and it manages the posting of events to the appropriate OMRS topic for each cohort it registers with. This capability is useful for a metadata repository that is aggregating reference copies of metadata from multiple open metadata repository cohorts.","title":"Cohort registration"},{"location":"features/cohort-operation/overview/#cohort-registry","text":"The cohort registry resides in each cohort member . It is responsible for registering a member with a specific open metadata repository cohort and maintaining a list of the other members of this cohort. The registration process is managed by exchanging registry events over the cohort topic(s) . The cohort registry maintains its record of the membership of the cohort in a cohort registry store . You may want to see the OMRS metamodel for more details on the granularity of metadata exchange. \u21a9","title":"Cohort registry"},{"location":"features/discovery-and-stewardship/overview/","text":"Metadata discovery and stewardship \u00b6 Integrated cataloguing typically automates the creation the basic asset entry, its connection and optionally, its schema. This is what is called technical metadata. Metadata discovery uses advanced analysis to inspect the content of specific assets to derive new insights that can augment or validate their catalog entry. The results can either be automatically applied to the asset's catalog entry or it can go through a stewardship process to have a subject matter expert confirm the findings (or not). Discovery and stewardship are the most advanced form of automation for asset cataloging. Egeria provides the server runtime environment and component framework to allow third parties to create discovery services and governance action implementations. It has only simple implementations of these components, mostly for demonstration purposes. This is the area where vendors and other open source projects are expected to provide additional value. Metadata Discovery \u00b6 Metadata discovery is an automated process that extracts metadata about an asset . This metadata may be: * embedded within the asset * (for example a digital photograph has embedded metadata), or * managed by the platform that is hosting the asset * (for example, a relational database platform maintains schema information about the data store in its databases) or * determined by analysing the content of the asset * (for example a metadata discovery tool may analyse the data content to determine the types and range of values it contains and, maybe determine a quality score for the data). Some metadata discovery may occur when the asset is first cataloged. For example, the schema of an asset may be stored through the Data Manager OMAS API. This schema may have been automatically extracted by a metadata extractor connector hosted in Egeria's Open Metadata Integration Services like Database Integrator OMIS or Files Integrator OMIS . Egeria also supports more advanced metadata discovery. The Open Discovery Framework ( ODF ) has open APIs that define how automated discovery services can be managed and interact with an open metadata repository. The metadata repository interfaces provide the metadata discovery service with: * the ability to manage discovery configuration, * a search function to locate assets in the metadata repository, * access all of the metadata known about each asset including its connector and * the ability to record the results of its analysis. This metadata repository interface for metadata discovery tools is implemented by the Discovery Engine OMAS . Egeria is also able to host automated metadata discovery services that implement the ODF interfaces in its Asset Analysis OMES .","title":"Discovery and Stewardship"},{"location":"features/discovery-and-stewardship/overview/#metadata-discovery-and-stewardship","text":"Integrated cataloguing typically automates the creation the basic asset entry, its connection and optionally, its schema. This is what is called technical metadata. Metadata discovery uses advanced analysis to inspect the content of specific assets to derive new insights that can augment or validate their catalog entry. The results can either be automatically applied to the asset's catalog entry or it can go through a stewardship process to have a subject matter expert confirm the findings (or not). Discovery and stewardship are the most advanced form of automation for asset cataloging. Egeria provides the server runtime environment and component framework to allow third parties to create discovery services and governance action implementations. It has only simple implementations of these components, mostly for demonstration purposes. This is the area where vendors and other open source projects are expected to provide additional value.","title":"Metadata discovery and stewardship"},{"location":"features/discovery-and-stewardship/overview/#metadata-discovery","text":"Metadata discovery is an automated process that extracts metadata about an asset . This metadata may be: * embedded within the asset * (for example a digital photograph has embedded metadata), or * managed by the platform that is hosting the asset * (for example, a relational database platform maintains schema information about the data store in its databases) or * determined by analysing the content of the asset * (for example a metadata discovery tool may analyse the data content to determine the types and range of values it contains and, maybe determine a quality score for the data). Some metadata discovery may occur when the asset is first cataloged. For example, the schema of an asset may be stored through the Data Manager OMAS API. This schema may have been automatically extracted by a metadata extractor connector hosted in Egeria's Open Metadata Integration Services like Database Integrator OMIS or Files Integrator OMIS . Egeria also supports more advanced metadata discovery. The Open Discovery Framework ( ODF ) has open APIs that define how automated discovery services can be managed and interact with an open metadata repository. The metadata repository interfaces provide the metadata discovery service with: * the ability to manage discovery configuration, * a search function to locate assets in the metadata repository, * access all of the metadata known about each asset including its connector and * the ability to record the results of its analysis. This metadata repository interface for metadata discovery tools is implemented by the Discovery Engine OMAS . Egeria is also able to host automated metadata discovery services that implement the ODF interfaces in its Asset Analysis OMES .","title":"Metadata Discovery"},{"location":"features/duplicate-management/overview/","text":"Duplicate Management \u00b6 Duplicate management covers the identification of multiple instances of metadata that represent the same concept or resource. These duplicate instances are then linked and classified so that when metadata is being retrieved from the open metadata ecosystem, the information from the duplicates is combined to give a meaningful result. What is a duplicate? \u00b6 Duplicates occur when the same concept or resource is captured in multiple tools. They are not noticed as duplicates when the tools operate independently. However, when these tools are connected together through Egeria, the inconsistencies between them create partial results and possible errors in decisions made using this information. Figure 1 shows a simple duplicate where each instance originates from a different repository. Although each instance has a different unique identifier ( GUID ), the rest of the metadata is consistent. This makes it easy to spot when both are returned in a search query. However, a query to count, say, the number of glossary terms would give misleading results. Figure 1: Two copies of the same glossary term originating from different repositories When related information is required (for example, which assets are linked to the glossary term customer ) the request needs to be issued for each duplicate instance to retrieve the complete picture. Figure 2 shows that the users of one repository have linked their copy of the glossary term to assets 1 and 2 whereas the users of the other repository have linked their copy of the glossary term to asset 3. Figure 2: Different sets of relationships associated with each duplicate It is often not possible to delete one of the duplicate instances because many repositories are not able to store metadata from other repositories and so each copy is needed by its originating repository. Egeria needs a mechanism to handle these duplicates. Some duplicates are not so easy to identify. Figure 3 shows an example of duplicate assets where the values in the assets are different, but the fact that they describe the same resource can be deduced by the fact that the related endpoints point to the same location. Figure 3: Duplicate assets identified through their endpoints In some circumstances the metadata is correctly cataloguing the existence of two resources however the resources themselves are duplicates of one another. Figure 4 shows two copies of the same image. The metadata records the name of each copy but has no knowledge that their contents are the same. Figure 4: Two copies of the same resource are catalogued as two assets. There is no shared values in the metadata. Avoiding duplicates \u00b6 Duplicates can add a significant burden to your data processing. Therefore there is value in controlling the copying of data and ensuring that resources are catalogued only once. However some duplication can not be avoided and Egeria has mechanisms to handle them. How are duplicates managed in Egeria? \u00b6 Duplicate management has four parts to it: Detecting duplicate resources Detecting duplicate metadata entries for the same resource or concept. Linking duplicates together so that they can be processed together. Combining duplicates so that they can be retrieved as if they were one. Figure 5 shows the architecture of an Egeria duplicate management solution. Figure 5: Components in a deduplication solution include the cohort members that are supplying the duplicates and retrieving metadata along with the engine host that is running the governance engines detecting and managing duplicates in conjunction with the stewards The numbers on the diagram refer to the following points: These are the tools that are potentially introducing duplicates into the cohort. In this example they are connected through repository proxies and are not capable of storing reference copies of metadata. This means the duplicates that they collectively introduce must be managed for the benefit of other consumers of the metadata. Metadata Discovery analyses the content of resources. There are algorithms for producing a fingerprint (like a hash) that represents the content of each resource. These fingerprints can be stored as annotations attached to the resource's asset via a discovery analysis report . These fingerprint annotations are metadata that can be automatically analysed during duplicate detection. The examples in figures 1-4 show that the mechanisms to detect duplicates are varied and often require knowledge of the data management practices in the organization. As such this function must be pluggable into Egeria's runtime. Governance Actions therefore monitor for changes in metadata and search for duplicate instances. They link detected duplicates together. A governance action, possibly the same one that detected the duplicates, can validate and action the duplicates so that survivorship processing occurs when they are retrieved from the metadata repositories (see step 6). Alternatively, the duplicates can be validated and actioned by a steward. When a service detects duplicates during a request to retrieve metadata from the repositories it automatically processes the duplicates so the caller is not aware that the duplicates exist. Figure 6 shows an example of a governance action process that controls the governance actions and the use of the stewards for duplicate detection. Figure 6: The steps in an example governance action process There is a watchdog governance action that is monitoring for new assets. It initiates a verification governance action to detect any duplicates for each new asset. Each verification governance action produces a guard whose value depends on the confidence that it has in the accuracy of any detected duplicates: no-duplcates guard means it discovered no duplicates and so the process stops. link-duplicates guard means it is very confident that it has detected a duplicate and it can be actioned automatically by a remediation governance action before the process stops. validate-duplicates guard means that a steward should verify that duplicates have really been detected. This is achieved by a triage governance action creating a ToDo and a watchdog governance action waiting for the steward to complete the ToDo before stopping. The steward uses the Stewardship Action OMAS to verify and set up the duplicates. Duplicate management styles \u00b6 Egeria has two styles of duplicate management that can be actioned automatically or by a steward. They are peer linking and consolidation. The open metadata types used in both styles are defined in model 0465 Duplicate Management . Peer linking \u00b6 When duplicate entities are first detected, they are linked together by the PeerDuplicateLink relationship. This relationship includes properties that indicate how confident the detecting process is that the entities are duplicates. No change occurs in the retrieval of these instances at this point. If a steward or automated process confirms the duplicates are correctly identified, KnownDuplicate classifications added to the entities tell the metadata retrieval functions to automatically combine the content of the duplicates when any of them is requested. This is peer linking. Consolidation \u00b6 Consolidation is the process where the combined results of the duplicates is pre-calculated, stored as an entity and linked to the duplicate entities using the ConsolidatedDuplicateLink relationship. The assessment of confidence of the deduplication is stored in the ConsolidatedDuplicate classification on the instance that contains the combined results. Metadata retrieval of duplicates \u00b6 When an Egeria retrieval operation is requested by an Open Metadata Access Service ( OMAS ) , it monitors for the KnownDuplicate classification on the entities it is retrieving. When found, and the retrieval request is not part of duplication management, deduplication occurs. Deduplication \u00b6 During deduplication, the retrieval process first looks for the ConsolidatedDuplicateLink relationship. If that is found, the consolidated instance is returned instead. If not, the instances linked via PeerDuplicateLink relationships are combined. The combination process requires choices to be made on which values to use. These choices are called the survivorship rules . Survivorship rules \u00b6 The survivorship rules operate on the following principles: Newer metadata is more accurate. The cardinality of relationships must be respected. If multiple peer entities point to the same target entity with the same type of uni-link relationship then the target entity is processed only once. Figure 7 shows two glossary terms linked as peer duplicates. When entity is queried by GUID , properties from requested entity are returned with combination of classifications. Conflicts in classifications are recorded on the audit log. The latest values are used. When the relationships of an identified duplicate are queried, the combination from all duplicates is returned unless only one instance of a relationship is allowed in which case the latest values are used. Figure 7: Peer duplicates with distinct relationships Figure 8 shows that both glossary terms link to the same schema attribute using the SemanticAssignment relationship. Although this relationship has a cardinality of many-to-many, it is uni-link so only the newesst relationship is processed. Figure 8: Peer duplicates pointing to the same entity via the same type of uni-link relationship Finally figure 9 shows a consolidated duplicate linked to the glossary terms. If any of these three entities are requested the consolidated duplicate is returned. Figure 9: Peer duplicates linked to a consolidated duplicate Note: survivorship rules only operate on instances with appropriate effectivity dates .","title":"Duplicate Management"},{"location":"features/duplicate-management/overview/#duplicate-management","text":"Duplicate management covers the identification of multiple instances of metadata that represent the same concept or resource. These duplicate instances are then linked and classified so that when metadata is being retrieved from the open metadata ecosystem, the information from the duplicates is combined to give a meaningful result.","title":"Duplicate Management"},{"location":"features/duplicate-management/overview/#what-is-a-duplicate","text":"Duplicates occur when the same concept or resource is captured in multiple tools. They are not noticed as duplicates when the tools operate independently. However, when these tools are connected together through Egeria, the inconsistencies between them create partial results and possible errors in decisions made using this information. Figure 1 shows a simple duplicate where each instance originates from a different repository. Although each instance has a different unique identifier ( GUID ), the rest of the metadata is consistent. This makes it easy to spot when both are returned in a search query. However, a query to count, say, the number of glossary terms would give misleading results. Figure 1: Two copies of the same glossary term originating from different repositories When related information is required (for example, which assets are linked to the glossary term customer ) the request needs to be issued for each duplicate instance to retrieve the complete picture. Figure 2 shows that the users of one repository have linked their copy of the glossary term to assets 1 and 2 whereas the users of the other repository have linked their copy of the glossary term to asset 3. Figure 2: Different sets of relationships associated with each duplicate It is often not possible to delete one of the duplicate instances because many repositories are not able to store metadata from other repositories and so each copy is needed by its originating repository. Egeria needs a mechanism to handle these duplicates. Some duplicates are not so easy to identify. Figure 3 shows an example of duplicate assets where the values in the assets are different, but the fact that they describe the same resource can be deduced by the fact that the related endpoints point to the same location. Figure 3: Duplicate assets identified through their endpoints In some circumstances the metadata is correctly cataloguing the existence of two resources however the resources themselves are duplicates of one another. Figure 4 shows two copies of the same image. The metadata records the name of each copy but has no knowledge that their contents are the same. Figure 4: Two copies of the same resource are catalogued as two assets. There is no shared values in the metadata.","title":"What is a duplicate?"},{"location":"features/duplicate-management/overview/#avoiding-duplicates","text":"Duplicates can add a significant burden to your data processing. Therefore there is value in controlling the copying of data and ensuring that resources are catalogued only once. However some duplication can not be avoided and Egeria has mechanisms to handle them.","title":"Avoiding duplicates"},{"location":"features/duplicate-management/overview/#how-are-duplicates-managed-in-egeria","text":"Duplicate management has four parts to it: Detecting duplicate resources Detecting duplicate metadata entries for the same resource or concept. Linking duplicates together so that they can be processed together. Combining duplicates so that they can be retrieved as if they were one. Figure 5 shows the architecture of an Egeria duplicate management solution. Figure 5: Components in a deduplication solution include the cohort members that are supplying the duplicates and retrieving metadata along with the engine host that is running the governance engines detecting and managing duplicates in conjunction with the stewards The numbers on the diagram refer to the following points: These are the tools that are potentially introducing duplicates into the cohort. In this example they are connected through repository proxies and are not capable of storing reference copies of metadata. This means the duplicates that they collectively introduce must be managed for the benefit of other consumers of the metadata. Metadata Discovery analyses the content of resources. There are algorithms for producing a fingerprint (like a hash) that represents the content of each resource. These fingerprints can be stored as annotations attached to the resource's asset via a discovery analysis report . These fingerprint annotations are metadata that can be automatically analysed during duplicate detection. The examples in figures 1-4 show that the mechanisms to detect duplicates are varied and often require knowledge of the data management practices in the organization. As such this function must be pluggable into Egeria's runtime. Governance Actions therefore monitor for changes in metadata and search for duplicate instances. They link detected duplicates together. A governance action, possibly the same one that detected the duplicates, can validate and action the duplicates so that survivorship processing occurs when they are retrieved from the metadata repositories (see step 6). Alternatively, the duplicates can be validated and actioned by a steward. When a service detects duplicates during a request to retrieve metadata from the repositories it automatically processes the duplicates so the caller is not aware that the duplicates exist. Figure 6 shows an example of a governance action process that controls the governance actions and the use of the stewards for duplicate detection. Figure 6: The steps in an example governance action process There is a watchdog governance action that is monitoring for new assets. It initiates a verification governance action to detect any duplicates for each new asset. Each verification governance action produces a guard whose value depends on the confidence that it has in the accuracy of any detected duplicates: no-duplcates guard means it discovered no duplicates and so the process stops. link-duplicates guard means it is very confident that it has detected a duplicate and it can be actioned automatically by a remediation governance action before the process stops. validate-duplicates guard means that a steward should verify that duplicates have really been detected. This is achieved by a triage governance action creating a ToDo and a watchdog governance action waiting for the steward to complete the ToDo before stopping. The steward uses the Stewardship Action OMAS to verify and set up the duplicates.","title":"How are duplicates managed in Egeria?"},{"location":"features/duplicate-management/overview/#duplicate-management-styles","text":"Egeria has two styles of duplicate management that can be actioned automatically or by a steward. They are peer linking and consolidation. The open metadata types used in both styles are defined in model 0465 Duplicate Management .","title":"Duplicate management styles"},{"location":"features/duplicate-management/overview/#peer-linking","text":"When duplicate entities are first detected, they are linked together by the PeerDuplicateLink relationship. This relationship includes properties that indicate how confident the detecting process is that the entities are duplicates. No change occurs in the retrieval of these instances at this point. If a steward or automated process confirms the duplicates are correctly identified, KnownDuplicate classifications added to the entities tell the metadata retrieval functions to automatically combine the content of the duplicates when any of them is requested. This is peer linking.","title":"Peer linking"},{"location":"features/duplicate-management/overview/#consolidation","text":"Consolidation is the process where the combined results of the duplicates is pre-calculated, stored as an entity and linked to the duplicate entities using the ConsolidatedDuplicateLink relationship. The assessment of confidence of the deduplication is stored in the ConsolidatedDuplicate classification on the instance that contains the combined results.","title":"Consolidation"},{"location":"features/duplicate-management/overview/#metadata-retrieval-of-duplicates","text":"When an Egeria retrieval operation is requested by an Open Metadata Access Service ( OMAS ) , it monitors for the KnownDuplicate classification on the entities it is retrieving. When found, and the retrieval request is not part of duplication management, deduplication occurs.","title":"Metadata retrieval of duplicates"},{"location":"features/duplicate-management/overview/#deduplication","text":"During deduplication, the retrieval process first looks for the ConsolidatedDuplicateLink relationship. If that is found, the consolidated instance is returned instead. If not, the instances linked via PeerDuplicateLink relationships are combined. The combination process requires choices to be made on which values to use. These choices are called the survivorship rules .","title":"Deduplication"},{"location":"features/duplicate-management/overview/#survivorship-rules","text":"The survivorship rules operate on the following principles: Newer metadata is more accurate. The cardinality of relationships must be respected. If multiple peer entities point to the same target entity with the same type of uni-link relationship then the target entity is processed only once. Figure 7 shows two glossary terms linked as peer duplicates. When entity is queried by GUID , properties from requested entity are returned with combination of classifications. Conflicts in classifications are recorded on the audit log. The latest values are used. When the relationships of an identified duplicate are queried, the combination from all duplicates is returned unless only one instance of a relationship is allowed in which case the latest values are used. Figure 7: Peer duplicates with distinct relationships Figure 8 shows that both glossary terms link to the same schema attribute using the SemanticAssignment relationship. Although this relationship has a cardinality of many-to-many, it is uni-link so only the newesst relationship is processed. Figure 8: Peer duplicates pointing to the same entity via the same type of uni-link relationship Finally figure 9 shows a consolidated duplicate linked to the glossary terms. If any of these three entities are requested the consolidated duplicate is returned. Figure 9: Peer duplicates linked to a consolidated duplicate Note: survivorship rules only operate on instances with appropriate effectivity dates .","title":"Survivorship rules"},{"location":"features/external-identifiers/external-identifiers/","text":"Managing External Identifiers \u00b6 Every open metadata instance has a unique identifier called its GUID . This provides a means to locate and retrieve the instance from the metadata repository. However, often the GUID is not known in the systems and tools that integrate with open metadata. Metadata instances that inherit from the Referenceable type have a property called qualifiedName . This is a unique name for the Referenceable instance. When such an instance is created, the qualified name can be set up to a unique identifier that is a natural unique name for the resource that it represents (such as the full path name of a file) or a unique identifier from an external tool. The element can then be retrieved using the qualifiedName . Now consider the situation where each external tool that uses the instance has a different identifier for the instance. There is only one qualified name property in the instance which will not be able to cover all the identifiers from the external systems/tools. In this situation it is possible to set up multiple external identifiers for an open metadata instance. Each external identifier is linked to the open metadata instance it represents and the software server capability of the external system/tool that uses it. You can think of this link to the software server capability as providing a scope in which the external identifier is valid. The external identifiers can support both one-to-many, many-to-one and many-to-many between metadata elements from external systems/tools and open metadata instances. Many-to-one \u00b6 Imagine situation where an external tool called myCatalog uses two metadata elements: one for a type it refers to as BusinessTerm and the other of type Example , to represent all the properties that are stored in one open metadata GlossaryTerm . To represent this in open metadata, the unique identifiers for the business term and example metadata elements ( gt1 and ex6 respectively) are each stored in their own external identifier that is linked to both the myCatalog 's software server capability and the corresponding open metadata glossary term. This means the glossary term can be located in an open metadata repository either using the identifier gt1 or ex6 . Similarly, it is possible to locate a glossary term's properties in myCatalog by looking up both the gt1 and ex6 elements. One-to-many \u00b6 Now imagine the opposite situation: where it takes multiple open metadata instances to represent a single metadata element in an external system/tool. In this example the external system/tool directly links its Database elements to its Table elements. Whereas in the open metadata types, there is a SchemaType (specifically RelationalDBSchemaType ) between a DeployedDatabaseSchema instance and the RelationalTable instance. Again, an external identifier is created for each of the external metadata elements and this is linked to the software server capability for myCatalog . Each external identifier is then linked to each of the open metadata instances that have properties that map to its equivalent metadata element in the external system/tool. The use of external identifiers is particularly important to the integration connectors running in the Open Metadata Integration Services ( OMIS ) , where the ability to maintain consistent metadata stores in both open metadata and third party systems and tools is important. Open metadata representation \u00b6 The open metadata types for external identifier are in model 0017 . The ExternalIdLink relationship is between the external identifier and the open metadata instance it represents. The ExternalIdScope is the relationship between the external identifier and the software server capability that represents the external system/tool. Implementations \u00b6 The Asset Manager OMAS provides support for external identifier mapping on its APIs. This capability is visible through the Catalog Integrator OMIS and the Lineage Integrator OMIS that are based on the Asset Manager OMAS client. The Open Connector Framework ( OCF ) provides the ability to query the external identifiers attached to an asset through the connected asset properties . This is also visible through the AssetUniverse interfaces of the: Asset Consumer OMAS Asset Owner OMAS Discovery Engine OMAS","title":"External identifiers"},{"location":"features/external-identifiers/external-identifiers/#managing-external-identifiers","text":"Every open metadata instance has a unique identifier called its GUID . This provides a means to locate and retrieve the instance from the metadata repository. However, often the GUID is not known in the systems and tools that integrate with open metadata. Metadata instances that inherit from the Referenceable type have a property called qualifiedName . This is a unique name for the Referenceable instance. When such an instance is created, the qualified name can be set up to a unique identifier that is a natural unique name for the resource that it represents (such as the full path name of a file) or a unique identifier from an external tool. The element can then be retrieved using the qualifiedName . Now consider the situation where each external tool that uses the instance has a different identifier for the instance. There is only one qualified name property in the instance which will not be able to cover all the identifiers from the external systems/tools. In this situation it is possible to set up multiple external identifiers for an open metadata instance. Each external identifier is linked to the open metadata instance it represents and the software server capability of the external system/tool that uses it. You can think of this link to the software server capability as providing a scope in which the external identifier is valid. The external identifiers can support both one-to-many, many-to-one and many-to-many between metadata elements from external systems/tools and open metadata instances.","title":"Managing External Identifiers"},{"location":"features/external-identifiers/external-identifiers/#many-to-one","text":"Imagine situation where an external tool called myCatalog uses two metadata elements: one for a type it refers to as BusinessTerm and the other of type Example , to represent all the properties that are stored in one open metadata GlossaryTerm . To represent this in open metadata, the unique identifiers for the business term and example metadata elements ( gt1 and ex6 respectively) are each stored in their own external identifier that is linked to both the myCatalog 's software server capability and the corresponding open metadata glossary term. This means the glossary term can be located in an open metadata repository either using the identifier gt1 or ex6 . Similarly, it is possible to locate a glossary term's properties in myCatalog by looking up both the gt1 and ex6 elements.","title":"Many-to-one"},{"location":"features/external-identifiers/external-identifiers/#one-to-many","text":"Now imagine the opposite situation: where it takes multiple open metadata instances to represent a single metadata element in an external system/tool. In this example the external system/tool directly links its Database elements to its Table elements. Whereas in the open metadata types, there is a SchemaType (specifically RelationalDBSchemaType ) between a DeployedDatabaseSchema instance and the RelationalTable instance. Again, an external identifier is created for each of the external metadata elements and this is linked to the software server capability for myCatalog . Each external identifier is then linked to each of the open metadata instances that have properties that map to its equivalent metadata element in the external system/tool. The use of external identifiers is particularly important to the integration connectors running in the Open Metadata Integration Services ( OMIS ) , where the ability to maintain consistent metadata stores in both open metadata and third party systems and tools is important.","title":"One-to-many"},{"location":"features/external-identifiers/external-identifiers/#open-metadata-representation","text":"The open metadata types for external identifier are in model 0017 . The ExternalIdLink relationship is between the external identifier and the open metadata instance it represents. The ExternalIdScope is the relationship between the external identifier and the software server capability that represents the external system/tool.","title":"Open metadata representation"},{"location":"features/external-identifiers/external-identifiers/#implementations","text":"The Asset Manager OMAS provides support for external identifier mapping on its APIs. This capability is visible through the Catalog Integrator OMIS and the Lineage Integrator OMIS that are based on the Asset Manager OMAS client. The Open Connector Framework ( OCF ) provides the ability to query the external identifiers attached to an asset through the connected asset properties . This is also visible through the AssetUniverse interfaces of the: Asset Consumer OMAS Asset Owner OMAS Discovery Engine OMAS","title":"Implementations"},{"location":"features/integrated-cataloguing/overview/","text":"Integrated cataloging \u00b6 It is possible to add metadata to a metadata repository using no automation beyond the management of the metadata once it is created. Individuals enter information about the assets into Egeria through tools that call Egeria's Open Metadata Access Services (OMASs) . The Asset Owner OMAS is the principle interface for such manual cataloguing. It is possible to catalog any type of asset through this interface although it is biased towards cataloging data assets such as data stores, data feeds, files, data sets, APIs and events. In addition there are specific cataloguing interfaces for particular types of subject matter expert. IT Infrastructure OMAS provides specialist interfaces for cataloguing infrastructure such as servers, host systems and applications. Digital Architecture OMAS provides specialist interfaces for architects and integration engineers to manually catalog reference data sets and processes. Reference data sets are assets in their own right, and their content can be used as classifiers to augment the description of other assets. Processes are also assets that, when linked together, show the lineage of the assets they are partly responsible for maintaining. Manual cataloguing works well for infrequent cataloguing. However it is expensive and error prone when aiming to systematially catalog your digital landscape. Integrated cataloging uses an integration daemon to monitor a specific digital technology that hosts particular types of assets and automatically maintain the catalog with information about these assets. For example, an integration daemon may be monitoring a database server, updating the asset catalog each time a new database is added, or a schema is changed. Integration daemons support different integration patterns to meet the variety of capabilities of digital technologies. For example, it may poll the technology or listen for events from it that indicate changes in the assets. They are limited to the metadata supported by the technology they are working with. Other types of automation \u00b6 Below are other types of automation to minimise the effort in managing your asset catalog. Templated cataloguing - copying predefined assets. Discovery and stewardship - analysis of asset contents to create metadata.","title":"Integrated Cataloguing"},{"location":"features/integrated-cataloguing/overview/#integrated-cataloging","text":"It is possible to add metadata to a metadata repository using no automation beyond the management of the metadata once it is created. Individuals enter information about the assets into Egeria through tools that call Egeria's Open Metadata Access Services (OMASs) . The Asset Owner OMAS is the principle interface for such manual cataloguing. It is possible to catalog any type of asset through this interface although it is biased towards cataloging data assets such as data stores, data feeds, files, data sets, APIs and events. In addition there are specific cataloguing interfaces for particular types of subject matter expert. IT Infrastructure OMAS provides specialist interfaces for cataloguing infrastructure such as servers, host systems and applications. Digital Architecture OMAS provides specialist interfaces for architects and integration engineers to manually catalog reference data sets and processes. Reference data sets are assets in their own right, and their content can be used as classifiers to augment the description of other assets. Processes are also assets that, when linked together, show the lineage of the assets they are partly responsible for maintaining. Manual cataloguing works well for infrequent cataloguing. However it is expensive and error prone when aiming to systematially catalog your digital landscape. Integrated cataloging uses an integration daemon to monitor a specific digital technology that hosts particular types of assets and automatically maintain the catalog with information about these assets. For example, an integration daemon may be monitoring a database server, updating the asset catalog each time a new database is added, or a schema is changed. Integration daemons support different integration patterns to meet the variety of capabilities of digital technologies. For example, it may poll the technology or listen for events from it that indicate changes in the assets. They are limited to the metadata supported by the technology they are working with.","title":"Integrated cataloging"},{"location":"features/integrated-cataloguing/overview/#other-types-of-automation","text":"Below are other types of automation to minimise the effort in managing your asset catalog. Templated cataloguing - copying predefined assets. Discovery and stewardship - analysis of asset contents to create metadata.","title":"Other types of automation"},{"location":"features/lineage-management/lineage-representation/","text":"Lineage Representation \u00b6 Lineage shows the flow of data between different technologies. When it is represented in open metadata, many of the metadata elements involved describe the structure of the different technologies and the software components that use them. This can include relationships to other technologies that a component depends on. For example, Figure 1 shows the representation of a derived column (Col 1) in a database with relationships to the columns in another table (Col A and Col B) that contains the data used to calculate the values in the derived column. Col A and Col B are called query targets and the relationships used to link them to Col 1 are of type DerivedSchemaTypeQueryTarget . These query target relationships form part of the lineage for Col 1. Figure 1: Query Target relationships Similarly if we consider an API that calls a microservice that retrieved data from a data store, then the metadata that captures these relationships is part of the lineage of the API. Figure 2 shows this API call stack on the left and the open metadata elements used to represent then on the right. DeployedAPI represents the API, DeployedSoftwareComponent represents the microservice and DeployedDatabaseSchema represents the data store (assuming the data store is a database). The ProcessCall relationships that link them together is part of the lineage for these components. Figure 2: API call hierarchy with metadata representation on the right hand side These structural relationships are augmented by lineage mapping relationships that connect the lineage graph together. Lineage mapping (stitching) \u00b6 The LineageMapping relationship is used to: * link metadata elements from one independent process/data store to another. * Link schema elements that describe the structure of the data supported by these assets to show the corresponding flow of data items. It can be used to show linkage between different levels of detail. Figure 3 shows the lineage mapping between processes. This shows the flow of control between processes but no details about the processing inside the processes. Figure 3: Lineage mapping between processes Figure 4 shows lineage mapping between ports on the processes. This detail is useful for more complex processes where different subsets of data fields are received and sent by the process through different interfaces. Figure 4: Lineage mapping between ports For critical processes, an organization may need to trace the journey of a particular data field as it flows between processes and data stores. For this to work, lineage needs to capture details of the inner workings of processes as well the parameters of APIs and schemas of data stores. However, not all technologies support this level of and so the lineage graph is often a mixture of different levels of detail. Figure 5 shows detailed mapping between data fields. This level of lineage means that it is possible to trace what is happening with specific data fields. Figure 5: Lineage mapping between the data fields APIs can also be described to a detailed level where the data fields that flow in the requests and responses are detailed out. This is shown in figure 6. Figure 6: Full API specification showing the operations and the parameters and responses Lineage mappings can then be added between the data fields as calls are made between APIs. This is show in figure 7. Figure 7: Lineage mapping between the data fields Figure 8 shows lineage across multiple technologies where the lineage mapping is done at different levels of detail. Figure 8: Lineage mapping between the data fields Lineage representation for dynamic landscapes \u00b6 In some situations, particularly when working with files, there are data sources that only have an existence for a short period of time. When an asset is deleted from the open metadata repositories, all of its relationships with other elements are also deleted. This includes the lineage relationships. So we do not want to delete the asset if it is needed for lineage. Similarly if we just leave it unchanged, it suggests that there is a file in the landing area which would be confusing to users of the catalog. It is possible to move assets out of the governance zones where active users are working with assets. This ensures the assets are no longer visible to these users. However it also means they are not visible for the lineage graph either. There is an option to mark assets as deleted whilst sill keeping them in the active governance zones. This involves adding the Memento classification to the asset. With this classification in place, the asset is only returned on lineage queries. The Memento classification is set in APIs such as the archiveDataFileInCatalog() methods on the Data Manager Open Metadata Access Service ( OMAS ) and Files Integrator Open Metadata Integration Service ( OMIS ) . Further reading \u00b6 Modeling technology using open metadata types APIs for capturing lineage * Asset Manager Open Metadata Access Service ( OMAS ) * Lineage Integrator Open Metadata Integration Server ( OMIS ) APIs for retrieving lineage * Open Lineage Services","title":"Lineage representation"},{"location":"features/lineage-management/lineage-representation/#lineage-representation","text":"Lineage shows the flow of data between different technologies. When it is represented in open metadata, many of the metadata elements involved describe the structure of the different technologies and the software components that use them. This can include relationships to other technologies that a component depends on. For example, Figure 1 shows the representation of a derived column (Col 1) in a database with relationships to the columns in another table (Col A and Col B) that contains the data used to calculate the values in the derived column. Col A and Col B are called query targets and the relationships used to link them to Col 1 are of type DerivedSchemaTypeQueryTarget . These query target relationships form part of the lineage for Col 1. Figure 1: Query Target relationships Similarly if we consider an API that calls a microservice that retrieved data from a data store, then the metadata that captures these relationships is part of the lineage of the API. Figure 2 shows this API call stack on the left and the open metadata elements used to represent then on the right. DeployedAPI represents the API, DeployedSoftwareComponent represents the microservice and DeployedDatabaseSchema represents the data store (assuming the data store is a database). The ProcessCall relationships that link them together is part of the lineage for these components. Figure 2: API call hierarchy with metadata representation on the right hand side These structural relationships are augmented by lineage mapping relationships that connect the lineage graph together.","title":"Lineage Representation"},{"location":"features/lineage-management/lineage-representation/#lineage-mapping-stitching","text":"The LineageMapping relationship is used to: * link metadata elements from one independent process/data store to another. * Link schema elements that describe the structure of the data supported by these assets to show the corresponding flow of data items. It can be used to show linkage between different levels of detail. Figure 3 shows the lineage mapping between processes. This shows the flow of control between processes but no details about the processing inside the processes. Figure 3: Lineage mapping between processes Figure 4 shows lineage mapping between ports on the processes. This detail is useful for more complex processes where different subsets of data fields are received and sent by the process through different interfaces. Figure 4: Lineage mapping between ports For critical processes, an organization may need to trace the journey of a particular data field as it flows between processes and data stores. For this to work, lineage needs to capture details of the inner workings of processes as well the parameters of APIs and schemas of data stores. However, not all technologies support this level of and so the lineage graph is often a mixture of different levels of detail. Figure 5 shows detailed mapping between data fields. This level of lineage means that it is possible to trace what is happening with specific data fields. Figure 5: Lineage mapping between the data fields APIs can also be described to a detailed level where the data fields that flow in the requests and responses are detailed out. This is shown in figure 6. Figure 6: Full API specification showing the operations and the parameters and responses Lineage mappings can then be added between the data fields as calls are made between APIs. This is show in figure 7. Figure 7: Lineage mapping between the data fields Figure 8 shows lineage across multiple technologies where the lineage mapping is done at different levels of detail. Figure 8: Lineage mapping between the data fields","title":"Lineage mapping (stitching)"},{"location":"features/lineage-management/lineage-representation/#lineage-representation-for-dynamic-landscapes","text":"In some situations, particularly when working with files, there are data sources that only have an existence for a short period of time. When an asset is deleted from the open metadata repositories, all of its relationships with other elements are also deleted. This includes the lineage relationships. So we do not want to delete the asset if it is needed for lineage. Similarly if we just leave it unchanged, it suggests that there is a file in the landing area which would be confusing to users of the catalog. It is possible to move assets out of the governance zones where active users are working with assets. This ensures the assets are no longer visible to these users. However it also means they are not visible for the lineage graph either. There is an option to mark assets as deleted whilst sill keeping them in the active governance zones. This involves adding the Memento classification to the asset. With this classification in place, the asset is only returned on lineage queries. The Memento classification is set in APIs such as the archiveDataFileInCatalog() methods on the Data Manager Open Metadata Access Service ( OMAS ) and Files Integrator Open Metadata Integration Service ( OMIS ) .","title":"Lineage representation for dynamic landscapes"},{"location":"features/lineage-management/lineage-representation/#further-reading","text":"Modeling technology using open metadata types APIs for capturing lineage * Asset Manager Open Metadata Access Service ( OMAS ) * Lineage Integrator Open Metadata Integration Server ( OMIS ) APIs for retrieving lineage * Open Lineage Services","title":"Further reading"},{"location":"features/lineage-management/overview/","text":"Lineage \u00b6 Lineage shows how data flows from its origins to its various destinations. This includes details of the processing along the way. It is used both to understand: whether the data used in reports and analytics models has come from the correct sources and has passed through the correct processing (traceability of data). what would be the impact on downstream processing and consumers if something was changed (impact analysis). The lineage graph \u00b6 Lineage is typically envisaged as a graph showing processes interacting with different data stores. Some processes copy data from one store to another. Other processes may retrieve data from multiple stores and combine them to produce a new value that is stored in another store. The result is that a logical flow of data emerges from the interaction. Figure 1 shows some examples of different types of processes and data stores. On the left here is an Apache Spark job that reads from a file, looks up a value in an Apache Hive table, makes a calculation and writes the results to an Apache Kafka topic. On the right, an API is called that invokes a microservice. The microservice updates a data store. This data store is also loaded by an ETL job and any changes to it are copied to other stores via a data replication service. This second example illustrates that the data in the data store may have come from two sources, either the API caller or the data sources used by the ETL job. Figure 1: Examples of processes As the importance of lineage is understood, it is becoming common that individual technologies provide a lineage view of their processing similar to figure 1. This is very useful to the immediate users of that technology. However from an enterprise perspective these technologies do not run in isolation. Enterprises need to be able to link the lineage from these technologies together to to show how data flows from its original sources to its ultimate destinations. Figure 2 shows a flow of data through multiple technologies. It begins with a Relational Database (RDB). This is read by an ETL job that writes all or some of its contents to an Apache Hive table. An Apache Spark job is initiated through an API that reads from the Apache Hive table and invokes an Apache Airflow DAG (process) that writes the information into an Apache Avro file and an event to an Apache Kafka topic. Figure 2: The lineage graph emerges You can also imagine that this flow is only a part of something much bigger. For example, what is responsible for maintaining the data in the relational database? Which technologies are consuming the events in the Apache Kafka topic. Lineage graphs can get very large. Figure 3 abstracts the example shown in figure 2. From this you can see that the flow is not a simple progression from left to right. API calls can pass data in either direction for example. Figure 3: The abstract lineage graph There are also often systems that act as a hub, with many processes extracting data, performing processing and then storing the results back into the same system. Other stores act as a consolidation point, receiving data from many systems and then distributing to multiple downstream stores. So the graph also involves loops and fan-in-fan-out structures. Lineage management \u00b6 Figure 4 shows Egeria's architecture for lineage. There are three parts to it: Lineage capture - through the Integration Daemon and Data Engine Proxy servers, metadata about data sources and the processing around them is captured and shared through open metadata. Stewardship - the lineage information each of the technologies is linked together. Where the naming of data sources and processes is consistent, this assembling of the lineage graph is automatic. However, experience shows that if it can be different, it will be different. Many technologies make there own choices in naming and so governance action services along with human stewardship is required to match and link the graph together. The governance action services run in the Engine Host server. They automatically add the relationships between the lineage contributions from each technology which may need to be verified by a human steward. The human steward may also add relationships where there is no well known pattern that can be encoded in a governance action services. Preservation and Use - Once the lineage graphs are assembled, the lineage can be viewed an analysed. This may be through standard open metadata queries. Since the lineage data is large, lineage may also be automatically captured and stored in the Open Lineage Server server. This captures and optimizes the lineage graphs for quick retrieval and analysis. Its presence allows lineage data to be regularly archived from the operational open metadata ecosystem. This is particularly important in regulated industries where lineage for critical reports may need to be kept for many years. The three parts of the lineage architecture are summarized in figure 4. Figure 4: The lineage architecture showing the three phases of (1) lineage capture, (2) stewardship to stitch the lineage contributions together and finally (3) its preservation and use Open Lineage \u00b6 Open Lineage is a sister open source project to Egeria that is also part of the LF AI and Data Foundation . It defines a standard for lineage produced by data processing engine as well as a collection point for this lineage data. Egeria has work in progress to capture lineage from any technology using the open lineage standard Figure 5 shows Apache Airflow and Apache Spark producing open lineage events that are picked up by Egeria and distributed to different tools and catalogs that are linked into the open metadata ecosystem. Figure 5: Inbound open lineage capture for distributing within the open metadata ecosystem There are also other data catalogs, for example, Marquez another of Egeria's sister projects at the LF AI and Data, also listens for open lineage events. Egeria's outbound open lineage support will publish lineage information that has been collected via other lineage capture mechanisms to the open lineage consumers. Thus, lineage information passes both ways between the open lineage world and the open metadata ecosystem. Figure 6: Outbound open lineage distribution to other open lineage consumers Figure 7 shows the open lineage integration connectors running in the Lineage Integrator OMIS within the Integration Daemon. Figure 7: Open lineage implementation showing the inbound and outbound integration connectors hosted by the Lineage Integrator OMIS running in an Integration Daemon. Summary \u00b6 Egeria's lineage support is comprehensive both in its capability and reach. Since the lineage is an integral part of the open metadata type system, metadata captured for lineage is useful for other purposes such as governance and quality management. Similarly, metadata captured to support a data catalog becomes part of the lineage graph. By using open metadata, metadata is captured once and used for many purposes. Further reading \u00b6 Lineage representation using Open Metadata Types File Lineage solution using Egeria APIs for capturing lineage * Asset Manager Open Metadata Access Service ( OMAS ) * Open Metadata Integration Services (OMISs) APIs for retrieving lineage * Open Lineage Services * Asset Owner and Asset Consumer through the Open Connector Framework ( OCF ) .","title":"Lineage Management"},{"location":"features/lineage-management/overview/#lineage","text":"Lineage shows how data flows from its origins to its various destinations. This includes details of the processing along the way. It is used both to understand: whether the data used in reports and analytics models has come from the correct sources and has passed through the correct processing (traceability of data). what would be the impact on downstream processing and consumers if something was changed (impact analysis).","title":"Lineage"},{"location":"features/lineage-management/overview/#the-lineage-graph","text":"Lineage is typically envisaged as a graph showing processes interacting with different data stores. Some processes copy data from one store to another. Other processes may retrieve data from multiple stores and combine them to produce a new value that is stored in another store. The result is that a logical flow of data emerges from the interaction. Figure 1 shows some examples of different types of processes and data stores. On the left here is an Apache Spark job that reads from a file, looks up a value in an Apache Hive table, makes a calculation and writes the results to an Apache Kafka topic. On the right, an API is called that invokes a microservice. The microservice updates a data store. This data store is also loaded by an ETL job and any changes to it are copied to other stores via a data replication service. This second example illustrates that the data in the data store may have come from two sources, either the API caller or the data sources used by the ETL job. Figure 1: Examples of processes As the importance of lineage is understood, it is becoming common that individual technologies provide a lineage view of their processing similar to figure 1. This is very useful to the immediate users of that technology. However from an enterprise perspective these technologies do not run in isolation. Enterprises need to be able to link the lineage from these technologies together to to show how data flows from its original sources to its ultimate destinations. Figure 2 shows a flow of data through multiple technologies. It begins with a Relational Database (RDB). This is read by an ETL job that writes all or some of its contents to an Apache Hive table. An Apache Spark job is initiated through an API that reads from the Apache Hive table and invokes an Apache Airflow DAG (process) that writes the information into an Apache Avro file and an event to an Apache Kafka topic. Figure 2: The lineage graph emerges You can also imagine that this flow is only a part of something much bigger. For example, what is responsible for maintaining the data in the relational database? Which technologies are consuming the events in the Apache Kafka topic. Lineage graphs can get very large. Figure 3 abstracts the example shown in figure 2. From this you can see that the flow is not a simple progression from left to right. API calls can pass data in either direction for example. Figure 3: The abstract lineage graph There are also often systems that act as a hub, with many processes extracting data, performing processing and then storing the results back into the same system. Other stores act as a consolidation point, receiving data from many systems and then distributing to multiple downstream stores. So the graph also involves loops and fan-in-fan-out structures.","title":"The lineage graph"},{"location":"features/lineage-management/overview/#lineage-management","text":"Figure 4 shows Egeria's architecture for lineage. There are three parts to it: Lineage capture - through the Integration Daemon and Data Engine Proxy servers, metadata about data sources and the processing around them is captured and shared through open metadata. Stewardship - the lineage information each of the technologies is linked together. Where the naming of data sources and processes is consistent, this assembling of the lineage graph is automatic. However, experience shows that if it can be different, it will be different. Many technologies make there own choices in naming and so governance action services along with human stewardship is required to match and link the graph together. The governance action services run in the Engine Host server. They automatically add the relationships between the lineage contributions from each technology which may need to be verified by a human steward. The human steward may also add relationships where there is no well known pattern that can be encoded in a governance action services. Preservation and Use - Once the lineage graphs are assembled, the lineage can be viewed an analysed. This may be through standard open metadata queries. Since the lineage data is large, lineage may also be automatically captured and stored in the Open Lineage Server server. This captures and optimizes the lineage graphs for quick retrieval and analysis. Its presence allows lineage data to be regularly archived from the operational open metadata ecosystem. This is particularly important in regulated industries where lineage for critical reports may need to be kept for many years. The three parts of the lineage architecture are summarized in figure 4. Figure 4: The lineage architecture showing the three phases of (1) lineage capture, (2) stewardship to stitch the lineage contributions together and finally (3) its preservation and use","title":"Lineage management"},{"location":"features/lineage-management/overview/#open-lineage","text":"Open Lineage is a sister open source project to Egeria that is also part of the LF AI and Data Foundation . It defines a standard for lineage produced by data processing engine as well as a collection point for this lineage data. Egeria has work in progress to capture lineage from any technology using the open lineage standard Figure 5 shows Apache Airflow and Apache Spark producing open lineage events that are picked up by Egeria and distributed to different tools and catalogs that are linked into the open metadata ecosystem. Figure 5: Inbound open lineage capture for distributing within the open metadata ecosystem There are also other data catalogs, for example, Marquez another of Egeria's sister projects at the LF AI and Data, also listens for open lineage events. Egeria's outbound open lineage support will publish lineage information that has been collected via other lineage capture mechanisms to the open lineage consumers. Thus, lineage information passes both ways between the open lineage world and the open metadata ecosystem. Figure 6: Outbound open lineage distribution to other open lineage consumers Figure 7 shows the open lineage integration connectors running in the Lineage Integrator OMIS within the Integration Daemon. Figure 7: Open lineage implementation showing the inbound and outbound integration connectors hosted by the Lineage Integrator OMIS running in an Integration Daemon.","title":"Open Lineage"},{"location":"features/lineage-management/overview/#summary","text":"Egeria's lineage support is comprehensive both in its capability and reach. Since the lineage is an integral part of the open metadata type system, metadata captured for lineage is useful for other purposes such as governance and quality management. Similarly, metadata captured to support a data catalog becomes part of the lineage graph. By using open metadata, metadata is captured once and used for many purposes.","title":"Summary"},{"location":"features/lineage-management/overview/#further-reading","text":"Lineage representation using Open Metadata Types File Lineage solution using Egeria APIs for capturing lineage * Asset Manager Open Metadata Access Service ( OMAS ) * Open Metadata Integration Services (OMISs) APIs for retrieving lineage * Open Lineage Services * Asset Owner and Asset Consumer through the Open Connector Framework ( OCF ) .","title":"Further reading"},{"location":"features/metadata-archiving/overview/","text":"Open Metadata Archives \u00b6 The open metadata archives provide pre-canned content (open metadata types and instances) to load into an open metadata repository. There are three main types of open metadata archive: Content packs - read only metadata types and instances that are reusable in many organizations. The type definitions for the Open Metadata Types are managed in a content pack. They are also used for distributing standard glossaries or other types of definitions. Metadata exports - metadata exported from a specific open metadata repository that can act as a backup. It is read-write if loaded into an open metadata repository with the same metadata collection id as the originating repository, or read-only if loaded into a repository with a different metadata collection id. Repository backups - used for creating a back up for an open metadata repository. Figure 1 shows a content pack being loaded into a metadata repository. It is stored in the local repository and distributed around any connected cohorts. These types of archives can be provided by the Egeria community and third party organizations. Notice that due to the distribution of this metadata across the cohorts, it is only necessary to load the archive into one of the servers. Figure 1: Loading a content pack When data and other types of assets are being transported between organizations, it is possible to use a metadata export open metadata archive to pass the related metadata as well. This is shown in figure 2. Figure 2: Exporting and reimporting metadata between unconnected repositories Figure 3 shows a metadata export archive to create a backup of selected metadata. This can be used to recover the metadata repository content after a bad load or other operational error. Figure 3: Selective back up of metadata elements Creating open metadata archives \u00b6 Open metadata archives are created through Java utilities. There are two approaches: Content packs are created using the repository services archive utilities . The Egeria supported utilities for open metadata archives described at the bottom of this page use this approach. Metadata export archives and repository back-ups are created by using the repository services clients to extract the metadata elements from a live repository and the to store them in the archive using the repository services archive utilities . Loading open metadata archives \u00b6 A metadata server's configuration document can list the archives to load each time the server is started. This is useful if the server does not retain metadata through a server restart (like the in-memory metadata repository). Open metadata archives may also be loaded while the server is running using a REST API call. The archive is loaded once and its content is immediately available. If the repository persists metadata over a server restart then this archive content continues to be available after the server restarts. It does not matter how many times an archive is loaded, only one copy of the content is added to the repository. These Administration Guide articles describe how to load open metadata archives into a server: Configuring an open metadata archive in an OMAG Server Adding an open metadata archive to a running OMAG Server Inside an Open Metadata Archive \u00b6 The open metadata archive has three parts to it. This is shown in Figure 4 . The header defines the type of archive and its properties. Then there is the type store. This contains new types and updates to types (patches). Finally there is the instance store. This contains new instances (entities, relationships and classifications). Figure 4: Inside an Open Metadata Archive The archive loads in the following order: Attribute Type Definitions (AttributeTypeDefs) from the type store. PrimitiveDefs CollectionDefs EnumDefs New Type Definitions (TypeDefs) from the type store. EntityDefs RelationshipDefs ClassificationDefs Updates to types (TypeDefPatches) New Instances Entities Relationships Classifications More information about the design of the open metadata archives can be found in the Open Metadata Repository Services ( OMRS ) design documentation. Supported utilities for open metadata archives \u00b6 Egeria supports the following open metadata archives. Associated with each archive are utilities that help you build additional archives of your own content. Open Metadata Types - the Egeria Open Metadata Type Definitions. This archive is always loaded by each OMAG metadata repository server at start-up. This is to reduce the chance that new types developed by a third party have names that conflict with the open metadata types. There is also a utility to create the archive file for these open metadata types. The find out more about the Open Metadata Types click here . Open Connector Archives - provides utilities for building open metadata archives containing information about one or more connectors that follow the Open Connector Framework ( OCF ) . In addition, there are utilities for building an open metadata archive containing the connector type definitions for Egeria's data store connectors. Design Model Archives - provides utilities to manage common/standard model content from third parties. It includes an example archive for the Cloud Information Model (CIM) .","title":"Metadata Archiving"},{"location":"features/metadata-archiving/overview/#open-metadata-archives","text":"The open metadata archives provide pre-canned content (open metadata types and instances) to load into an open metadata repository. There are three main types of open metadata archive: Content packs - read only metadata types and instances that are reusable in many organizations. The type definitions for the Open Metadata Types are managed in a content pack. They are also used for distributing standard glossaries or other types of definitions. Metadata exports - metadata exported from a specific open metadata repository that can act as a backup. It is read-write if loaded into an open metadata repository with the same metadata collection id as the originating repository, or read-only if loaded into a repository with a different metadata collection id. Repository backups - used for creating a back up for an open metadata repository. Figure 1 shows a content pack being loaded into a metadata repository. It is stored in the local repository and distributed around any connected cohorts. These types of archives can be provided by the Egeria community and third party organizations. Notice that due to the distribution of this metadata across the cohorts, it is only necessary to load the archive into one of the servers. Figure 1: Loading a content pack When data and other types of assets are being transported between organizations, it is possible to use a metadata export open metadata archive to pass the related metadata as well. This is shown in figure 2. Figure 2: Exporting and reimporting metadata between unconnected repositories Figure 3 shows a metadata export archive to create a backup of selected metadata. This can be used to recover the metadata repository content after a bad load or other operational error. Figure 3: Selective back up of metadata elements","title":"Open Metadata Archives"},{"location":"features/metadata-archiving/overview/#creating-open-metadata-archives","text":"Open metadata archives are created through Java utilities. There are two approaches: Content packs are created using the repository services archive utilities . The Egeria supported utilities for open metadata archives described at the bottom of this page use this approach. Metadata export archives and repository back-ups are created by using the repository services clients to extract the metadata elements from a live repository and the to store them in the archive using the repository services archive utilities .","title":"Creating open metadata archives"},{"location":"features/metadata-archiving/overview/#loading-open-metadata-archives","text":"A metadata server's configuration document can list the archives to load each time the server is started. This is useful if the server does not retain metadata through a server restart (like the in-memory metadata repository). Open metadata archives may also be loaded while the server is running using a REST API call. The archive is loaded once and its content is immediately available. If the repository persists metadata over a server restart then this archive content continues to be available after the server restarts. It does not matter how many times an archive is loaded, only one copy of the content is added to the repository. These Administration Guide articles describe how to load open metadata archives into a server: Configuring an open metadata archive in an OMAG Server Adding an open metadata archive to a running OMAG Server","title":"Loading open metadata archives"},{"location":"features/metadata-archiving/overview/#inside-an-open-metadata-archive","text":"The open metadata archive has three parts to it. This is shown in Figure 4 . The header defines the type of archive and its properties. Then there is the type store. This contains new types and updates to types (patches). Finally there is the instance store. This contains new instances (entities, relationships and classifications). Figure 4: Inside an Open Metadata Archive The archive loads in the following order: Attribute Type Definitions (AttributeTypeDefs) from the type store. PrimitiveDefs CollectionDefs EnumDefs New Type Definitions (TypeDefs) from the type store. EntityDefs RelationshipDefs ClassificationDefs Updates to types (TypeDefPatches) New Instances Entities Relationships Classifications More information about the design of the open metadata archives can be found in the Open Metadata Repository Services ( OMRS ) design documentation.","title":"Inside an Open Metadata Archive"},{"location":"features/metadata-archiving/overview/#supported-utilities-for-open-metadata-archives","text":"Egeria supports the following open metadata archives. Associated with each archive are utilities that help you build additional archives of your own content. Open Metadata Types - the Egeria Open Metadata Type Definitions. This archive is always loaded by each OMAG metadata repository server at start-up. This is to reduce the chance that new types developed by a third party have names that conflict with the open metadata types. There is also a utility to create the archive file for these open metadata types. The find out more about the Open Metadata Types click here . Open Connector Archives - provides utilities for building open metadata archives containing information about one or more connectors that follow the Open Connector Framework ( OCF ) . In addition, there are utilities for building an open metadata archive containing the connector type definitions for Egeria's data store connectors. Design Model Archives - provides utilities to manage common/standard model content from third parties. It includes an example archive for the Cloud Information Model (CIM) .","title":"Supported utilities for open metadata archives"},{"location":"features/metadata-provenance/overview/","text":"Metadata Provenance \u00b6 The open metadata ecosystem draws together metadata from many sources. Metadata provenance provides information about where metadata has come from and how it can be maintained (that is updated and deleted). Metadata Collections \u00b6 The metadata that a specific technology instance creates and maintains is collectively referred to as a metadata collection . Each metadata collection has a unique identifier, called the metadata collection id and an optional metadata collection name . When metadata from the collection is shared with the broader open metadata ecosystem, it includes the metadata collection id and metadata collection name in its header along with a category name that describes how the metadata was introduced into the open metadata ecosystem. This category name is called the Instance Provenance Type by the Open Metadata Repository Services ( OMRS ) and Element Origin by the Open Connector Framework ( OCF ) and most of the Open Metadata Access Services (OMASs) . We will use Element Origin for the rest of this description since it is the most commonly used name. Figure 1 shows the different values of Element Origin and how they tie into the mechanism used to introduce the metadata to the open metadata ecosystem. Figure 1: What the different values of Element Origin say about the source of metadata Local Cohort means that the metadata collection comes from a member of one of the open metadata repository cohorts that the local server is a member of. The owning cohort member will maintain the metadata and distribute any changes to the other cohort members. The metadata collection id and name is set up in the configuration of the cohort member's OMAG Server . Deregistered Repository means that the metadata collection is owned by a server that used to be a member of one of the cohorts that the local server belongs too but is has deregistered from the cohort. This means it is no longer sending updates to the rest of the cohort. Its metadata is still visible because reference copies (read only copies) have been kept by the other members. There are two routes to making this metadata maintainable again: Connect the original repository back into the cohort. If the original repository has gone forever, re-home the metadata so that it is owned by a current active member. External Source means the metadata is managed through an Open Metadata Access Service ( OMAS ) . Typically, the OMAS is called via an Open Metadata Integration Service ( OMIS ) running in an Integration Daemon . The metadata collection id and name is defined in Open Metadata as the unique identifier, or GUID , and unique name, or qualified name, of a Software Server Capability representing the source technology. Configuration means the metadata comes from a Configuration Document . Configuration documents control the capabilities of an OMAG Server . This metadata is maintained through Egeria's Administration Services Content Pack means the metadata comes from an open metadata archive that contains a collection of standard definitions. Content packs could contain glossaries, reference data sets, definitions from regulations and other types of standards. The archive documents the metadata collection id and name for the collection. In addition, a content pack is used to define Open Metadata Types . The metadata from a content pack can be updated by loading a later version of the content pack. Updated instances and types are replaced by the newer versions. Metadata Export is also content from an open metadata archive. However, it has been exported from a repository that has never been a member of the open metadata repository cohorts. It typically describes assets that are being imported from a third party (such as a business partner) that is also providing the accompanying metadata. Just as with content packs, this metadata is updated by loading a newer version of the metadata export archive. Using provenance to manage metadata integrity \u00b6 Egeria ensures that only the owner of a metadata instance is permitted to update it. This enforcement makes use of the metadata provenance information in the metadata instance's header. Typically the owner is the originator of the metadata instance, but the section below describes how to move a metadata instance's home from one metadata collection. This effectively changes the owner to the new metadata collection. Changing the metadata collection that a metadata instance belongs to \u00b6 The Open Metadata Repository Services supports commands to change the metadata collection that a metadata instance belongs to. This should be done only if the instance needs to be edited and the technology supporting the original metadata collection is no longer available. For example, for instances belonging to a deregistered repository. The change needs to be made with care and planning ensuring that all members of the cohort are connected when the command is issued so that the change of ownership can be recorded consistently in all repositories. Further Information \u00b6 Find out more about membership of a cohort . Learn about how external sources can integrate with the open metadata ecosystem . Set up metadata solutions that integrate metadata from many sources . Create and load Open Metadata Archives into your open metadata ecosystem. Learn about Configuration Documents that control the behaviour of OMAG Servers and how to set them up.","title":"Metadata Provenance"},{"location":"features/metadata-provenance/overview/#metadata-provenance","text":"The open metadata ecosystem draws together metadata from many sources. Metadata provenance provides information about where metadata has come from and how it can be maintained (that is updated and deleted).","title":"Metadata Provenance"},{"location":"features/metadata-provenance/overview/#metadata-collections","text":"The metadata that a specific technology instance creates and maintains is collectively referred to as a metadata collection . Each metadata collection has a unique identifier, called the metadata collection id and an optional metadata collection name . When metadata from the collection is shared with the broader open metadata ecosystem, it includes the metadata collection id and metadata collection name in its header along with a category name that describes how the metadata was introduced into the open metadata ecosystem. This category name is called the Instance Provenance Type by the Open Metadata Repository Services ( OMRS ) and Element Origin by the Open Connector Framework ( OCF ) and most of the Open Metadata Access Services (OMASs) . We will use Element Origin for the rest of this description since it is the most commonly used name. Figure 1 shows the different values of Element Origin and how they tie into the mechanism used to introduce the metadata to the open metadata ecosystem. Figure 1: What the different values of Element Origin say about the source of metadata Local Cohort means that the metadata collection comes from a member of one of the open metadata repository cohorts that the local server is a member of. The owning cohort member will maintain the metadata and distribute any changes to the other cohort members. The metadata collection id and name is set up in the configuration of the cohort member's OMAG Server . Deregistered Repository means that the metadata collection is owned by a server that used to be a member of one of the cohorts that the local server belongs too but is has deregistered from the cohort. This means it is no longer sending updates to the rest of the cohort. Its metadata is still visible because reference copies (read only copies) have been kept by the other members. There are two routes to making this metadata maintainable again: Connect the original repository back into the cohort. If the original repository has gone forever, re-home the metadata so that it is owned by a current active member. External Source means the metadata is managed through an Open Metadata Access Service ( OMAS ) . Typically, the OMAS is called via an Open Metadata Integration Service ( OMIS ) running in an Integration Daemon . The metadata collection id and name is defined in Open Metadata as the unique identifier, or GUID , and unique name, or qualified name, of a Software Server Capability representing the source technology. Configuration means the metadata comes from a Configuration Document . Configuration documents control the capabilities of an OMAG Server . This metadata is maintained through Egeria's Administration Services Content Pack means the metadata comes from an open metadata archive that contains a collection of standard definitions. Content packs could contain glossaries, reference data sets, definitions from regulations and other types of standards. The archive documents the metadata collection id and name for the collection. In addition, a content pack is used to define Open Metadata Types . The metadata from a content pack can be updated by loading a later version of the content pack. Updated instances and types are replaced by the newer versions. Metadata Export is also content from an open metadata archive. However, it has been exported from a repository that has never been a member of the open metadata repository cohorts. It typically describes assets that are being imported from a third party (such as a business partner) that is also providing the accompanying metadata. Just as with content packs, this metadata is updated by loading a newer version of the metadata export archive.","title":"Metadata Collections"},{"location":"features/metadata-provenance/overview/#using-provenance-to-manage-metadata-integrity","text":"Egeria ensures that only the owner of a metadata instance is permitted to update it. This enforcement makes use of the metadata provenance information in the metadata instance's header. Typically the owner is the originator of the metadata instance, but the section below describes how to move a metadata instance's home from one metadata collection. This effectively changes the owner to the new metadata collection.","title":"Using provenance to manage metadata integrity"},{"location":"features/metadata-provenance/overview/#changing-the-metadata-collection-that-a-metadata-instance-belongs-to","text":"The Open Metadata Repository Services supports commands to change the metadata collection that a metadata instance belongs to. This should be done only if the instance needs to be edited and the technology supporting the original metadata collection is no longer available. For example, for instances belonging to a deregistered repository. The change needs to be made with care and planning ensuring that all members of the cohort are connected when the command is issued so that the change of ownership can be recorded consistently in all repositories.","title":"Changing the metadata collection that a metadata instance belongs to"},{"location":"features/metadata-provenance/overview/#further-information","text":"Find out more about membership of a cohort . Learn about how external sources can integrate with the open metadata ecosystem . Set up metadata solutions that integrate metadata from many sources . Create and load Open Metadata Archives into your open metadata ecosystem. Learn about Configuration Documents that control the behaviour of OMAG Servers and how to set them up.","title":"Further Information"},{"location":"features/metadata-security/overview/","text":"Open Metadata Security \u00b6 Open Metadata Security provides fine-grained authorization services for open metadata services, types and instances. Since each organization will have different security requirements, the support is implemented through connectors. Egeria defines the interfaces and when it will call the connector. You define the behavior when the connector is called and Egeria acts on the returned decision. The metadata-security module defines the base classes and interfaces for the open metadata security connectors as well as the server implementation to host and call them. There are two types of connector: Open metadata platform security connector - secures access to the platform services that are not specific to an OMAG Server. This includes the admin services to create new servers, the ability to start and stop new servers as well as the ability to query whether a server is running, and if it is, what services are active. Open metadata server security connector - secures access to the specific services of an OMAG server. This includes the server itself, specific services within the server, specific Assets and Connections managed by the server and the types and instances stored in the local repository. The 2 types of connectors are shown in Figure 1: Figure 1: positioning of the security connectors Within an OMAG Server Platform there is one instance of the open metadata platform security connector. This connector is configured once the platform is running using the admin service call: POST /open-metadata/admin-services/users/{{adminUserId}}/platform/security/connection where the {{adminUserId}} is the administrator's userId. The connection for the connector and the platform URL root are passed in the request body. There are GET and DELETE services with the same URL to retrieve and remove this connector respectively. The open metadata server security connector is configured for each OMAG server to allow for each server to have a different implementation. The admin services command to configure a security connector for a server is: POST /open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection where the {{adminUserId}} is the administrator's userId and {{serverName}} is the name of the server where the connector is to run. The connection for the server security connector is passed in the request body. Again, there are GET and DELETE services with the same URL to retrieve and remove this connector respectively. The security implementation in a server potentially invokes the server security connector multiple types as the request (shown as dotted white arrow) penetrates the server code. Figure 2 shows the different layers of checks. Each layer is optional and so the server security connector can be implemented to support the most appropriate granularity of security for the situation. Details of the implementation choices are given in the security connector API . Figure 2: layers of security checks within the server The security connectors are optional. If they are not defined then there are no additional authorization checks performed inside the OMAG Server Platform nor the OMAG Servers hosted on the platform. As such, it is important that the open metadata platform security connector is configured as soon as the platform is started, and the server security connector is configured before the server is started for the first time. Metadata security APIs \u00b6 Below is a description of the API of the two Open Metadata Security Connectors . Open metadata platform security connector interface \u00b6 The connector that plugs in to the platform implements the following interface. OpenMetadataPlatformSecurity - provides the interface for a plugin connector that validates whether a calling user can access any service on an OMAG Server Platform. It is called within the context of a specific OMAG Server Platform request. Each OMAG Server Platform can define its own plugin connector implementation and will have its own instance of the connector. validateUserForPlatform - Check that the calling user is authorized to issue a (any) request to the OMAG Server Platform. validateUserAsAdminForPlatform - Check that the calling user is authorized to issue administration requests to the OMAG Server Platform. validateUserAsOperatorForPlatform - Check that the calling user is authorized to issue operator requests to the OMAG Server Platform. validateUserAsInvestigatorForPlatform - Check that the calling user is authorized to issue operator requests to the OMAG Server Platform. Open metadata server security connector interface \u00b6 The connector that can be defined for an OMAG Server offers a series of layers of security checks. An organization can choose which layers to make use of and which to allow all requests to pass. Figure 2 shows the layers. Each layer is implemented in a separate interface and the connector can choose which interfaces to implement. Below are the interfaces and methods for the different layers: OpenMetadataServerSecurity - provides the root interface for a connector that validates access to Open Metadata services and instances for a specific user. There are other optional interfaces that define which actions should be validated. validateUserForServer - Checks that the calling user is authorized to issue a (any) request to the OMAG Server. validateUserAsServerAdmin - Checks that the calling user is authorized to update the configuration for a server. validateUserAsServerOperator - Checks that the calling user is authorized to issue operator requests to the OMAG Server. validateUserAsServerInvestigator - Checks that the calling user is authorized to issue operator requests to the OMAG Server. OpenMetadataServiceSecurity - provides the interface for a plugin connector that validates whether a calling user can access a specific metadata service. It is called within the context of a specific OMAG Server. Each OMAG Server can define its own plugin connector implementation and will have its own instance of the connector. However the server name is supplied so a single connector can use it for logging error messages and locating the valid user list for the server. validateUserForService - Checks that the calling user is authorized to issue this request. validateUserForServiceOperation - Checks that the calling user is authorized to issue this specific request. OpenMetadataRepositorySecurity - defines security checks for accessing and maintaining open metadata types and instances in the local repository. An instance is an entity or a relationship. There is also a special method for changing classifications added to an entity. validateUserForTypeCreate - Tests for whether a specific user should have the right to create a typeDef within a repository. validateUserForTypeRead - Tests for whether a specific user should have read access to a specific typeDef within a repository. validateUserForTypeUpdate - Tests for whether a specific user should have the right to update a typeDef within a repository. validateUserForTypeDelete - Tests for whether a specific user should have the right to delete a typeDef within a repository. validateUserForEntityCreate - Tests for whether a specific user should have the right to create a instance within a repository. validateUserForEntityRead - Tests for whether a specific user should have read access to a specific instance within a repository. May also remove content from the entity before it is passed to caller. validateUserForEntitySummaryRead - Tests for whether a specific user should have read access to a specific instance within a repository. validateUserForEntityProxyRead - Tests for whether a specific user should have read access to a specific instance within a repository. validateUserForEntityUpdate - Tests for whether a specific user should have the right to update a instance within a repository. validateUserForEntityClassificationUpdate - Tests for whether a specific user should have the right to update the classification for an entity instance within a repository. validateUserForEntityDelete - Tests for whether a specific user should have the right to delete a instance within a repository. validateUserForRelationshipCreate - Tests for whether a specific user should have the right to create a instance within a repository. validateUserForRelationshipRead - Tests for whether a specific user should have read access to a specific instance within a repository. May also remove content from the relationship before it is passed to caller. validateUserForRelationshipUpdate - Tests for whether a specific user should have the right to update a instance within a repository. validateUserForRelationshipDelete - Tests for whether a specific user should have the right to delete a instance within a repository. validateEntityReferenceCopySave - Tests for whether a reference copy should be saved to the repository. validateRelationshipReferenceCopySave - Tests for whether a reference copy should be saved to the repository. OpenMetadataEventsSecurity - defines security checks for sending and receiving events on the open metadata repository cohorts . validateInboundEvent - Validates whether an event received from another member of the cohort should be processed by this server. May also remove content from the event before it is processed by the server. validateOutboundEvent - Validates whether an event should be sent to the other members of the cohort by this server. May also remove content from the event before it is sent to the cohort. OpenMetadataAssetSecurity - validates what a user is allowed to do with to Assets. The methods are given access to the whole asset to allow a variety of values to be tested. setSupportedZonesForUser - Provides an opportunity to override the deployed module setting of supportedZones for a user specific list. validateUserForAssetCreate - Tests for whether a specific user should have the right to create an asset. validateUserForAssetRead - Tests for whether a specific user should have read access to a specific asset. validateUserForAssetDetailUpdate - Tests for whether a specific user should have the right to update an asset. This is used for a general asset update, which may include changes to the zones and the ownership. validateUserForAssetAttachmentUpdate - Tests for whether a specific user should have the right to update elements attached directly to an asset such as schema and connections. validateUserForAssetFeedback - Tests for whether a specific user should have the right to attach feedback - such as comments, ratings, tags and likes, to the asset. validateUserForAssetDelete - Tests for whether a specific user should have the right to delete an asset. OpenMetadataConnectionSecurity - defines the interface of a connector that is validating whether a specific user should be given access to a specific Connection object. This connection information has been retrieved from an open metadata repository. It is used to create a Connector to an Asset. It may include user credentials that could enhance the access to data and function within the Asset that is far above the specific user's approval. This is why this optional check is performed by any open metadata service that is returning a Connection object (or a Connector created with the Connection object) to an external party. validateUserForConnection - Tests for whether a specific user should have access to a connection. validateUserForAssetConnectionList - Selects an appropriate connection for a user from the list of connections attached to an Asset. Sample connectors \u00b6 There are sample implementations of the security connectors for Coco Pharmaceuticals in the samples module under open-metadata-security-samples","title":"Metadata Security"},{"location":"features/metadata-security/overview/#open-metadata-security","text":"Open Metadata Security provides fine-grained authorization services for open metadata services, types and instances. Since each organization will have different security requirements, the support is implemented through connectors. Egeria defines the interfaces and when it will call the connector. You define the behavior when the connector is called and Egeria acts on the returned decision. The metadata-security module defines the base classes and interfaces for the open metadata security connectors as well as the server implementation to host and call them. There are two types of connector: Open metadata platform security connector - secures access to the platform services that are not specific to an OMAG Server. This includes the admin services to create new servers, the ability to start and stop new servers as well as the ability to query whether a server is running, and if it is, what services are active. Open metadata server security connector - secures access to the specific services of an OMAG server. This includes the server itself, specific services within the server, specific Assets and Connections managed by the server and the types and instances stored in the local repository. The 2 types of connectors are shown in Figure 1: Figure 1: positioning of the security connectors Within an OMAG Server Platform there is one instance of the open metadata platform security connector. This connector is configured once the platform is running using the admin service call: POST /open-metadata/admin-services/users/{{adminUserId}}/platform/security/connection where the {{adminUserId}} is the administrator's userId. The connection for the connector and the platform URL root are passed in the request body. There are GET and DELETE services with the same URL to retrieve and remove this connector respectively. The open metadata server security connector is configured for each OMAG server to allow for each server to have a different implementation. The admin services command to configure a security connector for a server is: POST /open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection where the {{adminUserId}} is the administrator's userId and {{serverName}} is the name of the server where the connector is to run. The connection for the server security connector is passed in the request body. Again, there are GET and DELETE services with the same URL to retrieve and remove this connector respectively. The security implementation in a server potentially invokes the server security connector multiple types as the request (shown as dotted white arrow) penetrates the server code. Figure 2 shows the different layers of checks. Each layer is optional and so the server security connector can be implemented to support the most appropriate granularity of security for the situation. Details of the implementation choices are given in the security connector API . Figure 2: layers of security checks within the server The security connectors are optional. If they are not defined then there are no additional authorization checks performed inside the OMAG Server Platform nor the OMAG Servers hosted on the platform. As such, it is important that the open metadata platform security connector is configured as soon as the platform is started, and the server security connector is configured before the server is started for the first time.","title":"Open Metadata Security"},{"location":"features/metadata-security/overview/#metadata-security-apis","text":"Below is a description of the API of the two Open Metadata Security Connectors .","title":"Metadata security APIs"},{"location":"features/metadata-security/overview/#open-metadata-platform-security-connector-interface","text":"The connector that plugs in to the platform implements the following interface. OpenMetadataPlatformSecurity - provides the interface for a plugin connector that validates whether a calling user can access any service on an OMAG Server Platform. It is called within the context of a specific OMAG Server Platform request. Each OMAG Server Platform can define its own plugin connector implementation and will have its own instance of the connector. validateUserForPlatform - Check that the calling user is authorized to issue a (any) request to the OMAG Server Platform. validateUserAsAdminForPlatform - Check that the calling user is authorized to issue administration requests to the OMAG Server Platform. validateUserAsOperatorForPlatform - Check that the calling user is authorized to issue operator requests to the OMAG Server Platform. validateUserAsInvestigatorForPlatform - Check that the calling user is authorized to issue operator requests to the OMAG Server Platform.","title":"Open metadata platform security connector interface"},{"location":"features/metadata-security/overview/#open-metadata-server-security-connector-interface","text":"The connector that can be defined for an OMAG Server offers a series of layers of security checks. An organization can choose which layers to make use of and which to allow all requests to pass. Figure 2 shows the layers. Each layer is implemented in a separate interface and the connector can choose which interfaces to implement. Below are the interfaces and methods for the different layers: OpenMetadataServerSecurity - provides the root interface for a connector that validates access to Open Metadata services and instances for a specific user. There are other optional interfaces that define which actions should be validated. validateUserForServer - Checks that the calling user is authorized to issue a (any) request to the OMAG Server. validateUserAsServerAdmin - Checks that the calling user is authorized to update the configuration for a server. validateUserAsServerOperator - Checks that the calling user is authorized to issue operator requests to the OMAG Server. validateUserAsServerInvestigator - Checks that the calling user is authorized to issue operator requests to the OMAG Server. OpenMetadataServiceSecurity - provides the interface for a plugin connector that validates whether a calling user can access a specific metadata service. It is called within the context of a specific OMAG Server. Each OMAG Server can define its own plugin connector implementation and will have its own instance of the connector. However the server name is supplied so a single connector can use it for logging error messages and locating the valid user list for the server. validateUserForService - Checks that the calling user is authorized to issue this request. validateUserForServiceOperation - Checks that the calling user is authorized to issue this specific request. OpenMetadataRepositorySecurity - defines security checks for accessing and maintaining open metadata types and instances in the local repository. An instance is an entity or a relationship. There is also a special method for changing classifications added to an entity. validateUserForTypeCreate - Tests for whether a specific user should have the right to create a typeDef within a repository. validateUserForTypeRead - Tests for whether a specific user should have read access to a specific typeDef within a repository. validateUserForTypeUpdate - Tests for whether a specific user should have the right to update a typeDef within a repository. validateUserForTypeDelete - Tests for whether a specific user should have the right to delete a typeDef within a repository. validateUserForEntityCreate - Tests for whether a specific user should have the right to create a instance within a repository. validateUserForEntityRead - Tests for whether a specific user should have read access to a specific instance within a repository. May also remove content from the entity before it is passed to caller. validateUserForEntitySummaryRead - Tests for whether a specific user should have read access to a specific instance within a repository. validateUserForEntityProxyRead - Tests for whether a specific user should have read access to a specific instance within a repository. validateUserForEntityUpdate - Tests for whether a specific user should have the right to update a instance within a repository. validateUserForEntityClassificationUpdate - Tests for whether a specific user should have the right to update the classification for an entity instance within a repository. validateUserForEntityDelete - Tests for whether a specific user should have the right to delete a instance within a repository. validateUserForRelationshipCreate - Tests for whether a specific user should have the right to create a instance within a repository. validateUserForRelationshipRead - Tests for whether a specific user should have read access to a specific instance within a repository. May also remove content from the relationship before it is passed to caller. validateUserForRelationshipUpdate - Tests for whether a specific user should have the right to update a instance within a repository. validateUserForRelationshipDelete - Tests for whether a specific user should have the right to delete a instance within a repository. validateEntityReferenceCopySave - Tests for whether a reference copy should be saved to the repository. validateRelationshipReferenceCopySave - Tests for whether a reference copy should be saved to the repository. OpenMetadataEventsSecurity - defines security checks for sending and receiving events on the open metadata repository cohorts . validateInboundEvent - Validates whether an event received from another member of the cohort should be processed by this server. May also remove content from the event before it is processed by the server. validateOutboundEvent - Validates whether an event should be sent to the other members of the cohort by this server. May also remove content from the event before it is sent to the cohort. OpenMetadataAssetSecurity - validates what a user is allowed to do with to Assets. The methods are given access to the whole asset to allow a variety of values to be tested. setSupportedZonesForUser - Provides an opportunity to override the deployed module setting of supportedZones for a user specific list. validateUserForAssetCreate - Tests for whether a specific user should have the right to create an asset. validateUserForAssetRead - Tests for whether a specific user should have read access to a specific asset. validateUserForAssetDetailUpdate - Tests for whether a specific user should have the right to update an asset. This is used for a general asset update, which may include changes to the zones and the ownership. validateUserForAssetAttachmentUpdate - Tests for whether a specific user should have the right to update elements attached directly to an asset such as schema and connections. validateUserForAssetFeedback - Tests for whether a specific user should have the right to attach feedback - such as comments, ratings, tags and likes, to the asset. validateUserForAssetDelete - Tests for whether a specific user should have the right to delete an asset. OpenMetadataConnectionSecurity - defines the interface of a connector that is validating whether a specific user should be given access to a specific Connection object. This connection information has been retrieved from an open metadata repository. It is used to create a Connector to an Asset. It may include user credentials that could enhance the access to data and function within the Asset that is far above the specific user's approval. This is why this optional check is performed by any open metadata service that is returning a Connection object (or a Connector created with the Connection object) to an external party. validateUserForConnection - Tests for whether a specific user should have access to a connection. validateUserForAssetConnectionList - Selects an appropriate connection for a user from the list of connections attached to an Asset.","title":"Open metadata server security connector interface"},{"location":"features/metadata-security/overview/#sample-connectors","text":"There are sample implementations of the security connectors for Coco Pharmaceuticals in the samples module under open-metadata-security-samples","title":"Sample connectors"},{"location":"features/templated-cataloguing/overview/","text":"Templated cataloging \u00b6 Templated cataloguing is useful for situations where new assets are regularly created that are of the same kind. When a new asset is cataloged, the catalog entry of a similar asset is supplied and it is used as a template to set up the new asset. This approach is extremely valuable where there has been investment to provide a rich set of information about the assets since it ensures this content is applied consistently to each new asset with a single command. The Asset Owner OMAS , IT Infrastructure OMAS and Digital Architecture OMAS provides the ability to set up and use templates to catalog new assets. For this to work well, the organization needs to have thought through the types of information that should be included in the catalog entry for these types of asset and manually set up the first asset so that it can be used as a template for subsequent assets. There is no linkage kept between an asset and its template except they may be linked to some of the same shared definitions. However, much of the core content of the asset catalog entry (such as the Asset definition itself, Connection and Schema) are copied into the new entry. If the same change is needed to all assets of a similar kind created from the same template, then this needs to be done to each asset entry. However the consistency of these asset catalog entries due to the use of the template means that automating this update is much easier. Adding automation \u00b6 Below are other types of automation to minimise the effort in managing your asset catalog. Integrated cataloguing - automated extraction of metadata from third party technologies. Discovery and stewardship - analysis of asset contents to create metadata.","title":"Templated Cataloguing"},{"location":"features/templated-cataloguing/overview/#templated-cataloging","text":"Templated cataloguing is useful for situations where new assets are regularly created that are of the same kind. When a new asset is cataloged, the catalog entry of a similar asset is supplied and it is used as a template to set up the new asset. This approach is extremely valuable where there has been investment to provide a rich set of information about the assets since it ensures this content is applied consistently to each new asset with a single command. The Asset Owner OMAS , IT Infrastructure OMAS and Digital Architecture OMAS provides the ability to set up and use templates to catalog new assets. For this to work well, the organization needs to have thought through the types of information that should be included in the catalog entry for these types of asset and manually set up the first asset so that it can be used as a template for subsequent assets. There is no linkage kept between an asset and its template except they may be linked to some of the same shared definitions. However, much of the core content of the asset catalog entry (such as the Asset definition itself, Connection and Schema) are copied into the new entry. If the same change is needed to all assets of a similar kind created from the same template, then this needs to be done to each asset entry. However the consistency of these asset catalog entries due to the use of the template means that automating this update is much easier.","title":"Templated cataloging"},{"location":"features/templated-cataloguing/overview/#adding-automation","text":"Below are other types of automation to minimise the effort in managing your asset catalog. Integrated cataloguing - automated extraction of metadata from third party technologies. Discovery and stewardship - analysis of asset contents to create metadata.","title":"Adding automation"},{"location":"frameworks/alf/overview/","text":"Released This function is complete and can be used. The interfaces will be supported until the function is removed from the project via the deprecation process. There will be ongoing extensions to this function, but it will be done to ensure backward compatibility as far as possible. If there is a need to break backward compatibility, this will be discussed and reviewed in the community, with a documented timeline. Audit Log Framework ( ALF ) \u00b6 The audit log framework ( ALF ) provides interface definitions and classes to enable connectors to support natural language enabled diagnostics such as exception messages and audit log messages. The audit log framework provides the ability to route audit log records to multiple destinations where they can be stored or processed automatically. This second option is particularly important in today's world of continuous operations. Figure 1 shows the main parts of the framework. Figure 1: Components of the Audit Log Framework ( ALF ) When processing activity wishes to log a message to the audit log, it selects a message definition from a message set, optionally passing in the values to fill out the placeholders in the message template. The message definition is passed to the audit log where it calls the message formatter, builds a log record and passes it on to the audit destination. The audit log destination can be extended to allow routing to different destinations for review and processing. Usage \u00b6 The Open Metadata Repository Services ( OMRS ) provide an extension to the audit log destination that supports audit log store connectors. This means that an OMAG Server can be configured to route audit log messages to different destinations. Details of the supported audit log store connectors and how to set them up are described in configuring the audit log .","title":"Overview"},{"location":"frameworks/alf/overview/#audit-log-framework-alf","text":"The audit log framework ( ALF ) provides interface definitions and classes to enable connectors to support natural language enabled diagnostics such as exception messages and audit log messages. The audit log framework provides the ability to route audit log records to multiple destinations where they can be stored or processed automatically. This second option is particularly important in today's world of continuous operations. Figure 1 shows the main parts of the framework. Figure 1: Components of the Audit Log Framework ( ALF ) When processing activity wishes to log a message to the audit log, it selects a message definition from a message set, optionally passing in the values to fill out the placeholders in the message template. The message definition is passed to the audit log where it calls the message formatter, builds a log record and passes it on to the audit destination. The audit log destination can be extended to allow routing to different destinations for review and processing.","title":"Audit Log Framework (ALF)"},{"location":"frameworks/alf/overview/#usage","text":"The Open Metadata Repository Services ( OMRS ) provide an extension to the audit log destination that supports audit log store connectors. This means that an OMAG Server can be configured to route audit log messages to different destinations. Details of the supported audit log store connectors and how to set them up are described in configuring the audit log .","title":"Usage"},{"location":"frameworks/gaf/overview/","text":"Technical preview Technical preview function is in a state that it can be tried. The development is complete, there is documentation and there are samples, tutorials and hands-on labs as appropriate. The community is looking for feedback on the function before releasing it. This feedback may result in changes to the external interfaces. Governance Action Framework ( GAF ) \u00b6 The governance action framework ( GAF ) provides the interfaces and base implementations for components (called governance action services ) that take action to: detect, report and eventually correct a situation that is harmful to the data or the organization in some way or to enhance the metadata to improve its use. The governance action framework can be used for three purposes: Provide the complete implementation and orchestration of a governance process. Provide coordination between processes run by specialized governance systems. For example, coordinating a DevOps pipeline with a data movement and quality process and security incident management. Provide contextual metadata plus an audit trail of actions managed by an external governance process. Governance action \u00b6 A governance action describes a specific governance activity that needs to be performed on one or more metadata elements, or their counterparts in the digital landscape. A governance action is represented as a metadata entity in the open metadata repositories and linked to: The source (cause) of the governance action. The target elements that need to be acted upon. The governance engine that will run the governance service that implements the desired behavior. The GovernanceAction metadata entity is used to coordinate the desired activity in the governance engine, record its current state and act as a record of the activity for future audits. Governance actions can be created through the Governance Engine OMAS . Some governance services (for example, the watchdog governance action service ) can create governance actions when they run. Governance services produce output strings called guards that indicate specific conditions or outcomes. These guards can be used to trigger new governance actions. Triggered governance actions are linked to their predecessor so it possible to trace through the governance actions that ran. The governance action process defines the flow of governance actions. It uses governance action types to build up a template of possible governance actions linked via the guards. When the process runs, its linked governance action types control the triggering of new governance actions. If the start date of the governance action is in the future, the engine host services running in the same engine host as the nominated governance engine will schedule the governance service to run soon after the requested start date. If the start date is left blank, the requested governance service is run as soon as possible. Governance action process \u00b6 A governance action process defines a prescribed sequence of governance actions . Its definition consists of a linked set of governance action types . Each governance action type describes which governance action service to run from which governance action engine along with the request type and request parameters to pass. The linkage between the governance action types shows the guards that must be true to initiate the next governance action in the flow. The 0461 governance action engines model shows how the request type links the governance action engine to the governance action service via the SupportedGovernanceActionService relationship. The 0470 incident reporting model shows the structure of the incident report. It is a Referenceable so it can support comments and have governance actions linked to it. Further information Governance action processes are defined using the Governance Engine OMAS . The Open Metadata Engine Services ( OMES ) provide the mechanisms that support the different types of governance action engines . These engines run the governance action services that execute the governance actions defined by the governance action process. Governance action type \u00b6 A governance action type is a template for a governance action . A set of linked governance action types form the definition of a governance action process. Governance action types are defined through the Governance Engine OMAS and this OMAS also coordinates the creation of a governance action from the governance action type as part of its execution of the governance action process. The governance action type is defined in the 0462 governance action type model. Guard \u00b6 Guards are labels that are created by governance action services and are used by the Governance Engine OMAS to determine which governance action service to run next. Incident report \u00b6 An incident report describes a situation that is out of line with the governance definitions (such as policies and rules). It provides a focus point to coordinate efforts to resolve the situation. As the incident is handled, details of the cause, affected resources and actions taken are attached to the incident report to create a complete record of the incident for future analysis. Incident reports are typically created by governance watchdog services . The 0470 incident reporting model shows the structure of the incident report. It is a Referenceable so it can support comments and linked classifications and tags. Governance action services \u00b6 A governance action service is a specialized connector that performs monitoring of metadata changes, validation of metadata, triage of issues, assessment and/or remediation activities on request. There are five types of governance action services, each of which supports a specialist governance activity (see subsections). These are often used in conjunction with the open discovery services from the Open Discovery Framework ( ODF ) . Collectively they are called the governance services and they can be linked together into governance action processes . Some governance action services invoke functions in external engines that are working with data and related assets. The GAF offers embeddable functions and APIs to simplify the implementation of governance action services, and their integration into the broader digital landscape, whilst being resilient and with good performance. Watchdog governance service \u00b6 The watchdog governance service monitors changes in the metadata and initiates one of the following as a result: governance action governance action process incident report One example of a watchdog governance service is to monitor for new assets . Another example is to monitor the addition of open discovery reports and take action on their content. Verification governance service \u00b6 Verification governance services test the properties of specific open metadata elements to ensure they are set up correctly and do not indicate a situation where governance activity is required. The results returned from the verification governance service can be used to trigger other governance services as part of a governance action process . The verification services may also publish guards to report on any errors it finds. For example, it may check that a new asset has an owner, is set up with zones and includes a connection and a schema. Triage governance service \u00b6 Triage governance services run triage rules to determine how to manage a situation. This could be to initiate an external workflow, wait for manual decision or initiate a remediation request through either an external workflow or by creating a ToDo for a specific person. Remediation governance service \u00b6 The remediation governance services perform updates to metadata. Examples of remediation services are duplicate linking and consolidation. Provisioning governance service \u00b6 A provisioning governance service invokes a provisioning service whenever a provisioning request is made. Typically, the provisioning service is an external service. It may also create lineage metadata to describe the work of the provisioning engine. Implementing governance action services \u00b6 Governance action services are open connectors that support the interfaces defined by the GAF . They may produce audit log records and exceptions, and they may make changes to metadata through the Open Metadata Access Services ( OMAS ) . A governance action service is passed a context as it is started. This provides access to the request type and associated parameters (name-value pairs) used to invoke the governance action service, along with a client to access open metadata through the Governance Engine OMAS . This context is then specialized for each type of governance action service. Details of the specific context for each service can be found in the links above to the various governance action service types. Configuring governance action services \u00b6 A collection of related governance action services are grouped into governance action engines for deployment. The governance action engine maps governance action request types to the governance action service that should be invoked along with. These definitions are created through the Governance Engine OMAS and are stored in the open metadata repositories. Governance action engines are hosted in an Open Metadata Engine Service ( OMES ) running on one or more engine hosts . The Open Metadata Types used to define the governance action engines are located in 0461 governance action engines . Running governance action services \u00b6 Governance action engines are hosted by the Governance Action OMES . The engine services run in dedicated OMAG Server called the engine host . You can find instructions for configuring the engine services in the engine host in the administration guide. The Governance Engine OMAS provides the services for: setting up the definitions of a governance action engine. configuring governance action processes . managing governance actions and incident reports . Governance pack \u00b6 A governance pack is a collection of pre-defined governance engines and services definitions plus governance service implementations. A team can use the governance pack to distribute the governance engine function to different metadata ecosystems.","title":"Overview"},{"location":"frameworks/gaf/overview/#governance-action-framework-gaf","text":"The governance action framework ( GAF ) provides the interfaces and base implementations for components (called governance action services ) that take action to: detect, report and eventually correct a situation that is harmful to the data or the organization in some way or to enhance the metadata to improve its use. The governance action framework can be used for three purposes: Provide the complete implementation and orchestration of a governance process. Provide coordination between processes run by specialized governance systems. For example, coordinating a DevOps pipeline with a data movement and quality process and security incident management. Provide contextual metadata plus an audit trail of actions managed by an external governance process.","title":"Governance Action Framework (GAF)"},{"location":"frameworks/gaf/overview/#governance-action","text":"A governance action describes a specific governance activity that needs to be performed on one or more metadata elements, or their counterparts in the digital landscape. A governance action is represented as a metadata entity in the open metadata repositories and linked to: The source (cause) of the governance action. The target elements that need to be acted upon. The governance engine that will run the governance service that implements the desired behavior. The GovernanceAction metadata entity is used to coordinate the desired activity in the governance engine, record its current state and act as a record of the activity for future audits. Governance actions can be created through the Governance Engine OMAS . Some governance services (for example, the watchdog governance action service ) can create governance actions when they run. Governance services produce output strings called guards that indicate specific conditions or outcomes. These guards can be used to trigger new governance actions. Triggered governance actions are linked to their predecessor so it possible to trace through the governance actions that ran. The governance action process defines the flow of governance actions. It uses governance action types to build up a template of possible governance actions linked via the guards. When the process runs, its linked governance action types control the triggering of new governance actions. If the start date of the governance action is in the future, the engine host services running in the same engine host as the nominated governance engine will schedule the governance service to run soon after the requested start date. If the start date is left blank, the requested governance service is run as soon as possible.","title":"Governance action"},{"location":"frameworks/gaf/overview/#governance-action-process","text":"A governance action process defines a prescribed sequence of governance actions . Its definition consists of a linked set of governance action types . Each governance action type describes which governance action service to run from which governance action engine along with the request type and request parameters to pass. The linkage between the governance action types shows the guards that must be true to initiate the next governance action in the flow. The 0461 governance action engines model shows how the request type links the governance action engine to the governance action service via the SupportedGovernanceActionService relationship. The 0470 incident reporting model shows the structure of the incident report. It is a Referenceable so it can support comments and have governance actions linked to it. Further information Governance action processes are defined using the Governance Engine OMAS . The Open Metadata Engine Services ( OMES ) provide the mechanisms that support the different types of governance action engines . These engines run the governance action services that execute the governance actions defined by the governance action process.","title":"Governance action process"},{"location":"frameworks/gaf/overview/#governance-action-type","text":"A governance action type is a template for a governance action . A set of linked governance action types form the definition of a governance action process. Governance action types are defined through the Governance Engine OMAS and this OMAS also coordinates the creation of a governance action from the governance action type as part of its execution of the governance action process. The governance action type is defined in the 0462 governance action type model.","title":"Governance action type"},{"location":"frameworks/gaf/overview/#guard","text":"Guards are labels that are created by governance action services and are used by the Governance Engine OMAS to determine which governance action service to run next.","title":"Guard"},{"location":"frameworks/gaf/overview/#incident-report","text":"An incident report describes a situation that is out of line with the governance definitions (such as policies and rules). It provides a focus point to coordinate efforts to resolve the situation. As the incident is handled, details of the cause, affected resources and actions taken are attached to the incident report to create a complete record of the incident for future analysis. Incident reports are typically created by governance watchdog services . The 0470 incident reporting model shows the structure of the incident report. It is a Referenceable so it can support comments and linked classifications and tags.","title":"Incident report"},{"location":"frameworks/gaf/overview/#governance-action-services","text":"A governance action service is a specialized connector that performs monitoring of metadata changes, validation of metadata, triage of issues, assessment and/or remediation activities on request. There are five types of governance action services, each of which supports a specialist governance activity (see subsections). These are often used in conjunction with the open discovery services from the Open Discovery Framework ( ODF ) . Collectively they are called the governance services and they can be linked together into governance action processes . Some governance action services invoke functions in external engines that are working with data and related assets. The GAF offers embeddable functions and APIs to simplify the implementation of governance action services, and their integration into the broader digital landscape, whilst being resilient and with good performance.","title":"Governance action services"},{"location":"frameworks/gaf/overview/#watchdog-governance-service","text":"The watchdog governance service monitors changes in the metadata and initiates one of the following as a result: governance action governance action process incident report One example of a watchdog governance service is to monitor for new assets . Another example is to monitor the addition of open discovery reports and take action on their content.","title":"Watchdog governance service"},{"location":"frameworks/gaf/overview/#verification-governance-service","text":"Verification governance services test the properties of specific open metadata elements to ensure they are set up correctly and do not indicate a situation where governance activity is required. The results returned from the verification governance service can be used to trigger other governance services as part of a governance action process . The verification services may also publish guards to report on any errors it finds. For example, it may check that a new asset has an owner, is set up with zones and includes a connection and a schema.","title":"Verification governance service"},{"location":"frameworks/gaf/overview/#triage-governance-service","text":"Triage governance services run triage rules to determine how to manage a situation. This could be to initiate an external workflow, wait for manual decision or initiate a remediation request through either an external workflow or by creating a ToDo for a specific person.","title":"Triage governance service"},{"location":"frameworks/gaf/overview/#remediation-governance-service","text":"The remediation governance services perform updates to metadata. Examples of remediation services are duplicate linking and consolidation.","title":"Remediation governance service"},{"location":"frameworks/gaf/overview/#provisioning-governance-service","text":"A provisioning governance service invokes a provisioning service whenever a provisioning request is made. Typically, the provisioning service is an external service. It may also create lineage metadata to describe the work of the provisioning engine.","title":"Provisioning governance service"},{"location":"frameworks/gaf/overview/#implementing-governance-action-services","text":"Governance action services are open connectors that support the interfaces defined by the GAF . They may produce audit log records and exceptions, and they may make changes to metadata through the Open Metadata Access Services ( OMAS ) . A governance action service is passed a context as it is started. This provides access to the request type and associated parameters (name-value pairs) used to invoke the governance action service, along with a client to access open metadata through the Governance Engine OMAS . This context is then specialized for each type of governance action service. Details of the specific context for each service can be found in the links above to the various governance action service types.","title":"Implementing governance action services"},{"location":"frameworks/gaf/overview/#configuring-governance-action-services","text":"A collection of related governance action services are grouped into governance action engines for deployment. The governance action engine maps governance action request types to the governance action service that should be invoked along with. These definitions are created through the Governance Engine OMAS and are stored in the open metadata repositories. Governance action engines are hosted in an Open Metadata Engine Service ( OMES ) running on one or more engine hosts . The Open Metadata Types used to define the governance action engines are located in 0461 governance action engines .","title":"Configuring governance action services"},{"location":"frameworks/gaf/overview/#running-governance-action-services","text":"Governance action engines are hosted by the Governance Action OMES . The engine services run in dedicated OMAG Server called the engine host . You can find instructions for configuring the engine services in the engine host in the administration guide. The Governance Engine OMAS provides the services for: setting up the definitions of a governance action engine. configuring governance action processes . managing governance actions and incident reports .","title":"Running governance action services"},{"location":"frameworks/gaf/overview/#governance-pack","text":"A governance pack is a collection of pre-defined governance engines and services definitions plus governance service implementations. A team can use the governance pack to distribute the governance engine function to different metadata ecosystems.","title":"Governance pack"},{"location":"frameworks/ocf/overview/","text":"Released This function is complete and can be used. The interfaces will be supported until the function is removed from the project via the deprecation process. There will be ongoing extensions to this function, but it will be done to ensure backward compatibility as far as possible. If there is a need to break backward compatibility, this will be discussed and reviewed in the community, with a documented timeline. Open Connector Framework ( OCF ) \u00b6 The open connector framework ( OCF ), as the name suggests, is an open framework for supporting connectors . Connector provide client-side access to remote digital assets such as data sets, APIs and software components. OCF connectors also provide access to metadata about the asset and may call the Governance Action Framework ( GAF ) to log audit messages and execute appropriate governance actions related to the use of these assets in real-time. Benefits \u00b6 Applications and tools benefit from using OCF connectors because: Network and security parameters for accessing the data resources are managed in the metadata repository as part of a named connection. The application need only supply the identifier of the connection and provided they have the appropriate security credentials then a connector is returned to them for use. There is no need to hard-code user ids and passwords in the application code - nor manage key stores for this sensitive information since the metadata repository handles this. If the location of the data changes, then the named connection configuration is changed in the metadata repository and the application will be connected to the new location the next time they request a connector. The OCF connector provides two sets of APIs. The first set provides access to the asset contents and the second set provides access to the properties of the asset stored in the open metadata repositories. This provides applications and tools with a simple mechanism to make use of metadata as they process about the asset. It is particularly useful for data science tools where these properties can help guide the end user in the use of the asset. OCF connectors are not limited to representing assets as they are physically implemented. An OCF connector can represent a simplified logical (virtual) data resource that is designed for the needs of a specific application or tool. This type of connector delegates the requests it receives to one or more physical data resources. Organizations benefit from advocating the use of OCF connectors for their systems because the OCF connectors provide a consistent approach to governance enforcement and audit logging. This is particularly important in data-rich environments where individuals are able to combine data from different assets creating new, potentially sensitive insight. The common approach to auditing, and the linkage between the data accessed and the metadata that describes its characteristics help to detect and prevent such actions. Design rationale \u00b6 The following factors influenced the design of the OCF . There are many existing connectors and connector frameworks in the industry today. It is important that these existing connectors can be incorporated into the OCF . Thus, the OCF includes placeholders for adapters to external connector providers and connectors. Application developers will only adopt a connector framework if it is easy to use. Thus, the connector interfaces allow for the use of native data APIs to minimize the effort an application developer has to take in order to use the OCF connectors. Governance enforcement is a complex topic, typically managed externally to the application development team. As a result, a separate framework called the governance action framework ( GAF ) manages governance enforcement. The role of the OCF is to bridge from the asset access requests to the GAF where necessary. Access to the all properties known about an asset should be available to the consumers of the asset.Therefore, the OCF provides a standard interface for accessing these properties. Different providers of these properties can plug into the OCF . Egeria provides an implementation of this interface to supply asset properties stored in open metadata repositories in the OCF metadata management common service . Terminology \u00b6 There are a number of key components within the OCF : Connector \u00b6 A connector is a Java client object that provides applications with access to a data source or service (known as an asset ) along with its related metadata and governance functions. An OCF connector provides four APIs: API Description Connector lifecycle Manages the lifecycle state of the connector and includes initialize() , start() and disconnect() . Metadata store initialization If the connector is created by a metadata service then it adds a client to the metadata server called ConnectedAssetProperties to the connector between initialize() and start() . The ConnectedAssetProperties client can be retrieved from the connector instance and used to retrieve metadata about the asset that is stored in the metadata server. Specific initialization for the type of connector Some types of connectors need additional initialization. These methods are called by the component creating the connector before the start() method is called. Asset content This API is crafted to provide the most natural interface to the asset's contents. Therefore, the asset content API is typically different for each type of connector. OCF connectors are not limited to representing assets as they are physically implemented. An OCF connector can represent a simplified logical (virtual) asset, such as a data set, that is designed for the needs of a specific application or tool. This type of connector delegates the requests it receives to one or more physical data resources. It is called a virtual connector . Further information See the developer guide for information on writing connectors. Connection \u00b6 The connection provides the set of properties needed to create and initialize an instance of a connector . A connection contains properties about the specific use of the connector, such as user Id and password, or parameters that control the scope or resources that should be made available to the connector. It links to an optional: Connector type that describes the type of the connector that needs to be created in order to access the asset. Endpoint that describes the server endpoint where the asset is accessed from. Connector types and endpoints can be reused in multiple connections. Connections are typically managed in a metadata repository, but they can also be manually populated. Connection implementations \u00b6 The OCF offers two implementations of the connection: Connection is a bean implementation of the connection used in REST API requests and events. It allows properties to be set up and retrieved. ConnectionProperties is a read-only wrapper for the connection properties that is used in client interfaces that do not allow the properties to be updated. Connection properties \u00b6 The properties for a connection are defined in model 0201 and include: Property Description guid GUID for the connection. url URL of the connection definition in the metadata repository. qualifiedName The official (unique) name for the connection. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. (Sourced from the qualifiedName attribute in Referenceable - model 0010 ) displayName A consumable name for the connection. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. type Information about the TypeDef for the connection. description A full description of the connection covering details of the assets it connects to along with usage and version information. additionalProperties Any additional properties associated with the connection. configurationProperties Properties for configuring the connector. securedProperties Protected properties for secure log on by connector to back end server. These are protected properties that can only be retrieved by privileged connector code. userId Name or URI of connecting user. encryptedPassword Password for the userId - needs decrypting by connector before use. clearPassword Password for userId - ready to use. connectorType Properties that describe the connector type for the connector. endpoint Properties that describe the server endpoint where the connector will retrieve the assets. Using Connections from open metadata repositories \u00b6 Each connection stored in a metadata repository has a unique identifier. An application can request a connector instance through selected Egeria OMAS interfaces, such as the Asset Consumer OMAS , with just the unique identifier or name of a connection. The OMAS retrieves the connection object from the open metadata repositories and passes it to the connector broker factory object. The connector broker (and underlying connector provider ) uses the information from the connection object to create an instance of the connector. The advantage of retrieving the connection information from a metadata repository is that the connection properties do not need to be hard-coded in the consuming applications and the metadata associated with the linked asset can be retrieved via the connector's connected asset properties interface. Connections can be created in the open metadata repositories through the following interfaces: Asset Owner OMAS Asset Manager OMAS Data Manager OMAS Database Integrator OMIS Files Integrator OMIS Governance Action OMES Configuring connections \u00b6 The administration guide describes how to configure Egeria's OMAG Server Platforms and servers. Both the platform and the servers use connectors for access to the external resources to support their basic operation and to coordinate metadata and governance with third party technologies. This means that the configuration includes connection definitions for these connectors. All of these interfaces have Java clients that enable you to set up the connection using the OCF connection bean. However, if you want to use the REST API directly, then you need to specify the connection in JSON. Example connection definition in JSON Egeria's JSON structures map one-to-ene with the properties in the equivalent Java beans and also include a class property that gives the name of the class that it maps to. So a simple connection object would look something like this in JSON: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"...fully qualified class name...\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"... network address of resource ...\" } } } Connector broker \u00b6 The connector broker is a generic factory class for all open connectors. Given a valid connection object, the connector broker is able to create a new instance of a connector . This means the caller does not need to know the implementation details of the connector - just its interface. It is implemented in the ConnectorBroker class, and is used as follows: Example usage of a connector broker 1 2 3 4 5 6 7 import org.odpi.openmetadata.frameworks.connectors.Connector ; import org.odpi.openmetadata.frameworks.connectors.ConnectorBroker ; // ... ConnectorBroker connectorBroker = new ConnectorBroker (); Connector connector = connectorBroker . getConnector ( connection ); When the connector instance is requested, the connector broker uses the connector type properties from the supplied connection to identify the appropriate connector provider . The connector broker delegates the connector instance request to the connector provider and returns the result to its caller. The connector broker is used in the client code of the Open Metadata Access Services ( OMAS ) that provide connector instances to their consumers, for example: Asset Consumer OMAS Asset Owner OMAS Connector type \u00b6 The connector type is a set of properties that defines the supported capabilities and the identity of the connector provider for a connector . Its properties are: Property Description guid GUID for the connector type. url External link address for the connector type properties in the metadata repository. qualifiedName The official (unique) name for the connector type. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. displayName A consumable name for the connector type. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. description A full description of the connector type covering details of the assets it connects to along with usage and versioning information. connectorProviderClassName The connector provider is the factory for a particular type of connector . This property defines the class name for the connector provider that the connector broker should use to request new connector instances. recognizedAdditionalProperties These are the connection 's additional properties recognized by the connector implementation. recognizedConfigurationProperties These are the connection 's configuration properties recognized by the connector implementation. recognizedSecuredProperties These are the connection 's secured properties recognized by the connector implementation. additionalProperties Any additional properties that the connector provider needs to know in order to create connector instances. The connector type is linked to the connection objects that request this type of connector. Further information The open metadata type for a connector type is defined in model 0201 . The open connector archives module provides an open metadata archive that contains connector types for connectors supported by Egeria. Connector provider \u00b6 A connector provider is the factory for a particular type of connector . It is typically called from the connector broker , although it may be called directly. Each connector provider implements the ConnectorProvider interface. It has two types of methods: Return the connector type object that is added to a connection object used to hold the properties needed to create an instance of the connector . Return a new instance of the connector based on the properties in a connection object. The connection object that has all the properties needed to create and configure the instance of the connector. The ConnectorProviderBase class provides much of the implementation for a connector provider. Example implementation of the connector provider for a simple connector If you have a simple connector implementation then your connector provider follows the following template. It assumes the connector is for the XXXStore and is called XXXStoreConnector . With this base implementation, a specific connector provider implementation need only implement a constructor to configure the base class's function with details of itself and the Java class of the connector it needs. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /** * XXXStoreProvider is the OCF connector provider for the XXX store connector. */ public class XXXStoreProvider extends ConnectorProviderBase { static final String connectorTypeGUID = \"Add unique GUID here\" ; static final String connectorTypeName = \"XXX Store Connector\" ; static final String connectorTypeDescription = \"Connector supports ... add details here\" ; /** * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific * store implementation. */ public BasicFileStoreProvider () { Class <?> connectorClass = XXXStoreConnector . class ; super . setConnectorClassName ( connectorClass . getName ()); ConnectorType connectorType = new ConnectorType (); connectorType . setType ( ConnectorType . getConnectorTypeType ()); connectorType . setGUID ( connectorTypeGUID ); connectorType . setQualifiedName ( connectorTypeName ); connectorType . setDisplayName ( connectorTypeName ); connectorType . setDescription ( connectorTypeDescription ); connectorType . setConnectorProviderClassName ( this . getClass (). getName ()); super . connectorTypeBean = connectorType ; } } Actual implementation of the connector provider for the basic file connector 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 /* SPDX-License-Identifier: Apache-2.0 */ /* Copyright Contributors to the Egeria project. */ package org.odpi.openmetadata.adapters.connectors.datastore.basicfile ; import org.odpi.openmetadata.frameworks.connectors.ConnectorProviderBase ; import org.odpi.openmetadata.frameworks.connectors.properties.beans.ConnectorType ; /** * BasicFileStoreProvider is the OCF connector provider for the basic file store connector. */ public class BasicFileStoreProvider extends ConnectorProviderBase { static final String connectorTypeGUID = \"ba213761-f5f5-4cf5-a95f-6150aef09e0b\" ; static final String connectorTypeName = \"Basic File Store Connector\" ; static final String connectorTypeDescription = \"Connector supports reading of Files.\" ; /** * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific * store implementation. */ public BasicFileStoreProvider () { Class <?> connectorClass = BasicFileStoreConnector . class ; super . setConnectorClassName ( connectorClass . getName ()); ConnectorType connectorType = new ConnectorType (); connectorType . setType ( ConnectorType . getConnectorTypeType ()); connectorType . setGUID ( connectorTypeGUID ); connectorType . setQualifiedName ( connectorTypeName ); connectorType . setDisplayName ( connectorTypeName ); connectorType . setDescription ( connectorTypeDescription ); connectorType . setConnectorProviderClassName ( this . getClass (). getName ()); super . connectorTypeBean = connectorType ; } } Connected asset properties \u00b6 Connected asset properties are the properties known about an asset accessed through a connector, hosted by a metadata server . These properties are presented at three levels: Asset summary \u00b6 AssetSummary holds asset properties that are used for displaying details of an asset in summary lists or hover text: Property Description type metadata type information for the asset guid GUID for the asset url external link for the asset qualifiedName The official (unique) name for the asset. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. (Sourced from the qualifiedName attribute in Referenceable - model 0010 ) displayName A consumable name for the asset. Often a shortened form of the asset's qualifiedName for use on user interfaces and messages. The asset's displayName should be only be used for audit logs and error messages if the qualifiedName is not set. (Sourced from displayName attribute within Asset - model 0010 )) shortDescription Short description about the asset. (Sourced from assetSummary within ConnectionsToAsset - model 0205 ) description Full description of the asset. (Sourced from description attribute within Asset - model 0010 ) owner Name of the person or organization that owns the asset. (Sourced from the AssetOwnership classification - model 0445 ) zoneMembership List of governance zones assigned to the asset. (Sourced from the AssetZoneMembership classification - model 0445 ) classifications Full list of the classifications assigned to the asset along with their properties. Asset detail \u00b6 AssetDetail extends AssetSummary to provide all the properties directly related to this asset: Property Description ExternalIdentifiers List of identifiers for this asset that are used in other systems. RelatedMediaReferences List of links to external media (images, audio, video) about this asset. NoteLogs List of NoteLogs for this asset, often providing more detail on how to use the asset and its current status. ExternalReferences List of links to additional information about this asset. Connections List of connections defined to access this asset. Licenses List of licenses associated with the asset. Certifications List of certifications that have been awarded to this asset. Asset universe \u00b6 AssetUniverse extends AssetDetail , and adds information about the common open metadata entities related to this asset: Property Description meanings Glossary term(s) assigned to this asset. schema Details of the schema type associated with the asset. feedback Details of the likes, reviews and comments, that are connected to the asset. knownLocations Details of the known locations of the asset. lineage Details of the lineage for the asset. relatedAssets Details of the assets linked to this asset. Implementation details \u00b6 The connector broker does not have access to a metadata repository because the OCF is metadata repository neutral. When it creates a connector, the connected asset properties are null. Egeria Open Metadata Access Services ( OMAS ) such as Asset Consumer OMAS , Asset Owner OMAS and Discovery Engine OMAS , include the connector broker in their clients and support APIs for managing connections and creating connectors. Connectors created by the Egeria access services will include the connected asset properties object configured to retrieve metadata from the same open metadata repository where the OMAS is running. The connected asset properties are retrieved from the open metadata repositories by OCF Metadata Management common services . It will use the same user id that was used to create the connector. Endpoint \u00b6 The endpoint is a set of properties that defines the network address and how to connect to it for a resource deployed in the digital landscape. Its properties are: Property Description guid GUID for the endpoint. url External link address for the endpoint properties in the metadata repository. This URL can be stored as a property in another entity to create an explicit link to this endpoint. qualifiedName The official (unique) name for the endpoint. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. displayName A consumable name for the endpoint. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. description A description for the endpoint. address The location of the asset. For network connected resources, this is typically the URL and port number (if needed) for the server where the asset is located (or at least accessible by the connector). For file-based resources, this is typically the name of the file. protocol The communication protocol that the connection should use to connect to the server. encryptionMethod Describes the encryption method to use (if any). This is an open value allowing information needed by the connector user to retrieve all of the information they need to work with the endpoint. additionalProperties Any additional properties that the connector need to know in order to access the asset . Types \u00b6 Open metadata repositories are able to store information needed to use OCF connectors. Details of the types involved are as follows: Model 0040 defines the structure of an Endpoint . Model 0201 defines the structures for Connection s and ConnectorType s. Model 0205 defines the linkage between the connection and the connected asset. Further information The OCF Metadata Management common services supports the retrieval of connection and connected asset properties from the open metadata repository/repositories. The Asset Consumer OMAS embeds the OCF to provide client-side support for connectors. The Open Metadata Repository Services ( OMRS ) make extensive use of OCF connectors for accessing open metadata repository servers and other resources. These connectors are collectively called the OMRS connectors . Many of the Open Metadata Governance Servers make use of OCF connectors to loosely-couple integration with a variety of underlying technologies. The developer guide provides more information on writing connectors for Egeria. The connector catalog lists the pre-built connectors supplied by Egeria.","title":"Overview"},{"location":"frameworks/ocf/overview/#open-connector-framework-ocf","text":"The open connector framework ( OCF ), as the name suggests, is an open framework for supporting connectors . Connector provide client-side access to remote digital assets such as data sets, APIs and software components. OCF connectors also provide access to metadata about the asset and may call the Governance Action Framework ( GAF ) to log audit messages and execute appropriate governance actions related to the use of these assets in real-time.","title":"Open Connector Framework (OCF)"},{"location":"frameworks/ocf/overview/#benefits","text":"Applications and tools benefit from using OCF connectors because: Network and security parameters for accessing the data resources are managed in the metadata repository as part of a named connection. The application need only supply the identifier of the connection and provided they have the appropriate security credentials then a connector is returned to them for use. There is no need to hard-code user ids and passwords in the application code - nor manage key stores for this sensitive information since the metadata repository handles this. If the location of the data changes, then the named connection configuration is changed in the metadata repository and the application will be connected to the new location the next time they request a connector. The OCF connector provides two sets of APIs. The first set provides access to the asset contents and the second set provides access to the properties of the asset stored in the open metadata repositories. This provides applications and tools with a simple mechanism to make use of metadata as they process about the asset. It is particularly useful for data science tools where these properties can help guide the end user in the use of the asset. OCF connectors are not limited to representing assets as they are physically implemented. An OCF connector can represent a simplified logical (virtual) data resource that is designed for the needs of a specific application or tool. This type of connector delegates the requests it receives to one or more physical data resources. Organizations benefit from advocating the use of OCF connectors for their systems because the OCF connectors provide a consistent approach to governance enforcement and audit logging. This is particularly important in data-rich environments where individuals are able to combine data from different assets creating new, potentially sensitive insight. The common approach to auditing, and the linkage between the data accessed and the metadata that describes its characteristics help to detect and prevent such actions.","title":"Benefits"},{"location":"frameworks/ocf/overview/#design-rationale","text":"The following factors influenced the design of the OCF . There are many existing connectors and connector frameworks in the industry today. It is important that these existing connectors can be incorporated into the OCF . Thus, the OCF includes placeholders for adapters to external connector providers and connectors. Application developers will only adopt a connector framework if it is easy to use. Thus, the connector interfaces allow for the use of native data APIs to minimize the effort an application developer has to take in order to use the OCF connectors. Governance enforcement is a complex topic, typically managed externally to the application development team. As a result, a separate framework called the governance action framework ( GAF ) manages governance enforcement. The role of the OCF is to bridge from the asset access requests to the GAF where necessary. Access to the all properties known about an asset should be available to the consumers of the asset.Therefore, the OCF provides a standard interface for accessing these properties. Different providers of these properties can plug into the OCF . Egeria provides an implementation of this interface to supply asset properties stored in open metadata repositories in the OCF metadata management common service .","title":"Design rationale"},{"location":"frameworks/ocf/overview/#terminology","text":"There are a number of key components within the OCF :","title":"Terminology"},{"location":"frameworks/ocf/overview/#connector","text":"A connector is a Java client object that provides applications with access to a data source or service (known as an asset ) along with its related metadata and governance functions. An OCF connector provides four APIs: API Description Connector lifecycle Manages the lifecycle state of the connector and includes initialize() , start() and disconnect() . Metadata store initialization If the connector is created by a metadata service then it adds a client to the metadata server called ConnectedAssetProperties to the connector between initialize() and start() . The ConnectedAssetProperties client can be retrieved from the connector instance and used to retrieve metadata about the asset that is stored in the metadata server. Specific initialization for the type of connector Some types of connectors need additional initialization. These methods are called by the component creating the connector before the start() method is called. Asset content This API is crafted to provide the most natural interface to the asset's contents. Therefore, the asset content API is typically different for each type of connector. OCF connectors are not limited to representing assets as they are physically implemented. An OCF connector can represent a simplified logical (virtual) asset, such as a data set, that is designed for the needs of a specific application or tool. This type of connector delegates the requests it receives to one or more physical data resources. It is called a virtual connector . Further information See the developer guide for information on writing connectors.","title":"Connector"},{"location":"frameworks/ocf/overview/#connection","text":"The connection provides the set of properties needed to create and initialize an instance of a connector . A connection contains properties about the specific use of the connector, such as user Id and password, or parameters that control the scope or resources that should be made available to the connector. It links to an optional: Connector type that describes the type of the connector that needs to be created in order to access the asset. Endpoint that describes the server endpoint where the asset is accessed from. Connector types and endpoints can be reused in multiple connections. Connections are typically managed in a metadata repository, but they can also be manually populated.","title":"Connection"},{"location":"frameworks/ocf/overview/#connection-implementations","text":"The OCF offers two implementations of the connection: Connection is a bean implementation of the connection used in REST API requests and events. It allows properties to be set up and retrieved. ConnectionProperties is a read-only wrapper for the connection properties that is used in client interfaces that do not allow the properties to be updated.","title":"Connection implementations"},{"location":"frameworks/ocf/overview/#connection-properties","text":"The properties for a connection are defined in model 0201 and include: Property Description guid GUID for the connection. url URL of the connection definition in the metadata repository. qualifiedName The official (unique) name for the connection. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. (Sourced from the qualifiedName attribute in Referenceable - model 0010 ) displayName A consumable name for the connection. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. type Information about the TypeDef for the connection. description A full description of the connection covering details of the assets it connects to along with usage and version information. additionalProperties Any additional properties associated with the connection. configurationProperties Properties for configuring the connector. securedProperties Protected properties for secure log on by connector to back end server. These are protected properties that can only be retrieved by privileged connector code. userId Name or URI of connecting user. encryptedPassword Password for the userId - needs decrypting by connector before use. clearPassword Password for userId - ready to use. connectorType Properties that describe the connector type for the connector. endpoint Properties that describe the server endpoint where the connector will retrieve the assets.","title":"Connection properties"},{"location":"frameworks/ocf/overview/#using-connections-from-open-metadata-repositories","text":"Each connection stored in a metadata repository has a unique identifier. An application can request a connector instance through selected Egeria OMAS interfaces, such as the Asset Consumer OMAS , with just the unique identifier or name of a connection. The OMAS retrieves the connection object from the open metadata repositories and passes it to the connector broker factory object. The connector broker (and underlying connector provider ) uses the information from the connection object to create an instance of the connector. The advantage of retrieving the connection information from a metadata repository is that the connection properties do not need to be hard-coded in the consuming applications and the metadata associated with the linked asset can be retrieved via the connector's connected asset properties interface. Connections can be created in the open metadata repositories through the following interfaces: Asset Owner OMAS Asset Manager OMAS Data Manager OMAS Database Integrator OMIS Files Integrator OMIS Governance Action OMES","title":"Using Connections from open metadata repositories"},{"location":"frameworks/ocf/overview/#configuring-connections","text":"The administration guide describes how to configure Egeria's OMAG Server Platforms and servers. Both the platform and the servers use connectors for access to the external resources to support their basic operation and to coordinate metadata and governance with third party technologies. This means that the configuration includes connection definitions for these connectors. All of these interfaces have Java clients that enable you to set up the connection using the OCF connection bean. However, if you want to use the REST API directly, then you need to specify the connection in JSON. Example connection definition in JSON Egeria's JSON structures map one-to-ene with the properties in the equivalent Java beans and also include a class property that gives the name of the class that it maps to. So a simple connection object would look something like this in JSON: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"...fully qualified class name...\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"... network address of resource ...\" } } }","title":"Configuring connections"},{"location":"frameworks/ocf/overview/#connector-broker","text":"The connector broker is a generic factory class for all open connectors. Given a valid connection object, the connector broker is able to create a new instance of a connector . This means the caller does not need to know the implementation details of the connector - just its interface. It is implemented in the ConnectorBroker class, and is used as follows: Example usage of a connector broker 1 2 3 4 5 6 7 import org.odpi.openmetadata.frameworks.connectors.Connector ; import org.odpi.openmetadata.frameworks.connectors.ConnectorBroker ; // ... ConnectorBroker connectorBroker = new ConnectorBroker (); Connector connector = connectorBroker . getConnector ( connection ); When the connector instance is requested, the connector broker uses the connector type properties from the supplied connection to identify the appropriate connector provider . The connector broker delegates the connector instance request to the connector provider and returns the result to its caller. The connector broker is used in the client code of the Open Metadata Access Services ( OMAS ) that provide connector instances to their consumers, for example: Asset Consumer OMAS Asset Owner OMAS","title":"Connector broker"},{"location":"frameworks/ocf/overview/#connector-type","text":"The connector type is a set of properties that defines the supported capabilities and the identity of the connector provider for a connector . Its properties are: Property Description guid GUID for the connector type. url External link address for the connector type properties in the metadata repository. qualifiedName The official (unique) name for the connector type. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. displayName A consumable name for the connector type. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. description A full description of the connector type covering details of the assets it connects to along with usage and versioning information. connectorProviderClassName The connector provider is the factory for a particular type of connector . This property defines the class name for the connector provider that the connector broker should use to request new connector instances. recognizedAdditionalProperties These are the connection 's additional properties recognized by the connector implementation. recognizedConfigurationProperties These are the connection 's configuration properties recognized by the connector implementation. recognizedSecuredProperties These are the connection 's secured properties recognized by the connector implementation. additionalProperties Any additional properties that the connector provider needs to know in order to create connector instances. The connector type is linked to the connection objects that request this type of connector. Further information The open metadata type for a connector type is defined in model 0201 . The open connector archives module provides an open metadata archive that contains connector types for connectors supported by Egeria.","title":"Connector type"},{"location":"frameworks/ocf/overview/#connector-provider","text":"A connector provider is the factory for a particular type of connector . It is typically called from the connector broker , although it may be called directly. Each connector provider implements the ConnectorProvider interface. It has two types of methods: Return the connector type object that is added to a connection object used to hold the properties needed to create an instance of the connector . Return a new instance of the connector based on the properties in a connection object. The connection object that has all the properties needed to create and configure the instance of the connector. The ConnectorProviderBase class provides much of the implementation for a connector provider. Example implementation of the connector provider for a simple connector If you have a simple connector implementation then your connector provider follows the following template. It assumes the connector is for the XXXStore and is called XXXStoreConnector . With this base implementation, a specific connector provider implementation need only implement a constructor to configure the base class's function with details of itself and the Java class of the connector it needs. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /** * XXXStoreProvider is the OCF connector provider for the XXX store connector. */ public class XXXStoreProvider extends ConnectorProviderBase { static final String connectorTypeGUID = \"Add unique GUID here\" ; static final String connectorTypeName = \"XXX Store Connector\" ; static final String connectorTypeDescription = \"Connector supports ... add details here\" ; /** * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific * store implementation. */ public BasicFileStoreProvider () { Class <?> connectorClass = XXXStoreConnector . class ; super . setConnectorClassName ( connectorClass . getName ()); ConnectorType connectorType = new ConnectorType (); connectorType . setType ( ConnectorType . getConnectorTypeType ()); connectorType . setGUID ( connectorTypeGUID ); connectorType . setQualifiedName ( connectorTypeName ); connectorType . setDisplayName ( connectorTypeName ); connectorType . setDescription ( connectorTypeDescription ); connectorType . setConnectorProviderClassName ( this . getClass (). getName ()); super . connectorTypeBean = connectorType ; } } Actual implementation of the connector provider for the basic file connector 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 /* SPDX-License-Identifier: Apache-2.0 */ /* Copyright Contributors to the Egeria project. */ package org.odpi.openmetadata.adapters.connectors.datastore.basicfile ; import org.odpi.openmetadata.frameworks.connectors.ConnectorProviderBase ; import org.odpi.openmetadata.frameworks.connectors.properties.beans.ConnectorType ; /** * BasicFileStoreProvider is the OCF connector provider for the basic file store connector. */ public class BasicFileStoreProvider extends ConnectorProviderBase { static final String connectorTypeGUID = \"ba213761-f5f5-4cf5-a95f-6150aef09e0b\" ; static final String connectorTypeName = \"Basic File Store Connector\" ; static final String connectorTypeDescription = \"Connector supports reading of Files.\" ; /** * Constructor used to initialize the ConnectorProviderBase with the Java class name of the specific * store implementation. */ public BasicFileStoreProvider () { Class <?> connectorClass = BasicFileStoreConnector . class ; super . setConnectorClassName ( connectorClass . getName ()); ConnectorType connectorType = new ConnectorType (); connectorType . setType ( ConnectorType . getConnectorTypeType ()); connectorType . setGUID ( connectorTypeGUID ); connectorType . setQualifiedName ( connectorTypeName ); connectorType . setDisplayName ( connectorTypeName ); connectorType . setDescription ( connectorTypeDescription ); connectorType . setConnectorProviderClassName ( this . getClass (). getName ()); super . connectorTypeBean = connectorType ; } }","title":"Connector provider"},{"location":"frameworks/ocf/overview/#connected-asset-properties","text":"Connected asset properties are the properties known about an asset accessed through a connector, hosted by a metadata server . These properties are presented at three levels:","title":"Connected asset properties"},{"location":"frameworks/ocf/overview/#asset-summary","text":"AssetSummary holds asset properties that are used for displaying details of an asset in summary lists or hover text: Property Description type metadata type information for the asset guid GUID for the asset url external link for the asset qualifiedName The official (unique) name for the asset. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. (Sourced from the qualifiedName attribute in Referenceable - model 0010 ) displayName A consumable name for the asset. Often a shortened form of the asset's qualifiedName for use on user interfaces and messages. The asset's displayName should be only be used for audit logs and error messages if the qualifiedName is not set. (Sourced from displayName attribute within Asset - model 0010 )) shortDescription Short description about the asset. (Sourced from assetSummary within ConnectionsToAsset - model 0205 ) description Full description of the asset. (Sourced from description attribute within Asset - model 0010 ) owner Name of the person or organization that owns the asset. (Sourced from the AssetOwnership classification - model 0445 ) zoneMembership List of governance zones assigned to the asset. (Sourced from the AssetZoneMembership classification - model 0445 ) classifications Full list of the classifications assigned to the asset along with their properties.","title":"Asset summary"},{"location":"frameworks/ocf/overview/#asset-detail","text":"AssetDetail extends AssetSummary to provide all the properties directly related to this asset: Property Description ExternalIdentifiers List of identifiers for this asset that are used in other systems. RelatedMediaReferences List of links to external media (images, audio, video) about this asset. NoteLogs List of NoteLogs for this asset, often providing more detail on how to use the asset and its current status. ExternalReferences List of links to additional information about this asset. Connections List of connections defined to access this asset. Licenses List of licenses associated with the asset. Certifications List of certifications that have been awarded to this asset.","title":"Asset detail"},{"location":"frameworks/ocf/overview/#asset-universe","text":"AssetUniverse extends AssetDetail , and adds information about the common open metadata entities related to this asset: Property Description meanings Glossary term(s) assigned to this asset. schema Details of the schema type associated with the asset. feedback Details of the likes, reviews and comments, that are connected to the asset. knownLocations Details of the known locations of the asset. lineage Details of the lineage for the asset. relatedAssets Details of the assets linked to this asset.","title":"Asset universe"},{"location":"frameworks/ocf/overview/#implementation-details","text":"The connector broker does not have access to a metadata repository because the OCF is metadata repository neutral. When it creates a connector, the connected asset properties are null. Egeria Open Metadata Access Services ( OMAS ) such as Asset Consumer OMAS , Asset Owner OMAS and Discovery Engine OMAS , include the connector broker in their clients and support APIs for managing connections and creating connectors. Connectors created by the Egeria access services will include the connected asset properties object configured to retrieve metadata from the same open metadata repository where the OMAS is running. The connected asset properties are retrieved from the open metadata repositories by OCF Metadata Management common services . It will use the same user id that was used to create the connector.","title":"Implementation details"},{"location":"frameworks/ocf/overview/#endpoint","text":"The endpoint is a set of properties that defines the network address and how to connect to it for a resource deployed in the digital landscape. Its properties are: Property Description guid GUID for the endpoint. url External link address for the endpoint properties in the metadata repository. This URL can be stored as a property in another entity to create an explicit link to this endpoint. qualifiedName The official (unique) name for the endpoint. This is often defined by the IT systems management organization and should be used (when available) on audit logs and error messages. displayName A consumable name for the endpoint. Often a shortened form of the qualifiedName for use on user interfaces and messages. The displayName should be only be used for audit logs and error messages if the qualifiedName is not set. description A description for the endpoint. address The location of the asset. For network connected resources, this is typically the URL and port number (if needed) for the server where the asset is located (or at least accessible by the connector). For file-based resources, this is typically the name of the file. protocol The communication protocol that the connection should use to connect to the server. encryptionMethod Describes the encryption method to use (if any). This is an open value allowing information needed by the connector user to retrieve all of the information they need to work with the endpoint. additionalProperties Any additional properties that the connector need to know in order to access the asset .","title":"Endpoint"},{"location":"frameworks/ocf/overview/#types","text":"Open metadata repositories are able to store information needed to use OCF connectors. Details of the types involved are as follows: Model 0040 defines the structure of an Endpoint . Model 0201 defines the structures for Connection s and ConnectorType s. Model 0205 defines the linkage between the connection and the connected asset. Further information The OCF Metadata Management common services supports the retrieval of connection and connected asset properties from the open metadata repository/repositories. The Asset Consumer OMAS embeds the OCF to provide client-side support for connectors. The Open Metadata Repository Services ( OMRS ) make extensive use of OCF connectors for accessing open metadata repository servers and other resources. These connectors are collectively called the OMRS connectors . Many of the Open Metadata Governance Servers make use of OCF connectors to loosely-couple integration with a variety of underlying technologies. The developer guide provides more information on writing connectors for Egeria. The connector catalog lists the pre-built connectors supplied by Egeria.","title":"Types"},{"location":"frameworks/odf/overview/","text":"Technical preview Technical preview function is in a state that it can be tried. The development is complete, there is documentation and there are samples, tutorials and hands-on labs as appropriate. The community is looking for feedback on the function before releasing it. This feedback may result in changes to the external interfaces. Open Discovery Framework ( ODF ) \u00b6 The open discovery framework ( ODF ) enables metadata discovery tools to integrate with open metadata repositories by defining the interfaces for metadata discovery components (called discovery services ) to: Access metadata discovery configuration. Search for assets in the metadata repository. Extract all the metadata known about a specific asset. Record the results of the analysis in the open metadata repository and attach it to the asset's metadata for later processing. Discovery service \u00b6 A discovery service provides specific analysis of the metadata and contents of an asset on request. It is implemented as a specialized connector . A discovery service is initialized with a connector to the asset it is to analyze and details of the results of other discovery services that have run before it if it is part of a discovery pipeline . The result is one or more sets of related properties that the discovery service has discovered about the asset, its metadata, structure and/or content. These are stored in a set of discovery annotations linked off of a discovery analysis report . The discovery analysis report is linked off of the asset definition in the open metadata repository. Discovery services run in a discovery engine that is hosted in a discovery server . Discovery context \u00b6 A discovery context provides the discovery service with access to information about the discovery request along with the open metadata repository interfaces. The discovery context provides parameters used by a discovery service to locate and analyze an asset and then record the results. Discovery request type \u00b6 The discovery request type , as the name suggests, is the name of the type of discovery that a discovery engine should run. It is a string value and is defined in the discovery configuration server . Each discovery request type is associated with a discovery service. When a discovery request is made the discovery engine, it looks up the discovery request type and runs the associated discovery service. Implementation in Egeria \u00b6 Egeria's discovery configuration server support is implemented by the Discovery Engine OMAS . It has a client called DiscoveryConfigurationClient that implements the ODF 's DiscoveryConfigurationServer interface. It also supports event notifications through the Discovery Engine OMAS 's out topic . Discovery pipeline \u00b6 A discovery pipeline is a specialized implementation of a discovery service that runs a set of discovery services against a single asset. The implementation of the discovery pipeline determines the order that these discovery services are run. The aim of the discovery pipeline is to enable a detailed picture of the properties of an asset to be built up by the discovery services it calls. Each discovery service is able to access the results of the discovery services that have run before it. Discovery annotation \u00b6 A discovery annotation describes one or more related properties about an asset that has been discovered by a discovery service . Some discovery annotations refer to an entire asset and others refer to a data field within an asset. The annotations that describe a single data field are called data field annotations . Annotation type Description Classification annotation Captures a recommendation of which classifications to attach to this asset. It can be made at the asset or data field level. Data class annotation Captures a recommendation of which data class this data field closely represents. Data profile annotation Capture the characteristics of the data values stored in a specific data field in a data source. Data profile log annotation Capture the names of the log files where profile characteristics of the data values stored in a specific data field. This is used when the profile results are too large to store in open metadata. Data source measurement annotation Collect arbitrary properties about a data source. Data source physical status annotation Documents the physical characteristics of a data source asset. Relationship advice annotation Document a recommended relationship that should be established with the asset. Quality annotation Document calculated quality scores on different dimensions. Schema analysis annotation Document the structure of the data (schema) inside the asset. Semantic annotation Documents suggested meanings for this data based on the values and name of the field. Suspect duplicate annotation Identifies other asset definitions that seem to point to the same physical asset. The open metadata types for a discovery annotations are described in area 6 of the model. The main entity type is called Annotation . It is extended by DataFieldAnnotation to distinguish annotations that refer, primarily to a data field. Other more specialist annotations extend these two basic annotation types. Discovery analysis report \u00b6 The discovery analysis report lists the discovery annotations that were created during the execution of a discovery service . The discovery analysis report is created in the open metadata repository by the discovery engine when it creates the discovery service instance. The discovery service can retrieve information about the discovery analysis report through the discovery analysis report store client. Discovery analysis report store \u00b6 The discovery analysis report store is a client to an open metadata server that enables a discovery service to query the properties of its discovery analysis report and update the analysis step that is currently executing. The discovery analysis report store is accessed from the discovery annotation store . The discovery analysis report store also enables a long-running discovery service (typically a discovery pipeline ) to record its current analysis step. Discovery annotation store \u00b6 The discovery annotation store provides a discovery-service with a client to write discovery annotations to an open metadata repository. These annotations describe the results of the analysis performed on an asset by the discovery service. The annotations are linked to a discovery analysis report that is in turn linked off of the analysed asset. The discovery service is passed the discovery annotation store via the discovery context . Discovery engine \u00b6 A discovery engine is the execution environment for discovery services . The discovery engine configuration defines a set of discovery services. Its definition is stored in an open metadata repository and maintained through the Discovery Engine OMAS . Discovery engines are hosted in discovery servers . Egeria's implementation of the discovery engine is provided by the Asset Analysis OMES . Discovery server \u00b6 The discovery server is the server environment that hosts one or more discovery engines . Discovery servers are deployed close to the physical assets they are analysing. They connect to the Discovery Engine OMAS running in a metadata server to provide metadata about assets and to store the results of the discovery service's analysis. Many discovery servers can use the same metadata server. In Egeria, the discovery server is implemented by the Asset Analysis OMES running in the engine host OMAG Server. Discovery configuration server \u00b6 The discovery configuration server is the server responsible for holding and managing the configuration needed by the discovery servers and the discovery engines within them. This configuration consists of defining which discovery request types are supported and which discovery services they map to. Discovery asset catalog store \u00b6 The discovery asset catalog store provides a search interface that enables a discovery service to locate assets that are described in the open metadata repository. The discovery service is passed the discovery asset catalog store via the discovery context . Framework implementation \u00b6 Egeria provides a full implementation of the ODF . It provides a discovery server as well as an implementation of the metadata server APIs by the Discovery Engine OMAS . There are also implementations of discovery services in the discovery-service-connectors module.","title":"Overview"},{"location":"frameworks/odf/overview/#open-discovery-framework-odf","text":"The open discovery framework ( ODF ) enables metadata discovery tools to integrate with open metadata repositories by defining the interfaces for metadata discovery components (called discovery services ) to: Access metadata discovery configuration. Search for assets in the metadata repository. Extract all the metadata known about a specific asset. Record the results of the analysis in the open metadata repository and attach it to the asset's metadata for later processing.","title":"Open Discovery Framework (ODF)"},{"location":"frameworks/odf/overview/#discovery-service","text":"A discovery service provides specific analysis of the metadata and contents of an asset on request. It is implemented as a specialized connector . A discovery service is initialized with a connector to the asset it is to analyze and details of the results of other discovery services that have run before it if it is part of a discovery pipeline . The result is one or more sets of related properties that the discovery service has discovered about the asset, its metadata, structure and/or content. These are stored in a set of discovery annotations linked off of a discovery analysis report . The discovery analysis report is linked off of the asset definition in the open metadata repository. Discovery services run in a discovery engine that is hosted in a discovery server .","title":"Discovery service"},{"location":"frameworks/odf/overview/#discovery-context","text":"A discovery context provides the discovery service with access to information about the discovery request along with the open metadata repository interfaces. The discovery context provides parameters used by a discovery service to locate and analyze an asset and then record the results.","title":"Discovery context"},{"location":"frameworks/odf/overview/#discovery-request-type","text":"The discovery request type , as the name suggests, is the name of the type of discovery that a discovery engine should run. It is a string value and is defined in the discovery configuration server . Each discovery request type is associated with a discovery service. When a discovery request is made the discovery engine, it looks up the discovery request type and runs the associated discovery service.","title":"Discovery request type"},{"location":"frameworks/odf/overview/#implementation-in-egeria","text":"Egeria's discovery configuration server support is implemented by the Discovery Engine OMAS . It has a client called DiscoveryConfigurationClient that implements the ODF 's DiscoveryConfigurationServer interface. It also supports event notifications through the Discovery Engine OMAS 's out topic .","title":"Implementation in Egeria"},{"location":"frameworks/odf/overview/#discovery-pipeline","text":"A discovery pipeline is a specialized implementation of a discovery service that runs a set of discovery services against a single asset. The implementation of the discovery pipeline determines the order that these discovery services are run. The aim of the discovery pipeline is to enable a detailed picture of the properties of an asset to be built up by the discovery services it calls. Each discovery service is able to access the results of the discovery services that have run before it.","title":"Discovery pipeline"},{"location":"frameworks/odf/overview/#discovery-annotation","text":"A discovery annotation describes one or more related properties about an asset that has been discovered by a discovery service . Some discovery annotations refer to an entire asset and others refer to a data field within an asset. The annotations that describe a single data field are called data field annotations . Annotation type Description Classification annotation Captures a recommendation of which classifications to attach to this asset. It can be made at the asset or data field level. Data class annotation Captures a recommendation of which data class this data field closely represents. Data profile annotation Capture the characteristics of the data values stored in a specific data field in a data source. Data profile log annotation Capture the names of the log files where profile characteristics of the data values stored in a specific data field. This is used when the profile results are too large to store in open metadata. Data source measurement annotation Collect arbitrary properties about a data source. Data source physical status annotation Documents the physical characteristics of a data source asset. Relationship advice annotation Document a recommended relationship that should be established with the asset. Quality annotation Document calculated quality scores on different dimensions. Schema analysis annotation Document the structure of the data (schema) inside the asset. Semantic annotation Documents suggested meanings for this data based on the values and name of the field. Suspect duplicate annotation Identifies other asset definitions that seem to point to the same physical asset. The open metadata types for a discovery annotations are described in area 6 of the model. The main entity type is called Annotation . It is extended by DataFieldAnnotation to distinguish annotations that refer, primarily to a data field. Other more specialist annotations extend these two basic annotation types.","title":"Discovery annotation"},{"location":"frameworks/odf/overview/#discovery-analysis-report","text":"The discovery analysis report lists the discovery annotations that were created during the execution of a discovery service . The discovery analysis report is created in the open metadata repository by the discovery engine when it creates the discovery service instance. The discovery service can retrieve information about the discovery analysis report through the discovery analysis report store client.","title":"Discovery analysis report"},{"location":"frameworks/odf/overview/#discovery-analysis-report-store","text":"The discovery analysis report store is a client to an open metadata server that enables a discovery service to query the properties of its discovery analysis report and update the analysis step that is currently executing. The discovery analysis report store is accessed from the discovery annotation store . The discovery analysis report store also enables a long-running discovery service (typically a discovery pipeline ) to record its current analysis step.","title":"Discovery analysis report store"},{"location":"frameworks/odf/overview/#discovery-annotation-store","text":"The discovery annotation store provides a discovery-service with a client to write discovery annotations to an open metadata repository. These annotations describe the results of the analysis performed on an asset by the discovery service. The annotations are linked to a discovery analysis report that is in turn linked off of the analysed asset. The discovery service is passed the discovery annotation store via the discovery context .","title":"Discovery annotation store"},{"location":"frameworks/odf/overview/#discovery-engine","text":"A discovery engine is the execution environment for discovery services . The discovery engine configuration defines a set of discovery services. Its definition is stored in an open metadata repository and maintained through the Discovery Engine OMAS . Discovery engines are hosted in discovery servers . Egeria's implementation of the discovery engine is provided by the Asset Analysis OMES .","title":"Discovery engine"},{"location":"frameworks/odf/overview/#discovery-server","text":"The discovery server is the server environment that hosts one or more discovery engines . Discovery servers are deployed close to the physical assets they are analysing. They connect to the Discovery Engine OMAS running in a metadata server to provide metadata about assets and to store the results of the discovery service's analysis. Many discovery servers can use the same metadata server. In Egeria, the discovery server is implemented by the Asset Analysis OMES running in the engine host OMAG Server.","title":"Discovery server"},{"location":"frameworks/odf/overview/#discovery-configuration-server","text":"The discovery configuration server is the server responsible for holding and managing the configuration needed by the discovery servers and the discovery engines within them. This configuration consists of defining which discovery request types are supported and which discovery services they map to.","title":"Discovery configuration server"},{"location":"frameworks/odf/overview/#discovery-asset-catalog-store","text":"The discovery asset catalog store provides a search interface that enables a discovery service to locate assets that are described in the open metadata repository. The discovery service is passed the discovery asset catalog store via the discovery context .","title":"Discovery asset catalog store"},{"location":"frameworks/odf/overview/#framework-implementation","text":"Egeria provides a full implementation of the ODF . It provides a discovery server as well as an implementation of the metadata server APIs by the Discovery Engine OMAS . There are also implementations of discovery services in the discovery-service-connectors module.","title":"Framework implementation"},{"location":"getting-started/dojo/introduction/","text":"Dojo Introduction \u00b6 The Egeria \"dojo\" is an intensive course to help you learn about Egeria. It is designed as a 3-day effort, although, since it is self-study you can dip in and out of it as time permits. The objectives of the three day are as follows: Day 1 : Learning about setting up and running Egeria on you own machine. Day 2 : Learning how to make a contribution to Egeria. Day 3 : Learning how to become either an advocate or a maintainer. The sessions are color-coded like ski runs: Beginner session Intermediate session Advanced session Expert session As you progress through the dojo, the colors of the sessions show how advanced your knowledge is becoming. The schedule also includes estimated times needed to complete each session. Do take breaks whenever needed! Overview Day 1 summary \u00b6 Day 1 After completing day 1 of the Egeria dojo you should feel comfortable with setting up and running the Egeria technology. It includes sessions on the prerequisite technology that Egeria uses, how to configure Egeria, how to start and stop various capabilities and well as diagnosing any problems you may come across. Egeria introduction (30 mins) Egeria project introduction (30 mins) Running Egeria on your machine, step-by-step (5 hrs) Platform setup and configuration (90 mins) Running metadata servers (2 hrs) Running metadata ecosystems (90 mins) Participating in the community (30 mins) Day 2 summary \u00b6 Day 2 Day 2 of the Egeria dojo is all about making changes to the Egeria project. This may be to add code, documentation or samples. You will have an opportunity to add a new file to the Egeria project and take it all the way through the process to update Egeria's git repository. Open source philosophy (30 mins) Tools for contributors (90 mins) Making a contribution, step-by-step (90 mins) Types of contribution (60 mins) Becoming a contributor (30 mins) Day 3 summary \u00b6 Day 3 Day 3 prepares you to become an Egeria professional - either as an advocate of the technology or a maintainer. It goes much deeper into the philosophy, design and processes of the project. Becoming an advocate (90 mins) Becoming a maintainer (90 mins) Egeria architecture and philosophy (the \"deep stuff\") (90 mins) Egeria social (90 mins)","title":"Dojo Introduction"},{"location":"getting-started/dojo/introduction/#dojo-introduction","text":"The Egeria \"dojo\" is an intensive course to help you learn about Egeria. It is designed as a 3-day effort, although, since it is self-study you can dip in and out of it as time permits. The objectives of the three day are as follows: Day 1 : Learning about setting up and running Egeria on you own machine. Day 2 : Learning how to make a contribution to Egeria. Day 3 : Learning how to become either an advocate or a maintainer. The sessions are color-coded like ski runs: Beginner session Intermediate session Advanced session Expert session As you progress through the dojo, the colors of the sessions show how advanced your knowledge is becoming. The schedule also includes estimated times needed to complete each session. Do take breaks whenever needed! Overview","title":"Dojo Introduction"},{"location":"getting-started/dojo/introduction/#day-1-summary","text":"Day 1 After completing day 1 of the Egeria dojo you should feel comfortable with setting up and running the Egeria technology. It includes sessions on the prerequisite technology that Egeria uses, how to configure Egeria, how to start and stop various capabilities and well as diagnosing any problems you may come across. Egeria introduction (30 mins) Egeria project introduction (30 mins) Running Egeria on your machine, step-by-step (5 hrs) Platform setup and configuration (90 mins) Running metadata servers (2 hrs) Running metadata ecosystems (90 mins) Participating in the community (30 mins)","title":"Day 1 summary"},{"location":"getting-started/dojo/introduction/#day-2-summary","text":"Day 2 Day 2 of the Egeria dojo is all about making changes to the Egeria project. This may be to add code, documentation or samples. You will have an opportunity to add a new file to the Egeria project and take it all the way through the process to update Egeria's git repository. Open source philosophy (30 mins) Tools for contributors (90 mins) Making a contribution, step-by-step (90 mins) Types of contribution (60 mins) Becoming a contributor (30 mins)","title":"Day 2 summary"},{"location":"getting-started/dojo/introduction/#day-3-summary","text":"Day 3 Day 3 prepares you to become an Egeria professional - either as an advocate of the technology or a maintainer. It goes much deeper into the philosophy, design and processes of the project. Becoming an advocate (90 mins) Becoming a maintainer (90 mins) Egeria architecture and philosophy (the \"deep stuff\") (90 mins) Egeria social (90 mins)","title":"Day 3 summary"},{"location":"getting-started/dojo/1/","text":"Dojo Day 1 \u00b6 Egeria introduction \u00b6 In this session, you will learn about the function and value of Egeria along with the key concepts and use cases it supports. Egeria introduction Test yourself \u00b6 Which of the following are part of the Open Metadata Manifesto? Metadata needs to be centralized so it can be managed. Maintenance of metadata must be automated. The availability of metadata management must become ubiquitous. Metadata access must become open and remotely accessible. Name 3 tools that could connect to Egeria. Name a metadata standard. Egeria project introduction \u00b6 In this session, you will learn about the contents of the Egeria project. It will also describe the software to download in preparation for the next session. Egeria project introduction GitHub repositories \u00b6 GitHub is a public service for managing files - particularly files associated with a software project. Many open source projects use GitHub and Egeria is no exception. All content for the Egeria project is stored in git repositories. For example, these web pages you are reading as part of the dojo are managed in Egeria's documentation git repository . Other resources \u00b6 The Egeria community love to collaborate on the work they do. Git and GitHub is an excellent way to exchange and manage files. In addition, the community runs public calls that anyone can join, as well as a number of Slack channels. Details of the different ways the community operates is described in our community guide . Test yourself \u00b6 Name three of the git repositories owned by the Egeria project, and describe what they do. Describe why the Egeria project is called Egeria Login to Slack and post a message to the #egeria-dojo-live channel A simple \"I'm working my way through the dojo!\" will do Running Egeria \u00b6 In this session, you will learn about the Open Metadata and Governance (OMAG) Server Platform that hosts many of the services provided by Egeria. Running Egeria Prerequisites \u00b6 Before we get started there are some steps to prepare your machine. Ensure Docker Desktop and Postman are installed and running For this session you will need both of these tools installed and running on your machine: Docker Desktop Postman Follow the links below to find out a little bit about these technologies and ensure the software is installed. Docker Desktop Postman Once these technologies are installed, work through the tutorials - starting with Docker to get the OMAG Server Platform running and then Postman to get ready to work with the platform and the servers running on top if it. Docker Tutorial Postman Tutorial At this point you should have Postman installed with the collections loaded, and Egeria's OMAG Server Platform running as a docker container. Test yourself \u00b6 What is the message from the OMAG Server Platform that says it is ready to process requests? How do you find out the version of Egeria running in an OMAG Server Platform? What is the url to view the Swagger UI page for the OMAG Server Platform? Configuring the OMAG Server Platform \u00b6 In this session, you will learn how to set up the OMAG Server Platform. Configuring the OMAG Server Platform Server origin \u00b6 In the previous session you downloaded an application called Postman and loaded collections of pre-defined requests. This tool makes it easy to issue REST API requests to the OMAG Server Platform. Check that it is working by locating the Get Server Origin request in the Egeria-platform-services collection. When you click on that request in the left-hand list, a new tab opens and you can click on send to issue the request. You should see the same response as when you issues the platform origin request from Swagger earlier. Below is this response in Postman. If this does not work, then there is something wrong either in Postman or your platform. Check the URL string that was used in the request (shown in orange in the middle of the screen.) The screen shot below shows the error message when the egeria environment is not set. This can be fixed by setting it in the top right-hand dropdown. If the Egeria environment is not listed then you need to load the environment ( Postman tutorial ). If the baseURL variable is set to a different value to the server platform then Postman can not connect. In the screen capture below, you can see the baseURL is set to the default of https://localhost:9443 when it should be https://localhost:9443 because the platform is running in docker. Finally, if the OMAG Server Platform is not running the even though everything is set up correctly in Postman, it has nothing to connect to. Restart the platform ( Docker tutorial ). In last part of this session you will learn how to set up the OMAG Server Platform so that it is secure and determine the services and servers that are associated with the platform. Configuration document store \u00b6 Platform security \u00b6 Registered services \u00b6 Known / active servers \u00b6 Review the description of the OMAG Server Platform configuration: Configuring the OMAG Server Platform The link below takes you to a task description in the Egeria Administration User Guide. The user guide describes the REST API call(s) needed to complete the task. You can choose to type the request into postman, or use the requests already defined in the Egeria-admin-services-platform-configuration Postman collection. Add the Coco Pharmaceuticals platform security connector to the platform Try running the platform origin command again - it should fail with a security error. Change the user variable in the Egeria environment from me to garygeeke and rerun the request. It will work again because garygeeke is the user id of the Coco Pharmaceuticals IT infrastructure lead and has permission to run the platform commands. Finally, use the Egeria-admin-services-platform-configuration Postman collection to experiment with the different registered services and and known and active server requests. These are useful to know as we move to configure servers on the platform. This is the end of the session on the OMAG Server Platform.","title":"Index"},{"location":"getting-started/dojo/1/#dojo-day-1","text":"","title":"Dojo Day 1"},{"location":"getting-started/dojo/1/#egeria-introduction","text":"In this session, you will learn about the function and value of Egeria along with the key concepts and use cases it supports. Egeria introduction","title":"Egeria introduction"},{"location":"getting-started/dojo/1/#test-yourself","text":"Which of the following are part of the Open Metadata Manifesto? Metadata needs to be centralized so it can be managed. Maintenance of metadata must be automated. The availability of metadata management must become ubiquitous. Metadata access must become open and remotely accessible. Name 3 tools that could connect to Egeria. Name a metadata standard.","title":"Test yourself"},{"location":"getting-started/dojo/1/#egeria-project-introduction","text":"In this session, you will learn about the contents of the Egeria project. It will also describe the software to download in preparation for the next session. Egeria project introduction","title":"Egeria project introduction"},{"location":"getting-started/dojo/1/#github-repositories","text":"GitHub is a public service for managing files - particularly files associated with a software project. Many open source projects use GitHub and Egeria is no exception. All content for the Egeria project is stored in git repositories. For example, these web pages you are reading as part of the dojo are managed in Egeria's documentation git repository .","title":"GitHub repositories"},{"location":"getting-started/dojo/1/#other-resources","text":"The Egeria community love to collaborate on the work they do. Git and GitHub is an excellent way to exchange and manage files. In addition, the community runs public calls that anyone can join, as well as a number of Slack channels. Details of the different ways the community operates is described in our community guide .","title":"Other resources"},{"location":"getting-started/dojo/1/#test-yourself_1","text":"Name three of the git repositories owned by the Egeria project, and describe what they do. Describe why the Egeria project is called Egeria Login to Slack and post a message to the #egeria-dojo-live channel A simple \"I'm working my way through the dojo!\" will do","title":"Test yourself"},{"location":"getting-started/dojo/1/#running-egeria","text":"In this session, you will learn about the Open Metadata and Governance (OMAG) Server Platform that hosts many of the services provided by Egeria. Running Egeria","title":"Running Egeria"},{"location":"getting-started/dojo/1/#prerequisites","text":"Before we get started there are some steps to prepare your machine. Ensure Docker Desktop and Postman are installed and running For this session you will need both of these tools installed and running on your machine: Docker Desktop Postman Follow the links below to find out a little bit about these technologies and ensure the software is installed. Docker Desktop Postman Once these technologies are installed, work through the tutorials - starting with Docker to get the OMAG Server Platform running and then Postman to get ready to work with the platform and the servers running on top if it. Docker Tutorial Postman Tutorial At this point you should have Postman installed with the collections loaded, and Egeria's OMAG Server Platform running as a docker container.","title":"Prerequisites"},{"location":"getting-started/dojo/1/#test-yourself_2","text":"What is the message from the OMAG Server Platform that says it is ready to process requests? How do you find out the version of Egeria running in an OMAG Server Platform? What is the url to view the Swagger UI page for the OMAG Server Platform?","title":"Test yourself"},{"location":"getting-started/dojo/1/#configuring-the-omag-server-platform","text":"In this session, you will learn how to set up the OMAG Server Platform. Configuring the OMAG Server Platform","title":"Configuring the OMAG Server Platform"},{"location":"getting-started/dojo/1/#server-origin","text":"In the previous session you downloaded an application called Postman and loaded collections of pre-defined requests. This tool makes it easy to issue REST API requests to the OMAG Server Platform. Check that it is working by locating the Get Server Origin request in the Egeria-platform-services collection. When you click on that request in the left-hand list, a new tab opens and you can click on send to issue the request. You should see the same response as when you issues the platform origin request from Swagger earlier. Below is this response in Postman. If this does not work, then there is something wrong either in Postman or your platform. Check the URL string that was used in the request (shown in orange in the middle of the screen.) The screen shot below shows the error message when the egeria environment is not set. This can be fixed by setting it in the top right-hand dropdown. If the Egeria environment is not listed then you need to load the environment ( Postman tutorial ). If the baseURL variable is set to a different value to the server platform then Postman can not connect. In the screen capture below, you can see the baseURL is set to the default of https://localhost:9443 when it should be https://localhost:9443 because the platform is running in docker. Finally, if the OMAG Server Platform is not running the even though everything is set up correctly in Postman, it has nothing to connect to. Restart the platform ( Docker tutorial ). In last part of this session you will learn how to set up the OMAG Server Platform so that it is secure and determine the services and servers that are associated with the platform.","title":"Server origin"},{"location":"getting-started/dojo/1/#configuration-document-store","text":"","title":"Configuration document store"},{"location":"getting-started/dojo/1/#platform-security","text":"","title":"Platform security"},{"location":"getting-started/dojo/1/#registered-services","text":"","title":"Registered services"},{"location":"getting-started/dojo/1/#known-active-servers","text":"Review the description of the OMAG Server Platform configuration: Configuring the OMAG Server Platform The link below takes you to a task description in the Egeria Administration User Guide. The user guide describes the REST API call(s) needed to complete the task. You can choose to type the request into postman, or use the requests already defined in the Egeria-admin-services-platform-configuration Postman collection. Add the Coco Pharmaceuticals platform security connector to the platform Try running the platform origin command again - it should fail with a security error. Change the user variable in the Egeria environment from me to garygeeke and rerun the request. It will work again because garygeeke is the user id of the Coco Pharmaceuticals IT infrastructure lead and has permission to run the platform commands. Finally, use the Egeria-admin-services-platform-configuration Postman collection to experiment with the different registered services and and known and active server requests. These are useful to know as we move to configure servers on the platform. This is the end of the session on the OMAG Server Platform.","title":"Known / active servers"},{"location":"getting-started/dojo/1/introduction/","text":"Egeria introduction \u00b6 In this session, you will learn about the function and value of Egeria along with the key concepts and use cases it supports. Egeria introduction Test yourself \u00b6 Which of the following are part of the Open Metadata Manifesto? Metadata needs to be centralized so it can be managed. Maintenance of metadata must be automated. The availability of metadata management must become ubiquitous. Metadata access must become open and remotely accessible. Name 3 tools that could connect to Egeria. Name a metadata standard.","title":"Egeria Introduction"},{"location":"getting-started/dojo/1/introduction/#egeria-introduction","text":"In this session, you will learn about the function and value of Egeria along with the key concepts and use cases it supports. Egeria introduction","title":"Egeria introduction"},{"location":"getting-started/dojo/1/introduction/#test-yourself","text":"Which of the following are part of the Open Metadata Manifesto? Metadata needs to be centralized so it can be managed. Maintenance of metadata must be automated. The availability of metadata management must become ubiquitous. Metadata access must become open and remotely accessible. Name 3 tools that could connect to Egeria. Name a metadata standard.","title":"Test yourself"},{"location":"guides/community/","text":"Community Guide \u00b6 This project welcomes contributors from any organization or background, provided they are willing to follow the simple processes outlined below, as well as adhere to the Code of Conduct . Joining the community \u00b6 Live discussions \u00b6 We have a variety of weekly and bi-weekly meetings to which all are welcome: Call Purpose Developers call Discussion on code development (not minuted) Community call Demos, meetups and other activities going on in the community ( agenda and minutes ) TSC call Strategy, planning and decision-making with the Technical Steering Committee (TSC) Asynchronous dialog \u00b6 Egeria uses the LF AI & Data Slack community to provide an ongoing dialogue between members. This creates a recorded discussion of design decisions and discussions that complement the project meetings. Follow the link above and register with the LF AI & Data Slack service using your email address. Once signed in you can see all the active Slack channels. The main Slack channel for the Egeria project is called #egeria-discussion Additional channels are added from time to time as new workgroups and discussion topics are established. For Egeria these channel names will begin with #egeria . You can also view Slack channels from other LF AI & Data projects. More information about Slack? Slack is an instant messaging tool that allows multiple conversations to occur amongst the community members at any one time. Each conversation is called a channel . Channels can be set up for a specific event or have a long-term existence. Mailing list \u00b6 The community tends to use the mailing list only for automated meeting reminders. We are best contacted through Slack (above). Other websites and resources \u00b6 Previous Webinars - previous virtual events covering topics of interest. Planned Webinars - planned virtual events covering topics of interest. Workshops - face-to-face workshops promoting discussion and education on Egeria Presentations - presentations given at conferences and private gatherings Git repositories \u00b6 The Egeria project uses GitHub to maintain its content across a number of repositories. All of these repositories are publicly visible; however, if you want to contribute new content you need to create a GitHub account. This can be created from the top of the GitHub home page. If you are not familiar with Git and GitHub, there is additional education in the developer-resources/tools pages. Steps to contribute content to the project \u00b6 Egeria uses GitHub's fork and pull model to create a contribution. This process is described in detail in the Egeria dojo education . Each change should have a GitHub issue explaining why the change is being made. The new or updated content should follow the Egeria developer guidelines . There are additional resources for contributors under developer-resources . Review the developer guidelines to understand the requirements associated with new content for Egeria. Every contribution is signed to say that the contributor has the rights to make the contribution and agrees with the Developer Certificate of Origin (DCO) Creating a Linux Foundation account \u00b6 The Linux Foundation provide build and distribution facilities. You need an account to access some of the reports from the build. This is the link to create a Linux Foundation account . Note the username and password you selected.","title":"Community Guide"},{"location":"guides/community/#community-guide","text":"This project welcomes contributors from any organization or background, provided they are willing to follow the simple processes outlined below, as well as adhere to the Code of Conduct .","title":"Community Guide"},{"location":"guides/community/#joining-the-community","text":"","title":"Joining the community"},{"location":"guides/community/#live-discussions","text":"We have a variety of weekly and bi-weekly meetings to which all are welcome: Call Purpose Developers call Discussion on code development (not minuted) Community call Demos, meetups and other activities going on in the community ( agenda and minutes ) TSC call Strategy, planning and decision-making with the Technical Steering Committee (TSC)","title":"Live discussions"},{"location":"guides/community/#asynchronous-dialog","text":"Egeria uses the LF AI & Data Slack community to provide an ongoing dialogue between members. This creates a recorded discussion of design decisions and discussions that complement the project meetings. Follow the link above and register with the LF AI & Data Slack service using your email address. Once signed in you can see all the active Slack channels. The main Slack channel for the Egeria project is called #egeria-discussion Additional channels are added from time to time as new workgroups and discussion topics are established. For Egeria these channel names will begin with #egeria . You can also view Slack channels from other LF AI & Data projects. More information about Slack? Slack is an instant messaging tool that allows multiple conversations to occur amongst the community members at any one time. Each conversation is called a channel . Channels can be set up for a specific event or have a long-term existence.","title":"Asynchronous dialog"},{"location":"guides/community/#mailing-list","text":"The community tends to use the mailing list only for automated meeting reminders. We are best contacted through Slack (above).","title":"Mailing list"},{"location":"guides/community/#other-websites-and-resources","text":"Previous Webinars - previous virtual events covering topics of interest. Planned Webinars - planned virtual events covering topics of interest. Workshops - face-to-face workshops promoting discussion and education on Egeria Presentations - presentations given at conferences and private gatherings","title":"Other websites and resources"},{"location":"guides/community/#git-repositories","text":"The Egeria project uses GitHub to maintain its content across a number of repositories. All of these repositories are publicly visible; however, if you want to contribute new content you need to create a GitHub account. This can be created from the top of the GitHub home page. If you are not familiar with Git and GitHub, there is additional education in the developer-resources/tools pages.","title":"Git repositories"},{"location":"guides/community/#steps-to-contribute-content-to-the-project","text":"Egeria uses GitHub's fork and pull model to create a contribution. This process is described in detail in the Egeria dojo education . Each change should have a GitHub issue explaining why the change is being made. The new or updated content should follow the Egeria developer guidelines . There are additional resources for contributors under developer-resources . Review the developer guidelines to understand the requirements associated with new content for Egeria. Every contribution is signed to say that the contributor has the rights to make the contribution and agrees with the Developer Certificate of Origin (DCO)","title":"Steps to contribute content to the project"},{"location":"guides/community/#creating-a-linux-foundation-account","text":"The Linux Foundation provide build and distribution facilities. You need an account to access some of the reports from the build. This is the link to create a Linux Foundation account . Note the username and password you selected.","title":"Creating a Linux Foundation account"},{"location":"guides/project-operations/","text":"Project Operations \u00b6 The Egeria project provides content (standards, data, code and documentation) that is intended for wide consumption across many types of organizations: from those that rely on data in their operation, to organizations that have products or technology designed to help manage data and its related processing. A project of this scope requires input from a wide range of subject matter experts with different backgrounds and allegiances. As such, we need a set of principles, roles and operating practices to ensure the results of our contributions are useful, have high quality and are widely consumable. General principles \u00b6 The principles set the tone of the operation of Egeria: The activities of the project ensure open collaboration. Through this open collaboration we aim to build a community of people who are interested in the success of the project. The scope of the content is determined by the individuals who are actively contributing. The resulting content is licensed under the Apache 2.0 license. An individual's privileges and position is awarded through their contribution and engagement. These principles should be respected as the procedures used to manage the Egeria project are evolved and matured. Community members \u00b6 Anyone can become a member of the Egeria community by signing up to the Egeria mailing list, joining the Slack community, attending the project online meetings or contributing content to one of more of the GitHub repositories. The community guide describes how to connect to these channels. All participants in the Egeria community are bound by the project's Code of Conduct . As a member you are able to attend our meetings, just to listen, or to play an active part in the discussion. The online meetings are recorded to allow community members to catch up if they are not able to attend the live meeting. When you attend the community meetings specifically, your name will be recorded in the meeting minutes along with any remarks or suggestions you make. The agenda and minutes of our community meetings are publicly available on the Egeria wiki . A member may make contributions to the Egeria content by submitting a GitHub pull request on the appropriate Git repository. This will be reviewed and processed by the Egeria maintainers . The process for making a contribution is described in the Egeria Dojo education. Each contribution is signed by the contributor to confirm they agree to our Developer Certificate of Origin (DCO) . Community members can progress to be Egeria contributors and then Egeria maintainers . Contributors \u00b6 Egeria contributors are members who have actively taken additional steps to promote and foster the success of Egeria and its acceptance/adoption across the IT community. The activities that contributors engage in might include: Provide best practices for information governance, lineage, metadata management and other related disciplines during active discussions and/or development of material. Actively participate in meetings and discussions Promote the goals of Egeria and the benefits of open metadata to the IT community (deliver presentations, informal talks, assist at trade shows, independent blogs, etc.) Assist in the recruitment of new members. Contribute where appropriate to documentation and code reviews, specification development, demonstration assets and other artifacts that help move Egeria forward. How to become a contributor Being recognized as an Egeria contributor is done by nomination of an Egeria maintainer with a majority vote of Egeria maintainers to confirm. Once confirmed, you will receive an Egeria Contributor badge to add to your social profiles and/or website, and can publicly refer to yourself as an Egeria contributor. Egeria's contributors are recognized in the contributors list Maintainers \u00b6 Maintainers are members of the Egeria community that have permission to change the Egeria content. This may be content that they have created themselves, or has been provided by another member. Maintainers also have responsibility for helping other project members with their contributions. This includes: Monitoring email aliases. Monitoring Slack (delayed response is perfectly acceptable). Triage GitHub issues and perform pull request reviews for other maintainers and the community. Make sure that ongoing git pull requests are moving forward at the right pace or closing them. In general continue to be willing to spend at least 25% of one's time working on the project (approximately 1.25 business days per week). How to become a maintainer New maintainers are voted onto the maintainers list by the existing maintainers . A person wishing to become a maintainer sends a note to the existing mailing list at egeria-technical-discuss@lists.lfaidata.foundation, listing their Egeria contributions to date and requesting to be made a maintainer. The maintainers vote and if a majority agree then the requester is added to the maintainers list and given write access to the Egeria Git repositories . Once confirmed, you will receive an an Egeria Maintainer badge to add to your social profiles and/or website, and can publicly refer to yourself as an Egeria maintainer. Losing maintainer status If a maintainer is no longer interested or cannot perform the maintainer duties listed above, they should volunteer to be moved to emeritus status. In extreme cases this can also occur by a vote of the maintainers per the voting process below. Emeritus maintainers can rejoin the maintainer list through a vote of the existing maintainers. Leadership \u00b6 The leadership of Egeria is granted through a vote of the Egeria maintainers. Egeria is currently led by Mandy Chessell. Project meetings \u00b6 Some meetings are face-to-face, but most are conference calls. Attendance at meetings is open to all. Conference calls can be joined without an explicit invitation. However, due to physical security requirements at some venues we use, it is necessary to ensure you are added to the invitee list of any face-to-face meetings that you wish to attend and complete the necessary formalities for the venue. For example, the face-to-face meeting may be at a conference that requires you to register for the conference to attend, or a meeting may be at an organization's offices that are required to maintain a list of everyone on site. See details in the community guide Refer to the community guide for further details on the specific meetings that are planned, conference call links and dial-in numbers, as well as other communications channels like Slack and email. Releases \u00b6 The Egeria team aim to create an official release of the open metadata and governance capability every month. This release will be available to include in products and other technology through Maven's Central Repository , or through a download from the GitHub site. Details of the releases are maintained in the release notes . In between official releases, the latest build is also available to developers in GitHub. The process for creating a release is described in the developer guide Conflict resolution and voting \u00b6 In general, we prefer that technical issues and maintainer membership are amicably worked out between the persons involved. If a dispute cannot be decided independently, the maintainers can be called in to decide an issue. If the maintainers themselves cannot decide an issue, the issue will be resolved by voting. The voting process is a simple majority in which each maintainer receives one vote.","title":"Project Operations"},{"location":"guides/project-operations/#project-operations","text":"The Egeria project provides content (standards, data, code and documentation) that is intended for wide consumption across many types of organizations: from those that rely on data in their operation, to organizations that have products or technology designed to help manage data and its related processing. A project of this scope requires input from a wide range of subject matter experts with different backgrounds and allegiances. As such, we need a set of principles, roles and operating practices to ensure the results of our contributions are useful, have high quality and are widely consumable.","title":"Project Operations"},{"location":"guides/project-operations/#general-principles","text":"The principles set the tone of the operation of Egeria: The activities of the project ensure open collaboration. Through this open collaboration we aim to build a community of people who are interested in the success of the project. The scope of the content is determined by the individuals who are actively contributing. The resulting content is licensed under the Apache 2.0 license. An individual's privileges and position is awarded through their contribution and engagement. These principles should be respected as the procedures used to manage the Egeria project are evolved and matured.","title":"General principles"},{"location":"guides/project-operations/#community-members","text":"Anyone can become a member of the Egeria community by signing up to the Egeria mailing list, joining the Slack community, attending the project online meetings or contributing content to one of more of the GitHub repositories. The community guide describes how to connect to these channels. All participants in the Egeria community are bound by the project's Code of Conduct . As a member you are able to attend our meetings, just to listen, or to play an active part in the discussion. The online meetings are recorded to allow community members to catch up if they are not able to attend the live meeting. When you attend the community meetings specifically, your name will be recorded in the meeting minutes along with any remarks or suggestions you make. The agenda and minutes of our community meetings are publicly available on the Egeria wiki . A member may make contributions to the Egeria content by submitting a GitHub pull request on the appropriate Git repository. This will be reviewed and processed by the Egeria maintainers . The process for making a contribution is described in the Egeria Dojo education. Each contribution is signed by the contributor to confirm they agree to our Developer Certificate of Origin (DCO) . Community members can progress to be Egeria contributors and then Egeria maintainers .","title":"Community members"},{"location":"guides/project-operations/#contributors","text":"Egeria contributors are members who have actively taken additional steps to promote and foster the success of Egeria and its acceptance/adoption across the IT community. The activities that contributors engage in might include: Provide best practices for information governance, lineage, metadata management and other related disciplines during active discussions and/or development of material. Actively participate in meetings and discussions Promote the goals of Egeria and the benefits of open metadata to the IT community (deliver presentations, informal talks, assist at trade shows, independent blogs, etc.) Assist in the recruitment of new members. Contribute where appropriate to documentation and code reviews, specification development, demonstration assets and other artifacts that help move Egeria forward. How to become a contributor Being recognized as an Egeria contributor is done by nomination of an Egeria maintainer with a majority vote of Egeria maintainers to confirm. Once confirmed, you will receive an Egeria Contributor badge to add to your social profiles and/or website, and can publicly refer to yourself as an Egeria contributor. Egeria's contributors are recognized in the contributors list","title":"Contributors"},{"location":"guides/project-operations/#maintainers","text":"Maintainers are members of the Egeria community that have permission to change the Egeria content. This may be content that they have created themselves, or has been provided by another member. Maintainers also have responsibility for helping other project members with their contributions. This includes: Monitoring email aliases. Monitoring Slack (delayed response is perfectly acceptable). Triage GitHub issues and perform pull request reviews for other maintainers and the community. Make sure that ongoing git pull requests are moving forward at the right pace or closing them. In general continue to be willing to spend at least 25% of one's time working on the project (approximately 1.25 business days per week). How to become a maintainer New maintainers are voted onto the maintainers list by the existing maintainers . A person wishing to become a maintainer sends a note to the existing mailing list at egeria-technical-discuss@lists.lfaidata.foundation, listing their Egeria contributions to date and requesting to be made a maintainer. The maintainers vote and if a majority agree then the requester is added to the maintainers list and given write access to the Egeria Git repositories . Once confirmed, you will receive an an Egeria Maintainer badge to add to your social profiles and/or website, and can publicly refer to yourself as an Egeria maintainer. Losing maintainer status If a maintainer is no longer interested or cannot perform the maintainer duties listed above, they should volunteer to be moved to emeritus status. In extreme cases this can also occur by a vote of the maintainers per the voting process below. Emeritus maintainers can rejoin the maintainer list through a vote of the existing maintainers.","title":"Maintainers"},{"location":"guides/project-operations/#leadership","text":"The leadership of Egeria is granted through a vote of the Egeria maintainers. Egeria is currently led by Mandy Chessell.","title":"Leadership"},{"location":"guides/project-operations/#project-meetings","text":"Some meetings are face-to-face, but most are conference calls. Attendance at meetings is open to all. Conference calls can be joined without an explicit invitation. However, due to physical security requirements at some venues we use, it is necessary to ensure you are added to the invitee list of any face-to-face meetings that you wish to attend and complete the necessary formalities for the venue. For example, the face-to-face meeting may be at a conference that requires you to register for the conference to attend, or a meeting may be at an organization's offices that are required to maintain a list of everyone on site. See details in the community guide Refer to the community guide for further details on the specific meetings that are planned, conference call links and dial-in numbers, as well as other communications channels like Slack and email.","title":"Project meetings"},{"location":"guides/project-operations/#releases","text":"The Egeria team aim to create an official release of the open metadata and governance capability every month. This release will be available to include in products and other technology through Maven's Central Repository , or through a download from the GitHub site. Details of the releases are maintained in the release notes . In between official releases, the latest build is also available to developers in GitHub. The process for creating a release is described in the developer guide","title":"Releases"},{"location":"guides/project-operations/#conflict-resolution-and-voting","text":"In general, we prefer that technical issues and maintainer membership are amicably worked out between the persons involved. If a dispute cannot be decided independently, the maintainers can be called in to decide an issue. If the maintainers themselves cannot decide an issue, the issue will be resolved by voting. The voting process is a simple majority in which each maintainer receives one vote.","title":"Conflict resolution and voting"},{"location":"guides/admin/configuring-the-omag-server-platform/","text":"Configuring the OMAG Server Platform \u00b6 The OMAG Server Platform is a JVM process that includes a Tomcat web server and uses Spring Boot to support REST APIs. Default setup \u00b6 REST APIs are registered at https://localhost:9443 . This address is called the platform's platform's URL root and is configured in a number of places in the OMAG Server's configuration. The platform supports no specific security authorization. All configuration is stored in encrypted files - one for each OMAG Server configured to run on it. Useful for development, be wary for production These defaults are suitable for a development environment; however, for production the platform should be configured with platform security because this ensures configuration is managed by authorized users. Configuring other options \u00b6 Configuration store \u00b6 The configuration document is the place where the configuration for a single OMAG Server is stored. This may include security certificates and passwords. By default, the configuration document is stored in its own encrypted file in the home directory of the OMAG Server Platform , named: omag.server.{serverName}.config As of v2.0 of Egeria, the contents of the configuration document are stored in an encrypted JSON format 1 . The clear-text contents of the configuration document can still be retrieved by accessing the admin services endpoint for retrieving the configuration document; however, this ensures security is applied before a user is able to retrieve the configuration document's contents: GET - retrieve configuration document {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/configuration/ You may also wish to: Move the location of the configuration documents Write you own alternative store for the configuration documents All of these options are possible because the configuration document store is implemented in a configuration document store connector . It is therefore possible to change the implementation or behavior of this connector with a simple configuration change to the OMAG Server Platform. The configuration document store connector is configured in the OMAG Server Platform using the following command: POST - configure the configuration store {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/stores/connection The request body should be a connection object used to create the connector to the configuration document store. Ensure the connector is available in the classpath In order to use any connector other than the default, you need to also ensure that the Connector and its ConnectorProvider class are available to the server platform (i.e. the jar file containing them is available in the LOADER_PATH location of the server platform). Exmaple: (unencrypted) file store connector For example, this connection would set up the (unencrypted) file store connector: 1 2 3 4 5 6 7 8 9 10 11 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.adminservices.configurationstore.file.FileBasedServerConfigStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"omag.server.{0}.config\" } } Example: encrypted JSON file store, non-default location As another example, this connection uses the default encrypted JSON file store, but the files are stored in a different location ( /my-config/omag.server.{0}.config ). 1 2 3 4 5 6 7 8 9 10 11 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.adminservices.configurationstore.encryptedfile.EncryptedFileBasedServerConfigStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"/my-config/omag.server.{0}.config\" } } Determine configured store \u00b6 It is possible to query the setting of the configuration document store connector using the following command: GET - retrieve configured configuration document store {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/stores/connection Response indicating default configuration store (encrypted JSON file store) { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used and the address shows where the configuration documents are stored. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.adminservices.configurationstore.file.FileBasedServerConfigStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"omag.server.{0}.config\" } } } Remove configured store \u00b6 It is also possible to remove the configuration for the connector using the following command: DELETE - remove configured configuration store {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/stores/connection This reverts the store to the default encrypted JSON file store. Platform security \u00b6 The OMAG Server Platform provides both configuration and diagnostic services for OMAG Servers which in themselves provide access to a wide variety of information and control points. Therefore, it is necessary to provide authorization services relating to the use of the platform services. Egeria provides a platform security authorization capability . It is implemented in a platform security connector that is called whenever requests are made to the server platform services. Security is configured for a specific platform once it is running by using the following command. POST - configure platform security {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/platform/security/connection The request body should be a connection object used to create the platform security connector and the platform URL root of the platform. Example: sample platform security connector For example, this is the request body that would set up the sample platform security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"PlatformSecurityRequestBody\" , \"urlRoot\" : \"{{platformURLRoot}}\" , \"platformSecurityConnection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.CocoPharmaPlatformSecurityProvider\" } } } Determine configured security \u00b6 It is possible to query the setting of the platform security connector using the following command: GET - retrieve configured platform security {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/platform/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.CocoPharmaPlatformSecurityProvider\" } } } Remove configured security \u00b6 It is possible to remove the configuration for the connector using the following command: DELETE - remove configured platform security {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/platform/security/connection This removes all authorization checking from the platform services. application.properties \u00b6 Since the OMAG Server Platform is a Spring Boot application, there are other values that can be set in its application.properties file found in the resources subdirectory: Defining the port that the OMAG Server Platform will listen on for REST API calls. Controlling the level of developer logging that the platform produces when it is running. See Configuring logging options for more details. Defining where the connector implementations should be loaded from. Spring provides extensive documentation on its standard properties . Auto-starting servers \u00b6 An OMAG Server is typically started on the OMAG Server Platform using a command; however, it is possible to set up a list of servers that are automatically started whenever the platform is started. These servers are also automatically shutdown when the platform is shutdown. OMAG Servers can be automatically activated at startup by setting spring-boot property startup.server.list , typically in the application.properties file. The server names are listed without quotes. For example: startup.server.list = cocoMDS1, cocoMDS2 Each server is started with the administration user id set in the spring-boot property startup.user . For example: startup.user = garygeeke By default, this user id is set to the user id system . When the platform shuts down, if any of the servers that were in the startup list are still running, they will be shut down before the server completes. Default setting If startup.server.list is null then no servers are automatically started or stopped. startup.server.list = This is the default setting. Transport Layer Security (TLS) \u00b6 Transport layer security describes the security applied to API calls made between servers. The most commonly known transport layer security is SSL. Egeria uses TLS with certificates to secure the communication to and from the OMAG Server Platforms . Brief background on TLS \u00b6 Transport Layer Security (TLS) protects communications over network connections through encryption, authentication and integrity. It is just one layer of security of many. One-way SSL exchange \u00b6 One-way SSL exchange is typically in use when browsing the web - since as a user you are most concerned that the server you are connecting to is authentic. With this approach, the server is not able to guarantee your authenticity at the transport level. This means you can be assured of the identity of the server, but it cannot be sure of who you are. Two-way (mutual) SSL exchange \u00b6 With two-way (mutual) SSL exchange, trust is established both ways. This mutual authentication is more typical when interconnecting different systems and applications which are known in advance. Certificates for the OMAG Server Platform \u00b6 Important note on terminology Egeria's OMAG Server Platform is a Spring Boot based application. We refer to it as Egeria's \"platform\", which hosts Egeria OMAG Servers . However, in the documentation relating to network communications and SSL, a \"server\" is usually seen as an application listening on a network port. For Egeria, this \"server\" would be the OMAG Server Platform. It is important to be aware of this terminology difference when reading the links and references mentioned here. An instance of the OMAG Server Platform services requests over a REST based API from other OMAG Server Platforms, UIs, tools and engines. In this regard its role in SSL network requests described above is that of a network server , with its callers performing the role of a network client . However, since the OMAG Server Platform also makes requests to other systems (including other OMAG Server Platforms and Apache Kafka) it is also fulfilling a network client role. As a Spring application, the OMAG Server Platform's configuration for its network server role allows the following Spring properties to be set: Property Use server.ssl-key-store Used by Tomcat/Spring Boot to locate keys that identify the server server.ssl-key-alias Used by Tomcat/Spring Boot to identify the alias of the key tomcat should use for itself server.ssl.key-store-password Used by Tomcat/Spring Boot for the keystore password (2 way SSL) server.ssl.trust-store Used by Tomcat/Spring Boot to understand what clients it can trust (2 way SSL) server.ssl.trust-store-password Used by Tomcat/Spring Boot for the password of the truststore (2 way SSL) strict.ssl This is an additional parameter Egeria provides (non-standard Spring property) which if true causes SSL verification to be skipped entirely For further details on these and other less common configuration options, refer to the Spring Docs. Since the OMAG Server Platform is also a network client the settings in the next section for clients are also required. Egeria Java clients \u00b6 Standard Java properties need to be set within the JVM running the Egeria client code (this includes the OMAG Server Platform): Property Use javax.net.ssl.keyStore keyStore for client to use (2 way SSL needs this) javax.net.ssl.keyStorePassword password for the keystore (2 way SSL needs this) javax.net.ssl.trustStore trustStore for the client to use (always needs setting as Egeria makes client calls) javax.net.ssl.trustStorePassword password for the truststore (always - as above) strict.ssl For any executable jars provided by Egeria (such as samples), setting this additional parameter to true will cause SSL verification to be skipped. This is only recommended for test and development. Note that in the case of Java clients, these are system properties, and do not use Spring conventions. Other clients \u00b6 Similar principles to those documented for Java should apply. If you need further assistance, please contact the team on Slack . A pull request (or issue) with contributed documentation is also very welcome! Example to launch Egeria \u00b6 Examples certificates are provided in the codebase under open-metadata-resources/open-metadata-deployment/certificates As an example of running the Egeria server chassis with the certificates generated above, add the following options when launching the OMAG Server Platform jar file: -Dserver.ssl.key-store=${KS} -Dserver.ssl.key-alias=EgeriaServerChassis -Dserver.ssl.key-store-password=egeria -Dserver.ssl.trust-store=EgeriaCA.p12 -Dserver.ssl.trust-store-password=egeria -Djavax.net.ssl.keyStore=EgeriaServerChassis -Djavax.net.ssl.keyStorePassword=egeria -Djavax.net.ssl.trustStore=EgeriaCA.p12 -Djavax.net.ssl.trustStorePassword=egeria Detailed explanation We have to use both server.ssl and javax.net values since the former controls how the OMAG Server Platform works when accepting inbound connections and the latter are needed when it acts as a network client. We have assumed the default keystore passwords, and also that we will use the same key regardless of whether it is the one that the chassis sends back to its client after they connect, or the one the chassis may send to those other repositories. They could be distinct if needed. Creating your own certificates \u00b6 The example certificates are fine for development; however, it is important to have your own certificates for a production environment. An example script (MacOS/Linux) to create certificates is provided in gensamplecerts.sh . It is intended only as an example. It requires the openssl tool and keytool . Deployment frameworks in cloud services may also offer support to generate certificates, and it is likely an enterprise process will be in place in larger organizations. The script creates a Certificate Authority and then specific certificates for different Egeria components. It could be extended to create certificates for other clients especially if using 2 way SSL. When the script is run it also makes use of the configuration template openssl.cnf . Together, both set some important characteristics that are needed to allow the certificate to work properly, especially with current browsers: ensuring basicConstraints are specified ensuring the certificate expiry time is not too far in the future ensuring subjectAltName is specified. Additional notes on building diagrams The rendered image files are checked in, however when updating, the diagrams can be regenerated using PlantUML For example: plantuml -svg ssl-oneway.puml The diagrams are best rendered to svg, however notes do not render with a background if using the IntelliJ markdown plugin. They do render correctly if opened directly in IntelliJ, as well as in a browser It's also recommended to install the IntelliJ 'PlantUML' plugin to get a real-time preview whilst updating the diagrams. For more details on the encrypted format, see the encrypted file store connector . \u21a9","title":"Configure OMAG Server Platform"},{"location":"guides/admin/configuring-the-omag-server-platform/#configuring-the-omag-server-platform","text":"The OMAG Server Platform is a JVM process that includes a Tomcat web server and uses Spring Boot to support REST APIs.","title":"Configuring the OMAG Server Platform"},{"location":"guides/admin/configuring-the-omag-server-platform/#default-setup","text":"REST APIs are registered at https://localhost:9443 . This address is called the platform's platform's URL root and is configured in a number of places in the OMAG Server's configuration. The platform supports no specific security authorization. All configuration is stored in encrypted files - one for each OMAG Server configured to run on it. Useful for development, be wary for production These defaults are suitable for a development environment; however, for production the platform should be configured with platform security because this ensures configuration is managed by authorized users.","title":"Default setup"},{"location":"guides/admin/configuring-the-omag-server-platform/#configuring-other-options","text":"","title":"Configuring other options"},{"location":"guides/admin/configuring-the-omag-server-platform/#configuration-store","text":"The configuration document is the place where the configuration for a single OMAG Server is stored. This may include security certificates and passwords. By default, the configuration document is stored in its own encrypted file in the home directory of the OMAG Server Platform , named: omag.server.{serverName}.config As of v2.0 of Egeria, the contents of the configuration document are stored in an encrypted JSON format 1 . The clear-text contents of the configuration document can still be retrieved by accessing the admin services endpoint for retrieving the configuration document; however, this ensures security is applied before a user is able to retrieve the configuration document's contents: GET - retrieve configuration document {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/configuration/ You may also wish to: Move the location of the configuration documents Write you own alternative store for the configuration documents All of these options are possible because the configuration document store is implemented in a configuration document store connector . It is therefore possible to change the implementation or behavior of this connector with a simple configuration change to the OMAG Server Platform. The configuration document store connector is configured in the OMAG Server Platform using the following command: POST - configure the configuration store {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/stores/connection The request body should be a connection object used to create the connector to the configuration document store. Ensure the connector is available in the classpath In order to use any connector other than the default, you need to also ensure that the Connector and its ConnectorProvider class are available to the server platform (i.e. the jar file containing them is available in the LOADER_PATH location of the server platform). Exmaple: (unencrypted) file store connector For example, this connection would set up the (unencrypted) file store connector: 1 2 3 4 5 6 7 8 9 10 11 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.adminservices.configurationstore.file.FileBasedServerConfigStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"omag.server.{0}.config\" } } Example: encrypted JSON file store, non-default location As another example, this connection uses the default encrypted JSON file store, but the files are stored in a different location ( /my-config/omag.server.{0}.config ). 1 2 3 4 5 6 7 8 9 10 11 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.adminservices.configurationstore.encryptedfile.EncryptedFileBasedServerConfigStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"/my-config/omag.server.{0}.config\" } }","title":"Configuration store"},{"location":"guides/admin/configuring-the-omag-server-platform/#determine-configured-store","text":"It is possible to query the setting of the configuration document store connector using the following command: GET - retrieve configured configuration document store {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/stores/connection Response indicating default configuration store (encrypted JSON file store) { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used and the address shows where the configuration documents are stored. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.adminservices.configurationstore.file.FileBasedServerConfigStoreProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"omag.server.{0}.config\" } } }","title":"Determine configured store"},{"location":"guides/admin/configuring-the-omag-server-platform/#remove-configured-store","text":"It is also possible to remove the configuration for the connector using the following command: DELETE - remove configured configuration store {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/stores/connection This reverts the store to the default encrypted JSON file store.","title":"Remove configured store"},{"location":"guides/admin/configuring-the-omag-server-platform/#platform-security","text":"The OMAG Server Platform provides both configuration and diagnostic services for OMAG Servers which in themselves provide access to a wide variety of information and control points. Therefore, it is necessary to provide authorization services relating to the use of the platform services. Egeria provides a platform security authorization capability . It is implemented in a platform security connector that is called whenever requests are made to the server platform services. Security is configured for a specific platform once it is running by using the following command. POST - configure platform security {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/platform/security/connection The request body should be a connection object used to create the platform security connector and the platform URL root of the platform. Example: sample platform security connector For example, this is the request body that would set up the sample platform security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"PlatformSecurityRequestBody\" , \"urlRoot\" : \"{{platformURLRoot}}\" , \"platformSecurityConnection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.CocoPharmaPlatformSecurityProvider\" } } }","title":"Platform security"},{"location":"guides/admin/configuring-the-omag-server-platform/#determine-configured-security","text":"It is possible to query the setting of the platform security connector using the following command: GET - retrieve configured platform security {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/platform/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.CocoPharmaPlatformSecurityProvider\" } } }","title":"Determine configured security"},{"location":"guides/admin/configuring-the-omag-server-platform/#remove-configured-security","text":"It is possible to remove the configuration for the connector using the following command: DELETE - remove configured platform security {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/platform/security/connection This removes all authorization checking from the platform services.","title":"Remove configured security"},{"location":"guides/admin/configuring-the-omag-server-platform/#applicationproperties","text":"Since the OMAG Server Platform is a Spring Boot application, there are other values that can be set in its application.properties file found in the resources subdirectory: Defining the port that the OMAG Server Platform will listen on for REST API calls. Controlling the level of developer logging that the platform produces when it is running. See Configuring logging options for more details. Defining where the connector implementations should be loaded from. Spring provides extensive documentation on its standard properties .","title":"application.properties"},{"location":"guides/admin/configuring-the-omag-server-platform/#auto-starting-servers","text":"An OMAG Server is typically started on the OMAG Server Platform using a command; however, it is possible to set up a list of servers that are automatically started whenever the platform is started. These servers are also automatically shutdown when the platform is shutdown. OMAG Servers can be automatically activated at startup by setting spring-boot property startup.server.list , typically in the application.properties file. The server names are listed without quotes. For example: startup.server.list = cocoMDS1, cocoMDS2 Each server is started with the administration user id set in the spring-boot property startup.user . For example: startup.user = garygeeke By default, this user id is set to the user id system . When the platform shuts down, if any of the servers that were in the startup list are still running, they will be shut down before the server completes. Default setting If startup.server.list is null then no servers are automatically started or stopped. startup.server.list = This is the default setting.","title":"Auto-starting servers"},{"location":"guides/admin/configuring-the-omag-server-platform/#transport-layer-security-tls","text":"Transport layer security describes the security applied to API calls made between servers. The most commonly known transport layer security is SSL. Egeria uses TLS with certificates to secure the communication to and from the OMAG Server Platforms .","title":"Transport Layer Security (TLS)"},{"location":"guides/admin/configuring-the-omag-server-platform/#brief-background-on-tls","text":"Transport Layer Security (TLS) protects communications over network connections through encryption, authentication and integrity. It is just one layer of security of many.","title":"Brief background on TLS"},{"location":"guides/admin/configuring-the-omag-server-platform/#one-way-ssl-exchange","text":"One-way SSL exchange is typically in use when browsing the web - since as a user you are most concerned that the server you are connecting to is authentic. With this approach, the server is not able to guarantee your authenticity at the transport level. This means you can be assured of the identity of the server, but it cannot be sure of who you are.","title":"One-way SSL exchange"},{"location":"guides/admin/configuring-the-omag-server-platform/#two-way-mutual-ssl-exchange","text":"With two-way (mutual) SSL exchange, trust is established both ways. This mutual authentication is more typical when interconnecting different systems and applications which are known in advance.","title":"Two-way (mutual) SSL exchange"},{"location":"guides/admin/configuring-the-omag-server-platform/#certificates-for-the-omag-server-platform","text":"Important note on terminology Egeria's OMAG Server Platform is a Spring Boot based application. We refer to it as Egeria's \"platform\", which hosts Egeria OMAG Servers . However, in the documentation relating to network communications and SSL, a \"server\" is usually seen as an application listening on a network port. For Egeria, this \"server\" would be the OMAG Server Platform. It is important to be aware of this terminology difference when reading the links and references mentioned here. An instance of the OMAG Server Platform services requests over a REST based API from other OMAG Server Platforms, UIs, tools and engines. In this regard its role in SSL network requests described above is that of a network server , with its callers performing the role of a network client . However, since the OMAG Server Platform also makes requests to other systems (including other OMAG Server Platforms and Apache Kafka) it is also fulfilling a network client role. As a Spring application, the OMAG Server Platform's configuration for its network server role allows the following Spring properties to be set: Property Use server.ssl-key-store Used by Tomcat/Spring Boot to locate keys that identify the server server.ssl-key-alias Used by Tomcat/Spring Boot to identify the alias of the key tomcat should use for itself server.ssl.key-store-password Used by Tomcat/Spring Boot for the keystore password (2 way SSL) server.ssl.trust-store Used by Tomcat/Spring Boot to understand what clients it can trust (2 way SSL) server.ssl.trust-store-password Used by Tomcat/Spring Boot for the password of the truststore (2 way SSL) strict.ssl This is an additional parameter Egeria provides (non-standard Spring property) which if true causes SSL verification to be skipped entirely For further details on these and other less common configuration options, refer to the Spring Docs. Since the OMAG Server Platform is also a network client the settings in the next section for clients are also required.","title":"Certificates for the OMAG Server Platform"},{"location":"guides/admin/configuring-the-omag-server-platform/#egeria-java-clients","text":"Standard Java properties need to be set within the JVM running the Egeria client code (this includes the OMAG Server Platform): Property Use javax.net.ssl.keyStore keyStore for client to use (2 way SSL needs this) javax.net.ssl.keyStorePassword password for the keystore (2 way SSL needs this) javax.net.ssl.trustStore trustStore for the client to use (always needs setting as Egeria makes client calls) javax.net.ssl.trustStorePassword password for the truststore (always - as above) strict.ssl For any executable jars provided by Egeria (such as samples), setting this additional parameter to true will cause SSL verification to be skipped. This is only recommended for test and development. Note that in the case of Java clients, these are system properties, and do not use Spring conventions.","title":"Egeria Java clients"},{"location":"guides/admin/configuring-the-omag-server-platform/#other-clients","text":"Similar principles to those documented for Java should apply. If you need further assistance, please contact the team on Slack . A pull request (or issue) with contributed documentation is also very welcome!","title":"Other clients"},{"location":"guides/admin/configuring-the-omag-server-platform/#example-to-launch-egeria","text":"Examples certificates are provided in the codebase under open-metadata-resources/open-metadata-deployment/certificates As an example of running the Egeria server chassis with the certificates generated above, add the following options when launching the OMAG Server Platform jar file: -Dserver.ssl.key-store=${KS} -Dserver.ssl.key-alias=EgeriaServerChassis -Dserver.ssl.key-store-password=egeria -Dserver.ssl.trust-store=EgeriaCA.p12 -Dserver.ssl.trust-store-password=egeria -Djavax.net.ssl.keyStore=EgeriaServerChassis -Djavax.net.ssl.keyStorePassword=egeria -Djavax.net.ssl.trustStore=EgeriaCA.p12 -Djavax.net.ssl.trustStorePassword=egeria Detailed explanation We have to use both server.ssl and javax.net values since the former controls how the OMAG Server Platform works when accepting inbound connections and the latter are needed when it acts as a network client. We have assumed the default keystore passwords, and also that we will use the same key regardless of whether it is the one that the chassis sends back to its client after they connect, or the one the chassis may send to those other repositories. They could be distinct if needed.","title":"Example to launch Egeria"},{"location":"guides/admin/configuring-the-omag-server-platform/#creating-your-own-certificates","text":"The example certificates are fine for development; however, it is important to have your own certificates for a production environment. An example script (MacOS/Linux) to create certificates is provided in gensamplecerts.sh . It is intended only as an example. It requires the openssl tool and keytool . Deployment frameworks in cloud services may also offer support to generate certificates, and it is likely an enterprise process will be in place in larger organizations. The script creates a Certificate Authority and then specific certificates for different Egeria components. It could be extended to create certificates for other clients especially if using 2 way SSL. When the script is run it also makes use of the configuration template openssl.cnf . Together, both set some important characteristics that are needed to allow the certificate to work properly, especially with current browsers: ensuring basicConstraints are specified ensuring the certificate expiry time is not too far in the future ensuring subjectAltName is specified. Additional notes on building diagrams The rendered image files are checked in, however when updating, the diagrams can be regenerated using PlantUML For example: plantuml -svg ssl-oneway.puml The diagrams are best rendered to svg, however notes do not render with a background if using the IntelliJ markdown plugin. They do render correctly if opened directly in IntelliJ, as well as in a browser It's also recommended to install the IntelliJ 'PlantUML' plugin to get a real-time preview whilst updating the diagrams. For more details on the encrypted format, see the encrypted file store connector . \u21a9","title":"Creating your own certificates"},{"location":"guides/admin/guide/","text":"Administration Guide \u00b6 The Egeria technology principally runs on the Open Metadata and Governance ( OMAG ) Server Platform . This platform hosts one or more OMAG Servers , each supporting a variety of open metadata and governance capabilities. In the illustration above, the OMAG Server Platforms are the blue, rounded boxes and the orange circles are the OMAG Servers. The green clouds represent different cloud platforms or data centers. This guide explains how to configure the OMAG Server Platform and the different types of OMAG Servers that run on it. TL;DR If you are keen to get started right away then these are the links to the configuration instructions. Configuring the OMAG Server Platform Configuring an OMAG Server to run on an OMAG Server Platform Configuring the Presentation Server (for UIs) and once you have your OMAG Servers configured: Operating an OMAG Server OMAG subsystems \u00b6 An OMAG Server is a set of configured OMAG subsystems supported by the OMAG Server Platform . Each subsystem supports a particular type of technology, so it can exchange metadata with the open metadata ecosystem. Some technologies are sources of metadata, others just consume metadata and then there are technologies that have a two-way exchange of metadata with the open metadata ecosystem. The OMAG subsystems that are to be enabled in a specific instance of an OMAG Server are defined in a configuration document . When the configuration document is loaded into the OMAG Server Platform, the OMAG Server that it describes is started, and the subsystems defined in the configuration document are activated for that server. OMAG Servers \u00b6 In an open metadata landscape, there may be multiple instances of OMAG Servers running in an OMAG Server Platform , each performing a different role. Each of these server instances would have their own configuration document allowing them to have different subsystems active. Configuring an OMAG Server \u00b6 The configuration document for a specific OMAG Server is identified by the server's name. This is passed on the URL of every admin services API request along with the user id of the administrator. By default, the configuration is stored in a file called: omag.server.{serverName}.config The administration services that set up this file all begin with a URL like this: .../open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/... The serverName specified on these calls determines which configuration document is used, and hence which OMAG Server's configuration it is working with. The OMAG Server Platform typically starts up without any OMAG Servers active. Once it is running, it can be used to set up the configuration documents that describe the open metadata subsystems needed for each OMAG Server instance. Once the configuration document is in place, the OMAG Server can be activated and deactivated multiple times, across multiple restarts of the OMAG Server Platform. Further information Configuring the OMAG Server Platform Configuring an OMAG Server Operating the OMAG Server Migrating OMAG Server Configuration Documents Examples of configuration calls \u00b6 The admin-services modules has three Postman collections to illustrate many of the configuration and operation calls: Egeria-admin-services-platform-configuration.postman_environment.json - setting up and configuring the OMAG Server Platform. Egeria-admin-services-server-configuration.postman_environment.json - setting up and configuring the variety of OMAG Servers. Egeria-admin-services-operational.postman_environment.json - operating the OMAG Servers.","title":"Administration Guide"},{"location":"guides/admin/guide/#administration-guide","text":"The Egeria technology principally runs on the Open Metadata and Governance ( OMAG ) Server Platform . This platform hosts one or more OMAG Servers , each supporting a variety of open metadata and governance capabilities. In the illustration above, the OMAG Server Platforms are the blue, rounded boxes and the orange circles are the OMAG Servers. The green clouds represent different cloud platforms or data centers. This guide explains how to configure the OMAG Server Platform and the different types of OMAG Servers that run on it. TL;DR If you are keen to get started right away then these are the links to the configuration instructions. Configuring the OMAG Server Platform Configuring an OMAG Server to run on an OMAG Server Platform Configuring the Presentation Server (for UIs) and once you have your OMAG Servers configured: Operating an OMAG Server","title":"Administration Guide"},{"location":"guides/admin/guide/#omag-subsystems","text":"An OMAG Server is a set of configured OMAG subsystems supported by the OMAG Server Platform . Each subsystem supports a particular type of technology, so it can exchange metadata with the open metadata ecosystem. Some technologies are sources of metadata, others just consume metadata and then there are technologies that have a two-way exchange of metadata with the open metadata ecosystem. The OMAG subsystems that are to be enabled in a specific instance of an OMAG Server are defined in a configuration document . When the configuration document is loaded into the OMAG Server Platform, the OMAG Server that it describes is started, and the subsystems defined in the configuration document are activated for that server.","title":"OMAG subsystems"},{"location":"guides/admin/guide/#omag-servers","text":"In an open metadata landscape, there may be multiple instances of OMAG Servers running in an OMAG Server Platform , each performing a different role. Each of these server instances would have their own configuration document allowing them to have different subsystems active.","title":"OMAG Servers"},{"location":"guides/admin/guide/#configuring-an-omag-server","text":"The configuration document for a specific OMAG Server is identified by the server's name. This is passed on the URL of every admin services API request along with the user id of the administrator. By default, the configuration is stored in a file called: omag.server.{serverName}.config The administration services that set up this file all begin with a URL like this: .../open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/... The serverName specified on these calls determines which configuration document is used, and hence which OMAG Server's configuration it is working with. The OMAG Server Platform typically starts up without any OMAG Servers active. Once it is running, it can be used to set up the configuration documents that describe the open metadata subsystems needed for each OMAG Server instance. Once the configuration document is in place, the OMAG Server can be activated and deactivated multiple times, across multiple restarts of the OMAG Server Platform. Further information Configuring the OMAG Server Platform Configuring an OMAG Server Operating the OMAG Server Migrating OMAG Server Configuration Documents","title":"Configuring an OMAG Server"},{"location":"guides/admin/guide/#examples-of-configuration-calls","text":"The admin-services modules has three Postman collections to illustrate many of the configuration and operation calls: Egeria-admin-services-platform-configuration.postman_environment.json - setting up and configuring the OMAG Server Platform. Egeria-admin-services-server-configuration.postman_environment.json - setting up and configuring the variety of OMAG Servers. Egeria-admin-services-operational.postman_environment.json - operating the OMAG Servers.","title":"Examples of configuration calls"},{"location":"guides/admin/omag-server-platform-logging/","text":"Configuring developer logging options for OMAG Server Platform \u00b6 Options for logging system using Spring Boot server chassis \u00b6 The default java application server chassis for OMAG server is Spring Boot. As such it comes with support for variety of logging options. You can always check the options in the official guidelines here . Spring itself uses abstraction layer and chooses the logging implementation during runtime based on content of the classpath. OMAG Server chassis spring application uses web starter by default which already brings basic logging options from JCL but also Logback logging system. Application level logging categories \u00b6 As described in the Spring documentation, you can control log levels for specific category logger using system or application properties: logging.level.root = ERROR logging.level.org.springframework.web = DEBUG logging.level.org.odpi.openmetadata = ERROR Connecting the OMAG Audit Log Framework \u00b6 While the default logging framework enables generic interface for system logging is not adequate option for diagnostic and auditing. For this purpose in OMAG Server platform Audit Log Framework is used. You can find out more about this on Egeria website Diagnostics Guide . Audit Logging framework is configured as part of the OMAG configuration document by choosing from the available destination systems. By default, the system will use the stdout - system standard output as a destination. One of the options suitable for production like operating environments is to choose SLF4J connector and connect AuditLog to the existing system logging implementation via dedicated audit log logger category: logging.level.org.odpi.openmetadata.frameworks.auditlog = INFO Using SLF4J connector you can also have granular auditlog logger category control per OMAG server instance following naming pattern below: logging.level.org.odpi.openmetadata.frameworks.auditlog.{omag-server-name}.{originator-component-name} Note that the category is defined by omitting the empty space characters. Example: logging.level.org.odpi.openmetadata.frameworks.auditlog.omag-server-1 = INFO logging.level.org.odpi.openmetadata.frameworks.auditlog.omag-server-2.RepositoryContentManager = ERROR","title":"Omag server platform logging"},{"location":"guides/admin/omag-server-platform-logging/#configuring-developer-logging-options-for-omag-server-platform","text":"","title":"Configuring developer logging options for OMAG Server Platform"},{"location":"guides/admin/omag-server-platform-logging/#options-for-logging-system-using-spring-boot-server-chassis","text":"The default java application server chassis for OMAG server is Spring Boot. As such it comes with support for variety of logging options. You can always check the options in the official guidelines here . Spring itself uses abstraction layer and chooses the logging implementation during runtime based on content of the classpath. OMAG Server chassis spring application uses web starter by default which already brings basic logging options from JCL but also Logback logging system.","title":"Options for logging system using Spring Boot server chassis"},{"location":"guides/admin/omag-server-platform-logging/#application-level-logging-categories","text":"As described in the Spring documentation, you can control log levels for specific category logger using system or application properties: logging.level.root = ERROR logging.level.org.springframework.web = DEBUG logging.level.org.odpi.openmetadata = ERROR","title":"Application level logging categories"},{"location":"guides/admin/omag-server-platform-logging/#connecting-the-omag-audit-log-framework","text":"While the default logging framework enables generic interface for system logging is not adequate option for diagnostic and auditing. For this purpose in OMAG Server platform Audit Log Framework is used. You can find out more about this on Egeria website Diagnostics Guide . Audit Logging framework is configured as part of the OMAG configuration document by choosing from the available destination systems. By default, the system will use the stdout - system standard output as a destination. One of the options suitable for production like operating environments is to choose SLF4J connector and connect AuditLog to the existing system logging implementation via dedicated audit log logger category: logging.level.org.odpi.openmetadata.frameworks.auditlog = INFO Using SLF4J connector you can also have granular auditlog logger category control per OMAG server instance following naming pattern below: logging.level.org.odpi.openmetadata.frameworks.auditlog.{omag-server-name}.{originator-component-name} Note that the category is defined by omitting the empty space characters. Example: logging.level.org.odpi.openmetadata.frameworks.auditlog.omag-server-1 = INFO logging.level.org.odpi.openmetadata.frameworks.auditlog.omag-server-2.RepositoryContentManager = ERROR","title":"Connecting the OMAG Audit Log Framework"},{"location":"guides/admin/omag-server-platform-transport-level-security/","text":"Transport Level Security (TLS) and Certificates \u00b6 Egeria uses TLS with certificates to secure the communication to and from the OMAG Server Platforms . In this document you'll find information on: * A background to TLS * Using TLS with the OMAG Server Platform * Using TLS with Egeria's Java clients (also used in the OMAG Server Platform) * Using TLS with other types of clients (third party tools and applications) TLS protocol \u00b6 Transport Level Security (TLS) protects communications over network connections through Encryption, Authentication and Integrity. It is just one layer of security of many. One-way SSL exchange \u00b6 One-way SSL exchange is typically in use when browsing the web - since as a user you are most concerned that the server you are connecting to is authentic. With this approach, the server is not able to guarantee your authenticity at the transport level. This means you can be assured of the identity of the server, but it can not be sure of who you are. Transport Level Security(Wikipedia) Two-way (mutual) SSL exchange \u00b6 With two-way (mutual) SSL exchange, trust is established both ways. This is more typical when interconnecting different systems and applications which are known in advance. Mutual Authentication(Wikipedia) Certificates for the OMAG Server Platform \u00b6 Egeria's OMAG Server Platform is a Spring boot based application. We refer to it as Egeria's 'platform', which hosts Egeria OMAG Servers . However in the documentation relating to network communications and SSL, a \"server\" is usually seen as an application listening on a network port. For Egeria, this 'server' would be the OMAG Server Platform. It is important to be aware of this terminology difference when reading the links and references mentioned here. An instance of the OMAG Server Platform services requests over a REST based API from other OMAG Server Platforms, UIs, tools and engines. In this regard it's role in SSL network requests described above is that of a network server , with its callers performing the role of a network client . However since the OMAG Server Platform also makes requests to other systems (including other OMAG Server Platforms and Apache Kafka) it is also fulfilling a network client role. As a spring application, the OMAG Server Platform's configuration for it's network server role allows the following spring properties to be set: server.ssl-key-store Used by tomcat/spring boot to locate keys that identify the server server.ssl-key-alias Used by tomcat/spring boot to identify the alias of the key tomcat should use for itself server.ssl.key-store-password Used by tomcat/spring boot for the keystore password (2 way SSL) server.ssl.trust-store Used by tomcat/spring boot to understand what clients it can trust (2 way SSL) server.ssl.trust-store-password Used by tomcat/spring boot for the password of the truststore (2 way SSL) In addition an additional parameter is provided which causes ssl verification to be skipped: strict.ssl true / false : If set to true skips checks on certificate For further details on these and other less common configuration options, refer to the Spring Docs Since the OMAG Server Platform is also a network client the settings in the next section for clients are also required. Egeria Java Clients \u00b6 Standard java properties need to be set within the JVM running the Egeria client code (this includes the OMAG Server Platform): javax.net.ssl.keyStore keyStore for client to use (2 way SSL needs this) javax.net.ssl.keyStorePassword password for the keystore (2 way SSL needs this) javax.net.ssl.trustStore trustStore for the client to use (always needs setting as egeria makes client calls) javax.net.ssl.trustStorePassword password for the truststore (always - as above) In addition, for any executable jars provided by Egeria - such as samples, an additional parameter will cause ssl verification to be skipped. This is only recommended for test and development strict.ssl true / false : If set to true skips checks on certificate Note that in the case of Java Clients, these are system properties, and do not use spring conventions. Other clients \u00b6 Similar principles to those documented for java should apply. If you need further assistance please contact the team on our slack channel at http://slack.lfai.foundation . A Pull Request (or issue) with contributed documentation is very welcome ! Example script to launch Egeria \u00b6 Example certificates are provided here As an example of running the Egeria server chassis with the certificates generated above, add the following options when launching the OMAG Server Platform jar file: -Dserver.ssl.key-store=${KS} -Dserver.ssl.key-alias=EgeriaServerChassis -Dserver.ssl.key-store-password=egeria -Dserver.ssl.trust-store=EgeriaCA.p12 -Dserver.ssl.trust-store-password=egeria -Djavax.net.ssl.keyStore=EgeriaServerChassis -Djavax.net.ssl.keyStorePassword=egeria -Djavax.net.ssl.trustStore=EgeriaCA.p12 -Djavax.net.ssl.trustStorePassword=egeria We have to use both server.ssl and javax.net values since the former controls how the OMAG Server Platform works when accepting inbound connections and the latter are needed when it acts as a network client. We have assumed the default keystore passwords, and also that we will use the same key regardless of whether it is the one that the chassis sends back to it's client after they connect, or the one the chassis may send to those other repositories. They could be distinct if needed. Creating your own certificates \u00b6 The example certificates are fine for development. However it is important to have your own certificates for a production environment. Example configurations and scripts can be found in open-metadata-resources/open-metadata-deployment/certificates An example script (MacOS/Linux)to create certificates is provided in gensamplecerts.sh . It is intended only as an example. It requires the openssl tool and keytool . Deployment frameworks in cloud services may also offer support to generate certificates and it's likely an enterprise process will be place in larger organizations. The script creates a Certificate Authority and then specific certificates for different Egeria components. It could be extended to create certificates for other clients especially if using 2 way SSL. When the script is run it also makes use of the configuration template openssl.cnf. Together both set some important characteristics that are needed to allow the certificate to work properly especially with current browsers - ensuring basicConstraints are specified - ensuring the certificate expiry time is not too far in the future - ensuring subjectAltName is specified. Additional Notes \u00b6 Building diagrams \u00b6 Note: Rendered image files are checked in, however when updating, the diagrams can be regenerated using For example: plantuml -svg ssl-oneway.puml The diagrams are best rendered to svg, however notes do not render with a background if using the IntelliJ markdown plugin. They do render correctly if opened directly in IntelliJ, as well as in a browser It's also recommended to install the IntelliJ 'PlantUML' plugin to get a real-time preview whilst updating the diagrams.","title":"Omag server platform transport level security"},{"location":"guides/admin/omag-server-platform-transport-level-security/#transport-level-security-tls-and-certificates","text":"Egeria uses TLS with certificates to secure the communication to and from the OMAG Server Platforms . In this document you'll find information on: * A background to TLS * Using TLS with the OMAG Server Platform * Using TLS with Egeria's Java clients (also used in the OMAG Server Platform) * Using TLS with other types of clients (third party tools and applications)","title":"Transport Level Security (TLS) and Certificates"},{"location":"guides/admin/omag-server-platform-transport-level-security/#tls-protocol","text":"Transport Level Security (TLS) protects communications over network connections through Encryption, Authentication and Integrity. It is just one layer of security of many.","title":"TLS protocol"},{"location":"guides/admin/omag-server-platform-transport-level-security/#one-way-ssl-exchange","text":"One-way SSL exchange is typically in use when browsing the web - since as a user you are most concerned that the server you are connecting to is authentic. With this approach, the server is not able to guarantee your authenticity at the transport level. This means you can be assured of the identity of the server, but it can not be sure of who you are. Transport Level Security(Wikipedia)","title":"One-way SSL exchange"},{"location":"guides/admin/omag-server-platform-transport-level-security/#two-way-mutual-ssl-exchange","text":"With two-way (mutual) SSL exchange, trust is established both ways. This is more typical when interconnecting different systems and applications which are known in advance. Mutual Authentication(Wikipedia)","title":"Two-way (mutual) SSL exchange"},{"location":"guides/admin/omag-server-platform-transport-level-security/#certificates-for-the-omag-server-platform","text":"Egeria's OMAG Server Platform is a Spring boot based application. We refer to it as Egeria's 'platform', which hosts Egeria OMAG Servers . However in the documentation relating to network communications and SSL, a \"server\" is usually seen as an application listening on a network port. For Egeria, this 'server' would be the OMAG Server Platform. It is important to be aware of this terminology difference when reading the links and references mentioned here. An instance of the OMAG Server Platform services requests over a REST based API from other OMAG Server Platforms, UIs, tools and engines. In this regard it's role in SSL network requests described above is that of a network server , with its callers performing the role of a network client . However since the OMAG Server Platform also makes requests to other systems (including other OMAG Server Platforms and Apache Kafka) it is also fulfilling a network client role. As a spring application, the OMAG Server Platform's configuration for it's network server role allows the following spring properties to be set: server.ssl-key-store Used by tomcat/spring boot to locate keys that identify the server server.ssl-key-alias Used by tomcat/spring boot to identify the alias of the key tomcat should use for itself server.ssl.key-store-password Used by tomcat/spring boot for the keystore password (2 way SSL) server.ssl.trust-store Used by tomcat/spring boot to understand what clients it can trust (2 way SSL) server.ssl.trust-store-password Used by tomcat/spring boot for the password of the truststore (2 way SSL) In addition an additional parameter is provided which causes ssl verification to be skipped: strict.ssl true / false : If set to true skips checks on certificate For further details on these and other less common configuration options, refer to the Spring Docs Since the OMAG Server Platform is also a network client the settings in the next section for clients are also required.","title":"Certificates for the OMAG Server Platform"},{"location":"guides/admin/omag-server-platform-transport-level-security/#egeria-java-clients","text":"Standard java properties need to be set within the JVM running the Egeria client code (this includes the OMAG Server Platform): javax.net.ssl.keyStore keyStore for client to use (2 way SSL needs this) javax.net.ssl.keyStorePassword password for the keystore (2 way SSL needs this) javax.net.ssl.trustStore trustStore for the client to use (always needs setting as egeria makes client calls) javax.net.ssl.trustStorePassword password for the truststore (always - as above) In addition, for any executable jars provided by Egeria - such as samples, an additional parameter will cause ssl verification to be skipped. This is only recommended for test and development strict.ssl true / false : If set to true skips checks on certificate Note that in the case of Java Clients, these are system properties, and do not use spring conventions.","title":"Egeria Java Clients"},{"location":"guides/admin/omag-server-platform-transport-level-security/#other-clients","text":"Similar principles to those documented for java should apply. If you need further assistance please contact the team on our slack channel at http://slack.lfai.foundation . A Pull Request (or issue) with contributed documentation is very welcome !","title":"Other clients"},{"location":"guides/admin/omag-server-platform-transport-level-security/#example-script-to-launch-egeria","text":"Example certificates are provided here As an example of running the Egeria server chassis with the certificates generated above, add the following options when launching the OMAG Server Platform jar file: -Dserver.ssl.key-store=${KS} -Dserver.ssl.key-alias=EgeriaServerChassis -Dserver.ssl.key-store-password=egeria -Dserver.ssl.trust-store=EgeriaCA.p12 -Dserver.ssl.trust-store-password=egeria -Djavax.net.ssl.keyStore=EgeriaServerChassis -Djavax.net.ssl.keyStorePassword=egeria -Djavax.net.ssl.trustStore=EgeriaCA.p12 -Djavax.net.ssl.trustStorePassword=egeria We have to use both server.ssl and javax.net values since the former controls how the OMAG Server Platform works when accepting inbound connections and the latter are needed when it acts as a network client. We have assumed the default keystore passwords, and also that we will use the same key regardless of whether it is the one that the chassis sends back to it's client after they connect, or the one the chassis may send to those other repositories. They could be distinct if needed.","title":"Example script to launch Egeria"},{"location":"guides/admin/omag-server-platform-transport-level-security/#creating-your-own-certificates","text":"The example certificates are fine for development. However it is important to have your own certificates for a production environment. Example configurations and scripts can be found in open-metadata-resources/open-metadata-deployment/certificates An example script (MacOS/Linux)to create certificates is provided in gensamplecerts.sh . It is intended only as an example. It requires the openssl tool and keytool . Deployment frameworks in cloud services may also offer support to generate certificates and it's likely an enterprise process will be place in larger organizations. The script creates a Certificate Authority and then specific certificates for different Egeria components. It could be extended to create certificates for other clients especially if using 2 way SSL. When the script is run it also makes use of the configuration template openssl.cnf. Together both set some important characteristics that are needed to allow the certificate to work properly especially with current browsers - ensuring basicConstraints are specified - ensuring the certificate expiry time is not too far in the future - ensuring subjectAltName is specified.","title":"Creating your own certificates"},{"location":"guides/admin/omag-server-platform-transport-level-security/#additional-notes","text":"","title":"Additional Notes"},{"location":"guides/admin/omag-server-platform-transport-level-security/#building-diagrams","text":"Note: Rendered image files are checked in, however when updating, the diagrams can be regenerated using For example: plantuml -svg ssl-oneway.puml The diagrams are best rendered to svg, however notes do not render with a background if using the IntelliJ markdown plugin. They do render correctly if opened directly in IntelliJ, as well as in a browser It's also recommended to install the IntelliJ 'PlantUML' plugin to get a real-time preview whilst updating the diagrams.","title":"Building diagrams"},{"location":"guides/admin/servers/","text":"Configuring an OMAG Server \u00b6 An OMAG Server is a configured set of services and connectors that support the integration of a particular type of technology. There are different types of OMAG Server for each type of technology. Each are configured separately and then linked together to form a connected ecosystem. The configuration document for the OMAG Server determines which OMAG subsystems (and hence the types of open metadata and governance services) should be activated in the OMAG Server. For example: Setting basic descriptive properties of the server that are used in logging and events originating from the server. What type of local repository to use. Whether the Open Metadata Access Services (OMASs) should be started. Which cohorts to connect to. Each of the configuration commands builds up sections in the configuration document. This document is stored in the configuration store after each configuration request, so it is immediately available for use each time the open metadata services are activated in the OMAG Server. Many of the configuration values are connections to allow the server to create the connectors to the resources it needs. These connectors enable Egeria to run in different deployment environments and to connect to different third party technologies. In the descriptions of the configuration commands, there are placeholders for the specific configuration values: they are names of the value in double curly braces. For example: {{platformURLRoot}} - the network address where the OMAG Server Platform is registered, such as https://localhost:9443 . {{adminUserId}} - the user id of the administrator, for example garygeeke . {{serverName}} - the name of the OMAG Server, for example cocoMDS1 . Retrieving the configuration \u00b6 GET - retrieve the configuration document for a specific OMAG Server {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/configuration GET - retrieve the origin of the server It is also possible to query the origin of the server supporting the open metadata services. For the Egeria OMAG Server Platform, the response is Egeria OMAG Server Platform (version 3.1-SNAPSHOT) . {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/servers/{{serverName}}/server-platform-origin Migrating configuration documents \u00b6 As Egeria evolves, the content of the configuration document expands. Many of the changes are pure additions and are therefore backward compatible. OMAG Server Platform fails to load configuration document From time to time the structure of the configuration document needs to change. When this happens, the OMAG Server Platform is not able to load the configuration document and a message similar to this is returned: { \"class\" : \"VoidResponse\" , \"relatedHTTPCode\" : 400 , \"exceptionClassName\" : \"org.odpi.openmetadata.adminservices.ffdc.exception.OMAGInvalidParameterException\" , \"exceptionErrorMessage\" : \"OMAG-ADMIN-400-022 The configuration document for OMAG Server cocoMDS1 is at version V1.0 which is not compatible with this OMAG Server Platform which supports versions [V2.0]\" , \"exceptionSystemAction\" : \"The system is unable to configure the local server because it can not read the configuration document.\" , \"exceptionUserAction\" : \"Migrate the configuration document to a compatible version (or delete and recreate it). See https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user/migrating-configuration-documents.html\" } Migrating a configuration document from V1.0 to V2.0 \u00b6 The additionalProperties property name changed to configurationProperties . To migrate the configuration document, make a global change from additionalProperties to configurationProperties throughout the configuration document. Release 2.x+ of Egeria \u00b6 Release 2.0 encrypts the configuration document by default. This includes automatically detecting and encrypting any clear-text (unencrypted) configuration document that may already exist. No user action is required for this migration, the encryption will be handled automatically when the clear-text configuration document is first opened by the platform in these releases.","title":"Configuring an OMAG Server"},{"location":"guides/admin/servers/#configuring-an-omag-server","text":"An OMAG Server is a configured set of services and connectors that support the integration of a particular type of technology. There are different types of OMAG Server for each type of technology. Each are configured separately and then linked together to form a connected ecosystem. The configuration document for the OMAG Server determines which OMAG subsystems (and hence the types of open metadata and governance services) should be activated in the OMAG Server. For example: Setting basic descriptive properties of the server that are used in logging and events originating from the server. What type of local repository to use. Whether the Open Metadata Access Services (OMASs) should be started. Which cohorts to connect to. Each of the configuration commands builds up sections in the configuration document. This document is stored in the configuration store after each configuration request, so it is immediately available for use each time the open metadata services are activated in the OMAG Server. Many of the configuration values are connections to allow the server to create the connectors to the resources it needs. These connectors enable Egeria to run in different deployment environments and to connect to different third party technologies. In the descriptions of the configuration commands, there are placeholders for the specific configuration values: they are names of the value in double curly braces. For example: {{platformURLRoot}} - the network address where the OMAG Server Platform is registered, such as https://localhost:9443 . {{adminUserId}} - the user id of the administrator, for example garygeeke . {{serverName}} - the name of the OMAG Server, for example cocoMDS1 .","title":"Configuring an OMAG Server"},{"location":"guides/admin/servers/#retrieving-the-configuration","text":"GET - retrieve the configuration document for a specific OMAG Server {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/configuration GET - retrieve the origin of the server It is also possible to query the origin of the server supporting the open metadata services. For the Egeria OMAG Server Platform, the response is Egeria OMAG Server Platform (version 3.1-SNAPSHOT) . {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/servers/{{serverName}}/server-platform-origin","title":"Retrieving the configuration"},{"location":"guides/admin/servers/#migrating-configuration-documents","text":"As Egeria evolves, the content of the configuration document expands. Many of the changes are pure additions and are therefore backward compatible. OMAG Server Platform fails to load configuration document From time to time the structure of the configuration document needs to change. When this happens, the OMAG Server Platform is not able to load the configuration document and a message similar to this is returned: { \"class\" : \"VoidResponse\" , \"relatedHTTPCode\" : 400 , \"exceptionClassName\" : \"org.odpi.openmetadata.adminservices.ffdc.exception.OMAGInvalidParameterException\" , \"exceptionErrorMessage\" : \"OMAG-ADMIN-400-022 The configuration document for OMAG Server cocoMDS1 is at version V1.0 which is not compatible with this OMAG Server Platform which supports versions [V2.0]\" , \"exceptionSystemAction\" : \"The system is unable to configure the local server because it can not read the configuration document.\" , \"exceptionUserAction\" : \"Migrate the configuration document to a compatible version (or delete and recreate it). See https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user/migrating-configuration-documents.html\" }","title":"Migrating configuration documents"},{"location":"guides/admin/servers/#migrating-a-configuration-document-from-v10-to-v20","text":"The additionalProperties property name changed to configurationProperties . To migrate the configuration document, make a global change from additionalProperties to configurationProperties throughout the configuration document.","title":"Migrating a configuration document from V1.0 to V2.0"},{"location":"guides/admin/servers/#release-2x-of-egeria","text":"Release 2.0 encrypts the configuration document by default. This includes automatically detecting and encrypting any clear-text (unencrypted) configuration document that may already exist. No user action is required for this migration, the encryption will be handled automatically when the clear-text configuration document is first opened by the platform in these releases.","title":"Release 2.x+ of Egeria"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/","text":"Configuring a conformance test server \u00b6 Each type of OMAG Server is configured by creating a configuration document . Set up the default event bus \u00b6 An OMAG Server uses an event bus such as Apache Kafka to exchange events with other servers and tools. Egeria manages the specific topic names and the event payloads; however, it needs to know where the event bus is deployed and any properties needed to configure it. Since the event bus is used in multiple places, the configuration document allows you to set up the details of the event bus which are then incorporated into all the places where the event bus is needed. Important sequencing information You need to set up this information before configuring any of the following: Using an event topic as the destination for the audit log . Configuring the access services in a metadata access store or a metadata access point . Configuring registration to a cohort in a metadata access store , a metadata access point , a repository proxy or a conformance test server . The following command creates information about the event bus. This information is used on the subsequent configuration of the OMAG Server subsystems. It does not affect any subsystems that have already been configured in the configuration document and if the event bus is not needed, its values are ignored. It is possible to add arbitrary name/value pairs as JSON in the request body. The correct properties to use are defined in the connector type for the event bus. POST - configure event bus {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/event-bus Example: Apache Kafka For example, when using Apache Kafka as your event bus you may want to configure properties that control the behavior of the consumer that receives events and the producer that sends events. This is a typical set of producer and consumer properties: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"producer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"acks\" : \"all\" , \"retries\" : \"0\" , \"batch.size\" : \"16384\" , \"linger.ms\" : \"1\" , \"buffer.memory\" : \"33554432\" , \"max.request.size\" : \"10485760\" , \"key.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"value.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" }, \"consumer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"zookeeper.session.timeout.ms\" : \"400\" , \"zookeeper.sync.time.ms\" : \"200\" , \"fetch.message.max.bytes\" : \"10485760\" , \"max.partition.fetch.bytes\" : \"10485760\" , \"key.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"value.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" } } A different type of event bus would use different properties. Set the server URL root \u00b6 Configure the local server URL root with the value of the OMAG Server Platform where the service will run: in particular if the configuration document will be deployed to a different OMAG Server Platform from the one used to maintain the configuration document. POST - set server URL root {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-url-root?url={{targetPlatformURLRoot}} Detailed explanation The {{targetPlatformURLRoot}} gives the location of the OMAG Server Platform on which this configured service is intended to run, while the {{platformURLRoot}} gives the location of the OMAG Server Platform in which this configuration document is maintained. They could be, but do not need to be, the same location. Configure the basic properties \u00b6 The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values. Set server type name \u00b6 The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\" Set organization name \u00b6 The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\" Set the server's user ID and optional password \u00b6 The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\" Set the maximum page size for REST API requests \u00b6 The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}} Configure the audit log \u00b6 Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination. Add audit log destinations \u00b6 There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations Remove audit logs \u00b6 The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none Configure the server security connector \u00b6 Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } } Determine configured security \u00b6 GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } } Remove configured security \u00b6 DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server. Configure the workbenches \u00b6 The workbenches are configured using the OMAG Server Platform Administration Services. This defines which workbenches to run and how to connect to the technology to test. This configuration defines an OMAG Server that will run the requested conformance suite tests. Configure the OMAG Server that will run the requested conformance suite tests. The requested workbenches will begin to execute their tests as soon as the OMAG Server is started. Repository workbench \u00b6 To run a metadata repository through the Repository Workbench, first configure a CTS server in the OMAG Server Platform by configuring its general properties like server type, event bus, cohort, etc. Before starting the CTS server instance, configure the repository workbench within it using the following command: POST - configure repository workbench {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/cts/conformance-suite-workbenches/repository-workbench/repositories Send the repository workbench configuration as the request body, similar to the following: { \"class\" : \"RepositoryConformanceWorkbenchConfig\" , \"tutRepositoryServerName\" : \"myserver\" , \"maxSearchResults\" : 5 } The required tutRepositoryServerName parameter defines the name of the repository server you wish to test, while the optional maxSearchResults parameter controls the sizing of the tests: both the number of instances the tests will attempt to create to carry out its tests and how extensive the search-based tests are. Start the technology under test after the CTS server This repository server to test ( myserver in the example above) should be configured and started after starting the CTS repository workbench instance. Once the CTS server instance is started it will wait for the technology under test (the server named by the tutRepositoryServerName parameter) to be up and running before then starting its suite of tests. The OMAG Server also supports a REST API for querying the results of running the conformance suite tests. These commands include: Retrieve the results from a single named workbench. Retrieve the results from all workbenches and test cases (beware that the response can be 100's of MB in size, and may overflow your JVM heap). Retrieve the results from all failed test cases. Retrieve the IDs of all test cases. Retrieve the results from a specific test cases (for example, iterating through the above call's response). Retrieve the names of all profiles. Retrieve the details of a single profile's results (for example, iterating through the above call's response). The resulting reports can be large Ensure the jvm running the CTS server has at least 1GB heap to avoid any Java heap errors. The Open Metadata Conformance Suite also has a client called OpenMetadataConformanceTestReport that will retrieve the conformance report and all details. It will store a summarized report in openmetadata_cts_summary.json , and the full details of each profile and test case in profile-details and test-cases sub-directories, respectively. The client also outputs a summary of the test run. Example output for a successful CTS run This output is an example of a successful run: $ OpenMetadataConformanceTestReport cSuiteServer https://localhost:9444 ======================================= Open Metadata Conformance Test Report ======================================= Contacting conformance suite server: cts (https://localhost:9443) Saving full profile details into 'profile-details' directory... Summary of profile results: ... Metadata sharing: CONFORMANT_FULL_SUPPORT ... Reference copies: CONFORMANT_FULL_SUPPORT ... Metadata maintenance: CONFORMANT_FULL_SUPPORT ... Dynamic types: UNKNOWN_STATUS ... Graph queries: CONFORMANT_FULL_SUPPORT ... Historical search: CONFORMANT_FULL_SUPPORT ... Entity proxies: CONFORMANT_FULL_SUPPORT ... Soft-delete and restore: CONFORMANT_FULL_SUPPORT ... Undo an update: CONFORMANT_FULL_SUPPORT ... Reidentify instance: CONFORMANT_FULL_SUPPORT ... Retype instance: CONFORMANT_FULL_SUPPORT ... Rehome instance: CONFORMANT_FULL_SUPPORT ... Entity search: CONFORMANT_FULL_SUPPORT ... Relationship search: CONFORMANT_FULL_SUPPORT ... Entity advanced search: CONFORMANT_FULL_SUPPORT ... Relationship advanced search: CONFORMANT_FULL_SUPPORT Saving full test case details into 'test-case-details' directory (can take 1-2 minutes)... Summary: ... number of tests: 4965 ... number of tests passed: 4965 ... number of tests failed: 0 ... number of tests skipped: 0 Congratulations, technology under test is conformant Process finished with exit code 0 Example output for an unsuccessful CTS run The example below is for an unsuccessful run (where one of the Entity search tests has failed): $ OpenMetadataConformanceTestReport cSuiteServer https://localhost:9444 ======================================= Open Metadata Conformance Test Report ======================================= Contacting conformance suite server: cts (https://localhost:9443) Saving full profile details into 'profile-details' directory... Summary of profile results: ... Metadata sharing: CONFORMANT_FULL_SUPPORT ... Reference copies: CONFORMANT_FULL_SUPPORT ... Metadata maintenance: CONFORMANT_FULL_SUPPORT ... Dynamic types: UNKNOWN_STATUS ... Graph queries: CONFORMANT_FULL_SUPPORT ... Historical search: CONFORMANT_FULL_SUPPORT ... Entity proxies: CONFORMANT_FULL_SUPPORT ... Soft-delete and restore: CONFORMANT_FULL_SUPPORT ... Undo an update: CONFORMANT_FULL_SUPPORT ... Reidentify instance: CONFORMANT_FULL_SUPPORT ... Retype instance: CONFORMANT_FULL_SUPPORT ... Rehome instance: CONFORMANT_FULL_SUPPORT ... Entity search: NOT_CONFORMANT ... Relationship search: CONFORMANT_FULL_SUPPORT ... Entity advanced search: CONFORMANT_FULL_SUPPORT ... Relationship advanced search: CONFORMANT_FULL_SUPPORT Saving full test case details into 'test-case-details' directory (can take 1-2 minutes)... Summary: ... number of tests: 4965 ... number of tests passed: 4964 ... number of tests failed: 1 ... number of tests skipped: 0 Technology under test is not yet conformant Process finished with exit code 1","title":"Configure Conformance Test Server"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#configuring-a-conformance-test-server","text":"Each type of OMAG Server is configured by creating a configuration document .","title":"Configuring a conformance test server"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#set-up-the-default-event-bus","text":"An OMAG Server uses an event bus such as Apache Kafka to exchange events with other servers and tools. Egeria manages the specific topic names and the event payloads; however, it needs to know where the event bus is deployed and any properties needed to configure it. Since the event bus is used in multiple places, the configuration document allows you to set up the details of the event bus which are then incorporated into all the places where the event bus is needed. Important sequencing information You need to set up this information before configuring any of the following: Using an event topic as the destination for the audit log . Configuring the access services in a metadata access store or a metadata access point . Configuring registration to a cohort in a metadata access store , a metadata access point , a repository proxy or a conformance test server . The following command creates information about the event bus. This information is used on the subsequent configuration of the OMAG Server subsystems. It does not affect any subsystems that have already been configured in the configuration document and if the event bus is not needed, its values are ignored. It is possible to add arbitrary name/value pairs as JSON in the request body. The correct properties to use are defined in the connector type for the event bus. POST - configure event bus {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/event-bus Example: Apache Kafka For example, when using Apache Kafka as your event bus you may want to configure properties that control the behavior of the consumer that receives events and the producer that sends events. This is a typical set of producer and consumer properties: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"producer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"acks\" : \"all\" , \"retries\" : \"0\" , \"batch.size\" : \"16384\" , \"linger.ms\" : \"1\" , \"buffer.memory\" : \"33554432\" , \"max.request.size\" : \"10485760\" , \"key.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"value.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" }, \"consumer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"zookeeper.session.timeout.ms\" : \"400\" , \"zookeeper.sync.time.ms\" : \"200\" , \"fetch.message.max.bytes\" : \"10485760\" , \"max.partition.fetch.bytes\" : \"10485760\" , \"key.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"value.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" } } A different type of event bus would use different properties.","title":"Set up the default event bus"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#set-the-server-url-root","text":"Configure the local server URL root with the value of the OMAG Server Platform where the service will run: in particular if the configuration document will be deployed to a different OMAG Server Platform from the one used to maintain the configuration document. POST - set server URL root {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-url-root?url={{targetPlatformURLRoot}} Detailed explanation The {{targetPlatformURLRoot}} gives the location of the OMAG Server Platform on which this configured service is intended to run, while the {{platformURLRoot}} gives the location of the OMAG Server Platform in which this configuration document is maintained. They could be, but do not need to be, the same location.","title":"Set the server URL root"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#configure-the-basic-properties","text":"The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values.","title":"Configure the basic properties"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#set-server-type-name","text":"The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\"","title":"Set server type name"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#set-organization-name","text":"The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\"","title":"Set organization name"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#set-the-servers-user-id-and-optional-password","text":"The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\"","title":"Set the server's user ID and optional password"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#set-the-maximum-page-size-for-rest-api-requests","text":"The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}}","title":"Set the maximum page size for REST API requests"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#configure-the-audit-log","text":"Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination.","title":"Configure the audit log"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#add-audit-log-destinations","text":"There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations","title":"Add audit log destinations"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#remove-audit-logs","text":"The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none","title":"Remove audit logs"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#configure-the-server-security-connector","text":"Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } }","title":"Configure the server security connector"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#determine-configured-security","text":"GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } }","title":"Determine configured security"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#remove-configured-security","text":"DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server.","title":"Remove configured security"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#configure-the-workbenches","text":"The workbenches are configured using the OMAG Server Platform Administration Services. This defines which workbenches to run and how to connect to the technology to test. This configuration defines an OMAG Server that will run the requested conformance suite tests. Configure the OMAG Server that will run the requested conformance suite tests. The requested workbenches will begin to execute their tests as soon as the OMAG Server is started.","title":"Configure the workbenches"},{"location":"guides/admin/servers/configuring-a-conformance-test-server/#repository-workbench","text":"To run a metadata repository through the Repository Workbench, first configure a CTS server in the OMAG Server Platform by configuring its general properties like server type, event bus, cohort, etc. Before starting the CTS server instance, configure the repository workbench within it using the following command: POST - configure repository workbench {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/cts/conformance-suite-workbenches/repository-workbench/repositories Send the repository workbench configuration as the request body, similar to the following: { \"class\" : \"RepositoryConformanceWorkbenchConfig\" , \"tutRepositoryServerName\" : \"myserver\" , \"maxSearchResults\" : 5 } The required tutRepositoryServerName parameter defines the name of the repository server you wish to test, while the optional maxSearchResults parameter controls the sizing of the tests: both the number of instances the tests will attempt to create to carry out its tests and how extensive the search-based tests are. Start the technology under test after the CTS server This repository server to test ( myserver in the example above) should be configured and started after starting the CTS repository workbench instance. Once the CTS server instance is started it will wait for the technology under test (the server named by the tutRepositoryServerName parameter) to be up and running before then starting its suite of tests. The OMAG Server also supports a REST API for querying the results of running the conformance suite tests. These commands include: Retrieve the results from a single named workbench. Retrieve the results from all workbenches and test cases (beware that the response can be 100's of MB in size, and may overflow your JVM heap). Retrieve the results from all failed test cases. Retrieve the IDs of all test cases. Retrieve the results from a specific test cases (for example, iterating through the above call's response). Retrieve the names of all profiles. Retrieve the details of a single profile's results (for example, iterating through the above call's response). The resulting reports can be large Ensure the jvm running the CTS server has at least 1GB heap to avoid any Java heap errors. The Open Metadata Conformance Suite also has a client called OpenMetadataConformanceTestReport that will retrieve the conformance report and all details. It will store a summarized report in openmetadata_cts_summary.json , and the full details of each profile and test case in profile-details and test-cases sub-directories, respectively. The client also outputs a summary of the test run. Example output for a successful CTS run This output is an example of a successful run: $ OpenMetadataConformanceTestReport cSuiteServer https://localhost:9444 ======================================= Open Metadata Conformance Test Report ======================================= Contacting conformance suite server: cts (https://localhost:9443) Saving full profile details into 'profile-details' directory... Summary of profile results: ... Metadata sharing: CONFORMANT_FULL_SUPPORT ... Reference copies: CONFORMANT_FULL_SUPPORT ... Metadata maintenance: CONFORMANT_FULL_SUPPORT ... Dynamic types: UNKNOWN_STATUS ... Graph queries: CONFORMANT_FULL_SUPPORT ... Historical search: CONFORMANT_FULL_SUPPORT ... Entity proxies: CONFORMANT_FULL_SUPPORT ... Soft-delete and restore: CONFORMANT_FULL_SUPPORT ... Undo an update: CONFORMANT_FULL_SUPPORT ... Reidentify instance: CONFORMANT_FULL_SUPPORT ... Retype instance: CONFORMANT_FULL_SUPPORT ... Rehome instance: CONFORMANT_FULL_SUPPORT ... Entity search: CONFORMANT_FULL_SUPPORT ... Relationship search: CONFORMANT_FULL_SUPPORT ... Entity advanced search: CONFORMANT_FULL_SUPPORT ... Relationship advanced search: CONFORMANT_FULL_SUPPORT Saving full test case details into 'test-case-details' directory (can take 1-2 minutes)... Summary: ... number of tests: 4965 ... number of tests passed: 4965 ... number of tests failed: 0 ... number of tests skipped: 0 Congratulations, technology under test is conformant Process finished with exit code 0 Example output for an unsuccessful CTS run The example below is for an unsuccessful run (where one of the Entity search tests has failed): $ OpenMetadataConformanceTestReport cSuiteServer https://localhost:9444 ======================================= Open Metadata Conformance Test Report ======================================= Contacting conformance suite server: cts (https://localhost:9443) Saving full profile details into 'profile-details' directory... Summary of profile results: ... Metadata sharing: CONFORMANT_FULL_SUPPORT ... Reference copies: CONFORMANT_FULL_SUPPORT ... Metadata maintenance: CONFORMANT_FULL_SUPPORT ... Dynamic types: UNKNOWN_STATUS ... Graph queries: CONFORMANT_FULL_SUPPORT ... Historical search: CONFORMANT_FULL_SUPPORT ... Entity proxies: CONFORMANT_FULL_SUPPORT ... Soft-delete and restore: CONFORMANT_FULL_SUPPORT ... Undo an update: CONFORMANT_FULL_SUPPORT ... Reidentify instance: CONFORMANT_FULL_SUPPORT ... Retype instance: CONFORMANT_FULL_SUPPORT ... Rehome instance: CONFORMANT_FULL_SUPPORT ... Entity search: NOT_CONFORMANT ... Relationship search: CONFORMANT_FULL_SUPPORT ... Entity advanced search: CONFORMANT_FULL_SUPPORT ... Relationship advanced search: CONFORMANT_FULL_SUPPORT Saving full test case details into 'test-case-details' directory (can take 1-2 minutes)... Summary: ... number of tests: 4965 ... number of tests passed: 4964 ... number of tests failed: 1 ... number of tests skipped: 0 Technology under test is not yet conformant Process finished with exit code 1","title":"Repository workbench"},{"location":"guides/admin/servers/configuring-a-data-engine-proxy-server/","text":"Configuring a Data Engine Proxy Server \u00b6 Start an OMAG Server Platform Configure the Data Engine Proxy Server: POST following JSON object (following shows an example for IBM DataStage) { \"class\" : \"DataEngineProxyConfig\" , \"accessServiceRootURL\" : \"{serverURLRoot}\" , \"accessServiceServerName\" : \"{MetadataServerName}\" , \"dataEngineConnection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.ibm.datastage.dataengineconnector.DataStageConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"myhost.somewhere.com:9445\" , \"protocol\" : \"https\" }, \"userId\" : \"{dataEngineAccessUserId}\" , \"clearPassword\" : \"dataEngineAccessPassword\" }, \"pollIntervalInSeconds\" : 60 } to the following address {serverURLRoot}/open-metadata/admin-services/users/{userId}/servers/{serverName}/data-engine-proxy-service/configuration The object dataEngineConfig is the information required to implement the specific proxy connector to the data engine. The keys should be modified based on the information needed by the connector. Start the instance of the OMAG Server Platform POST to the following address {serverURLRoot}/open-metadata/admin-services/users/{userId}/servers/{serverName}/instance","title":"Configuring a data engine proxy server"},{"location":"guides/admin/servers/configuring-a-data-engine-proxy-server/#configuring-a-data-engine-proxy-server","text":"Start an OMAG Server Platform Configure the Data Engine Proxy Server: POST following JSON object (following shows an example for IBM DataStage) { \"class\" : \"DataEngineProxyConfig\" , \"accessServiceRootURL\" : \"{serverURLRoot}\" , \"accessServiceServerName\" : \"{MetadataServerName}\" , \"dataEngineConnection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.ibm.datastage.dataengineconnector.DataStageConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"myhost.somewhere.com:9445\" , \"protocol\" : \"https\" }, \"userId\" : \"{dataEngineAccessUserId}\" , \"clearPassword\" : \"dataEngineAccessPassword\" }, \"pollIntervalInSeconds\" : 60 } to the following address {serverURLRoot}/open-metadata/admin-services/users/{userId}/servers/{serverName}/data-engine-proxy-service/configuration The object dataEngineConfig is the information required to implement the specific proxy connector to the data engine. The keys should be modified based on the information needed by the connector. Start the instance of the OMAG Server Platform POST to the following address {serverURLRoot}/open-metadata/admin-services/users/{userId}/servers/{serverName}/instance","title":"Configuring a Data Engine Proxy Server"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/","text":"Configuring a metadata access point \u00b6 Each type of OMAG Server is configured by creating a configuration document . For a metadata access point, the following can be configured: Set up the default event bus \u00b6 An OMAG Server uses an event bus such as Apache Kafka to exchange events with other servers and tools. Egeria manages the specific topic names and the event payloads; however, it needs to know where the event bus is deployed and any properties needed to configure it. Since the event bus is used in multiple places, the configuration document allows you to set up the details of the event bus which are then incorporated into all the places where the event bus is needed. Important sequencing information You need to set up this information before configuring any of the following: Using an event topic as the destination for the audit log . Configuring the access services in a metadata access store or a metadata access point . Configuring registration to a cohort in a metadata access store , a metadata access point , a repository proxy or a conformance test server . The following command creates information about the event bus. This information is used on the subsequent configuration of the OMAG Server subsystems. It does not affect any subsystems that have already been configured in the configuration document and if the event bus is not needed, its values are ignored. It is possible to add arbitrary name/value pairs as JSON in the request body. The correct properties to use are defined in the connector type for the event bus. POST - configure event bus {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/event-bus Example: Apache Kafka For example, when using Apache Kafka as your event bus you may want to configure properties that control the behavior of the consumer that receives events and the producer that sends events. This is a typical set of producer and consumer properties: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"producer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"acks\" : \"all\" , \"retries\" : \"0\" , \"batch.size\" : \"16384\" , \"linger.ms\" : \"1\" , \"buffer.memory\" : \"33554432\" , \"max.request.size\" : \"10485760\" , \"key.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"value.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" }, \"consumer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"zookeeper.session.timeout.ms\" : \"400\" , \"zookeeper.sync.time.ms\" : \"200\" , \"fetch.message.max.bytes\" : \"10485760\" , \"max.partition.fetch.bytes\" : \"10485760\" , \"key.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"value.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" } } A different type of event bus would use different properties. Set the server URL root \u00b6 Configure the local server URL root with the value of the OMAG Server Platform where the service will run: in particular if the configuration document will be deployed to a different OMAG Server Platform from the one used to maintain the configuration document. POST - set server URL root {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-url-root?url={{targetPlatformURLRoot}} Detailed explanation The {{targetPlatformURLRoot}} gives the location of the OMAG Server Platform on which this configured service is intended to run, while the {{platformURLRoot}} gives the location of the OMAG Server Platform in which this configuration document is maintained. They could be, but do not need to be, the same location. Configure the basic properties \u00b6 The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values. Set server type name \u00b6 The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\" Set organization name \u00b6 The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\" Set the server's user ID and optional password \u00b6 The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\" Set the maximum page size for REST API requests \u00b6 The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}} Configure the audit log \u00b6 Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination. Add audit log destinations \u00b6 There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations Remove audit logs \u00b6 The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none Configure the server security connector \u00b6 Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } } Determine configured security \u00b6 GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } } Remove configured security \u00b6 DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server. Configure the access services \u00b6 The Open Metadata Access Services (OMASs) provide the domain-specific APIs for metadata management and governance. They run in a metadata access store or metadata access point and typically offer a REST API, Java client and an event-based interface for asynchronous interaction. Prerequisite configuration The access service configuration depends on the definitions of the event bus and the local server's userId . List available access services \u00b6 GET - list all available access services {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/server-platform/registered-services/access-services Response listing available access services { \"relatedHTTPCode\" : 200 , \"services\" : [ { \"serviceName\" : \"Asset Owner\" , \"serviceURLMarker\" : \"asset-owner\" , \"serviceDescription\" : \"Manage an asset\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-owner/\" }, { \"serviceName\" : \"Stewardship Action\" , \"serviceURLMarker\" : \"stewardship-action\" , \"serviceDescription\" : \"Manage exceptions and actions from open governance\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/stewardship-action/\" }, { \"serviceName\" : \"Subject Area\" , \"serviceURLMarker\" : \"subject-area\" , \"serviceDescription\" : \"Document knowledge about a subject area\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/subject-area/\" }, { \"serviceName\" : \"Governance Program\" , \"serviceURLMarker\" : \"governance-program\" , \"serviceDescription\" : \"Manage the governance program\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-program/\" }, { \"serviceName\" : \"Asset Lineage\" , \"serviceURLMarker\" : \"asset-lineage\" , \"serviceDescription\" : \"Store asset lineage\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-lineage/\" }, { \"serviceName\" : \"Design Model\" , \"serviceURLMarker\" : \"design-model\" , \"serviceDescription\" : \"Exchange design model content with tools and standard packages\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/design-model/\" }, { \"serviceName\" : \"Glossary View\" , \"serviceURLMarker\" : \"glossary-view\" , \"serviceDescription\" : \"Support glossary terms visualization\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/glossary-view/\" }, { \"serviceName\" : \"Security Manager\" , \"serviceURLMarker\" : \"security-officer\" , \"serviceDescription\" : \"Set up rules to protect data\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/security-officer/\" }, { \"serviceName\" : \"Asset Consumer\" , \"serviceURLMarker\" : \"asset-consumer\" , \"serviceDescription\" : \"Access assets through connectors\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-consumer/\" }, { \"serviceName\" : \"IT Infrastructure\" , \"serviceURLMarker\" : \"it-infrastructure\" , \"serviceDescription\" : \"Manage information about the deployed IT infrastructure\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/it-infrastructure/\" }, { \"serviceName\" : \"Asset Catalog\" , \"serviceURLMarker\" : \"asset-catalog\" , \"serviceDescription\" : \"Search and understand your assets\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-catalog/\" }, { \"serviceName\" : \"Data Science\" , \"serviceURLMarker\" : \"data-science\" , \"serviceDescription\" : \"Create and manage data science definitions and models\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-science/\" }, { \"serviceName\" : \"Community Profile\" , \"serviceURLMarker\" : \"community-profile\" , \"serviceDescription\" : \"Define personal profile and collaborate\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/community-profile/\" }, { \"serviceName\" : \"DevOps\" , \"serviceURLMarker\" : \"devops\" , \"serviceDescription\" : \"Manage a DevOps pipeline\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/dev-ops/\" }, { \"serviceName\" : \"Software Developer\" , \"serviceURLMarker\" : \"software-developer\" , \"serviceDescription\" : \"Interact with software development tools\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/software-developer/\" }, { \"serviceName\" : \"Discovery Engine\" , \"serviceURLMarker\" : \"discovery-engine\" , \"serviceDescription\" : \"Support for automated metadata discovery engines\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/discovery-engine/\" }, { \"serviceName\" : \"Data Engine\" , \"serviceURLMarker\" : \"data-engine\" , \"serviceDescription\" : \"Exchange process models and lineage with a data engine\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-engine/\" }, { \"serviceName\" : \"Project Management\" , \"serviceURLMarker\" : \"project-management\" , \"serviceDescription\" : \"Manage data projects\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/project-management/\" }, { \"serviceName\" : \"Governance Engine\" , \"serviceURLMarker\" : \"governance-engine\" , \"serviceDescription\" : \"Set up an operational governance engine\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-engine/\" }, { \"serviceName\" : \"Digital Architecture\" , \"serviceURLMarker\" : \"digital-architecture\" , \"serviceDescription\" : \"Design of the digital services for an organization\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/digital-architecture/\" }, { \"serviceName\" : \"Data Privacy\" , \"serviceURLMarker\" : \"data-privacy\" , \"serviceDescription\" : \"Manage governance of privacy\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-privacy/\" }, { \"serviceName\" : \"Data Manager\" , \"serviceURLMarker\" : \"data-manager\" , \"serviceDescription\" : \"Capture changes to the data stores and data set managed by a technology managing collections of data\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-manager/\" } ] } These access services are available to configure either all together or individually. Enable access services \u00b6 The access services can either all be enabled (with default configuration values) or individually enabled: all, with defaults To enable all the access services (and the enterprise repository services that support them) with default configuration values use the following command. POST - enable all access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services individually Alternatively, each service can be configured individually with the following command: POST - configure an individual access service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/{{serviceURLMarker}} The service URL marker for each service is shown in the example response given above. In both cases, it is possible to pass a list of properties to the access service that controls the behavior of each access service. These are sent in the request body. More details of which properties are supported are documented with each access service. Disable the access services \u00b6 The access services can be disabled with the following command. This also disables the enterprise repository services since they are not being used. DELETE - disable the access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services Review configuration \u00b6 GET - retrieve current configuration for the access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/configuration POST - save changes back to the configuration {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/configuration","title":"Configure Metadata Access Point"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#configuring-a-metadata-access-point","text":"Each type of OMAG Server is configured by creating a configuration document . For a metadata access point, the following can be configured:","title":"Configuring a metadata access point"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#set-up-the-default-event-bus","text":"An OMAG Server uses an event bus such as Apache Kafka to exchange events with other servers and tools. Egeria manages the specific topic names and the event payloads; however, it needs to know where the event bus is deployed and any properties needed to configure it. Since the event bus is used in multiple places, the configuration document allows you to set up the details of the event bus which are then incorporated into all the places where the event bus is needed. Important sequencing information You need to set up this information before configuring any of the following: Using an event topic as the destination for the audit log . Configuring the access services in a metadata access store or a metadata access point . Configuring registration to a cohort in a metadata access store , a metadata access point , a repository proxy or a conformance test server . The following command creates information about the event bus. This information is used on the subsequent configuration of the OMAG Server subsystems. It does not affect any subsystems that have already been configured in the configuration document and if the event bus is not needed, its values are ignored. It is possible to add arbitrary name/value pairs as JSON in the request body. The correct properties to use are defined in the connector type for the event bus. POST - configure event bus {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/event-bus Example: Apache Kafka For example, when using Apache Kafka as your event bus you may want to configure properties that control the behavior of the consumer that receives events and the producer that sends events. This is a typical set of producer and consumer properties: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"producer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"acks\" : \"all\" , \"retries\" : \"0\" , \"batch.size\" : \"16384\" , \"linger.ms\" : \"1\" , \"buffer.memory\" : \"33554432\" , \"max.request.size\" : \"10485760\" , \"key.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"value.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" }, \"consumer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"zookeeper.session.timeout.ms\" : \"400\" , \"zookeeper.sync.time.ms\" : \"200\" , \"fetch.message.max.bytes\" : \"10485760\" , \"max.partition.fetch.bytes\" : \"10485760\" , \"key.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"value.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" } } A different type of event bus would use different properties.","title":"Set up the default event bus"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#set-the-server-url-root","text":"Configure the local server URL root with the value of the OMAG Server Platform where the service will run: in particular if the configuration document will be deployed to a different OMAG Server Platform from the one used to maintain the configuration document. POST - set server URL root {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-url-root?url={{targetPlatformURLRoot}} Detailed explanation The {{targetPlatformURLRoot}} gives the location of the OMAG Server Platform on which this configured service is intended to run, while the {{platformURLRoot}} gives the location of the OMAG Server Platform in which this configuration document is maintained. They could be, but do not need to be, the same location.","title":"Set the server URL root"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#configure-the-basic-properties","text":"The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values.","title":"Configure the basic properties"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#set-server-type-name","text":"The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\"","title":"Set server type name"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#set-organization-name","text":"The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\"","title":"Set organization name"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#set-the-servers-user-id-and-optional-password","text":"The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\"","title":"Set the server's user ID and optional password"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#set-the-maximum-page-size-for-rest-api-requests","text":"The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}}","title":"Set the maximum page size for REST API requests"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#configure-the-audit-log","text":"Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination.","title":"Configure the audit log"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#add-audit-log-destinations","text":"There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations","title":"Add audit log destinations"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#remove-audit-logs","text":"The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none","title":"Remove audit logs"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#configure-the-server-security-connector","text":"Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } }","title":"Configure the server security connector"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#determine-configured-security","text":"GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } }","title":"Determine configured security"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#remove-configured-security","text":"DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server.","title":"Remove configured security"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#configure-the-access-services","text":"The Open Metadata Access Services (OMASs) provide the domain-specific APIs for metadata management and governance. They run in a metadata access store or metadata access point and typically offer a REST API, Java client and an event-based interface for asynchronous interaction. Prerequisite configuration The access service configuration depends on the definitions of the event bus and the local server's userId .","title":"Configure the access services"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#list-available-access-services","text":"GET - list all available access services {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/server-platform/registered-services/access-services Response listing available access services { \"relatedHTTPCode\" : 200 , \"services\" : [ { \"serviceName\" : \"Asset Owner\" , \"serviceURLMarker\" : \"asset-owner\" , \"serviceDescription\" : \"Manage an asset\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-owner/\" }, { \"serviceName\" : \"Stewardship Action\" , \"serviceURLMarker\" : \"stewardship-action\" , \"serviceDescription\" : \"Manage exceptions and actions from open governance\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/stewardship-action/\" }, { \"serviceName\" : \"Subject Area\" , \"serviceURLMarker\" : \"subject-area\" , \"serviceDescription\" : \"Document knowledge about a subject area\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/subject-area/\" }, { \"serviceName\" : \"Governance Program\" , \"serviceURLMarker\" : \"governance-program\" , \"serviceDescription\" : \"Manage the governance program\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-program/\" }, { \"serviceName\" : \"Asset Lineage\" , \"serviceURLMarker\" : \"asset-lineage\" , \"serviceDescription\" : \"Store asset lineage\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-lineage/\" }, { \"serviceName\" : \"Design Model\" , \"serviceURLMarker\" : \"design-model\" , \"serviceDescription\" : \"Exchange design model content with tools and standard packages\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/design-model/\" }, { \"serviceName\" : \"Glossary View\" , \"serviceURLMarker\" : \"glossary-view\" , \"serviceDescription\" : \"Support glossary terms visualization\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/glossary-view/\" }, { \"serviceName\" : \"Security Manager\" , \"serviceURLMarker\" : \"security-officer\" , \"serviceDescription\" : \"Set up rules to protect data\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/security-officer/\" }, { \"serviceName\" : \"Asset Consumer\" , \"serviceURLMarker\" : \"asset-consumer\" , \"serviceDescription\" : \"Access assets through connectors\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-consumer/\" }, { \"serviceName\" : \"IT Infrastructure\" , \"serviceURLMarker\" : \"it-infrastructure\" , \"serviceDescription\" : \"Manage information about the deployed IT infrastructure\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/it-infrastructure/\" }, { \"serviceName\" : \"Asset Catalog\" , \"serviceURLMarker\" : \"asset-catalog\" , \"serviceDescription\" : \"Search and understand your assets\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-catalog/\" }, { \"serviceName\" : \"Data Science\" , \"serviceURLMarker\" : \"data-science\" , \"serviceDescription\" : \"Create and manage data science definitions and models\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-science/\" }, { \"serviceName\" : \"Community Profile\" , \"serviceURLMarker\" : \"community-profile\" , \"serviceDescription\" : \"Define personal profile and collaborate\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/community-profile/\" }, { \"serviceName\" : \"DevOps\" , \"serviceURLMarker\" : \"devops\" , \"serviceDescription\" : \"Manage a DevOps pipeline\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/dev-ops/\" }, { \"serviceName\" : \"Software Developer\" , \"serviceURLMarker\" : \"software-developer\" , \"serviceDescription\" : \"Interact with software development tools\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/software-developer/\" }, { \"serviceName\" : \"Discovery Engine\" , \"serviceURLMarker\" : \"discovery-engine\" , \"serviceDescription\" : \"Support for automated metadata discovery engines\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/discovery-engine/\" }, { \"serviceName\" : \"Data Engine\" , \"serviceURLMarker\" : \"data-engine\" , \"serviceDescription\" : \"Exchange process models and lineage with a data engine\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-engine/\" }, { \"serviceName\" : \"Project Management\" , \"serviceURLMarker\" : \"project-management\" , \"serviceDescription\" : \"Manage data projects\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/project-management/\" }, { \"serviceName\" : \"Governance Engine\" , \"serviceURLMarker\" : \"governance-engine\" , \"serviceDescription\" : \"Set up an operational governance engine\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-engine/\" }, { \"serviceName\" : \"Digital Architecture\" , \"serviceURLMarker\" : \"digital-architecture\" , \"serviceDescription\" : \"Design of the digital services for an organization\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/digital-architecture/\" }, { \"serviceName\" : \"Data Privacy\" , \"serviceURLMarker\" : \"data-privacy\" , \"serviceDescription\" : \"Manage governance of privacy\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-privacy/\" }, { \"serviceName\" : \"Data Manager\" , \"serviceURLMarker\" : \"data-manager\" , \"serviceDescription\" : \"Capture changes to the data stores and data set managed by a technology managing collections of data\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-manager/\" } ] } These access services are available to configure either all together or individually.","title":"List available access services"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#enable-access-services","text":"The access services can either all be enabled (with default configuration values) or individually enabled: all, with defaults To enable all the access services (and the enterprise repository services that support them) with default configuration values use the following command. POST - enable all access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services individually Alternatively, each service can be configured individually with the following command: POST - configure an individual access service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/{{serviceURLMarker}} The service URL marker for each service is shown in the example response given above. In both cases, it is possible to pass a list of properties to the access service that controls the behavior of each access service. These are sent in the request body. More details of which properties are supported are documented with each access service.","title":"Enable access services"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#disable-the-access-services","text":"The access services can be disabled with the following command. This also disables the enterprise repository services since they are not being used. DELETE - disable the access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services","title":"Disable the access services"},{"location":"guides/admin/servers/configuring-a-metadata-access-point/#review-configuration","text":"GET - retrieve current configuration for the access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/configuration POST - save changes back to the configuration {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/configuration","title":"Review configuration"},{"location":"guides/admin/servers/configuring-a-metadata-server/","text":"Configuring a metadata server \u00b6 Each type of OMAG Server is configured by creating a configuration document . A metadata server can be run standalone, without connecting to a cohort: Adding the cohort configuration enables the metadata server to communicate with other metadata servers: Set up the default event bus \u00b6 An OMAG Server uses an event bus such as Apache Kafka to exchange events with other servers and tools. Egeria manages the specific topic names and the event payloads; however, it needs to know where the event bus is deployed and any properties needed to configure it. Since the event bus is used in multiple places, the configuration document allows you to set up the details of the event bus which are then incorporated into all the places where the event bus is needed. Important sequencing information You need to set up this information before configuring any of the following: Using an event topic as the destination for the audit log . Configuring the access services in a metadata access store or a metadata access point . Configuring registration to a cohort in a metadata access store , a metadata access point , a repository proxy or a conformance test server . The following command creates information about the event bus. This information is used on the subsequent configuration of the OMAG Server subsystems. It does not affect any subsystems that have already been configured in the configuration document and if the event bus is not needed, its values are ignored. It is possible to add arbitrary name/value pairs as JSON in the request body. The correct properties to use are defined in the connector type for the event bus. POST - configure event bus {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/event-bus Example: Apache Kafka For example, when using Apache Kafka as your event bus you may want to configure properties that control the behavior of the consumer that receives events and the producer that sends events. This is a typical set of producer and consumer properties: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"producer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"acks\" : \"all\" , \"retries\" : \"0\" , \"batch.size\" : \"16384\" , \"linger.ms\" : \"1\" , \"buffer.memory\" : \"33554432\" , \"max.request.size\" : \"10485760\" , \"key.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"value.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" }, \"consumer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"zookeeper.session.timeout.ms\" : \"400\" , \"zookeeper.sync.time.ms\" : \"200\" , \"fetch.message.max.bytes\" : \"10485760\" , \"max.partition.fetch.bytes\" : \"10485760\" , \"key.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"value.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" } } A different type of event bus would use different properties. Set the server URL root \u00b6 Configure the local server URL root with the value of the OMAG Server Platform where the service will run: in particular if the configuration document will be deployed to a different OMAG Server Platform from the one used to maintain the configuration document. POST - set server URL root {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-url-root?url={{targetPlatformURLRoot}} Detailed explanation The {{targetPlatformURLRoot}} gives the location of the OMAG Server Platform on which this configured service is intended to run, while the {{platformURLRoot}} gives the location of the OMAG Server Platform in which this configuration document is maintained. They could be, but do not need to be, the same location. Configure the basic properties \u00b6 The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values. Set server type name \u00b6 The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\" Set organization name \u00b6 The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\" Set the server's user ID and optional password \u00b6 The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\" Set the maximum page size for REST API requests \u00b6 The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}} Configure the audit log \u00b6 Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination. Add audit log destinations \u00b6 There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations Remove audit logs \u00b6 The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none Configure the server security connector \u00b6 Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } } Determine configured security \u00b6 GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } } Remove configured security \u00b6 DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server. Configure the local repository \u00b6 A metadata server supports a local metadata repository that has native support for the Open Metadata Repository Services ( OMRS ) types and instances . Choose a repository \u00b6 Egeria provides a number of implementations of such a repository -- only one of these options can be configured for a given metadata server at a time. bi-temporal graph This command enables a XTDB-based metadata repository, which itself has a number of pluggable back-end options for persistence and other configuration options . This plugin repository is currently the highest-performing, most fully-functional repository for Egeria, supporting all metadata operations including historical metadata as well as being highly-available through clustered deployment . POST - enable the bi-temporal graph repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/plugin-repository/connection { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" } } May require additional driver libraries Note that depending on the persistence you configure, you may need to obtain additional driver libraries for your back-end service , as not every driver is embedded in the XTDB connector itself. non-temporal graph This command enables a JanusGraph-based metadata repository that is embedded in the metadata server and uses the local disk to store the metadata, but does not manage any historical metadata. POST - enable the graph repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/local-graph-repository in-memory The in-memory repository maintains an in-memory store of metadata. It is useful for demos and testing. No metadata is kept if the open metadata services are deactivated, or the server is shutdown. It should nto be used in a production environment. POST - enable the in-memory repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/in-memory-repository read-only The read-only repository connector provides a compliant implementation of a local repository that can be configured into a metadata server. It does not support the interfaces for create, update, delete. However, it does support the search interfaces and is able to cache metadata. This means it can be loaded with metadata from an open metadata archive and connected to a cohort. The content from the archive will be shared with other members of the cohort. POST - enable the read-only repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/read-only-repository Remove the local repository \u00b6 This command removes all configuration for the local repository. This includes the local metadata collection id . If a new local repository is added, it will have a new local metadata collection id and will not be able to automatically re-register with its cohort(s). DELETE - remove the local repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository Load metadata \u00b6 Open metadata archives contain pre-canned metadata types and instances for cohort members . Archives can be added to the configuration document of a server to ensure their content is loaded each time the server is started. This is intended for repositories that do not store the archive content but keep it in memory. Archives can also be loaded to a running server . Loading the same archive multiple times If an archive is loaded multiple times, its content is only added to the local repository if the repository does not have the content already. Add to a running server \u00b6 Typically, an open metadata archive is stored as JSON format in a file. To load such a file use the following command: POST - load file {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/open-metadata-archives/file The body of the request should be the fully-qualified path name or path relative to the startup directory of the OMAG Server Platform -- and the file name should not have any quotes around it. Alternatively it is possible to set up the list of open metadata archives as a list of connections . These connections refer to open metadata archive connectors that can read and retrieve the open metadata archive content. POST - load from connection(s) {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/open-metadata-archives/connection The body of the request should be the list of connections from which to load archives. This option can be used when the open metadata archives are not stored in a file, or a different file format from the default one for the OMAG Server Platform is required. Configure metadata to load on startup \u00b6 Typically, an open metadata archive is stored as JSON format in a file. To configure the load of such a file use the following command: POST - specify file to load POST {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives/file The body of the request should be the fully-qualified path name or path relative to the startup directory of the OMAG Server Platform -- and the file name should not have any quotes around it. Alternatively it is possible to set up the list of open metadata archives as a list of connections . These connections refer to connectors that can read and retrieve the open metadata archive content. POST - specify connection(s) to load {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives The body of the request should be the list of connections from which to load archives. This option can be used when the open metadata archives are not stored in a file, or a different file connector from the default one for the OMAG Server Platform is required. Remove metadata load on startup \u00b6 Finally, this is how to remove the archives from the configuration document. DELETE - remove archives from configuration document {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives The body of the request should be the path to the metadata archive file. Configure the access services \u00b6 The Open Metadata Access Services (OMASs) provide the domain-specific APIs for metadata management and governance. They run in a metadata access store or metadata access point and typically offer a REST API, Java client and an event-based interface for asynchronous interaction. Prerequisite configuration The access service configuration depends on the definitions of the event bus and the local server's userId . List available access services \u00b6 GET - list all available access services {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/server-platform/registered-services/access-services Response listing available access services { \"relatedHTTPCode\" : 200 , \"services\" : [ { \"serviceName\" : \"Asset Owner\" , \"serviceURLMarker\" : \"asset-owner\" , \"serviceDescription\" : \"Manage an asset\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-owner/\" }, { \"serviceName\" : \"Stewardship Action\" , \"serviceURLMarker\" : \"stewardship-action\" , \"serviceDescription\" : \"Manage exceptions and actions from open governance\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/stewardship-action/\" }, { \"serviceName\" : \"Subject Area\" , \"serviceURLMarker\" : \"subject-area\" , \"serviceDescription\" : \"Document knowledge about a subject area\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/subject-area/\" }, { \"serviceName\" : \"Governance Program\" , \"serviceURLMarker\" : \"governance-program\" , \"serviceDescription\" : \"Manage the governance program\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-program/\" }, { \"serviceName\" : \"Asset Lineage\" , \"serviceURLMarker\" : \"asset-lineage\" , \"serviceDescription\" : \"Store asset lineage\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-lineage/\" }, { \"serviceName\" : \"Design Model\" , \"serviceURLMarker\" : \"design-model\" , \"serviceDescription\" : \"Exchange design model content with tools and standard packages\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/design-model/\" }, { \"serviceName\" : \"Glossary View\" , \"serviceURLMarker\" : \"glossary-view\" , \"serviceDescription\" : \"Support glossary terms visualization\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/glossary-view/\" }, { \"serviceName\" : \"Security Manager\" , \"serviceURLMarker\" : \"security-officer\" , \"serviceDescription\" : \"Set up rules to protect data\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/security-officer/\" }, { \"serviceName\" : \"Asset Consumer\" , \"serviceURLMarker\" : \"asset-consumer\" , \"serviceDescription\" : \"Access assets through connectors\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-consumer/\" }, { \"serviceName\" : \"IT Infrastructure\" , \"serviceURLMarker\" : \"it-infrastructure\" , \"serviceDescription\" : \"Manage information about the deployed IT infrastructure\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/it-infrastructure/\" }, { \"serviceName\" : \"Asset Catalog\" , \"serviceURLMarker\" : \"asset-catalog\" , \"serviceDescription\" : \"Search and understand your assets\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-catalog/\" }, { \"serviceName\" : \"Data Science\" , \"serviceURLMarker\" : \"data-science\" , \"serviceDescription\" : \"Create and manage data science definitions and models\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-science/\" }, { \"serviceName\" : \"Community Profile\" , \"serviceURLMarker\" : \"community-profile\" , \"serviceDescription\" : \"Define personal profile and collaborate\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/community-profile/\" }, { \"serviceName\" : \"DevOps\" , \"serviceURLMarker\" : \"devops\" , \"serviceDescription\" : \"Manage a DevOps pipeline\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/dev-ops/\" }, { \"serviceName\" : \"Software Developer\" , \"serviceURLMarker\" : \"software-developer\" , \"serviceDescription\" : \"Interact with software development tools\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/software-developer/\" }, { \"serviceName\" : \"Discovery Engine\" , \"serviceURLMarker\" : \"discovery-engine\" , \"serviceDescription\" : \"Support for automated metadata discovery engines\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/discovery-engine/\" }, { \"serviceName\" : \"Data Engine\" , \"serviceURLMarker\" : \"data-engine\" , \"serviceDescription\" : \"Exchange process models and lineage with a data engine\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-engine/\" }, { \"serviceName\" : \"Project Management\" , \"serviceURLMarker\" : \"project-management\" , \"serviceDescription\" : \"Manage data projects\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/project-management/\" }, { \"serviceName\" : \"Governance Engine\" , \"serviceURLMarker\" : \"governance-engine\" , \"serviceDescription\" : \"Set up an operational governance engine\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-engine/\" }, { \"serviceName\" : \"Digital Architecture\" , \"serviceURLMarker\" : \"digital-architecture\" , \"serviceDescription\" : \"Design of the digital services for an organization\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/digital-architecture/\" }, { \"serviceName\" : \"Data Privacy\" , \"serviceURLMarker\" : \"data-privacy\" , \"serviceDescription\" : \"Manage governance of privacy\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-privacy/\" }, { \"serviceName\" : \"Data Manager\" , \"serviceURLMarker\" : \"data-manager\" , \"serviceDescription\" : \"Capture changes to the data stores and data set managed by a technology managing collections of data\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-manager/\" } ] } These access services are available to configure either all together or individually. Enable access services \u00b6 The access services can either all be enabled (with default configuration values) or individually enabled: all, with defaults To enable all the access services (and the enterprise repository services that support them) with default configuration values use the following command. POST - enable all access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services individually Alternatively, each service can be configured individually with the following command: POST - configure an individual access service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/{{serviceURLMarker}} The service URL marker for each service is shown in the example response given above. In both cases, it is possible to pass a list of properties to the access service that controls the behavior of each access service. These are sent in the request body. More details of which properties are supported are documented with each access service. Disable the access services \u00b6 The access services can be disabled with the following command. This also disables the enterprise repository services since they are not being used. DELETE - disable the access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services Review configuration \u00b6 GET - retrieve current configuration for the access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/configuration POST - save changes back to the configuration {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/configuration","title":"Configure Metadata Server"},{"location":"guides/admin/servers/configuring-a-metadata-server/#configuring-a-metadata-server","text":"Each type of OMAG Server is configured by creating a configuration document . A metadata server can be run standalone, without connecting to a cohort: Adding the cohort configuration enables the metadata server to communicate with other metadata servers:","title":"Configuring a metadata server"},{"location":"guides/admin/servers/configuring-a-metadata-server/#set-up-the-default-event-bus","text":"An OMAG Server uses an event bus such as Apache Kafka to exchange events with other servers and tools. Egeria manages the specific topic names and the event payloads; however, it needs to know where the event bus is deployed and any properties needed to configure it. Since the event bus is used in multiple places, the configuration document allows you to set up the details of the event bus which are then incorporated into all the places where the event bus is needed. Important sequencing information You need to set up this information before configuring any of the following: Using an event topic as the destination for the audit log . Configuring the access services in a metadata access store or a metadata access point . Configuring registration to a cohort in a metadata access store , a metadata access point , a repository proxy or a conformance test server . The following command creates information about the event bus. This information is used on the subsequent configuration of the OMAG Server subsystems. It does not affect any subsystems that have already been configured in the configuration document and if the event bus is not needed, its values are ignored. It is possible to add arbitrary name/value pairs as JSON in the request body. The correct properties to use are defined in the connector type for the event bus. POST - configure event bus {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/event-bus Example: Apache Kafka For example, when using Apache Kafka as your event bus you may want to configure properties that control the behavior of the consumer that receives events and the producer that sends events. This is a typical set of producer and consumer properties: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"producer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"acks\" : \"all\" , \"retries\" : \"0\" , \"batch.size\" : \"16384\" , \"linger.ms\" : \"1\" , \"buffer.memory\" : \"33554432\" , \"max.request.size\" : \"10485760\" , \"key.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"value.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" }, \"consumer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"zookeeper.session.timeout.ms\" : \"400\" , \"zookeeper.sync.time.ms\" : \"200\" , \"fetch.message.max.bytes\" : \"10485760\" , \"max.partition.fetch.bytes\" : \"10485760\" , \"key.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"value.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" } } A different type of event bus would use different properties.","title":"Set up the default event bus"},{"location":"guides/admin/servers/configuring-a-metadata-server/#set-the-server-url-root","text":"Configure the local server URL root with the value of the OMAG Server Platform where the service will run: in particular if the configuration document will be deployed to a different OMAG Server Platform from the one used to maintain the configuration document. POST - set server URL root {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-url-root?url={{targetPlatformURLRoot}} Detailed explanation The {{targetPlatformURLRoot}} gives the location of the OMAG Server Platform on which this configured service is intended to run, while the {{platformURLRoot}} gives the location of the OMAG Server Platform in which this configuration document is maintained. They could be, but do not need to be, the same location.","title":"Set the server URL root"},{"location":"guides/admin/servers/configuring-a-metadata-server/#configure-the-basic-properties","text":"The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values.","title":"Configure the basic properties"},{"location":"guides/admin/servers/configuring-a-metadata-server/#set-server-type-name","text":"The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\"","title":"Set server type name"},{"location":"guides/admin/servers/configuring-a-metadata-server/#set-organization-name","text":"The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\"","title":"Set organization name"},{"location":"guides/admin/servers/configuring-a-metadata-server/#set-the-servers-user-id-and-optional-password","text":"The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\"","title":"Set the server's user ID and optional password"},{"location":"guides/admin/servers/configuring-a-metadata-server/#set-the-maximum-page-size-for-rest-api-requests","text":"The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}}","title":"Set the maximum page size for REST API requests"},{"location":"guides/admin/servers/configuring-a-metadata-server/#configure-the-audit-log","text":"Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination.","title":"Configure the audit log"},{"location":"guides/admin/servers/configuring-a-metadata-server/#add-audit-log-destinations","text":"There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations","title":"Add audit log destinations"},{"location":"guides/admin/servers/configuring-a-metadata-server/#remove-audit-logs","text":"The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none","title":"Remove audit logs"},{"location":"guides/admin/servers/configuring-a-metadata-server/#configure-the-server-security-connector","text":"Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } }","title":"Configure the server security connector"},{"location":"guides/admin/servers/configuring-a-metadata-server/#determine-configured-security","text":"GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } }","title":"Determine configured security"},{"location":"guides/admin/servers/configuring-a-metadata-server/#remove-configured-security","text":"DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server.","title":"Remove configured security"},{"location":"guides/admin/servers/configuring-a-metadata-server/#configure-the-local-repository","text":"A metadata server supports a local metadata repository that has native support for the Open Metadata Repository Services ( OMRS ) types and instances .","title":"Configure the local repository"},{"location":"guides/admin/servers/configuring-a-metadata-server/#choose-a-repository","text":"Egeria provides a number of implementations of such a repository -- only one of these options can be configured for a given metadata server at a time. bi-temporal graph This command enables a XTDB-based metadata repository, which itself has a number of pluggable back-end options for persistence and other configuration options . This plugin repository is currently the highest-performing, most fully-functional repository for Egeria, supporting all metadata operations including historical metadata as well as being highly-available through clustered deployment . POST - enable the bi-temporal graph repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/plugin-repository/connection { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.juxt.xtdb.repositoryconnector.XtdbOMRSRepositoryConnectorProvider\" } } May require additional driver libraries Note that depending on the persistence you configure, you may need to obtain additional driver libraries for your back-end service , as not every driver is embedded in the XTDB connector itself. non-temporal graph This command enables a JanusGraph-based metadata repository that is embedded in the metadata server and uses the local disk to store the metadata, but does not manage any historical metadata. POST - enable the graph repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/local-graph-repository in-memory The in-memory repository maintains an in-memory store of metadata. It is useful for demos and testing. No metadata is kept if the open metadata services are deactivated, or the server is shutdown. It should nto be used in a production environment. POST - enable the in-memory repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/in-memory-repository read-only The read-only repository connector provides a compliant implementation of a local repository that can be configured into a metadata server. It does not support the interfaces for create, update, delete. However, it does support the search interfaces and is able to cache metadata. This means it can be loaded with metadata from an open metadata archive and connected to a cohort. The content from the archive will be shared with other members of the cohort. POST - enable the read-only repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/read-only-repository","title":"Choose a repository"},{"location":"guides/admin/servers/configuring-a-metadata-server/#remove-the-local-repository","text":"This command removes all configuration for the local repository. This includes the local metadata collection id . If a new local repository is added, it will have a new local metadata collection id and will not be able to automatically re-register with its cohort(s). DELETE - remove the local repository {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository","title":"Remove the local repository"},{"location":"guides/admin/servers/configuring-a-metadata-server/#load-metadata","text":"Open metadata archives contain pre-canned metadata types and instances for cohort members . Archives can be added to the configuration document of a server to ensure their content is loaded each time the server is started. This is intended for repositories that do not store the archive content but keep it in memory. Archives can also be loaded to a running server . Loading the same archive multiple times If an archive is loaded multiple times, its content is only added to the local repository if the repository does not have the content already.","title":"Load metadata"},{"location":"guides/admin/servers/configuring-a-metadata-server/#add-to-a-running-server","text":"Typically, an open metadata archive is stored as JSON format in a file. To load such a file use the following command: POST - load file {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/open-metadata-archives/file The body of the request should be the fully-qualified path name or path relative to the startup directory of the OMAG Server Platform -- and the file name should not have any quotes around it. Alternatively it is possible to set up the list of open metadata archives as a list of connections . These connections refer to open metadata archive connectors that can read and retrieve the open metadata archive content. POST - load from connection(s) {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/open-metadata-archives/connection The body of the request should be the list of connections from which to load archives. This option can be used when the open metadata archives are not stored in a file, or a different file format from the default one for the OMAG Server Platform is required.","title":"Add to a running server"},{"location":"guides/admin/servers/configuring-a-metadata-server/#configure-metadata-to-load-on-startup","text":"Typically, an open metadata archive is stored as JSON format in a file. To configure the load of such a file use the following command: POST - specify file to load POST {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives/file The body of the request should be the fully-qualified path name or path relative to the startup directory of the OMAG Server Platform -- and the file name should not have any quotes around it. Alternatively it is possible to set up the list of open metadata archives as a list of connections . These connections refer to connectors that can read and retrieve the open metadata archive content. POST - specify connection(s) to load {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives The body of the request should be the list of connections from which to load archives. This option can be used when the open metadata archives are not stored in a file, or a different file connector from the default one for the OMAG Server Platform is required.","title":"Configure metadata to load on startup"},{"location":"guides/admin/servers/configuring-a-metadata-server/#remove-metadata-load-on-startup","text":"Finally, this is how to remove the archives from the configuration document. DELETE - remove archives from configuration document {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives The body of the request should be the path to the metadata archive file.","title":"Remove metadata load on startup"},{"location":"guides/admin/servers/configuring-a-metadata-server/#configure-the-access-services","text":"The Open Metadata Access Services (OMASs) provide the domain-specific APIs for metadata management and governance. They run in a metadata access store or metadata access point and typically offer a REST API, Java client and an event-based interface for asynchronous interaction. Prerequisite configuration The access service configuration depends on the definitions of the event bus and the local server's userId .","title":"Configure the access services"},{"location":"guides/admin/servers/configuring-a-metadata-server/#list-available-access-services","text":"GET - list all available access services {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/server-platform/registered-services/access-services Response listing available access services { \"relatedHTTPCode\" : 200 , \"services\" : [ { \"serviceName\" : \"Asset Owner\" , \"serviceURLMarker\" : \"asset-owner\" , \"serviceDescription\" : \"Manage an asset\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-owner/\" }, { \"serviceName\" : \"Stewardship Action\" , \"serviceURLMarker\" : \"stewardship-action\" , \"serviceDescription\" : \"Manage exceptions and actions from open governance\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/stewardship-action/\" }, { \"serviceName\" : \"Subject Area\" , \"serviceURLMarker\" : \"subject-area\" , \"serviceDescription\" : \"Document knowledge about a subject area\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/subject-area/\" }, { \"serviceName\" : \"Governance Program\" , \"serviceURLMarker\" : \"governance-program\" , \"serviceDescription\" : \"Manage the governance program\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-program/\" }, { \"serviceName\" : \"Asset Lineage\" , \"serviceURLMarker\" : \"asset-lineage\" , \"serviceDescription\" : \"Store asset lineage\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-lineage/\" }, { \"serviceName\" : \"Design Model\" , \"serviceURLMarker\" : \"design-model\" , \"serviceDescription\" : \"Exchange design model content with tools and standard packages\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/design-model/\" }, { \"serviceName\" : \"Glossary View\" , \"serviceURLMarker\" : \"glossary-view\" , \"serviceDescription\" : \"Support glossary terms visualization\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/glossary-view/\" }, { \"serviceName\" : \"Security Manager\" , \"serviceURLMarker\" : \"security-officer\" , \"serviceDescription\" : \"Set up rules to protect data\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/security-officer/\" }, { \"serviceName\" : \"Asset Consumer\" , \"serviceURLMarker\" : \"asset-consumer\" , \"serviceDescription\" : \"Access assets through connectors\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-consumer/\" }, { \"serviceName\" : \"IT Infrastructure\" , \"serviceURLMarker\" : \"it-infrastructure\" , \"serviceDescription\" : \"Manage information about the deployed IT infrastructure\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/it-infrastructure/\" }, { \"serviceName\" : \"Asset Catalog\" , \"serviceURLMarker\" : \"asset-catalog\" , \"serviceDescription\" : \"Search and understand your assets\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/asset-catalog/\" }, { \"serviceName\" : \"Data Science\" , \"serviceURLMarker\" : \"data-science\" , \"serviceDescription\" : \"Create and manage data science definitions and models\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-science/\" }, { \"serviceName\" : \"Community Profile\" , \"serviceURLMarker\" : \"community-profile\" , \"serviceDescription\" : \"Define personal profile and collaborate\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/community-profile/\" }, { \"serviceName\" : \"DevOps\" , \"serviceURLMarker\" : \"devops\" , \"serviceDescription\" : \"Manage a DevOps pipeline\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/dev-ops/\" }, { \"serviceName\" : \"Software Developer\" , \"serviceURLMarker\" : \"software-developer\" , \"serviceDescription\" : \"Interact with software development tools\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/software-developer/\" }, { \"serviceName\" : \"Discovery Engine\" , \"serviceURLMarker\" : \"discovery-engine\" , \"serviceDescription\" : \"Support for automated metadata discovery engines\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/discovery-engine/\" }, { \"serviceName\" : \"Data Engine\" , \"serviceURLMarker\" : \"data-engine\" , \"serviceDescription\" : \"Exchange process models and lineage with a data engine\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-engine/\" }, { \"serviceName\" : \"Project Management\" , \"serviceURLMarker\" : \"project-management\" , \"serviceDescription\" : \"Manage data projects\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/project-management/\" }, { \"serviceName\" : \"Governance Engine\" , \"serviceURLMarker\" : \"governance-engine\" , \"serviceDescription\" : \"Set up an operational governance engine\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/governance-engine/\" }, { \"serviceName\" : \"Digital Architecture\" , \"serviceURLMarker\" : \"digital-architecture\" , \"serviceDescription\" : \"Design of the digital services for an organization\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/digital-architecture/\" }, { \"serviceName\" : \"Data Privacy\" , \"serviceURLMarker\" : \"data-privacy\" , \"serviceDescription\" : \"Manage governance of privacy\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-privacy/\" }, { \"serviceName\" : \"Data Manager\" , \"serviceURLMarker\" : \"data-manager\" , \"serviceDescription\" : \"Capture changes to the data stores and data set managed by a technology managing collections of data\" , \"serviceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/access-services/data-manager/\" } ] } These access services are available to configure either all together or individually.","title":"List available access services"},{"location":"guides/admin/servers/configuring-a-metadata-server/#enable-access-services","text":"The access services can either all be enabled (with default configuration values) or individually enabled: all, with defaults To enable all the access services (and the enterprise repository services that support them) with default configuration values use the following command. POST - enable all access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services individually Alternatively, each service can be configured individually with the following command: POST - configure an individual access service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/{{serviceURLMarker}} The service URL marker for each service is shown in the example response given above. In both cases, it is possible to pass a list of properties to the access service that controls the behavior of each access service. These are sent in the request body. More details of which properties are supported are documented with each access service.","title":"Enable access services"},{"location":"guides/admin/servers/configuring-a-metadata-server/#disable-the-access-services","text":"The access services can be disabled with the following command. This also disables the enterprise repository services since they are not being used. DELETE - disable the access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services","title":"Disable the access services"},{"location":"guides/admin/servers/configuring-a-metadata-server/#review-configuration","text":"GET - retrieve current configuration for the access services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/configuration POST - save changes back to the configuration {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/access-services/configuration","title":"Review configuration"},{"location":"guides/admin/servers/configuring-a-repository-proxy/","text":"Configuring a repository proxy \u00b6 Each type of OMAG Server is configured by creating a configuration document . Set up the default event bus \u00b6 An OMAG Server uses an event bus such as Apache Kafka to exchange events with other servers and tools. Egeria manages the specific topic names and the event payloads; however, it needs to know where the event bus is deployed and any properties needed to configure it. Since the event bus is used in multiple places, the configuration document allows you to set up the details of the event bus which are then incorporated into all the places where the event bus is needed. Important sequencing information You need to set up this information before configuring any of the following: Using an event topic as the destination for the audit log . Configuring the access services in a metadata access store or a metadata access point . Configuring registration to a cohort in a metadata access store , a metadata access point , a repository proxy or a conformance test server . The following command creates information about the event bus. This information is used on the subsequent configuration of the OMAG Server subsystems. It does not affect any subsystems that have already been configured in the configuration document and if the event bus is not needed, its values are ignored. It is possible to add arbitrary name/value pairs as JSON in the request body. The correct properties to use are defined in the connector type for the event bus. POST - configure event bus {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/event-bus Example: Apache Kafka For example, when using Apache Kafka as your event bus you may want to configure properties that control the behavior of the consumer that receives events and the producer that sends events. This is a typical set of producer and consumer properties: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"producer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"acks\" : \"all\" , \"retries\" : \"0\" , \"batch.size\" : \"16384\" , \"linger.ms\" : \"1\" , \"buffer.memory\" : \"33554432\" , \"max.request.size\" : \"10485760\" , \"key.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"value.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" }, \"consumer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"zookeeper.session.timeout.ms\" : \"400\" , \"zookeeper.sync.time.ms\" : \"200\" , \"fetch.message.max.bytes\" : \"10485760\" , \"max.partition.fetch.bytes\" : \"10485760\" , \"key.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"value.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" } } A different type of event bus would use different properties. Set the server URL root \u00b6 Configure the local server URL root with the value of the OMAG Server Platform where the service will run: in particular if the configuration document will be deployed to a different OMAG Server Platform from the one used to maintain the configuration document. POST - set server URL root {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-url-root?url={{targetPlatformURLRoot}} Detailed explanation The {{targetPlatformURLRoot}} gives the location of the OMAG Server Platform on which this configured service is intended to run, while the {{platformURLRoot}} gives the location of the OMAG Server Platform in which this configuration document is maintained. They could be, but do not need to be, the same location. Configure the basic properties \u00b6 The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values. Set server type name \u00b6 The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\" Set organization name \u00b6 The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\" Set the server's user ID and optional password \u00b6 The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\" Set the maximum page size for REST API requests \u00b6 The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}} Configure the audit log \u00b6 Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination. Add audit log destinations \u00b6 There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations Remove audit logs \u00b6 The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none Configure the server security connector \u00b6 Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } } Determine configured security \u00b6 GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } } Remove configured security \u00b6 DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server. Load metadata \u00b6 Open metadata archives contain pre-canned metadata types and instances for cohort members . Archives can be added to the configuration document of a server to ensure their content is loaded each time the server is started. This is intended for repositories that do not store the archive content but keep it in memory. Archives can also be loaded to a running server . Loading the same archive multiple times If an archive is loaded multiple times, its content is only added to the local repository if the repository does not have the content already. Add to a running server \u00b6 Typically, an open metadata archive is stored as JSON format in a file. To load such a file use the following command: POST - load file {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/open-metadata-archives/file The body of the request should be the fully-qualified path name or path relative to the startup directory of the OMAG Server Platform -- and the file name should not have any quotes around it. Alternatively it is possible to set up the list of open metadata archives as a list of connections . These connections refer to open metadata archive connectors that can read and retrieve the open metadata archive content. POST - load from connection(s) {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/open-metadata-archives/connection The body of the request should be the list of connections from which to load archives. This option can be used when the open metadata archives are not stored in a file, or a different file format from the default one for the OMAG Server Platform is required. Configure metadata to load on startup \u00b6 Typically, an open metadata archive is stored as JSON format in a file. To configure the load of such a file use the following command: POST - specify file to load POST {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives/file The body of the request should be the fully-qualified path name or path relative to the startup directory of the OMAG Server Platform -- and the file name should not have any quotes around it. Alternatively it is possible to set up the list of open metadata archives as a list of connections . These connections refer to connectors that can read and retrieve the open metadata archive content. POST - specify connection(s) to load {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives The body of the request should be the list of connections from which to load archives. This option can be used when the open metadata archives are not stored in a file, or a different file connector from the default one for the OMAG Server Platform is required. Remove metadata load on startup \u00b6 Finally, this is how to remove the archives from the configuration document. DELETE - remove archives from configuration document {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives The body of the request should be the path to the metadata archive file. Configure the repository proxy connector \u00b6 The mapping between a third party metadata repository and the open metadata protocols in a repository proxy is implemented in two connectors: An OMRS repository connector An OMRS event mapper connector They are configured as follows. Configure the repository connector \u00b6 The OMAG Server can act as a proxy to a vendor's repository. This is done by adding the connection for the repository proxy as the local repository. POST - configure the repository connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/repository-proxy/connection The request body should be the connection option to use for configuring the connector, which can include any connector-specific options as well as general details like the endpoint and credentials for the third party repository. Example: connection to configure the IBM Information Governance Catalog repository connector 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.ibm.igc.repositoryconnector.IGCOMRSRepositoryConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"infosvr:9446\" , \"protocol\" : \"https\" }, \"userId\" : \"a-user\" , \"clearPassword\" : \"a-password\" , \"configurationProperties\" : { \"defaultZones\" : [ \"default\" ] } } In this example, the type of connector to configure is given by the class name on line 5, and details about how to connect to the third party repository (IBM Information Governance Catalog) itself are provided on lines 9 (hostname and port), and 12-13 (credentials). Configure the repository's event mapper \u00b6 Any open metadata repository that supports its own API may also implement an event mapper to ensure the Open Metadata Repository Services ( OMRS ) is notified when metadata is added to the repository without going through the open metadata APIs. The event mapper is a connector that listens for proprietary events from the repository and converts them into calls to the OMRS . The OMRS then distributes this new metadata. POST - configure event mapper {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/event-mapper-details?connectorProvider={{fullyQualifiedJavaClassName}}&eventSource={{resourceName}} The connectorProvider should be set to the fully-qualified Java class name for the connector provider , and the eventSource should give the details for how to access the events (for example, the hostname and port number of an Apache Kafka bootstrap server).","title":"Configure Repository Proxy"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#configuring-a-repository-proxy","text":"Each type of OMAG Server is configured by creating a configuration document .","title":"Configuring a repository proxy"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#set-up-the-default-event-bus","text":"An OMAG Server uses an event bus such as Apache Kafka to exchange events with other servers and tools. Egeria manages the specific topic names and the event payloads; however, it needs to know where the event bus is deployed and any properties needed to configure it. Since the event bus is used in multiple places, the configuration document allows you to set up the details of the event bus which are then incorporated into all the places where the event bus is needed. Important sequencing information You need to set up this information before configuring any of the following: Using an event topic as the destination for the audit log . Configuring the access services in a metadata access store or a metadata access point . Configuring registration to a cohort in a metadata access store , a metadata access point , a repository proxy or a conformance test server . The following command creates information about the event bus. This information is used on the subsequent configuration of the OMAG Server subsystems. It does not affect any subsystems that have already been configured in the configuration document and if the event bus is not needed, its values are ignored. It is possible to add arbitrary name/value pairs as JSON in the request body. The correct properties to use are defined in the connector type for the event bus. POST - configure event bus {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/event-bus Example: Apache Kafka For example, when using Apache Kafka as your event bus you may want to configure properties that control the behavior of the consumer that receives events and the producer that sends events. This is a typical set of producer and consumer properties: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"producer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"acks\" : \"all\" , \"retries\" : \"0\" , \"batch.size\" : \"16384\" , \"linger.ms\" : \"1\" , \"buffer.memory\" : \"33554432\" , \"max.request.size\" : \"10485760\" , \"key.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"value.serializer\" : \"org.apache.kafka.common.serialization.StringSerializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" }, \"consumer\" : { \"bootstrap.servers\" : \"localhost:9092\" , \"zookeeper.session.timeout.ms\" : \"400\" , \"zookeeper.sync.time.ms\" : \"200\" , \"fetch.message.max.bytes\" : \"10485760\" , \"max.partition.fetch.bytes\" : \"10485760\" , \"key.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"value.deserializer\" : \"org.apache.kafka.common.serialization.StringDeserializer\" , \"kafka.omrs.topic.id\" : \"cocoCohort\" } } A different type of event bus would use different properties.","title":"Set up the default event bus"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#set-the-server-url-root","text":"Configure the local server URL root with the value of the OMAG Server Platform where the service will run: in particular if the configuration document will be deployed to a different OMAG Server Platform from the one used to maintain the configuration document. POST - set server URL root {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-url-root?url={{targetPlatformURLRoot}} Detailed explanation The {{targetPlatformURLRoot}} gives the location of the OMAG Server Platform on which this configured service is intended to run, while the {{platformURLRoot}} gives the location of the OMAG Server Platform in which this configuration document is maintained. They could be, but do not need to be, the same location.","title":"Set the server URL root"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#configure-the-basic-properties","text":"The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values.","title":"Configure the basic properties"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#set-server-type-name","text":"The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\"","title":"Set server type name"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#set-organization-name","text":"The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\"","title":"Set organization name"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#set-the-servers-user-id-and-optional-password","text":"The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\"","title":"Set the server's user ID and optional password"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#set-the-maximum-page-size-for-rest-api-requests","text":"The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}}","title":"Set the maximum page size for REST API requests"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#configure-the-audit-log","text":"Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination.","title":"Configure the audit log"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#add-audit-log-destinations","text":"There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations","title":"Add audit log destinations"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#remove-audit-logs","text":"The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none","title":"Remove audit logs"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#configure-the-server-security-connector","text":"Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } }","title":"Configure the server security connector"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#determine-configured-security","text":"GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } }","title":"Determine configured security"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#remove-configured-security","text":"DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server.","title":"Remove configured security"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#load-metadata","text":"Open metadata archives contain pre-canned metadata types and instances for cohort members . Archives can be added to the configuration document of a server to ensure their content is loaded each time the server is started. This is intended for repositories that do not store the archive content but keep it in memory. Archives can also be loaded to a running server . Loading the same archive multiple times If an archive is loaded multiple times, its content is only added to the local repository if the repository does not have the content already.","title":"Load metadata"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#add-to-a-running-server","text":"Typically, an open metadata archive is stored as JSON format in a file. To load such a file use the following command: POST - load file {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/open-metadata-archives/file The body of the request should be the fully-qualified path name or path relative to the startup directory of the OMAG Server Platform -- and the file name should not have any quotes around it. Alternatively it is possible to set up the list of open metadata archives as a list of connections . These connections refer to open metadata archive connectors that can read and retrieve the open metadata archive content. POST - load from connection(s) {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/instance/open-metadata-archives/connection The body of the request should be the list of connections from which to load archives. This option can be used when the open metadata archives are not stored in a file, or a different file format from the default one for the OMAG Server Platform is required.","title":"Add to a running server"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#configure-metadata-to-load-on-startup","text":"Typically, an open metadata archive is stored as JSON format in a file. To configure the load of such a file use the following command: POST - specify file to load POST {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives/file The body of the request should be the fully-qualified path name or path relative to the startup directory of the OMAG Server Platform -- and the file name should not have any quotes around it. Alternatively it is possible to set up the list of open metadata archives as a list of connections . These connections refer to connectors that can read and retrieve the open metadata archive content. POST - specify connection(s) to load {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives The body of the request should be the list of connections from which to load archives. This option can be used when the open metadata archives are not stored in a file, or a different file connector from the default one for the OMAG Server Platform is required.","title":"Configure metadata to load on startup"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#remove-metadata-load-on-startup","text":"Finally, this is how to remove the archives from the configuration document. DELETE - remove archives from configuration document {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/open-metadata-archives The body of the request should be the path to the metadata archive file.","title":"Remove metadata load on startup"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#configure-the-repository-proxy-connector","text":"The mapping between a third party metadata repository and the open metadata protocols in a repository proxy is implemented in two connectors: An OMRS repository connector An OMRS event mapper connector They are configured as follows.","title":"Configure the repository proxy connector"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#configure-the-repository-connector","text":"The OMAG Server can act as a proxy to a vendor's repository. This is done by adding the connection for the repository proxy as the local repository. POST - configure the repository connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/mode/repository-proxy/connection The request body should be the connection option to use for configuring the connector, which can include any connector-specific options as well as general details like the endpoint and credentials for the third party repository. Example: connection to configure the IBM Information Governance Catalog repository connector 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.egeria.connectors.ibm.igc.repositoryconnector.IGCOMRSRepositoryConnectorProvider\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"infosvr:9446\" , \"protocol\" : \"https\" }, \"userId\" : \"a-user\" , \"clearPassword\" : \"a-password\" , \"configurationProperties\" : { \"defaultZones\" : [ \"default\" ] } } In this example, the type of connector to configure is given by the class name on line 5, and details about how to connect to the third party repository (IBM Information Governance Catalog) itself are provided on lines 9 (hostname and port), and 12-13 (credentials).","title":"Configure the repository connector"},{"location":"guides/admin/servers/configuring-a-repository-proxy/#configure-the-repositorys-event-mapper","text":"Any open metadata repository that supports its own API may also implement an event mapper to ensure the Open Metadata Repository Services ( OMRS ) is notified when metadata is added to the repository without going through the open metadata APIs. The event mapper is a connector that listens for proprietary events from the repository and converts them into calls to the OMRS . The OMRS then distributes this new metadata. POST - configure event mapper {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/local-repository/event-mapper-details?connectorProvider={{fullyQualifiedJavaClassName}}&eventSource={{resourceName}} The connectorProvider should be set to the fully-qualified Java class name for the connector provider , and the eventSource should give the details for how to access the events (for example, the hostname and port number of an Apache Kafka bootstrap server).","title":"Configure the repository's event mapper"},{"location":"guides/admin/servers/configuring-a-view-server/","text":"Configuring a view server \u00b6 Each type of OMAG Server is configured by creating a configuration document . Configure the basic properties \u00b6 The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values. Set server type name \u00b6 The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\" Set organization name \u00b6 The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\" Set the server's user ID and optional password \u00b6 The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\" Set the maximum page size for REST API requests \u00b6 The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}} Configure the audit log \u00b6 Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination. Add audit log destinations \u00b6 There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations Remove audit logs \u00b6 The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none Configure the server security connector \u00b6 Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } } Determine configured security \u00b6 GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } } Remove configured security \u00b6 DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server. Configure the view services \u00b6 The Open Metadata View Services ( OMVS 's) run in a view server . View services provide task-oriented, domain-specific services for user interfaces that integrate with open metadata. View services are part of a multi-tier architecture for the provision of multi-tenant user interfaces. The front tier consists of web components that are rendered in a web browser and served by a web application called the presentation server . The presentation server in turn delegates requests to a set of view services that form a second tier running in the view server. Each view service exposes a REST API that supports the domain-specific operations relevant to the service and issues queries and commands to other OMAG Servers. To get a description of each of the registered view services, and each service's viewServiceURLMarker , see list view services instructions below. To activate a specific view service in a view server, it is necessary to add an entry for the view service to the view server's configuration document. The descriptive information and operational status are filled out automatically by the administration services based on the viewServiceURLMarker value that you supply. The other values are supplied on the configuration call. There are two types of view services, each with a different type of view service configuration object: Solution view services \u00b6 A solution view service supports operations needed by a solution-oriented user interface. These are typically geared toward a specific Open Metadata Access Service ( OMAS ) . For example, the Glossary Author view service supports a user interface for creation and management of glossaries using the Subject Area OMAS . A solution view service is configured using a SolutionViewServiceConfig object which has the following properties: Property Use viewServiceId required property, set to a unique numeric identifier viewServiceAdminClass required property, set to the admin class of the view service viewServiceName required property, set to the name of the view service being configured viewServiceFullName required property, set to the full name of view service viewServiceURLMarker required property, set to the serviceURL Marker of the service - this can be discovered by listing the registered view services viewServiceDescription optional property that describes the view service viewServiceWiki optional property specifying the location of the view service documentation viewServiceOperationalStatus required property, set to ENABLED or DISABLED viewServiceOptions optional property that specifies options needed by a specific view service (refer to the documentation for the specific service for details) omagServerPlatformRootURL required property (see below) omagServerName required property (see below) A solution view service configuration must include omagServerPlatformRootURL and omagServerName properties(defined in OMAGServerClientConfig ). These properties specify the OMAG Server to which to send downstream REST calls to an OMAG Server that is running the OMAS needed by the view service. Example solution view service configuration Below is an example of a configuration object for a solution view service. In this example, the view service is Glossary Author View Service . It would be similar for the other solution view services. The configuration contains the name and status of the view service and contains the name and rootURL of the OMAG Server to which 'downstream' requests will be sent. In this example the 'downstream' server is the server running the Subject Area OMAS , required by the Glossary Author view service. { \"class\":\"SolutionViewServiceConfig\", \"viewServiceAdminClass\":\"org.odpi.openmetadata.viewservices.glossaryauthor.admin.GlossaryAuthorViewAdmin\", \"viewServiceFullName\":\"Glossary Author\", \"viewServiceOperationalStatus\":\"ENABLED\", \"omagserverName\":\"Subject_Area_Server\", \"omagserverPlatformRootURL\":\"https://localhost:8083\" } Integration view services \u00b6 An integration view service supports operations needed by an integration-oriented user interface. Examples include the Repository Explorer View Service , Type Explorer View Service or Dino View Service for operational management. It additionally has the following configuration properties: Property Use viewServiceId required property, set to a unique numeric identifier viewServiceAdminClass required property, set to the admin class of the view service viewServiceName required property, set to the name of the view service being configured viewServiceFullName required property, set to the full name of view service viewServiceURLMarker required property, set to the serviceURL marker of the service - this can be discovered by listing the registered view services viewServiceDescription optional property that describes the view service viewServiceWiki optional property specifying the location of the view service documentation viewServiceOperationalStatus required property, set to ENABLED or DISABLED viewServiceOptions optional property that specifies options needed by a specific view service (refer to the documentation for the specific service for details) resourceEndpoints required property that lists the platform and server endpoints of the OMAG Platforms or Servers to which to send downstream REST calls, for example to query metadata repositories (see below) An integration view service configuration does not need the omagServerPlatformRootURL and omagServerName properties that are required for a solution view service configuration. This is because an integration view service will generally need to perform operations routed to a variety of open metadata servers, selected by the user at runtime. The set of platforms and servers that the user can select are configured by the resourceEndpoints configuration property. The resourceEndpoints property is a list of ResourceEndpointConfig objects, which each have the following properties: Property Use resourceCategory required property, set to either \"Platform\" or \"Server\" platformName required property, a unique name given to a \"Platform\" resource, or a reference to a named \"Platform\" resource endpoint from a \"Server\" resource serverName required property for a \"Server\" resource, set to the name of the OMAG Server. Not used for a \"Platform\" resource. serverInstanceName required property for a \"Server\" resource, a unique name for the combination of server and platform. description optional property that is displayed by some integration view services In an Egeria deployment, a server may be deployed to multiple platforms; this is typically used for clustering. A \"Server\" ResourceEndpointConfig must possess a serverInstanceName property which contains a unique name that refers to the specific instance of the server identified by the serverName property hosted by the platform identified by the platformName property. For example, you could configure a pair of server resource endpoints called Server1@PlatformA and Server1@PlatformB : both are Server1 , but hosted on different platforms ( PlatformA and PlatformB ). The serverInstanceName is used to display the resource in the user interface selector lists. Example integration view service configuration Below is an example of a configuration object for an Integration View Service. In this example, the view service is Dino View Service . It would be similar for the other integration view services. The configuration contains the name and status of the view service and contains a list of the resources that will appear in the platform and server selectors in the user interface. All requests to the view service REST API are based on these configured named resources. When a user selects a platform name or server name from the selector lists, the interface sends the resource name to the view service, which resolves the platform or server name to a resource endpoint to identify the URL needed to send a request to the platform or server. In the example configuration, the list of ResourceEndpointConfig objects represents two platforms and two servers. Every ResourceEndpointConfig has a resourceCategory , set to either \"Platform\" or \"Server\" . Each platform ResourceEndpointConfig has a unique platformName and platformRootURL and an optional description property. Each server ResourceEndpointConfig has a serverInstanceName , serverName and the platformName of one of the configured platform resource endpoints. Each server also has an optional description property. You would need to replace the <hostname> and <port> variables with your own values: { \"class\" : \"IntegrationViewServiceConfig\" , \"viewServiceAdminClass\" : \"org.odpi.openmetadata.viewservices.rex.admin.RexViewAdmin\" , \"viewServiceFullName\" : \"RepositoryExplorer\" , \"viewServiceOperationalStatus\" : \"ENABLED\" , \"resourceEndpoints\" : [ { \"class\" : \"ResourceEndpointConfig\" , \"resourceCategory\" : \"Platform\" , \"platformName\" : \"Platform1\" , \"platformRootURL\" : \"https://<hostname>:<port>\" , \"description\" : \"This platform is running in the development cloud\" }, { \"class\" : \"ResourceEndpointConfig\" , \"resourceCategory\" : \"Platform\" , \"platformName\" : \"Platform2\" , \"platformRootURL\" : \"https://<hostname>:<port>\" , \"description\" : \"This platform is running in the departmental test cluster\" }, { \"class\" : \"ResourceEndpointConfig\" , \"resourceCategory\" : \"Server\" , \"serverInstanceName\" : \"Central Metadata Server\" , \"serverName\" : \"Metadata_Server1\" , \"platformName\" : \"Platform1\" , \"description\" : \"Metadata server with home reopsitory for schema artefacts\" }, { \"class\" : \"ResourceEndpointConfig\" , \"resourceCategory\" : \"Server\" , \"serverInstanceName\" : \"Supplementary Metadata Server\" , \"serverName\" : \"Metadata_Server2\" , \"platformName\" : \"Platform2\" , \"description\" : \"Metadata server with home repository for review artefacts\" } ] } Administrative operations \u00b6 List view services \u00b6 It is possible to list the registered view services for an OMAG Server Platform using the following command: GET - list view services {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/server-platform/registered-services/view-services Response from listing view services { \"class\" : \"RegisteredOMAGServicesResponse\" , \"relatedHTTPCode\" : 200 , \"services\" : [ { \"serviceName\" : \"Glossary Author\" , \"serviceURLMarker\" : \"glossary-author\" , \"serviceDescription\" : \"View Service for glossary authoring.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/access-services/subject-area/\" }, { \"serviceName\" : \"Repository Explorer\" , \"serviceURLMarker\" : \"rex\" , \"serviceDescription\" : \"Explore open metadata instances.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/rex-view/\" }, { \"serviceName\" : \"Type Explorer\" , \"serviceURLMarker\" : \"tex\" , \"serviceDescription\" : \"Explore the open metadata types.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/tex-view/\" }, { \"serviceName\" : \"Dino\" , \"serviceURLMarker\" : \"dino\" , \"serviceDescription\" : \"Operate an open metadata topology.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/dino-view/\" } ] } These view services are available to configure either together or individually. This operation is a good way to discover the serviceURLMarker property for each view service, which is needed for various operations described below. List configured view services \u00b6 It is possible to list the configured view services for an OMAG Server using the following command: GET - list configured view services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/configuration Response from listing configured view services The response will be a RegisteredOMAGServicesResponse which contains a list of RegisteredOMAGService objects, that will look something like the following: { \"class\" : \"RegisteredOMAGServicesResponse\" , \"relatedHTTPCode\" : 200 , \"services\" : [ { \"serviceName\" : \"Glossary Author\" , \"serviceURLMarker\" : \"glossary-author\" , \"serviceDescription\" : \"View Service for glossary authoring.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/access-services/subject-area/\" }, { \"serviceName\" : \"Repository Explorer\" , \"serviceURLMarker\" : \"rex\" , \"serviceDescription\" : \"Explore open metadata instances.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/rex-view/\" }, { \"serviceName\" : \"Type Explorer\" , \"serviceURLMarker\" : \"tex\" , \"serviceDescription\" : \"Explore the open metadata types.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/tex-view/\" } ] } These view services are available to configure either together or individually. Retrieve view service configuration \u00b6 individually Retrieve a specific view service's configuration: GET - retrieve a specific view service's configuration {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/{{serviceURLMarker}} The response will be a ViewServiceConfigResponse containing a ViewServiceConfig object. multiple It is also possible to retrieve the current configuration for all configured view services: GET - retrieve current configuration for all configured view services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services This will return a ViewServicesResponse which will contain a list of ViewServiceConfig objects. Configure view services \u00b6 individually A specific view service can be individually configured with the following command: POST - configure a specific view service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/{{serviceURLMarker}} The request body must contain a ViewServiceConfig object, while the serviceURLMarker can be found by listing the configured view services . multiple It is also possible to configurate a set of view services at the same time, using the following command: POST - configure multiple view services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/configuration The request body must contain a list of ViewServiceConfig objects. Remove view services \u00b6 individually A specific view service can be individually cleared with the following command. This will remove the view service's configuration from the server. DELETE - remove configuration for a specific view service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/{{serviceURLMarker}} The serviceURLMarker can be found by listing the configured view services . multiple All the view services configured on a server can be cleared with the following command: DELETE - remove configured view services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services Configure the presentation server \u00b6 The presentation server is a multi-tenant web application that calls view services running in a view server to retrieve information and perform operations relating to metadata servers. A presentation server tenant is designed to support an organization. These may be independent organizations or divisions/departments within an organization. The tenant routes requests to the appropriate view server and then on to the metadata servers behind. Therefore, each tenant sees a different collection of metadata. Information for configuring the presentation server is provided in a separate GitHub repository .","title":"Configure View Server"},{"location":"guides/admin/servers/configuring-a-view-server/#configuring-a-view-server","text":"Each type of OMAG Server is configured by creating a configuration document .","title":"Configuring a view server"},{"location":"guides/admin/servers/configuring-a-view-server/#configure-the-basic-properties","text":"The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values.","title":"Configure the basic properties"},{"location":"guides/admin/servers/configuring-a-view-server/#set-server-type-name","text":"The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\"","title":"Set server type name"},{"location":"guides/admin/servers/configuring-a-view-server/#set-organization-name","text":"The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\"","title":"Set organization name"},{"location":"guides/admin/servers/configuring-a-view-server/#set-the-servers-user-id-and-optional-password","text":"The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\"","title":"Set the server's user ID and optional password"},{"location":"guides/admin/servers/configuring-a-view-server/#set-the-maximum-page-size-for-rest-api-requests","text":"The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}}","title":"Set the maximum page size for REST API requests"},{"location":"guides/admin/servers/configuring-a-view-server/#configure-the-audit-log","text":"Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination.","title":"Configure the audit log"},{"location":"guides/admin/servers/configuring-a-view-server/#add-audit-log-destinations","text":"There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations","title":"Add audit log destinations"},{"location":"guides/admin/servers/configuring-a-view-server/#remove-audit-logs","text":"The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none","title":"Remove audit logs"},{"location":"guides/admin/servers/configuring-a-view-server/#configure-the-server-security-connector","text":"Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } }","title":"Configure the server security connector"},{"location":"guides/admin/servers/configuring-a-view-server/#determine-configured-security","text":"GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } }","title":"Determine configured security"},{"location":"guides/admin/servers/configuring-a-view-server/#remove-configured-security","text":"DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server.","title":"Remove configured security"},{"location":"guides/admin/servers/configuring-a-view-server/#configure-the-view-services","text":"The Open Metadata View Services ( OMVS 's) run in a view server . View services provide task-oriented, domain-specific services for user interfaces that integrate with open metadata. View services are part of a multi-tier architecture for the provision of multi-tenant user interfaces. The front tier consists of web components that are rendered in a web browser and served by a web application called the presentation server . The presentation server in turn delegates requests to a set of view services that form a second tier running in the view server. Each view service exposes a REST API that supports the domain-specific operations relevant to the service and issues queries and commands to other OMAG Servers. To get a description of each of the registered view services, and each service's viewServiceURLMarker , see list view services instructions below. To activate a specific view service in a view server, it is necessary to add an entry for the view service to the view server's configuration document. The descriptive information and operational status are filled out automatically by the administration services based on the viewServiceURLMarker value that you supply. The other values are supplied on the configuration call. There are two types of view services, each with a different type of view service configuration object:","title":"Configure the view services"},{"location":"guides/admin/servers/configuring-a-view-server/#solution-view-services","text":"A solution view service supports operations needed by a solution-oriented user interface. These are typically geared toward a specific Open Metadata Access Service ( OMAS ) . For example, the Glossary Author view service supports a user interface for creation and management of glossaries using the Subject Area OMAS . A solution view service is configured using a SolutionViewServiceConfig object which has the following properties: Property Use viewServiceId required property, set to a unique numeric identifier viewServiceAdminClass required property, set to the admin class of the view service viewServiceName required property, set to the name of the view service being configured viewServiceFullName required property, set to the full name of view service viewServiceURLMarker required property, set to the serviceURL Marker of the service - this can be discovered by listing the registered view services viewServiceDescription optional property that describes the view service viewServiceWiki optional property specifying the location of the view service documentation viewServiceOperationalStatus required property, set to ENABLED or DISABLED viewServiceOptions optional property that specifies options needed by a specific view service (refer to the documentation for the specific service for details) omagServerPlatformRootURL required property (see below) omagServerName required property (see below) A solution view service configuration must include omagServerPlatformRootURL and omagServerName properties(defined in OMAGServerClientConfig ). These properties specify the OMAG Server to which to send downstream REST calls to an OMAG Server that is running the OMAS needed by the view service. Example solution view service configuration Below is an example of a configuration object for a solution view service. In this example, the view service is Glossary Author View Service . It would be similar for the other solution view services. The configuration contains the name and status of the view service and contains the name and rootURL of the OMAG Server to which 'downstream' requests will be sent. In this example the 'downstream' server is the server running the Subject Area OMAS , required by the Glossary Author view service. { \"class\":\"SolutionViewServiceConfig\", \"viewServiceAdminClass\":\"org.odpi.openmetadata.viewservices.glossaryauthor.admin.GlossaryAuthorViewAdmin\", \"viewServiceFullName\":\"Glossary Author\", \"viewServiceOperationalStatus\":\"ENABLED\", \"omagserverName\":\"Subject_Area_Server\", \"omagserverPlatformRootURL\":\"https://localhost:8083\" }","title":"Solution view services"},{"location":"guides/admin/servers/configuring-a-view-server/#integration-view-services","text":"An integration view service supports operations needed by an integration-oriented user interface. Examples include the Repository Explorer View Service , Type Explorer View Service or Dino View Service for operational management. It additionally has the following configuration properties: Property Use viewServiceId required property, set to a unique numeric identifier viewServiceAdminClass required property, set to the admin class of the view service viewServiceName required property, set to the name of the view service being configured viewServiceFullName required property, set to the full name of view service viewServiceURLMarker required property, set to the serviceURL marker of the service - this can be discovered by listing the registered view services viewServiceDescription optional property that describes the view service viewServiceWiki optional property specifying the location of the view service documentation viewServiceOperationalStatus required property, set to ENABLED or DISABLED viewServiceOptions optional property that specifies options needed by a specific view service (refer to the documentation for the specific service for details) resourceEndpoints required property that lists the platform and server endpoints of the OMAG Platforms or Servers to which to send downstream REST calls, for example to query metadata repositories (see below) An integration view service configuration does not need the omagServerPlatformRootURL and omagServerName properties that are required for a solution view service configuration. This is because an integration view service will generally need to perform operations routed to a variety of open metadata servers, selected by the user at runtime. The set of platforms and servers that the user can select are configured by the resourceEndpoints configuration property. The resourceEndpoints property is a list of ResourceEndpointConfig objects, which each have the following properties: Property Use resourceCategory required property, set to either \"Platform\" or \"Server\" platformName required property, a unique name given to a \"Platform\" resource, or a reference to a named \"Platform\" resource endpoint from a \"Server\" resource serverName required property for a \"Server\" resource, set to the name of the OMAG Server. Not used for a \"Platform\" resource. serverInstanceName required property for a \"Server\" resource, a unique name for the combination of server and platform. description optional property that is displayed by some integration view services In an Egeria deployment, a server may be deployed to multiple platforms; this is typically used for clustering. A \"Server\" ResourceEndpointConfig must possess a serverInstanceName property which contains a unique name that refers to the specific instance of the server identified by the serverName property hosted by the platform identified by the platformName property. For example, you could configure a pair of server resource endpoints called Server1@PlatformA and Server1@PlatformB : both are Server1 , but hosted on different platforms ( PlatformA and PlatformB ). The serverInstanceName is used to display the resource in the user interface selector lists. Example integration view service configuration Below is an example of a configuration object for an Integration View Service. In this example, the view service is Dino View Service . It would be similar for the other integration view services. The configuration contains the name and status of the view service and contains a list of the resources that will appear in the platform and server selectors in the user interface. All requests to the view service REST API are based on these configured named resources. When a user selects a platform name or server name from the selector lists, the interface sends the resource name to the view service, which resolves the platform or server name to a resource endpoint to identify the URL needed to send a request to the platform or server. In the example configuration, the list of ResourceEndpointConfig objects represents two platforms and two servers. Every ResourceEndpointConfig has a resourceCategory , set to either \"Platform\" or \"Server\" . Each platform ResourceEndpointConfig has a unique platformName and platformRootURL and an optional description property. Each server ResourceEndpointConfig has a serverInstanceName , serverName and the platformName of one of the configured platform resource endpoints. Each server also has an optional description property. You would need to replace the <hostname> and <port> variables with your own values: { \"class\" : \"IntegrationViewServiceConfig\" , \"viewServiceAdminClass\" : \"org.odpi.openmetadata.viewservices.rex.admin.RexViewAdmin\" , \"viewServiceFullName\" : \"RepositoryExplorer\" , \"viewServiceOperationalStatus\" : \"ENABLED\" , \"resourceEndpoints\" : [ { \"class\" : \"ResourceEndpointConfig\" , \"resourceCategory\" : \"Platform\" , \"platformName\" : \"Platform1\" , \"platformRootURL\" : \"https://<hostname>:<port>\" , \"description\" : \"This platform is running in the development cloud\" }, { \"class\" : \"ResourceEndpointConfig\" , \"resourceCategory\" : \"Platform\" , \"platformName\" : \"Platform2\" , \"platformRootURL\" : \"https://<hostname>:<port>\" , \"description\" : \"This platform is running in the departmental test cluster\" }, { \"class\" : \"ResourceEndpointConfig\" , \"resourceCategory\" : \"Server\" , \"serverInstanceName\" : \"Central Metadata Server\" , \"serverName\" : \"Metadata_Server1\" , \"platformName\" : \"Platform1\" , \"description\" : \"Metadata server with home reopsitory for schema artefacts\" }, { \"class\" : \"ResourceEndpointConfig\" , \"resourceCategory\" : \"Server\" , \"serverInstanceName\" : \"Supplementary Metadata Server\" , \"serverName\" : \"Metadata_Server2\" , \"platformName\" : \"Platform2\" , \"description\" : \"Metadata server with home repository for review artefacts\" } ] }","title":"Integration view services"},{"location":"guides/admin/servers/configuring-a-view-server/#administrative-operations","text":"","title":"Administrative operations"},{"location":"guides/admin/servers/configuring-a-view-server/#list-view-services","text":"It is possible to list the registered view services for an OMAG Server Platform using the following command: GET - list view services {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/server-platform/registered-services/view-services Response from listing view services { \"class\" : \"RegisteredOMAGServicesResponse\" , \"relatedHTTPCode\" : 200 , \"services\" : [ { \"serviceName\" : \"Glossary Author\" , \"serviceURLMarker\" : \"glossary-author\" , \"serviceDescription\" : \"View Service for glossary authoring.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/access-services/subject-area/\" }, { \"serviceName\" : \"Repository Explorer\" , \"serviceURLMarker\" : \"rex\" , \"serviceDescription\" : \"Explore open metadata instances.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/rex-view/\" }, { \"serviceName\" : \"Type Explorer\" , \"serviceURLMarker\" : \"tex\" , \"serviceDescription\" : \"Explore the open metadata types.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/tex-view/\" }, { \"serviceName\" : \"Dino\" , \"serviceURLMarker\" : \"dino\" , \"serviceDescription\" : \"Operate an open metadata topology.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/dino-view/\" } ] } These view services are available to configure either together or individually. This operation is a good way to discover the serviceURLMarker property for each view service, which is needed for various operations described below.","title":"List view services"},{"location":"guides/admin/servers/configuring-a-view-server/#list-configured-view-services","text":"It is possible to list the configured view services for an OMAG Server using the following command: GET - list configured view services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/configuration Response from listing configured view services The response will be a RegisteredOMAGServicesResponse which contains a list of RegisteredOMAGService objects, that will look something like the following: { \"class\" : \"RegisteredOMAGServicesResponse\" , \"relatedHTTPCode\" : 200 , \"services\" : [ { \"serviceName\" : \"Glossary Author\" , \"serviceURLMarker\" : \"glossary-author\" , \"serviceDescription\" : \"View Service for glossary authoring.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/access-services/subject-area/\" }, { \"serviceName\" : \"Repository Explorer\" , \"serviceURLMarker\" : \"rex\" , \"serviceDescription\" : \"Explore open metadata instances.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/rex-view/\" }, { \"serviceName\" : \"Type Explorer\" , \"serviceURLMarker\" : \"tex\" , \"serviceDescription\" : \"Explore the open metadata types.\" , \"serviceWiki\" : \"https://odpi.github.io/egeria/open-metadata-implementation/view-services/tex-view/\" } ] } These view services are available to configure either together or individually.","title":"List configured view services"},{"location":"guides/admin/servers/configuring-a-view-server/#retrieve-view-service-configuration","text":"individually Retrieve a specific view service's configuration: GET - retrieve a specific view service's configuration {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/{{serviceURLMarker}} The response will be a ViewServiceConfigResponse containing a ViewServiceConfig object. multiple It is also possible to retrieve the current configuration for all configured view services: GET - retrieve current configuration for all configured view services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services This will return a ViewServicesResponse which will contain a list of ViewServiceConfig objects.","title":"Retrieve view service configuration"},{"location":"guides/admin/servers/configuring-a-view-server/#configure-view-services","text":"individually A specific view service can be individually configured with the following command: POST - configure a specific view service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/{{serviceURLMarker}} The request body must contain a ViewServiceConfig object, while the serviceURLMarker can be found by listing the configured view services . multiple It is also possible to configurate a set of view services at the same time, using the following command: POST - configure multiple view services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/configuration The request body must contain a list of ViewServiceConfig objects.","title":"Configure view services"},{"location":"guides/admin/servers/configuring-a-view-server/#remove-view-services","text":"individually A specific view service can be individually cleared with the following command. This will remove the view service's configuration from the server. DELETE - remove configuration for a specific view service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services/{{serviceURLMarker}} The serviceURLMarker can be found by listing the configured view services . multiple All the view services configured on a server can be cleared with the following command: DELETE - remove configured view services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/view-services","title":"Remove view services"},{"location":"guides/admin/servers/configuring-a-view-server/#configure-the-presentation-server","text":"The presentation server is a multi-tenant web application that calls view services running in a view server to retrieve information and perform operations relating to metadata servers. A presentation server tenant is designed to support an organization. These may be independent organizations or divisions/departments within an organization. The tenant routes requests to the appropriate view server and then on to the metadata servers behind. Therefore, each tenant sees a different collection of metadata. Information for configuring the presentation server is provided in a separate GitHub repository .","title":"Configure the presentation server"},{"location":"guides/admin/servers/configuring-an-engine-host/","text":"Configuring an engine host \u00b6 Each type of OMAG Server is configured by creating a configuration document . Example configuration of a minimal engine host server Below is an example of the configuration for a minimal engine host server. It has a single engine service ( Asset Analysis OMES ) and the default audit log. Both the Governance Engine OMAS used by the engine host services and the Discovery Engine OMAS used by the Asset Analysis OMES are running on the metadata server called myMetadataServer . { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"versionId\" : \"V2.0\" , \"localServerId\" : \"8b745d03-5ffc-4978-81ab-bd3d5156eebe\" , \"localServerName\" : \"myserver\" , \"localServerType\" : \"Open Metadata and Governance Server\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"engineHostServicesConfig\" : { \"omagserverPlatformRootURL\" : \"https://localhost:9443\" , \"omagserverName\" : \"myMetadataServer\" , \"engineServices\" : [ { \"class\" : \"EngineServiceConfig\" , \"engineId\" : 6000 , \"engineQualifiedName\" : \"Asset Analysis\" , \"engineServiceFullName\" : \"Asset Analysis OMES\" , \"engineServiceURLMarker\" : \"asset-analysis\" , \"engineServiceDescription\" : \"Analyses the content of an asset's real world counterpart, generates annotations in an open discovery report that is attached to the asset in the open metadata repositories .\" , \"engineServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/engine-services/asset-analysis/\" , \"engines\" : [ { \"engineId\" : \"daff1dca-984b-4b8a-8a8f-febaf72b82a8\" , \"engineName\" : \"engine1\" , \"engineUserId\" : \"engine1UserId\" }, { \"engineId\" : \"a80aa0f8-2ea0-4f84-b613-d68becba2693\" , \"engineName\" : \"engine2\" , \"engineUserId\" : \"engine2UserId\" } ], \"engineServiceOperationalStatus\" : \"ENABLED\" , \"engineServiceAdminClass\" : \"org.odpi.openmetadata.engineservices.assetanalysis.admin.AssetAnalysisAdmin\" , \"omagserverPlatformRootURL\" : \"https://localhost:9443\" , \"omagserverName\" : \"myMetadataServer\" } ]}, \"repositoryServicesConfig\" : { \"class\" : \"RepositoryServicesConfig\" , \"auditLogConnections\" : [ { \"class\" : \"Connection\" , \"headerVersion\" : 0 , \"displayName\" : \"Console\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"headerVersion\" : 0 , \"type\" : { \"class\" : \"ElementType\" , \"headerVersion\" : 0 , \"elementOrigin\" : \"LOCAL_COHORT\" , \"elementVersion\" : 0 , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" }, \"guid\" : \"4afac741-3dcc-4c60-a4ca-a6dede994e3f\" , \"qualifiedName\" : \"Console Audit Log Store Connector\" , \"displayName\" : \"Console Audit Log Store Connector\" , \"description\" : \"Connector supports logging of audit log messages to stdout.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.auditlogstore.console.ConsoleAuditLogStoreProvider\" }, \"configurationProperties\" : { \"supportedSeverities\" : [ \"<Unknown>\" , \"Information\" , \"Event\" , \"Decision\" , \"Action\" , \"Error\" , \"Exception\" , \"Security\" , \"Startup\" , \"Shutdown\" , \"Asset\" , \"Types\" , \"Cohort\" ] } } ] }, \"auditTrail\" : [ \"Tue Dec 08 18:38:32 GMT 2020 me updated configuration for engine service asset-analysis.\" , \"Tue Dec 08 18:43:47 GMT 2020 me set up default audit log destinations.\" ] } } Configure the basic properties \u00b6 The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values. Set server type name \u00b6 The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\" Set organization name \u00b6 The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\" Set the server's user ID and optional password \u00b6 The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\" Set the maximum page size for REST API requests \u00b6 The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}} Configure the audit log \u00b6 Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination. Add audit log destinations \u00b6 There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations Remove audit logs \u00b6 The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none Configure the server security connector \u00b6 Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } } Determine configured security \u00b6 GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } } Remove configured security \u00b6 DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server. Configure the engine host services \u00b6 The engine host services provide the base implementation of the engine host OMAG Server. There are two parts to configuring the engine host services: Specify location of governance engine \u00b6 The location of the metadata access store (or metadata access point ) running the Governance Engine OMAS , which will supply the definitions of the governance engines that will run in the engine services, is configured using two properties: the server url root of the metadata server's OMAG Server Platform, and the name of the metadata server . POST - specify location of governance engine {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{engineHostServerName}}/engine-definitions/client-config With a request body like the following: { \"class\" : \"OMAGServerClientConfig\" , \"omagserverPlatformRootURL\" : {{ MDServerURLRoo t }}, \"omagserverName\" : \"{{MDServerName}}\" } Configure the engines services \u00b6 The engine services (or Open Metadata Engine Services ( OMES ) to give them their full name) also run in the engine host. Each engine service provides support for a particular type of governance engine: Open Discovery Engines Governance Action Engines Each engine service hosts one or more governance engines. A governance engine is a collection of governance services of a specific type: Asset analysis hosts open discovery services that analyze the content of an asset's real world counterpart, generates annotations in an open discovery analysis report that is attached to the asset in the open metadata repositories. Governance action hosts governance action services that monitor changes in the metadata and initiate updates and other actions as a result. List engine services \u00b6 It is possible to get a description of each of the registered engine services using the following command: GET - list engine services {{platformURLRoot}}/open-metadata/platform-services/users/{{userId}}/server-platform/registered-services/engine-services Note the engineServiceURLMarker for the engine service that you want to configure. Configure engine service \u00b6 The descriptive information and operational status are filled out automatically by the administration services based on the engineServiceURLMarker value that you supply. The other values are supplied on the configuration call. Each engine service is configured with the network location of the metadata access point / metadata access store running the appropriate OMAS . There are a set of options that the engine service supports along with the list of configuration properties for the governance engines that will be run in the engine service. The governance engine's configuration properties identify which governance engine to run. The governance engine's definition, including the services it supports are retrieved from the metadata access point / metadata server when the engine service starts up. POST - configure engine service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/engine-services/{{engineServiceURLMarker}} With a request body like the following: { \"class\" : \"EngineServiceRequestBody\" , \"omagserverPlatformRootURL\" : {{ MDServerURLRoo t }}, \"omagserverName\" : \"{{MDServerName}}\" , [ { \"class\" : \"EngineConfig\" , \"engineQualifiedName\" : \" ... \" \"engineUserId\" : \" ... \" } ] } Where: engineQualifiedName - set up the qualified name of the governance engine stored in the metadata servers. connectorUserId - set up the user id for the engine: if this is null, the engine host's userId is used on requests to the Open Metadata Access Service ( OMAS ). Further Information \u00b6 The definition of the governance services that are supported by these governance engines are retrieved from the open metadata server when the engine host server starts up. Maintaining these definitions is described: For discovery engines and services see Discovery Engine OMAS For governance action engines and services see Governance Engine OMAS Remove engine host services \u00b6 The following command removes the configuration for the engine host services from an OMAG Server's configuration document. This may be used if the engine host services have been added in error. DELETE - remove engine host services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{engineHostServerName}}/engine-host-services","title":"Configure Engine Host"},{"location":"guides/admin/servers/configuring-an-engine-host/#configuring-an-engine-host","text":"Each type of OMAG Server is configured by creating a configuration document . Example configuration of a minimal engine host server Below is an example of the configuration for a minimal engine host server. It has a single engine service ( Asset Analysis OMES ) and the default audit log. Both the Governance Engine OMAS used by the engine host services and the Discovery Engine OMAS used by the Asset Analysis OMES are running on the metadata server called myMetadataServer . { \"class\" : \"OMAGServerConfigResponse\" , \"relatedHTTPCode\" : 200 , \"omagserverConfig\" : { \"class\" : \"OMAGServerConfig\" , \"versionId\" : \"V2.0\" , \"localServerId\" : \"8b745d03-5ffc-4978-81ab-bd3d5156eebe\" , \"localServerName\" : \"myserver\" , \"localServerType\" : \"Open Metadata and Governance Server\" , \"localServerURL\" : \"https://localhost:9443\" , \"localServerUserId\" : \"OMAGServer\" , \"maxPageSize\" : 1000 , \"engineHostServicesConfig\" : { \"omagserverPlatformRootURL\" : \"https://localhost:9443\" , \"omagserverName\" : \"myMetadataServer\" , \"engineServices\" : [ { \"class\" : \"EngineServiceConfig\" , \"engineId\" : 6000 , \"engineQualifiedName\" : \"Asset Analysis\" , \"engineServiceFullName\" : \"Asset Analysis OMES\" , \"engineServiceURLMarker\" : \"asset-analysis\" , \"engineServiceDescription\" : \"Analyses the content of an asset's real world counterpart, generates annotations in an open discovery report that is attached to the asset in the open metadata repositories .\" , \"engineServiceWiki\" : \"https://egeria.odpi.org/open-metadata-implementation/engine-services/asset-analysis/\" , \"engines\" : [ { \"engineId\" : \"daff1dca-984b-4b8a-8a8f-febaf72b82a8\" , \"engineName\" : \"engine1\" , \"engineUserId\" : \"engine1UserId\" }, { \"engineId\" : \"a80aa0f8-2ea0-4f84-b613-d68becba2693\" , \"engineName\" : \"engine2\" , \"engineUserId\" : \"engine2UserId\" } ], \"engineServiceOperationalStatus\" : \"ENABLED\" , \"engineServiceAdminClass\" : \"org.odpi.openmetadata.engineservices.assetanalysis.admin.AssetAnalysisAdmin\" , \"omagserverPlatformRootURL\" : \"https://localhost:9443\" , \"omagserverName\" : \"myMetadataServer\" } ]}, \"repositoryServicesConfig\" : { \"class\" : \"RepositoryServicesConfig\" , \"auditLogConnections\" : [ { \"class\" : \"Connection\" , \"headerVersion\" : 0 , \"displayName\" : \"Console\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"headerVersion\" : 0 , \"type\" : { \"class\" : \"ElementType\" , \"headerVersion\" : 0 , \"elementOrigin\" : \"LOCAL_COHORT\" , \"elementVersion\" : 0 , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" }, \"guid\" : \"4afac741-3dcc-4c60-a4ca-a6dede994e3f\" , \"qualifiedName\" : \"Console Audit Log Store Connector\" , \"displayName\" : \"Console Audit Log Store Connector\" , \"description\" : \"Connector supports logging of audit log messages to stdout.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.auditlogstore.console.ConsoleAuditLogStoreProvider\" }, \"configurationProperties\" : { \"supportedSeverities\" : [ \"<Unknown>\" , \"Information\" , \"Event\" , \"Decision\" , \"Action\" , \"Error\" , \"Exception\" , \"Security\" , \"Startup\" , \"Shutdown\" , \"Asset\" , \"Types\" , \"Cohort\" ] } } ] }, \"auditTrail\" : [ \"Tue Dec 08 18:38:32 GMT 2020 me updated configuration for engine service asset-analysis.\" , \"Tue Dec 08 18:43:47 GMT 2020 me set up default audit log destinations.\" ] } }","title":"Configuring an engine host"},{"location":"guides/admin/servers/configuring-an-engine-host/#configure-the-basic-properties","text":"The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values.","title":"Configure the basic properties"},{"location":"guides/admin/servers/configuring-an-engine-host/#set-server-type-name","text":"The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\"","title":"Set server type name"},{"location":"guides/admin/servers/configuring-an-engine-host/#set-organization-name","text":"The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\"","title":"Set organization name"},{"location":"guides/admin/servers/configuring-an-engine-host/#set-the-servers-user-id-and-optional-password","text":"The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\"","title":"Set the server's user ID and optional password"},{"location":"guides/admin/servers/configuring-an-engine-host/#set-the-maximum-page-size-for-rest-api-requests","text":"The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}}","title":"Set the maximum page size for REST API requests"},{"location":"guides/admin/servers/configuring-an-engine-host/#configure-the-audit-log","text":"Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination.","title":"Configure the audit log"},{"location":"guides/admin/servers/configuring-an-engine-host/#add-audit-log-destinations","text":"There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations","title":"Add audit log destinations"},{"location":"guides/admin/servers/configuring-an-engine-host/#remove-audit-logs","text":"The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none","title":"Remove audit logs"},{"location":"guides/admin/servers/configuring-an-engine-host/#configure-the-server-security-connector","text":"Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } }","title":"Configure the server security connector"},{"location":"guides/admin/servers/configuring-an-engine-host/#determine-configured-security","text":"GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } }","title":"Determine configured security"},{"location":"guides/admin/servers/configuring-an-engine-host/#remove-configured-security","text":"DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server.","title":"Remove configured security"},{"location":"guides/admin/servers/configuring-an-engine-host/#configure-the-engine-host-services","text":"The engine host services provide the base implementation of the engine host OMAG Server. There are two parts to configuring the engine host services:","title":"Configure the engine host services"},{"location":"guides/admin/servers/configuring-an-engine-host/#specify-location-of-governance-engine","text":"The location of the metadata access store (or metadata access point ) running the Governance Engine OMAS , which will supply the definitions of the governance engines that will run in the engine services, is configured using two properties: the server url root of the metadata server's OMAG Server Platform, and the name of the metadata server . POST - specify location of governance engine {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{engineHostServerName}}/engine-definitions/client-config With a request body like the following: { \"class\" : \"OMAGServerClientConfig\" , \"omagserverPlatformRootURL\" : {{ MDServerURLRoo t }}, \"omagserverName\" : \"{{MDServerName}}\" }","title":"Specify location of governance engine"},{"location":"guides/admin/servers/configuring-an-engine-host/#configure-the-engines-services","text":"The engine services (or Open Metadata Engine Services ( OMES ) to give them their full name) also run in the engine host. Each engine service provides support for a particular type of governance engine: Open Discovery Engines Governance Action Engines Each engine service hosts one or more governance engines. A governance engine is a collection of governance services of a specific type: Asset analysis hosts open discovery services that analyze the content of an asset's real world counterpart, generates annotations in an open discovery analysis report that is attached to the asset in the open metadata repositories. Governance action hosts governance action services that monitor changes in the metadata and initiate updates and other actions as a result.","title":"Configure the engines services"},{"location":"guides/admin/servers/configuring-an-engine-host/#list-engine-services","text":"It is possible to get a description of each of the registered engine services using the following command: GET - list engine services {{platformURLRoot}}/open-metadata/platform-services/users/{{userId}}/server-platform/registered-services/engine-services Note the engineServiceURLMarker for the engine service that you want to configure.","title":"List engine services"},{"location":"guides/admin/servers/configuring-an-engine-host/#configure-engine-service","text":"The descriptive information and operational status are filled out automatically by the administration services based on the engineServiceURLMarker value that you supply. The other values are supplied on the configuration call. Each engine service is configured with the network location of the metadata access point / metadata access store running the appropriate OMAS . There are a set of options that the engine service supports along with the list of configuration properties for the governance engines that will be run in the engine service. The governance engine's configuration properties identify which governance engine to run. The governance engine's definition, including the services it supports are retrieved from the metadata access point / metadata server when the engine service starts up. POST - configure engine service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/engine-services/{{engineServiceURLMarker}} With a request body like the following: { \"class\" : \"EngineServiceRequestBody\" , \"omagserverPlatformRootURL\" : {{ MDServerURLRoo t }}, \"omagserverName\" : \"{{MDServerName}}\" , [ { \"class\" : \"EngineConfig\" , \"engineQualifiedName\" : \" ... \" \"engineUserId\" : \" ... \" } ] } Where: engineQualifiedName - set up the qualified name of the governance engine stored in the metadata servers. connectorUserId - set up the user id for the engine: if this is null, the engine host's userId is used on requests to the Open Metadata Access Service ( OMAS ).","title":"Configure engine service"},{"location":"guides/admin/servers/configuring-an-engine-host/#further-information","text":"The definition of the governance services that are supported by these governance engines are retrieved from the open metadata server when the engine host server starts up. Maintaining these definitions is described: For discovery engines and services see Discovery Engine OMAS For governance action engines and services see Governance Engine OMAS","title":"Further Information"},{"location":"guides/admin/servers/configuring-an-engine-host/#remove-engine-host-services","text":"The following command removes the configuration for the engine host services from an OMAG Server's configuration document. This may be used if the engine host services have been added in error. DELETE - remove engine host services {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{engineHostServerName}}/engine-host-services","title":"Remove engine host services"},{"location":"guides/admin/servers/configuring-an-integration-daemon/","text":"Configuring an integration daemon \u00b6 Each type of OMAG Server is configured by creating a configuration document . Configure the basic properties \u00b6 The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values. Set server type name \u00b6 The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\" Set organization name \u00b6 The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\" Set the server's user ID and optional password \u00b6 The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\" Set the maximum page size for REST API requests \u00b6 The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}} Configure the audit log \u00b6 Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination. Add audit log destinations \u00b6 There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations Remove audit logs \u00b6 The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none Configure the server security connector \u00b6 Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } } Determine configured security \u00b6 GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } } Remove configured security \u00b6 DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server. Configure the integration services \u00b6 The integration services (or Open Metadata Integration Services ( OMIS ) to give them their full name) run in an integration daemon . Each integration service hosts one or more integration connectors . An integration connector is responsible for the exchange of metadata with a specific deployment of a third party technology. For example, the database integrator integration service supports integration connectors that work with relational databases (RDBMS). A deployment of this integration service in an integration daemon may host, say, two integration connectors each loading metadata from their own relational database server. The descriptive information and operational status are filled out automatically by the administration services based on the integrationServiceURLMarker value that you supply. The other values are supplied on the configuration call. List integration services \u00b6 It is possible to get a description of each of the registered integration services using the following command: GET - list integration services {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/server-platform/registered-services/integration-services Note the integrationServiceURLMarker for the integration service that you want to configure. Configure an integration service \u00b6 Each integration service is configured with the network location of the metadata access point / metadata access store running the appropriate OMAS . There are a set of options that the integration service supports along with the list of configuration properties for the integration connectors that will be run in the integration service. The integration connector's configuration properties defines which connector implementation to use and how it should be operated. POST - configure an integration service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/integration-services/{{integrationServiceURLMarker}} With a request body like the following: { \"class\" : \"IntegrationServiceRequestBody\" , \"omagserverPlatformRootURL\" : \"{MDServerURLRoot}\" , \"omagserverName\" : \"{MDServerName}\" , \"integrationConnectorConfigs\" : [ { \"class\" : \"IntegrationConnectorConfig\" , \"connectorName\" : \" ... \" , \"connectorUserId\" : \" ... \" , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{connector provider class name}\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"...\" } }, \"metadataSourceQualifiedName\" : \" ... \" , \"refreshTimeInterval\" : \"60\" , \"usesBlockingCalls\" : \"false\" , \"permittedSynchronization\" : \" ... \" } ] } Detailed description of the properties: connectorName sets up the name of the connector. This name is used for routing refresh calls to the connector as well as being used for diagnostics. Ideally it should be unique amongst the connectors for the integration service. connectorUserId sets up the user id for the connector - if this is null, the integration daemon's userId is used on requests to the Open Metadata Access Service ( OMAS ). connection sets up the connection for the integration connector. metadataSourceQualifiedName sets up the qualified name of the metadata source for this integration connector. This is the qualified name of an appropriate software server capability stored in open metadata. This software server capability is accessed via the partner OMAS . refreshTimeInterval sets up the number of minutes between each call to the connector to refresh the metadata. Zero means that refresh is only called at server start up and whenever the refresh REST API request is made to the integration daemon. If the refresh time interval is greater than 0 then additional calls to refresh are added spaced out by the refresh time interval. usesBlockingCalls sets up whether the connector should be started in its own thread to allow it to block on a listening call. permittedSynchronization is an optional property that defines the permitted directions of metadata flow between the third party technology and open metadata. If the integration connector attempts to flow metadata in a direction that is not permitted, it receives the UserNotAuthorizedException . The default for this value is set up automatically in the integration service's descriptive information so this value only needs to be set if it is necessary to restrict the behavior of the connector. These are the different values for this property and their effect: TO_THIRD_PARTY - The third party technology is logically downstream of open metadata. This means the open metadata ecosystem is the originator and owner of the metadata being synchronized. Any updates detected in the third technology are overridden by the latest open metadata values. FROM_THIRD_PARTY - The third party technology is logically upstream (the originator and owner of the metadata). Any updates made in open metadata are not passed to the third party technology and the third party technology is requested to refresh the open metadata version. BOTH_DIRECTIONS - Metadata exchange is permitted in both directions. Synchronization is halted on a specific element if potentially clashing updates have occurred both in the third party technology and open metadata. Such conflicts are logged on the audit log and resolved through manual stewardship. Further information \u00b6 For help in fixing any error you find using the integration daemon, visit the integration daemon diagnostic guide . Link to the Egeria solutions to see the integration daemon in action. Link to the integration daemon services to understand how the integration daemon is implemented.","title":"Configure Integration Daemon"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#configuring-an-integration-daemon","text":"Each type of OMAG Server is configured by creating a configuration document .","title":"Configuring an integration daemon"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#configure-the-basic-properties","text":"The basic properties of the OMAG Server are used in logging and events originating from the server. They help to document the purpose of the server (which helps with problem determination) and enable performance improvements by allowing the server to ignore activity or metadata that is not relevant to its operation. The basic properties include two unique identifiers: Property Description localServerId Unique identifier for this server. By default, this is initialized to a randomly generated Universal Unique identifier (UUID). localServerName Meaningful name for the server for use in messages and UIs. Ideally this value is unique to aid administrators in understanding the source of messages and events from the server. This value is set to the server name assigned when the configuration is created. The other basic properties have values that can be changed through the admin services API: Property Description localServerType Descriptive type name for the server. Again this is useful information for the administrator to understand the role of the server. The default value is Open Metadata and Governance Server . organizationName Descriptive name for the organization that owns the local server/repository. This is useful when the open metadata repository cluster consists of metadata servers from different organizations, or different departments of an enterprise. The default value is null . localServerUserId UserId to use for server-initiated REST calls. The default is OMAGServer . localServerPassword Password to use for server-initiated REST calls. The default is null . This means that only the userId is sent in the HTTP header. maxPageSize The maximum page size that can be set on requests to the server. The default value is 1000 . A value of zero means unlimited page size. Although supported, the zero value is not recommended because it provides no protection from a large request denial of service attack. The sections that follow cover how to set up these values.","title":"Configure the basic properties"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#set-server-type-name","text":"The server type name should be set to something that describes the OMAG Server's role. It may be the name of a specific product that it is enabling, or a role in the metadata and governance landscape. POST - set server type {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-type?typeName=\"{{serverTypeName}}\"","title":"Set server type name"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#set-organization-name","text":"The organization name may be the owning organization or department or team supported by the server. POST - set organization name {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/organization-name?name=\"{{organizationName}}\"","title":"Set organization name"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#set-the-servers-user-id-and-optional-password","text":"The server's user ID is used when processing requests that do not have an end user, such as receiving an event from a topic. The default value is OMAGServer . Ideally each server should have its own user ID so it is possible to restrict the resources that each server has access to. If the password is specified as well, the userId and password combination are used to provide authentication information on each REST call made by the server. POST - set server's userId {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-id?id=\"{{serverUserId}}\" POST - set server's password {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/server-user-password?password=\"{{serverUserPassword}}\"","title":"Set the server's user ID and optional password"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#set-the-maximum-page-size-for-rest-api-requests","text":"The maximum page size value sets an upper limit on the number of results that a caller can request on any paging REST API to this server. Setting maximum page size helps to prevent a denial of service attack that uses very large requests to overwhelm the server. A value of 0 means no limit, and leaves the server open to such attacks. POST - set maximum page size {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/max-page-size?limit={{maxPageSize}}","title":"Set the maximum page size for REST API requests"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#configure-the-audit-log","text":"Egeria's audit log provides a configurable set of destinations for audit records and other diagnostic logging for an OMAG Server . Some destinations also support a query interface to allow an administrator to understand how the server is running. If the server is a development or test server, then the default audit log configuration is probably sufficient: the console audit log destination. POST - set default audit log destination {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/default Using this option overrides all previous audit log destinations. If this server is a production server then you will probably want to set up the audit log destinations explicitly. You can add multiple destinations and each one can be set up to process specific severities of log records. The audit log severities are as follows: Severity Description Information The server is providing information about its normal operation. Event An event was received from another member of the open metadata repository cohort. Decision A decision has been made related to the interaction of the local metadata repository and the rest of the cohort. Action An Action is required by the administrator. At a minimum, the situation needs to be investigated and if necessary, corrective action taken. Error An error occurred, possibly caused by an incompatibility between the local metadata repository and one of the remote repositories. The local repository may restrict some of the metadata interchange functions as a result. Exception An unexpected exception occurred. This means that the server needs some administration attention to correct configuration or fix a logic error because it is not operating as a proper peer in the open metadata repository cohort. Security Unauthorized access to a service or metadata instance has been attempted. Startup A new component is starting up. Shutdown An existing component is shutting down. Asset An auditable action relating to an asset has been taken. Types Activity is occurring that relates to the open metadata types in use by this server. Cohort The server is exchanging registration information about an open metadata repository cohort that it is connecting to. Trace This is additional information on the operation of the server that may be of assistance in debugging a problem. It is not normally logged to any destination, but can be added when needed. PerfMon This log record contains performance monitoring timing information for specific types of processing. It is not normally logged to any destination, but can be added when needed. <Unknown> Uninitialized Severity The body of the request should be a list of severities If an empty list is passed as the request body then all severities are supported by the destination.","title":"Configure the audit log"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#add-audit-log-destinations","text":"There are various destinations that can be configured for the audit log: console POST - add console audit log destination This writes selected parts of each audit log record to stdout. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/console slf4j POST - add slf4j audit log destination This writes full log records to the slf4j ecosystem. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/slf4j When configuring slf4j as destination you also need to specify auditlog logger category via the application properties. This is described in Connecting the OMAG Audit Log Framework section of the developer logging guide. file POST - add JSON file-based audit log destination This writes JSON files in a shared directory. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/files event POST - add event-based audit log destination This writes each log record as an event on the supplied event topic. It assumes that the event bus is set up first. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/event-topic connection POST - add connection-based audit log destination This sets up an audit log destination that is described though a connection . In this case, the connection is passed in the request body and the supported severities can be supplied in the connection's configuration properties. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/connection list POST - add a list of connection-based audit log destinations It is also possible to set up the audit log destinations as a list of connections. Using this option overrides all previous audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations","title":"Add audit log destinations"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#remove-audit-logs","text":"The following will remove all audit log destinations: POST - clear all audit log destinations Clears the list of audit log destinations from the configuration enabling you to add a new set of audit log destinations. {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/audit-log-destinations/none","title":"Remove audit logs"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#configure-the-server-security-connector","text":"Metadata that is being aggregated from different sources is likely to need comprehensive access controls. Egeria provides fine-grained security control for metadata access . It is implemented in a server security connector that is called whenever requests are made for to the server. Security is configured for a specific OMAG Server by adding a connection for this connector to the server's configuration document using the following command. POST - configure security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This passes in a connection used to create the server security connector in the request body. { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } Example: set up the sample server security connector For example, this is the connection that would set up the sample server security connector provided for the Coco Pharmaceuticals case study: { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.metadatasecurity.samples.OpenMetadataServerSecurityProvider\" } }","title":"Configure the server security connector"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#determine-configured-security","text":"GET - query the server security connector setting {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection Response indicating no security { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 } Response indicating a specific security connector If the response looks more like the JSON below, a connector is configured. The connectorProviderClassName tells you which connector is being used. { \"class\" : \"ConnectionResponse\" , \"relatedHTTPCode\" : 200 , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{fullyQualifiedJavaClassName}\" } } }","title":"Determine configured security"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#remove-configured-security","text":"DELETE - remove configured security connector {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/security/connection This removes all authorization checking from the server.","title":"Remove configured security"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#configure-the-integration-services","text":"The integration services (or Open Metadata Integration Services ( OMIS ) to give them their full name) run in an integration daemon . Each integration service hosts one or more integration connectors . An integration connector is responsible for the exchange of metadata with a specific deployment of a third party technology. For example, the database integrator integration service supports integration connectors that work with relational databases (RDBMS). A deployment of this integration service in an integration daemon may host, say, two integration connectors each loading metadata from their own relational database server. The descriptive information and operational status are filled out automatically by the administration services based on the integrationServiceURLMarker value that you supply. The other values are supplied on the configuration call.","title":"Configure the integration services"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#list-integration-services","text":"It is possible to get a description of each of the registered integration services using the following command: GET - list integration services {{platformURLRoot}}/open-metadata/platform-services/users/{{adminUserId}}/server-platform/registered-services/integration-services Note the integrationServiceURLMarker for the integration service that you want to configure.","title":"List integration services"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#configure-an-integration-service","text":"Each integration service is configured with the network location of the metadata access point / metadata access store running the appropriate OMAS . There are a set of options that the integration service supports along with the list of configuration properties for the integration connectors that will be run in the integration service. The integration connector's configuration properties defines which connector implementation to use and how it should be operated. POST - configure an integration service {{platformURLRoot}}/open-metadata/admin-services/users/{{adminUserId}}/servers/{{serverName}}/integration-services/{{integrationServiceURLMarker}} With a request body like the following: { \"class\" : \"IntegrationServiceRequestBody\" , \"omagserverPlatformRootURL\" : \"{MDServerURLRoot}\" , \"omagserverName\" : \"{MDServerName}\" , \"integrationConnectorConfigs\" : [ { \"class\" : \"IntegrationConnectorConfig\" , \"connectorName\" : \" ... \" , \"connectorUserId\" : \" ... \" , \"connection\" : { \"class\" : \"Connection\" , \"connectorType\" : { \"class\" : \"ConnectorType\" , \"connectorProviderClassName\" : \"{connector provider class name}\" }, \"endpoint\" : { \"class\" : \"Endpoint\" , \"address\" : \"...\" } }, \"metadataSourceQualifiedName\" : \" ... \" , \"refreshTimeInterval\" : \"60\" , \"usesBlockingCalls\" : \"false\" , \"permittedSynchronization\" : \" ... \" } ] } Detailed description of the properties: connectorName sets up the name of the connector. This name is used for routing refresh calls to the connector as well as being used for diagnostics. Ideally it should be unique amongst the connectors for the integration service. connectorUserId sets up the user id for the connector - if this is null, the integration daemon's userId is used on requests to the Open Metadata Access Service ( OMAS ). connection sets up the connection for the integration connector. metadataSourceQualifiedName sets up the qualified name of the metadata source for this integration connector. This is the qualified name of an appropriate software server capability stored in open metadata. This software server capability is accessed via the partner OMAS . refreshTimeInterval sets up the number of minutes between each call to the connector to refresh the metadata. Zero means that refresh is only called at server start up and whenever the refresh REST API request is made to the integration daemon. If the refresh time interval is greater than 0 then additional calls to refresh are added spaced out by the refresh time interval. usesBlockingCalls sets up whether the connector should be started in its own thread to allow it to block on a listening call. permittedSynchronization is an optional property that defines the permitted directions of metadata flow between the third party technology and open metadata. If the integration connector attempts to flow metadata in a direction that is not permitted, it receives the UserNotAuthorizedException . The default for this value is set up automatically in the integration service's descriptive information so this value only needs to be set if it is necessary to restrict the behavior of the connector. These are the different values for this property and their effect: TO_THIRD_PARTY - The third party technology is logically downstream of open metadata. This means the open metadata ecosystem is the originator and owner of the metadata being synchronized. Any updates detected in the third technology are overridden by the latest open metadata values. FROM_THIRD_PARTY - The third party technology is logically upstream (the originator and owner of the metadata). Any updates made in open metadata are not passed to the third party technology and the third party technology is requested to refresh the open metadata version. BOTH_DIRECTIONS - Metadata exchange is permitted in both directions. Synchronization is halted on a specific element if potentially clashing updates have occurred both in the third party technology and open metadata. Such conflicts are logged on the audit log and resolved through manual stewardship.","title":"Configure an integration service"},{"location":"guides/admin/servers/configuring-an-integration-daemon/#further-information","text":"For help in fixing any error you find using the integration daemon, visit the integration daemon diagnostic guide . Link to the Egeria solutions to see the integration daemon in action. Link to the integration daemon services to understand how the integration daemon is implemented.","title":"Further information"},{"location":"guides/contributor/guidelines/","text":"Coding Guidelines \u00b6 Egeria provides technology for an open standard that seeks to improve the processing and protection of data across organizations. For its developers, this carries the benefit that their work receives high recognition, but also additional responsibilities to ensure its wide applicability and longevity. For example, Egeria seeks a broad audience - from developers to adopting vendors to consuming users. Building this audience and allowing the community to scale requires clarity in the way the software is written, documented, packaged and used. Many of the guidelines seek to make it easier for someone new to pick up the software, at the expense of maybe a little more work, or a little less freedom of action for the original developer. As such, these guidelines exist to remind us of these broader responsibilities. Build environment \u00b6 The core of Egeria is written primarily in Java , and the minimum level required to build and run it is 11. Most developers use MacOS, while our official builds use Linux (Ubuntu/Centos/RHEL should all be fine). Windows is unsupported The traditional Windows environment is not directly supported. It is recommended to use WSL2 which offers a full Linux environment. Apache Maven is used to control the builds, and 3.5 or higher is required to build Egeria (3.6.x or above is recommended). Gradle is not currently supported but is being developed. IDEs can make navigating the Egeria code easier. Each IDE can vary a lot. Many of our team use JetBrains IntelliJ . In the case of problems the first problem determination step is to check you can build Egeria normally at the command line i.e. mvn clean install from the source root. That will prove at least Java and Maven are correct. Set JAVA_HOME We have also noticed that you need to ensure JAVA_HOME is set or the build will fail running Javadoc. Eliminate any build warnings \u00b6 Build output should be checked for any warnings, i.e. [WARNING] , and these should be eliminated. The Java compiler is set to use -Xlint:all and may report warnings about deprecated function, unsafe casts, unchecked conversions, and so on -- all of which should be addressed. Other tools used in the build may also result in warnings which should also be addressed, whilst test cases should ensure output is captured to avoid such warnings appear in the build logs. Include license in every file \u00b6 All files for Egeria should have a license included. We use the SPDX encoding to keep the headers simple. License header for documentation ( .md ) 1 2 <!-- SPDX-License-Identifier: CC-BY-4.0 --> <!-- Copyright Contributors to the Egeria project. --> Note that we no longer need to include an explicit footer in documentation files, as this is already included in the overall documentation site as the footer of every page. License header for XML files ( .xml ) 1 2 3 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!-- SPDX-License-Identifier: Apache-2.0 --> <!-- Copyright Contributors to the Egeria project. --> License header for Java code ( .java ) 1 2 /* SPDX-License-Identifier: Apache-2.0 */ /* Copyright Contributors to the Egeria project. */ Document \u00b6 Although all code for Egeria should be clear and easy to read, the code itself can only describe what it is doing: it can rarely describe why it is doing it. Also, the Egeria codebase is quite large and hard to digest in one go. Having summaries of its behavior and philosophy helps people to understand its capability faster. README.md \u00b6 Each directory (apart from Java packages) should have a README.md file that describes the content of the directory. These files are displayed automatically by GitHub when the directory is accessed and this helps someone to understand the structure while navigating through the directories. The exception is that directories representing Java packages do not need README files because they are covered by Javadoc. Javadoc \u00b6 Javadoc is used to build a code reference for our public site. It is generated as part of the build. There are three places where Javadoc should be provided by the developer of Java code: Every Java source file should begin with a header Javadoc tag just before the start of the class/interface/enum, which explains the purpose and responsibilities of the code. All public methods should have a clear Javadoc header describing the purpose, parameters and results (including exceptions). This includes test cases. Each Java package should include a package-info.java file describing the purpose of the package and its content. Java code files may have additional comments, particularly where the processing is complex. The most useful comments are those that describe the purpose, or intent of the code, rather than a description of what each line of code is doing. The output from a build should be checked to ensure there are no Javadoc warnings: for example about undocumented parameters or exceptions. Log through ALF \u00b6 Egeria will typically be embedded in complex deployment environments. This means that we cannot rely on standard developer logging provided by components such as SLF4J. Instead, we use First Failure Data Capture (FFDC) through the Audit Log Framework ( ALF ) . Be consistent with style and layout \u00b6 There are many coding and layout styles that provide clear and readable code. Developers can choose the layout they prefer but with the following restrictions / suggestions: Try to use full words rather than abbreviations or shortened versions of a word for names such as class names, method names and variable names. Cryptic names create more effort for the reader to follow the code. Use the same style throughout a file. If changing an existing file, use the same style and layout as the original developer. Do not impose your own style in the middle of the code since the inconsistency that you introduce makes the whole file harder to read. It should not be possible to see where you have made the changes once the code is committed into git. For Java unit tests use /src/test/java folder of the module (standard Maven location), and postfix Java file names for tests with the word Test . Dates and times \u00b6 In Egeria, date / time instants are always represented as Unix Epoch time with millisecond precision (milliseconds elapsed since January 1, 1970). The Egeria OMRS layer handles date / time as either java.lang.Long or as java.util.Date objects. It does not store localised versions of the date / time. In other Egeria APIs that might be developed, it is strongly recommended to store dates and times as a Long or Date. In addition, it is possible to expose localised date representations if required. Write tests \u00b6 Egeria is an integration technology which means that it uses a comprehensive multi-level approach to testing. Modules include unit tests. These unit tests should focus on simple validation of Java beans, utilities and code that can easily be tested in isolation. The unit tests run as part of the build and a pull request cannot be incorporated into master if any unit tests are failing. They should not significantly extend the time of the build since this impacts all the contributors' productivity. Our preferred Java frameworks for unit testing are TestNG and Mockito . External APIs (typically they include both a client and a server component) are tested using functional verification tests (FVTs). These are located in the open-metadata-test/open-metadata-fvt module. The aim of these tests is to check that the APIs validate all of their parameters and function correctly in a single server environment. These tests also operate as part of the build but are not run as part of the PR process. Modules should ensure they include some FVTs as they move from development to technical preview . By the time the module is moving to released function, the FVTs should be able to validate that this function is stable and correct. Some connectors are tested via the Conformance Test Suite . If you deliver a connector that is covered by this test suite, you should run the tests before merging changes into master. The conformance test suite is also run as part of the release process. Egeria's hands on labs provide a complex multi-server environment and are typically used by contributors to verify that their changes have not regressed any of the basic function. We are also interested in building out a comprehensive integration test to allow automated complex multi-server scenarios that can be running continuously. Sign commits to accept DCO \u00b6 We have tried to make it as easy as possible to make contributions. This applies to how we handle the legal aspects of contribution. We simply ask that when submitting a patch for review, the developer must include a sign-off statement in the commit message. This is the same approach that the Linux\u00ae Kernel community uses to manage code contributions. Here is an example Signed-off-by line, which indicates that the submitter accepts the DCO: Signed-off-by: John Doe <john.doe@hisdomain.com> You can include this automatically when you commit a change to your local git repository using: Include DCO automatically when committing changes $ git commit -s By signing your work, you are confirming that the origin of the content makes it suitable to add to this project. See Developer Certificate of Origin (DCO) . Review code changes \u00b6 If you are asked to review a code change it will be located in a pull request ( PR ) on one of Egeria's git repositories . Within the pull requests are a number of commits that describe the changes to particular files that will be made when the pull request is merged into the repository. As a reviewer, you need to look at the code changes and satisfy yourself that: The code change is neat and readable and follows the code style of the rest of the module. The logic is clear and there are comments if the logic is complex. The code does not have any obvious defects - such as likely to cause a NullPointerException . There are no uses of log.error() for logging errors that are not accompanied by an equivalent message to the audit log. If new dependencies have been added, these are documented in the developer resources. If changes to the types have been made, these changes are: only made to the current release's types (that is, in OpenMetadataTypesArchive.java ). It is permissible to correct typos in the other files but not change the shape of the types in the types created in previous releases (in files called OpenMetadataTypesArchiveX_X.java ). documented in UML diagrams in the drawio files and the diagram has been exported as an image. If you are also the code owner of the changed code then you also need to be sure that the changes are consistent with the current and intended future design of the module. Create samples \u00b6 Postman artifacts for APIs \u00b6 We tend to use Postman to test the various API endpoints we develop in Egeria. As such, there are a number of samples we make available for anyone to use for testing or otherwise becoming familiar with the Egeria APIs. Disable SSL verification in Postman Egeria by default uses https:// requests with a self-signed certificate. Any Postman users therefore will need to go into Settings -> General and turn off SSL certificate verification or requests will fail. When developing a new API in Egeria, you may want to make similar samples available to both provide examples of using the API and for basic testing purposes. These should be developed as follows: Wherever possible, re-use the environment variables that are already defined in Egeria.postman_environment.json . If you need another variable that is not already defined, add it to this environment definition. This way we have a single environment definition that covers all possible sample configurations. Create a Postman Collection that includes REST samples for your API. Name it using the convention Egeria-<area>-<operations> where <area> represents the unique area of your API (for example the name of an OMAS ) and <operations> can optionally be used to distinguish between multiple collections that may be useful for different purposes (e.g. read vs. write operations). Consider adding test scripts to your collection to check expected values, if you intend to use them for testing purposes. Once ready for sharing, export the collection into a file and commit your collection into GitHub wherever is most appropriate for the anticipated users of the samples. Create a descriptive entry in postman-rest-samples/README.md under a sub-section of the Sample Collections heading, linking to your new collection within GitHub. Use the existing samples defined there for guidance: provide a limited introductory description to any pre-requisites for your collection, if it needs to be run after some other collection define these in a sequence, etc. If your description for use requires more than 1-2 simple sentences, consider linking to more detailed instructions rather than putting these all into the general README . (See samples where we link out to more information on loading Coco Pharmaceuticals samples rather than embedding all of this detail directly in the one README .) Within your descriptive entry, link to your collection. Following the other examples, provide a link to the raw file so that the link itself can be copy / pasted into Postman (without needing to download the file and then import it). In this way, anyone wanting access to the REST samples of Egeria has a single place from which to find them, while those working in a particular area of Egeria can still find the appropriate samples for that area directly within the area of interest. Manage dependencies \u00b6 New dependencies must only be introduced with the agreement of the broader community. These include frameworks, utility classes, annotations and external packages. This may seem annoying but there are good reasons for this: The Egeria code needs to be embeddable in different vendor products. This is made easier by keeping the code libraries we are dependent on to the minimum in order to avoid conflicts with libraries a consuming vendor may have already chosen, or where it needs to be embedded in an environment where certain dependencies may not be available. As developers, we have legal obligations to ensure we only use appropriately licensed software in our work and part of the discussion related a new dependency is to understand its license. Some projects may provide useful functionality but are only supported by one person who may get bored with it, or no longer have the time to support it. We should aim to build on dependent libraries that are backed by a strong community or vendor. Each library function, or set of annotations, adds to the learning curve of new people joining the team. By only bringing in the really beneficial libraries we ensure that the complexity they see relates only to the complexity of the problem space, rather than the additional complexity we have introduced in pursuit of playing with new functions. Each additional library extends the code footprint on which Egeria is based, and this inevitably extends the potential security exposure footprint. Limiting the libraries we use allows us to more quickly focus on resolving any potential security concerns (CVEs) any particular library may introduce. If a developer wishes to introduce a new dependency to the Egeria project, they should prepare a short guide (in a markdown file) that explains the value of the new library, how it is to be used and links to more information. They should then present their recommendation to the community and if agreed by the community, store the guide in the developer resources. Once in place, the dependency should be maintained across the smallest appropriate number of modules, and should be consistent throughout: particularly when it may impact consuming technologies. General rules \u00b6 Calls to third party technology that Egeria is integrating must be isolated into connectors so that they are optional. Try to use standard Java and Egeria's existing dependencies where possible - consider carefully if a new dependency is needed. Always define the dependency at the lowest-level pom.xml where it's needed. Use a current non-beta version of a dependency. Check build output carefully for any dependency warnings and errors. Do not add any exceptions to the existing rules without discussion with other maintainers. slf4j and bindings \u00b6 Any utility, sample, tool or other applications (like the server chassis) that have an entry point (typically main() ) should include a binding for slf4j . Use logback when possible (for example, ch.qos.logback:logback-classic ). Do not provide a configuration file: default formatting will be used and can be overriden by logback configuration at deployment time. Test code automatically includes slf4j-simple - a simple logging implementation Other code that forms libraries (most of our code) must not include a slf4j logging implementation. Otherwise, the application loses control of the logging implementation, hidden config files can change behavior, and a multiple_bindings issue will be raised by slf4j . Understanding dependencies \u00b6 Running mvn dependency:tree is a useful way to understand what dependencies (direct and transitive) a module has. Adding a new dependency \u00b6 Check if the dependency is already listed in the top-level pom.xml . If not, add a section such as the following within the <dependencyManagement> section of the top-level pom.xml : Example dependency entry in top-level pom.xml 1 2 3 4 5 6 <dependency> <groupId> org.apache.kafka </groupId> <artifactId> kafka-clients </artifactId> <scope> compile </scope> <version> ${kafka.version} </version> </dependency> This declaration only means that if a dependency is used, these are the defaults to use -- most critically including version, though scope is a useful default to add, too: for example if the dependency is only for tests. Add the dependency to the <dependency> section of your module's pom.xml : Example dependency entry in module's pom.xml 1 2 3 4 <dependency> <groupId> org.apache.kafka </groupId> <artifactId> kafka-clients </artifactId> </dependency> Note that the version is not included - it will be picked up from <dependencyManagement> . Now build to include some checks for correct usage of dependencies (see below): Build Egeria mvn clean install More on scopes Most dependencies will be of scope compile (used for build and runtime), or test (for test tools). There are other scopes available that you may want to use in specific circumstances . Build time checks \u00b6 The top-level pom.xml defines checks that are run in reference to dependencies: the maven dependency plugin analyze-only goal is used to check that any dependencies referred to in the object code are declared as dependencies, and that any not used are not. Any discrepancies will be reported as part of the build. Occasionally exceptions may be required, generally for dependencies that are only needed at runtime. the maven dependency plugin analyze-dep-mgt goal is used to check all dependencies declared are of the same version as that in dependencyManagement in the top-level pom.xml the maven enforcer plugin enforce goal is used with the following rules: reactorModuleConvergence checks for correct parent/child relationships and inconsistency requireUpperBoundDeps checks that minimum versions are satisfied for all transitive dependencies. If any of these checks fail an appropriate message will be displayed and the build will fail. Incompatible versions In some cases where incompatible versions are reported, it may be due to transitive dependencies: for example a component the Egeria code does not depend on directly, but only indirectly. The path to resolve the version could result in different versions being used, or at least attempted, then failing. To resolve this a reference can be added in <dependencyManagement> to specify the version to use. Maintain security \u00b6 Egeria's dependencies are scanned for potential CVEs automatically in two main ways: GitHub scans dependencies for known CVEs. A weekly Nexus CLM scan is run. The maintainers will review these regularly and action any required changes through issues and pull requests. Egeria code itself is also scanned for vulnerabilities using Sonar . Any developer can perform similar checks by running: Perform security scans mvn clean install -DfindBugs This will run (and create a file for each module): Goal(s) Output file(s) spotBugs including findsecbugs spotBugsXml.xml pmd pmd.xml OWASP dependency checker dependency-check-report.html May take more than an hour Note that the scan may take a long time - an hour or more for all checks. Handling memory requirements If running against all components (i.e. from the root) an invocation like the following may be needed due to the memory requirements of a security scan: Run with additional memory MAVEN_OPTS=\"-Xmx5000M -Xss512M -XX:MaxPermSize=2048M -XX:+CMSClassUnloadingEnabled -XX:+UseConcMarkSweepGC\" mvn clean install -DfindBugs For more information on how potential security issues are handled, see security hardening .","title":"Coding Guidelines"},{"location":"guides/contributor/guidelines/#coding-guidelines","text":"Egeria provides technology for an open standard that seeks to improve the processing and protection of data across organizations. For its developers, this carries the benefit that their work receives high recognition, but also additional responsibilities to ensure its wide applicability and longevity. For example, Egeria seeks a broad audience - from developers to adopting vendors to consuming users. Building this audience and allowing the community to scale requires clarity in the way the software is written, documented, packaged and used. Many of the guidelines seek to make it easier for someone new to pick up the software, at the expense of maybe a little more work, or a little less freedom of action for the original developer. As such, these guidelines exist to remind us of these broader responsibilities.","title":"Coding Guidelines"},{"location":"guides/contributor/guidelines/#build-environment","text":"The core of Egeria is written primarily in Java , and the minimum level required to build and run it is 11. Most developers use MacOS, while our official builds use Linux (Ubuntu/Centos/RHEL should all be fine). Windows is unsupported The traditional Windows environment is not directly supported. It is recommended to use WSL2 which offers a full Linux environment. Apache Maven is used to control the builds, and 3.5 or higher is required to build Egeria (3.6.x or above is recommended). Gradle is not currently supported but is being developed. IDEs can make navigating the Egeria code easier. Each IDE can vary a lot. Many of our team use JetBrains IntelliJ . In the case of problems the first problem determination step is to check you can build Egeria normally at the command line i.e. mvn clean install from the source root. That will prove at least Java and Maven are correct. Set JAVA_HOME We have also noticed that you need to ensure JAVA_HOME is set or the build will fail running Javadoc.","title":"Build environment"},{"location":"guides/contributor/guidelines/#eliminate-any-build-warnings","text":"Build output should be checked for any warnings, i.e. [WARNING] , and these should be eliminated. The Java compiler is set to use -Xlint:all and may report warnings about deprecated function, unsafe casts, unchecked conversions, and so on -- all of which should be addressed. Other tools used in the build may also result in warnings which should also be addressed, whilst test cases should ensure output is captured to avoid such warnings appear in the build logs.","title":"Eliminate any build warnings"},{"location":"guides/contributor/guidelines/#include-license-in-every-file","text":"All files for Egeria should have a license included. We use the SPDX encoding to keep the headers simple. License header for documentation ( .md ) 1 2 <!-- SPDX-License-Identifier: CC-BY-4.0 --> <!-- Copyright Contributors to the Egeria project. --> Note that we no longer need to include an explicit footer in documentation files, as this is already included in the overall documentation site as the footer of every page. License header for XML files ( .xml ) 1 2 3 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!-- SPDX-License-Identifier: Apache-2.0 --> <!-- Copyright Contributors to the Egeria project. --> License header for Java code ( .java ) 1 2 /* SPDX-License-Identifier: Apache-2.0 */ /* Copyright Contributors to the Egeria project. */","title":"Include license in every file"},{"location":"guides/contributor/guidelines/#document","text":"Although all code for Egeria should be clear and easy to read, the code itself can only describe what it is doing: it can rarely describe why it is doing it. Also, the Egeria codebase is quite large and hard to digest in one go. Having summaries of its behavior and philosophy helps people to understand its capability faster.","title":"Document"},{"location":"guides/contributor/guidelines/#readmemd","text":"Each directory (apart from Java packages) should have a README.md file that describes the content of the directory. These files are displayed automatically by GitHub when the directory is accessed and this helps someone to understand the structure while navigating through the directories. The exception is that directories representing Java packages do not need README files because they are covered by Javadoc.","title":"README.md"},{"location":"guides/contributor/guidelines/#javadoc","text":"Javadoc is used to build a code reference for our public site. It is generated as part of the build. There are three places where Javadoc should be provided by the developer of Java code: Every Java source file should begin with a header Javadoc tag just before the start of the class/interface/enum, which explains the purpose and responsibilities of the code. All public methods should have a clear Javadoc header describing the purpose, parameters and results (including exceptions). This includes test cases. Each Java package should include a package-info.java file describing the purpose of the package and its content. Java code files may have additional comments, particularly where the processing is complex. The most useful comments are those that describe the purpose, or intent of the code, rather than a description of what each line of code is doing. The output from a build should be checked to ensure there are no Javadoc warnings: for example about undocumented parameters or exceptions.","title":"Javadoc"},{"location":"guides/contributor/guidelines/#log-through-alf","text":"Egeria will typically be embedded in complex deployment environments. This means that we cannot rely on standard developer logging provided by components such as SLF4J. Instead, we use First Failure Data Capture (FFDC) through the Audit Log Framework ( ALF ) .","title":"Log through ALF"},{"location":"guides/contributor/guidelines/#be-consistent-with-style-and-layout","text":"There are many coding and layout styles that provide clear and readable code. Developers can choose the layout they prefer but with the following restrictions / suggestions: Try to use full words rather than abbreviations or shortened versions of a word for names such as class names, method names and variable names. Cryptic names create more effort for the reader to follow the code. Use the same style throughout a file. If changing an existing file, use the same style and layout as the original developer. Do not impose your own style in the middle of the code since the inconsistency that you introduce makes the whole file harder to read. It should not be possible to see where you have made the changes once the code is committed into git. For Java unit tests use /src/test/java folder of the module (standard Maven location), and postfix Java file names for tests with the word Test .","title":"Be consistent with style and layout"},{"location":"guides/contributor/guidelines/#dates-and-times","text":"In Egeria, date / time instants are always represented as Unix Epoch time with millisecond precision (milliseconds elapsed since January 1, 1970). The Egeria OMRS layer handles date / time as either java.lang.Long or as java.util.Date objects. It does not store localised versions of the date / time. In other Egeria APIs that might be developed, it is strongly recommended to store dates and times as a Long or Date. In addition, it is possible to expose localised date representations if required.","title":"Dates and times"},{"location":"guides/contributor/guidelines/#write-tests","text":"Egeria is an integration technology which means that it uses a comprehensive multi-level approach to testing. Modules include unit tests. These unit tests should focus on simple validation of Java beans, utilities and code that can easily be tested in isolation. The unit tests run as part of the build and a pull request cannot be incorporated into master if any unit tests are failing. They should not significantly extend the time of the build since this impacts all the contributors' productivity. Our preferred Java frameworks for unit testing are TestNG and Mockito . External APIs (typically they include both a client and a server component) are tested using functional verification tests (FVTs). These are located in the open-metadata-test/open-metadata-fvt module. The aim of these tests is to check that the APIs validate all of their parameters and function correctly in a single server environment. These tests also operate as part of the build but are not run as part of the PR process. Modules should ensure they include some FVTs as they move from development to technical preview . By the time the module is moving to released function, the FVTs should be able to validate that this function is stable and correct. Some connectors are tested via the Conformance Test Suite . If you deliver a connector that is covered by this test suite, you should run the tests before merging changes into master. The conformance test suite is also run as part of the release process. Egeria's hands on labs provide a complex multi-server environment and are typically used by contributors to verify that their changes have not regressed any of the basic function. We are also interested in building out a comprehensive integration test to allow automated complex multi-server scenarios that can be running continuously.","title":"Write tests"},{"location":"guides/contributor/guidelines/#sign-commits-to-accept-dco","text":"We have tried to make it as easy as possible to make contributions. This applies to how we handle the legal aspects of contribution. We simply ask that when submitting a patch for review, the developer must include a sign-off statement in the commit message. This is the same approach that the Linux\u00ae Kernel community uses to manage code contributions. Here is an example Signed-off-by line, which indicates that the submitter accepts the DCO: Signed-off-by: John Doe <john.doe@hisdomain.com> You can include this automatically when you commit a change to your local git repository using: Include DCO automatically when committing changes $ git commit -s By signing your work, you are confirming that the origin of the content makes it suitable to add to this project. See Developer Certificate of Origin (DCO) .","title":"Sign commits to accept DCO"},{"location":"guides/contributor/guidelines/#review-code-changes","text":"If you are asked to review a code change it will be located in a pull request ( PR ) on one of Egeria's git repositories . Within the pull requests are a number of commits that describe the changes to particular files that will be made when the pull request is merged into the repository. As a reviewer, you need to look at the code changes and satisfy yourself that: The code change is neat and readable and follows the code style of the rest of the module. The logic is clear and there are comments if the logic is complex. The code does not have any obvious defects - such as likely to cause a NullPointerException . There are no uses of log.error() for logging errors that are not accompanied by an equivalent message to the audit log. If new dependencies have been added, these are documented in the developer resources. If changes to the types have been made, these changes are: only made to the current release's types (that is, in OpenMetadataTypesArchive.java ). It is permissible to correct typos in the other files but not change the shape of the types in the types created in previous releases (in files called OpenMetadataTypesArchiveX_X.java ). documented in UML diagrams in the drawio files and the diagram has been exported as an image. If you are also the code owner of the changed code then you also need to be sure that the changes are consistent with the current and intended future design of the module.","title":"Review code changes"},{"location":"guides/contributor/guidelines/#create-samples","text":"","title":"Create samples"},{"location":"guides/contributor/guidelines/#postman-artifacts-for-apis","text":"We tend to use Postman to test the various API endpoints we develop in Egeria. As such, there are a number of samples we make available for anyone to use for testing or otherwise becoming familiar with the Egeria APIs. Disable SSL verification in Postman Egeria by default uses https:// requests with a self-signed certificate. Any Postman users therefore will need to go into Settings -> General and turn off SSL certificate verification or requests will fail. When developing a new API in Egeria, you may want to make similar samples available to both provide examples of using the API and for basic testing purposes. These should be developed as follows: Wherever possible, re-use the environment variables that are already defined in Egeria.postman_environment.json . If you need another variable that is not already defined, add it to this environment definition. This way we have a single environment definition that covers all possible sample configurations. Create a Postman Collection that includes REST samples for your API. Name it using the convention Egeria-<area>-<operations> where <area> represents the unique area of your API (for example the name of an OMAS ) and <operations> can optionally be used to distinguish between multiple collections that may be useful for different purposes (e.g. read vs. write operations). Consider adding test scripts to your collection to check expected values, if you intend to use them for testing purposes. Once ready for sharing, export the collection into a file and commit your collection into GitHub wherever is most appropriate for the anticipated users of the samples. Create a descriptive entry in postman-rest-samples/README.md under a sub-section of the Sample Collections heading, linking to your new collection within GitHub. Use the existing samples defined there for guidance: provide a limited introductory description to any pre-requisites for your collection, if it needs to be run after some other collection define these in a sequence, etc. If your description for use requires more than 1-2 simple sentences, consider linking to more detailed instructions rather than putting these all into the general README . (See samples where we link out to more information on loading Coco Pharmaceuticals samples rather than embedding all of this detail directly in the one README .) Within your descriptive entry, link to your collection. Following the other examples, provide a link to the raw file so that the link itself can be copy / pasted into Postman (without needing to download the file and then import it). In this way, anyone wanting access to the REST samples of Egeria has a single place from which to find them, while those working in a particular area of Egeria can still find the appropriate samples for that area directly within the area of interest.","title":"Postman artifacts for APIs"},{"location":"guides/contributor/guidelines/#manage-dependencies","text":"New dependencies must only be introduced with the agreement of the broader community. These include frameworks, utility classes, annotations and external packages. This may seem annoying but there are good reasons for this: The Egeria code needs to be embeddable in different vendor products. This is made easier by keeping the code libraries we are dependent on to the minimum in order to avoid conflicts with libraries a consuming vendor may have already chosen, or where it needs to be embedded in an environment where certain dependencies may not be available. As developers, we have legal obligations to ensure we only use appropriately licensed software in our work and part of the discussion related a new dependency is to understand its license. Some projects may provide useful functionality but are only supported by one person who may get bored with it, or no longer have the time to support it. We should aim to build on dependent libraries that are backed by a strong community or vendor. Each library function, or set of annotations, adds to the learning curve of new people joining the team. By only bringing in the really beneficial libraries we ensure that the complexity they see relates only to the complexity of the problem space, rather than the additional complexity we have introduced in pursuit of playing with new functions. Each additional library extends the code footprint on which Egeria is based, and this inevitably extends the potential security exposure footprint. Limiting the libraries we use allows us to more quickly focus on resolving any potential security concerns (CVEs) any particular library may introduce. If a developer wishes to introduce a new dependency to the Egeria project, they should prepare a short guide (in a markdown file) that explains the value of the new library, how it is to be used and links to more information. They should then present their recommendation to the community and if agreed by the community, store the guide in the developer resources. Once in place, the dependency should be maintained across the smallest appropriate number of modules, and should be consistent throughout: particularly when it may impact consuming technologies.","title":"Manage dependencies"},{"location":"guides/contributor/guidelines/#general-rules","text":"Calls to third party technology that Egeria is integrating must be isolated into connectors so that they are optional. Try to use standard Java and Egeria's existing dependencies where possible - consider carefully if a new dependency is needed. Always define the dependency at the lowest-level pom.xml where it's needed. Use a current non-beta version of a dependency. Check build output carefully for any dependency warnings and errors. Do not add any exceptions to the existing rules without discussion with other maintainers.","title":"General rules"},{"location":"guides/contributor/guidelines/#slf4j-and-bindings","text":"Any utility, sample, tool or other applications (like the server chassis) that have an entry point (typically main() ) should include a binding for slf4j . Use logback when possible (for example, ch.qos.logback:logback-classic ). Do not provide a configuration file: default formatting will be used and can be overriden by logback configuration at deployment time. Test code automatically includes slf4j-simple - a simple logging implementation Other code that forms libraries (most of our code) must not include a slf4j logging implementation. Otherwise, the application loses control of the logging implementation, hidden config files can change behavior, and a multiple_bindings issue will be raised by slf4j .","title":"slf4j and bindings"},{"location":"guides/contributor/guidelines/#understanding-dependencies","text":"Running mvn dependency:tree is a useful way to understand what dependencies (direct and transitive) a module has.","title":"Understanding dependencies"},{"location":"guides/contributor/guidelines/#adding-a-new-dependency","text":"Check if the dependency is already listed in the top-level pom.xml . If not, add a section such as the following within the <dependencyManagement> section of the top-level pom.xml : Example dependency entry in top-level pom.xml 1 2 3 4 5 6 <dependency> <groupId> org.apache.kafka </groupId> <artifactId> kafka-clients </artifactId> <scope> compile </scope> <version> ${kafka.version} </version> </dependency> This declaration only means that if a dependency is used, these are the defaults to use -- most critically including version, though scope is a useful default to add, too: for example if the dependency is only for tests. Add the dependency to the <dependency> section of your module's pom.xml : Example dependency entry in module's pom.xml 1 2 3 4 <dependency> <groupId> org.apache.kafka </groupId> <artifactId> kafka-clients </artifactId> </dependency> Note that the version is not included - it will be picked up from <dependencyManagement> . Now build to include some checks for correct usage of dependencies (see below): Build Egeria mvn clean install More on scopes Most dependencies will be of scope compile (used for build and runtime), or test (for test tools). There are other scopes available that you may want to use in specific circumstances .","title":"Adding a new dependency"},{"location":"guides/contributor/guidelines/#build-time-checks","text":"The top-level pom.xml defines checks that are run in reference to dependencies: the maven dependency plugin analyze-only goal is used to check that any dependencies referred to in the object code are declared as dependencies, and that any not used are not. Any discrepancies will be reported as part of the build. Occasionally exceptions may be required, generally for dependencies that are only needed at runtime. the maven dependency plugin analyze-dep-mgt goal is used to check all dependencies declared are of the same version as that in dependencyManagement in the top-level pom.xml the maven enforcer plugin enforce goal is used with the following rules: reactorModuleConvergence checks for correct parent/child relationships and inconsistency requireUpperBoundDeps checks that minimum versions are satisfied for all transitive dependencies. If any of these checks fail an appropriate message will be displayed and the build will fail. Incompatible versions In some cases where incompatible versions are reported, it may be due to transitive dependencies: for example a component the Egeria code does not depend on directly, but only indirectly. The path to resolve the version could result in different versions being used, or at least attempted, then failing. To resolve this a reference can be added in <dependencyManagement> to specify the version to use.","title":"Build time checks"},{"location":"guides/contributor/guidelines/#maintain-security","text":"Egeria's dependencies are scanned for potential CVEs automatically in two main ways: GitHub scans dependencies for known CVEs. A weekly Nexus CLM scan is run. The maintainers will review these regularly and action any required changes through issues and pull requests. Egeria code itself is also scanned for vulnerabilities using Sonar . Any developer can perform similar checks by running: Perform security scans mvn clean install -DfindBugs This will run (and create a file for each module): Goal(s) Output file(s) spotBugs including findsecbugs spotBugsXml.xml pmd pmd.xml OWASP dependency checker dependency-check-report.html May take more than an hour Note that the scan may take a long time - an hour or more for all checks. Handling memory requirements If running against all components (i.e. from the root) an invocation like the following may be needed due to the memory requirements of a security scan: Run with additional memory MAVEN_OPTS=\"-Xmx5000M -Xss512M -XX:MaxPermSize=2048M -XX:+CMSClassUnloadingEnabled -XX:+UseConcMarkSweepGC\" mvn clean install -DfindBugs For more information on how potential security issues are handled, see security hardening .","title":"Maintain security"},{"location":"guides/contributor/languages/","text":"Programming Languages \u00b6 Java \u00b6 Egeria's runtime and clients are written in Java. Java is a strongly-typed, compiled language. The resulting object code runs in a virtual machine called the Java Virtual Machine ( JVM ). The JVM is supported on most operating systems and so Java programs can run with the same behavior on almost any machine. This portability of code is why Java is used for the Egeria runtime (the OMAG Server Platform ) and the clients. If you want to run Egeria you need to install the Java Runtime Environment ( JRE ). To build and test Egeria, you need the Java Development Kit ( JDK ) installed. The JDK also contains the runtime environment ( JRE ). There are various JDK 's available, and you may even have one pre-installed on your system. Check for a pre-installed Java java -version Egeria requires Java 11 as a minimum level. Language constructs up to Java 11 are permitted, but not above. We use the Adoptium (formerly AdoptOpenJDK) distribution. Official images and maven artifacts are built with this level. Additionally, code must compile and run on the current latest Java release. This is validated before any code can be merged. Java can be installed by: Downloading the OpenJDK 11 (LTS) HotSpot JVM from Adoptium . Running the installer that is downloaded. Alternatively, JDK 's may be found on your operating system install repositories or via third party tools like HomeBrew on MacOS. Also, you must ensure JAVA_HOME is set, and pointing to a JDK . If this is not done, an error such as Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:3.1.1:jar (attach-javadocs) on project open-connector-framework: MavenReportException: Error while generating Javadoc: Unable to find javadoc command: The environment variable JAVA_HOME is not correctly set. will be seen as the Javadoc Maven plugin depends on this value to work correctly. Python \u00b6 Python is used in much of the educational material . Python is an interpreted programming language. It is favored by data scientists and script writers because it supports writing in snippets where variables can be created on the fly and are typically global. Egeria uses Python in the hands-on labs since it is the native language of the Jupyter Notebooks environment we use for the labs. Markdown \u00b6 Markdown is a simple tagging language that generates HTML webpages. We use it for documentation (this page is written in Markdown for example), in GitHub comments and in the Jupyter Notebooks that form the teaching material for the hand-on labs . GitHub provides a useful summary for Markdown and our own documentation guide provides Egeria-specific formatting and stylistic pointers, as well as further information on the system we use to translate such .md files into the website you are currently reading.","title":"Languages"},{"location":"guides/contributor/languages/#programming-languages","text":"","title":"Programming Languages"},{"location":"guides/contributor/languages/#java","text":"Egeria's runtime and clients are written in Java. Java is a strongly-typed, compiled language. The resulting object code runs in a virtual machine called the Java Virtual Machine ( JVM ). The JVM is supported on most operating systems and so Java programs can run with the same behavior on almost any machine. This portability of code is why Java is used for the Egeria runtime (the OMAG Server Platform ) and the clients. If you want to run Egeria you need to install the Java Runtime Environment ( JRE ). To build and test Egeria, you need the Java Development Kit ( JDK ) installed. The JDK also contains the runtime environment ( JRE ). There are various JDK 's available, and you may even have one pre-installed on your system. Check for a pre-installed Java java -version Egeria requires Java 11 as a minimum level. Language constructs up to Java 11 are permitted, but not above. We use the Adoptium (formerly AdoptOpenJDK) distribution. Official images and maven artifacts are built with this level. Additionally, code must compile and run on the current latest Java release. This is validated before any code can be merged. Java can be installed by: Downloading the OpenJDK 11 (LTS) HotSpot JVM from Adoptium . Running the installer that is downloaded. Alternatively, JDK 's may be found on your operating system install repositories or via third party tools like HomeBrew on MacOS. Also, you must ensure JAVA_HOME is set, and pointing to a JDK . If this is not done, an error such as Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:3.1.1:jar (attach-javadocs) on project open-connector-framework: MavenReportException: Error while generating Javadoc: Unable to find javadoc command: The environment variable JAVA_HOME is not correctly set. will be seen as the Javadoc Maven plugin depends on this value to work correctly.","title":"Java"},{"location":"guides/contributor/languages/#python","text":"Python is used in much of the educational material . Python is an interpreted programming language. It is favored by data scientists and script writers because it supports writing in snippets where variables can be created on the fly and are typically global. Egeria uses Python in the hands-on labs since it is the native language of the Jupyter Notebooks environment we use for the labs.","title":"Python"},{"location":"guides/contributor/languages/#markdown","text":"Markdown is a simple tagging language that generates HTML webpages. We use it for documentation (this page is written in Markdown for example), in GitHub comments and in the Jupyter Notebooks that form the teaching material for the hand-on labs . GitHub provides a useful summary for Markdown and our own documentation guide provides Egeria-specific formatting and stylistic pointers, as well as further information on the system we use to translate such .md files into the website you are currently reading.","title":"Markdown"},{"location":"guides/contributor/process/","text":"Way of Working \u00b6 Issues \u00b6 Egeria uses GitHub issues . Opening issues \u00b6 Issues can be opened by any GitHub user, and are used for a variety of purposes: Problems getting Egeria working Proposed new features Identification of a bug Suggested process change Or really anything that affects Egeria All PRs should have an associated issue to facilitate discussion. You should include a helpful abstract and as many notes as possible about what you see, what you've tried, your environment, any logs, what you expected to happen, etc. Triaging new issues \u00b6 New issues are triaged by maintainers , who will: Assign the issue to someone who can take care of what is reported - even if not the final owner Assign a milestone if it is immediately obvious that the issue relates to capability set out in a release plan, or is needed very soon, otherwise leave blank Assign relevant tags to the issue Working on issues \u00b6 The issue owner (assignee) will then: Update the issue as soon as possible with an initial response When raising a PR , refer to the issue number (e.g. #1234 ) so that the discussion is clearly linked with the proposed code change. Use Fixes #1234 if this PR will completely address the issue, so that GitHub will automatically close the issue when the PR is merged. Keep the milestone realistic, if set Regularly review outstanding issues and update, reassign, close as needed Closing issues \u00b6 Issues with PRs marked as fixes #1234 will close automatically when the PR is merged Other issues fixed in other ways should be closed manually Any issues open after 60 days with no activity (including assignments) will have a comment added saying they will be closed 20 days later the issue will be closed If an issue is closed accidentally or prematurely, reopen and add appropriate comments Release process \u00b6 New releases can be created by Egeria maintainers that have the appropriate access on each GitHub repository. Releases are published to Maven Central . Overall release policy \u00b6 Aim to release approximately every month Typically, target end of month for external availability Will only release an update between releases in exceptional circumstances Preserves backwards compatibility as much as possible Try and maintain a regular heartbeat: even if completion of some features continues in a subsequent release master kept open for new code features Obtaining releases / artifacts \u00b6 Location Usage Maven Central typically used by other developers integrating with our code Github Release source code in zip and tar.gz formats git git checkout Vx.y to get version as-shipped (each release is tagged at the point it is shipped) Release notes are available as part of the online documentation . Release process \u00b6 1. Agree schedule Agree on appropriate dates for branching given expected duration for testing, vacation / public holidays Typically, allow 1-2 weeks between branching and availability Communicate with team on regular calls, and via #egeria-github on Slack In the last week before branching discuss holding off on any big changes in master that could destabilize the codebase 2. Track remaining issues and PRs Ensure any required issues / PRs for the release have the correct milestone set Move any issues / PRs not expected to make / not required for the release to a future milestone Aim to branch when most issues / PRs are complete to minimize back-porting from master, but not at the expense of impacting ongoing master development Agree final branch date / criteria 3. Create branch Checkout master git checkout master Ensure local update git pull upstream master Create branch git branch egeria-release-x.y Push to upstream git push upstream egeria-release-x.y 4. Update master from x.y-SNAPSHOT to x.z-SNAPSHOT git checkout master git pull upstream master Edit all files (command line or IDE) to replace x.y-SNAPSHOT with the next version, e.g. change 1.3-SNAPSHOT to 3.1-SNAPSHOT . Most of the changes are in pom.xml files, however some code and documentation also has references to our versions and all need modifying. If using an IDE like IntelliJ, make sure you have all hits by searching again as by default only a limited number of hits are shown . Commit Now remove all the release notes from the release-notes directory other than README.md - so users will always get directed to the latest in master Commit Create a PR , have reviewed / approved and merged as usual - aim to do this as quickly as reasonable so that there is no potential for version clash 5. Test, merge any remaining required changes into branch Run appropriate tests for the release. For example, in addition to automated tests: check notebooks, run the CTS and check for compliance, check the user interface. Raise issues for any changes required as usual Note that approval is required for changes going into a release branch PR builds are run as usual; however, merge builds, Sonar, etc do not run To backport changes from master , first wait until the PR is merged into master , then use git cherrypick -s <commithash> to apply to egeria-release-x.y , then push as usual. In some cases a merge commit will need to be made using git cherrypick -s -m 1 <commithash> If code has diverged significantly a manual recode may be easiest 6. Update branch's release version from x.y-SNAPSHOT to x.y Aim to make this change when the code appears to be ready to ship apart from final tests in order to avoid version confusion git checkout egeria-release-x.y git pull upstream egeria-release-x.y Edit all files (command line or IDE) to replace x.y-SNAPSHOT with x.y , i.e. removing the -SNAPSHOT designation. Most of the changes are in pom.xml files; however, some code and documentation also has references to our versions and all need modifying. Commit, and do not make any other changes. Create a PR , have reviewed / approved and merged as usual 7. Create a release in GitHub Create the GitHub release . Use Vx.y as the tag, and ensure the correct branch is set for the target, i.e. egeria-release-x.y Fill in the release notes using a title of Release x.y and copy the notes from the appropriate release notes Artifacts will be available on Maven Central within around half a day. Source archives will be added to the release on GitHub within an hour or so. Security hardening \u00b6 As part of developing Egeria, we will inevitably come across areas identified by various code analysis tools as potential security vulnerabilities. The following guidelines define the way we will work with these (identifying, reporting, tracking, etc) as well as some common techniques we can apply to address them. The maintainers have a weekly call to triage identified vulnerabilities from various sources: Sonar scans Nexus IQ scans Any third party inputs (i.e. from consumers) -- which can be sent to us at egeria-security@lists.lfaidata.foundation Work can then begin on resolving them, with two potential options (depending on complexity): Quick to resolve: create an issue when we believe we have a fix, and link the PR with the fix to the issue For any we cannot quickly resolve, we will use GitHub's security advisories to capture the details and notify publicly about the potential vulnerability In general, any vulnerabilities will typically be addressed through one of the following techniques: Code changes \u00b6 When the code identified as having a potential vulnerability is our own, we should naturally investigate how to change our code in order to reduce or remove the impact or likelihood of that exposure. This could be through applying input or output validation of data we receive, or ensuring that we use features built-in to any external components to do such processing. Dependency exclusions \u00b6 External modules on which we depend often have their own set of embedded dependencies. Some of these transitive dependencies may have vulnerabilities, and we may not actually use any of the functionality they provide. In these cases, we can (and should) safely exclude these transitive dependencies as part of the POM dependency management. Example: excluding a transitive dependency from a dependent library For example, testng has a dependency on the snakeyaml library, but this is only used when configuring testng with YAML documents (which we do not do). We can therefore safely exclude the transitive snakeyaml dependency of testng using the following in the root-level pom.xml : 1 2 3 4 5 6 7 8 9 10 11 12 13 <dependency> <groupId> org.testng </groupId> <artifactId> testng </artifactId> <scope> test </scope> <version> 7.1.0 </version> <exclusions> <!-- Exclude snakeyaml, which has open CVEs and is unused --> <exclusion> <groupId> org.yaml </groupId> <artifactId> snakeyaml </artifactId> </exclusion> </exclusions> </dependency> Forced dependency version updates \u00b6 In other cases we actually do rely on the functionality provided by these transitive dependencies, so we cannot simply exclude them. However, it may be possible to force the version of these dependencies to be updated so that a vulnerable older version of the dependency (the minimal version on which the library depends) is not used by default. Example: forcing an updated version of a transitive dependency Take for example janusgraph -- it has a transitive dependency on the sleepycat library, and by default quite an old version which has some known problems. By adding an explicit dependency for a newer version of the sleepycat module we can force this newer version to be used by janusgraph as well. <dependency> <groupId> com.sleepycat </groupId> <artifactId> je </artifactId> <version> 18.3.12 </version> </dependency> Of course making this change requires testing, to ensure that the newer version of the transitive library is still compatible with the base dependency. Feature branches \u00b6 The standard development approach for Egeria is to: make code changes on a branch on one's own fork create a PR to push from this branch to master Most of the time these are coded by a single developer, with additional review / testing from peers as part of the PR process. On occasion a few developers may directly collaborate on the code changes and can pull / push to / from each other's branches, or share updates in other ways. master therefore always represents the \"best so far\" code, ideally in a \"ready to release\" state, through build automation, testing and peer pressure. Everyone benefits from the latest code changes and any divergence between a developer's environment and master is minimized. Sometimes, however, there is a need to coordinate a larger piece of work in a team of developers who need the ability to: Reduce the impact of changes on master - i.e. for everyone else Reduce the impact of constant updates from master, in order to have a stable environment for feature-oriented testing In these cases a feature branch may be proposed. A GitHub issue should be created, and the proposal discussed in one of the regular Egeria calls to build consensus around the need for such a branch. Feature branches add overhead They can lead to code divergence and complexity, and they will only be created in compelling circumstances for long-running feature work. Once agreed, one of the maintainers / admins will make the required setup. See the last section of this document for some more information on this. Working in a feature branch \u00b6 Any work specifically and solely for the feature should be done on the agreed branch, but it's important that normal defect fixes and enhancements to unrelated features should continue to be worked on via master : i.e. working on a dev's own fork for a short period (hours/days) and merged back to master . This helps other developers working on the project, and reduces the complexity of subsequent merges from the feature branch. The team working on the feature will need to arrange / agree their own builds for testing / deployment. Merging to master and releasing \u00b6 We do not release from a feature branch. All release branches are made from master . It is the feature team's responsibility to: Merge the latest code from master Merge feature branch back to master There's no set schedule for this. Longer intervals offers the feature more stability, but can rapidly build up a much more complex merge scenario which the feature team will need to resolve. It is the feature team's responsibility to respond to any issues in master , and to validate that the feature is \"good\". Administrative tasks \u00b6 These tasks should only be performed by someone familiar with the process and with appropriate authority after establishing team agreement. As such, exact commands are not given below: Creating a branch Create a feature branch named feature-XXX where XXX is a descriptive name for the feature. (With issues, using the issue number can be helpful, but since we expect a small number of feature branches, this seems clearer.) Ensure branch protections are set to the same as master , to ensure all changes follow the same process as for master: for example, must go via PRs. Builds It's expected that all Feature branches should have PR verification to ensure submitted code changes in a PR do not break the main build. This is purely a compilation test to check against breakage. Build artifacts are not distributed or saved. Features could benefit from a 'merge' build which ensures the latest code in the branch works well together. This build also typically generates: - Maven artifacts (to a snapshot repository) - Docker images (to Docker Hub) In the future, it's expected these will get used for automatic tests, and used by other deployment approaches such as Docker Compose and Kubernetes. However, currently our repository and naming / versioning setup is not able to do this since branch names are not taken into account. In Egeria we also may perform: Scans for code quality Scans for licensing Security-related scans Builds for Docker images other than core Egeria These will also not be done for a feature branch. Closing a feature branch \u00b6 When the feature branch is no longer required, it can be deleted by an admin. Similarly to requesting a feature branch, an issue should be raised, and team agreement sought beforehand.","title":"Way of Working"},{"location":"guides/contributor/process/#way-of-working","text":"","title":"Way of Working"},{"location":"guides/contributor/process/#issues","text":"Egeria uses GitHub issues .","title":"Issues"},{"location":"guides/contributor/process/#opening-issues","text":"Issues can be opened by any GitHub user, and are used for a variety of purposes: Problems getting Egeria working Proposed new features Identification of a bug Suggested process change Or really anything that affects Egeria All PRs should have an associated issue to facilitate discussion. You should include a helpful abstract and as many notes as possible about what you see, what you've tried, your environment, any logs, what you expected to happen, etc.","title":"Opening issues"},{"location":"guides/contributor/process/#triaging-new-issues","text":"New issues are triaged by maintainers , who will: Assign the issue to someone who can take care of what is reported - even if not the final owner Assign a milestone if it is immediately obvious that the issue relates to capability set out in a release plan, or is needed very soon, otherwise leave blank Assign relevant tags to the issue","title":"Triaging new issues"},{"location":"guides/contributor/process/#working-on-issues","text":"The issue owner (assignee) will then: Update the issue as soon as possible with an initial response When raising a PR , refer to the issue number (e.g. #1234 ) so that the discussion is clearly linked with the proposed code change. Use Fixes #1234 if this PR will completely address the issue, so that GitHub will automatically close the issue when the PR is merged. Keep the milestone realistic, if set Regularly review outstanding issues and update, reassign, close as needed","title":"Working on issues"},{"location":"guides/contributor/process/#closing-issues","text":"Issues with PRs marked as fixes #1234 will close automatically when the PR is merged Other issues fixed in other ways should be closed manually Any issues open after 60 days with no activity (including assignments) will have a comment added saying they will be closed 20 days later the issue will be closed If an issue is closed accidentally or prematurely, reopen and add appropriate comments","title":"Closing issues"},{"location":"guides/contributor/process/#release-process","text":"New releases can be created by Egeria maintainers that have the appropriate access on each GitHub repository. Releases are published to Maven Central .","title":"Release process"},{"location":"guides/contributor/process/#overall-release-policy","text":"Aim to release approximately every month Typically, target end of month for external availability Will only release an update between releases in exceptional circumstances Preserves backwards compatibility as much as possible Try and maintain a regular heartbeat: even if completion of some features continues in a subsequent release master kept open for new code features","title":"Overall release policy"},{"location":"guides/contributor/process/#obtaining-releases-artifacts","text":"Location Usage Maven Central typically used by other developers integrating with our code Github Release source code in zip and tar.gz formats git git checkout Vx.y to get version as-shipped (each release is tagged at the point it is shipped) Release notes are available as part of the online documentation .","title":"Obtaining releases / artifacts"},{"location":"guides/contributor/process/#release-process_1","text":"1. Agree schedule Agree on appropriate dates for branching given expected duration for testing, vacation / public holidays Typically, allow 1-2 weeks between branching and availability Communicate with team on regular calls, and via #egeria-github on Slack In the last week before branching discuss holding off on any big changes in master that could destabilize the codebase 2. Track remaining issues and PRs Ensure any required issues / PRs for the release have the correct milestone set Move any issues / PRs not expected to make / not required for the release to a future milestone Aim to branch when most issues / PRs are complete to minimize back-porting from master, but not at the expense of impacting ongoing master development Agree final branch date / criteria 3. Create branch Checkout master git checkout master Ensure local update git pull upstream master Create branch git branch egeria-release-x.y Push to upstream git push upstream egeria-release-x.y 4. Update master from x.y-SNAPSHOT to x.z-SNAPSHOT git checkout master git pull upstream master Edit all files (command line or IDE) to replace x.y-SNAPSHOT with the next version, e.g. change 1.3-SNAPSHOT to 3.1-SNAPSHOT . Most of the changes are in pom.xml files, however some code and documentation also has references to our versions and all need modifying. If using an IDE like IntelliJ, make sure you have all hits by searching again as by default only a limited number of hits are shown . Commit Now remove all the release notes from the release-notes directory other than README.md - so users will always get directed to the latest in master Commit Create a PR , have reviewed / approved and merged as usual - aim to do this as quickly as reasonable so that there is no potential for version clash 5. Test, merge any remaining required changes into branch Run appropriate tests for the release. For example, in addition to automated tests: check notebooks, run the CTS and check for compliance, check the user interface. Raise issues for any changes required as usual Note that approval is required for changes going into a release branch PR builds are run as usual; however, merge builds, Sonar, etc do not run To backport changes from master , first wait until the PR is merged into master , then use git cherrypick -s <commithash> to apply to egeria-release-x.y , then push as usual. In some cases a merge commit will need to be made using git cherrypick -s -m 1 <commithash> If code has diverged significantly a manual recode may be easiest 6. Update branch's release version from x.y-SNAPSHOT to x.y Aim to make this change when the code appears to be ready to ship apart from final tests in order to avoid version confusion git checkout egeria-release-x.y git pull upstream egeria-release-x.y Edit all files (command line or IDE) to replace x.y-SNAPSHOT with x.y , i.e. removing the -SNAPSHOT designation. Most of the changes are in pom.xml files; however, some code and documentation also has references to our versions and all need modifying. Commit, and do not make any other changes. Create a PR , have reviewed / approved and merged as usual 7. Create a release in GitHub Create the GitHub release . Use Vx.y as the tag, and ensure the correct branch is set for the target, i.e. egeria-release-x.y Fill in the release notes using a title of Release x.y and copy the notes from the appropriate release notes Artifacts will be available on Maven Central within around half a day. Source archives will be added to the release on GitHub within an hour or so.","title":"Release process"},{"location":"guides/contributor/process/#security-hardening","text":"As part of developing Egeria, we will inevitably come across areas identified by various code analysis tools as potential security vulnerabilities. The following guidelines define the way we will work with these (identifying, reporting, tracking, etc) as well as some common techniques we can apply to address them. The maintainers have a weekly call to triage identified vulnerabilities from various sources: Sonar scans Nexus IQ scans Any third party inputs (i.e. from consumers) -- which can be sent to us at egeria-security@lists.lfaidata.foundation Work can then begin on resolving them, with two potential options (depending on complexity): Quick to resolve: create an issue when we believe we have a fix, and link the PR with the fix to the issue For any we cannot quickly resolve, we will use GitHub's security advisories to capture the details and notify publicly about the potential vulnerability In general, any vulnerabilities will typically be addressed through one of the following techniques:","title":"Security hardening"},{"location":"guides/contributor/process/#code-changes","text":"When the code identified as having a potential vulnerability is our own, we should naturally investigate how to change our code in order to reduce or remove the impact or likelihood of that exposure. This could be through applying input or output validation of data we receive, or ensuring that we use features built-in to any external components to do such processing.","title":"Code changes"},{"location":"guides/contributor/process/#dependency-exclusions","text":"External modules on which we depend often have their own set of embedded dependencies. Some of these transitive dependencies may have vulnerabilities, and we may not actually use any of the functionality they provide. In these cases, we can (and should) safely exclude these transitive dependencies as part of the POM dependency management. Example: excluding a transitive dependency from a dependent library For example, testng has a dependency on the snakeyaml library, but this is only used when configuring testng with YAML documents (which we do not do). We can therefore safely exclude the transitive snakeyaml dependency of testng using the following in the root-level pom.xml : 1 2 3 4 5 6 7 8 9 10 11 12 13 <dependency> <groupId> org.testng </groupId> <artifactId> testng </artifactId> <scope> test </scope> <version> 7.1.0 </version> <exclusions> <!-- Exclude snakeyaml, which has open CVEs and is unused --> <exclusion> <groupId> org.yaml </groupId> <artifactId> snakeyaml </artifactId> </exclusion> </exclusions> </dependency>","title":"Dependency exclusions"},{"location":"guides/contributor/process/#forced-dependency-version-updates","text":"In other cases we actually do rely on the functionality provided by these transitive dependencies, so we cannot simply exclude them. However, it may be possible to force the version of these dependencies to be updated so that a vulnerable older version of the dependency (the minimal version on which the library depends) is not used by default. Example: forcing an updated version of a transitive dependency Take for example janusgraph -- it has a transitive dependency on the sleepycat library, and by default quite an old version which has some known problems. By adding an explicit dependency for a newer version of the sleepycat module we can force this newer version to be used by janusgraph as well. <dependency> <groupId> com.sleepycat </groupId> <artifactId> je </artifactId> <version> 18.3.12 </version> </dependency> Of course making this change requires testing, to ensure that the newer version of the transitive library is still compatible with the base dependency.","title":"Forced dependency version updates"},{"location":"guides/contributor/process/#feature-branches","text":"The standard development approach for Egeria is to: make code changes on a branch on one's own fork create a PR to push from this branch to master Most of the time these are coded by a single developer, with additional review / testing from peers as part of the PR process. On occasion a few developers may directly collaborate on the code changes and can pull / push to / from each other's branches, or share updates in other ways. master therefore always represents the \"best so far\" code, ideally in a \"ready to release\" state, through build automation, testing and peer pressure. Everyone benefits from the latest code changes and any divergence between a developer's environment and master is minimized. Sometimes, however, there is a need to coordinate a larger piece of work in a team of developers who need the ability to: Reduce the impact of changes on master - i.e. for everyone else Reduce the impact of constant updates from master, in order to have a stable environment for feature-oriented testing In these cases a feature branch may be proposed. A GitHub issue should be created, and the proposal discussed in one of the regular Egeria calls to build consensus around the need for such a branch. Feature branches add overhead They can lead to code divergence and complexity, and they will only be created in compelling circumstances for long-running feature work. Once agreed, one of the maintainers / admins will make the required setup. See the last section of this document for some more information on this.","title":"Feature branches"},{"location":"guides/contributor/process/#working-in-a-feature-branch","text":"Any work specifically and solely for the feature should be done on the agreed branch, but it's important that normal defect fixes and enhancements to unrelated features should continue to be worked on via master : i.e. working on a dev's own fork for a short period (hours/days) and merged back to master . This helps other developers working on the project, and reduces the complexity of subsequent merges from the feature branch. The team working on the feature will need to arrange / agree their own builds for testing / deployment.","title":"Working in a feature branch"},{"location":"guides/contributor/process/#merging-to-master-and-releasing","text":"We do not release from a feature branch. All release branches are made from master . It is the feature team's responsibility to: Merge the latest code from master Merge feature branch back to master There's no set schedule for this. Longer intervals offers the feature more stability, but can rapidly build up a much more complex merge scenario which the feature team will need to resolve. It is the feature team's responsibility to respond to any issues in master , and to validate that the feature is \"good\".","title":"Merging to master and releasing"},{"location":"guides/contributor/process/#administrative-tasks","text":"These tasks should only be performed by someone familiar with the process and with appropriate authority after establishing team agreement. As such, exact commands are not given below: Creating a branch Create a feature branch named feature-XXX where XXX is a descriptive name for the feature. (With issues, using the issue number can be helpful, but since we expect a small number of feature branches, this seems clearer.) Ensure branch protections are set to the same as master , to ensure all changes follow the same process as for master: for example, must go via PRs. Builds It's expected that all Feature branches should have PR verification to ensure submitted code changes in a PR do not break the main build. This is purely a compilation test to check against breakage. Build artifacts are not distributed or saved. Features could benefit from a 'merge' build which ensures the latest code in the branch works well together. This build also typically generates: - Maven artifacts (to a snapshot repository) - Docker images (to Docker Hub) In the future, it's expected these will get used for automatic tests, and used by other deployment approaches such as Docker Compose and Kubernetes. However, currently our repository and naming / versioning setup is not able to do this since branch names are not taken into account. In Egeria we also may perform: Scans for code quality Scans for licensing Security-related scans Builds for Docker images other than core Egeria These will also not be done for a feature branch.","title":"Administrative tasks"},{"location":"guides/contributor/process/#closing-a-feature-branch","text":"When the feature branch is no longer required, it can be deleted by an admin. Similarly to requesting a feature branch, an issue should be raised, and team agreement sought beforehand.","title":"Closing a feature branch"},{"location":"guides/cts/overview/","text":"Conformance Test Suite Overview \u00b6 The open metadata conformance suite provides a testing framework to help the developers integrate a specific technology into the open metadata ecosystem. The actual tests are run by an open metadata conformance workbench within the open metadata conformance suite server. Each workbench focuses on testing a specific type of technology, and typically define the set of functionality being tested in a profile . Test cases within profiles The profiles are supported by one or more test cases (described in detail within each profile). Each test case typically focuses on a specific requirement within a profile. However, it may verify other requirements from either the same of different profiles if it is efficient to do so. When a test case encounters errors, it will log them and if possible it will continue testing. However, some failures are blocking and the test case will end when one of these is encountered. Platform workbench \u00b6 The open metadata conformance platform workbench is responsible for testing the various APIs supported by an Open Metadata and Governance ( OMAG ) Server Platform . This workbench supports the following profiles: Profile Description Platform origin Does the platform support the server-platform-origin API. Repository workbench \u00b6 The open metadata conformance repository workbench is responsible for testing the ability of an open metadata repository to connect and interact with other open metadata repositories in a conformant way. It tests both the repository's repository services API and its ability to exchange events with the OMRS cohort event topic . The workbench uses the registration information that is passed when the technology under test registers with the same open metadata repository cohort as the conformance suite. It will confirm that the information received in the events matches the information returned by the technology under test's repository services. This workbench works as a pipeline processor, accumulating information from one test and using it to seed subsequent tests. A failure early on in the pipeline may prevent other tests from running. In addition, this workbench dynamically generates tests based on the types returned by the repository. So for example, the repository TypeDef test case runs for each TypeDef returned by the repository. A failure in the early set up test cases will prevent the repository workbench from generating the full suite of test cases for the repository under test. The functions expected of an open metadata repository are numerous. These functions are broken down into the profiles listed below. An open metadata repository needs to support at least one profile to be conformant: in practice, metadata sharing is required in order to support any of the other profiles, so it is mandatory. Profile Description Metadata sharing The technology under test is able to share metadata with other members of the cohort. Reference copies The technology under test is able to store reference copies of metadata from other members of the cohort. Metadata maintenance The technology under test supports requests to create, update and purge metadata instances. Effectivity dating The technology under test supports effectivity dating properties. Dynamic types The technology under test supports changes to the list of its supported types while it is running. Graph queries The technology under test supports graph-like queries that return collections of metadata instances. Historical search The technology under test supports search for the state of the metadata instances at a specific time in the past. Entity proxies The technology under test is able to store stubs for entities to use on relationships when the full entity is not available. Soft-delete and restore The technology under test allows an instance to be soft-deleted and restored. Undo an update The technology under test is able to restore an instance to its previous version (although the version number is updated). Reidentify instance The technology under test supports the command to change the unique identifier (guid) of a metadata instance. Retype instance The technology under test supports the command to change the type of a metadata instance to either its super type or a subtype. Rehome instance The technology under test supports the command to update the metadata collection id for a metadata instance. Performance workbench \u00b6 The open metadata conformance performance workbench is responsible for testing the performance of various APIs supported by an Open Metadata and Governance ( OMAG ) server repository. Focused purely on measuring performance Note that the workbench is focused purely on measuring performance, and will not extensively test for correctness of results across a variety of edge cases, etc. For that, use the normal repository workbench . This workbench runs the following profiles, in the following order: Profile Description Entity creation tests the performance of addEntity and saveEntityReferenceCopy methods Entity search tests the performance of findEntities , findEntitiesByProperty and findEntitiesByPropertyValue methods Relationship creation tests the performance of addRelationship and saveRelationshipReferenceCopy methods Relationship search tests the performance of findRelationships , findRelationshipsByProperty and findRelationshipsByPropertyValue methods Entity classification tests the performance of classifyEntity and saveClassificationReferenceCopy methods Classification search tests the performance of findEntitiesByClassification method Entity update tests the performance of updateEntityProperties method Relationship update tests the performance of updateRelationshipProperties method Classification update tests the performance of updateEntityClassification method Entity undo tests the performance of undoEntityUpdate method Relationship undo tests the performance of undoRelationshipUpdate method Entity retrieval tests the performance of isEntityKnown , getEntitySummary and getEntityDetail methods Entity history retrieval tests the performance of getEntityDetail (with non-null asOfTime ) and getEntityDetailHistory methods Relationship retrieval tests the performance of isRelationshipKnown and getRelationship methods Relationship history retrieval tests the performance of getRelationship (with non-null asOfTime ) and getRelationshipHistory methods Entity history search tests the performance of the same search operations as Entity Search, but in each case with a non-null asOfTime Relationship history search tests the performance of the same search operations as Relationship Search, but in each case with a non-null asOfTime Graph queries tests the performance of getRelationshipsForEntity , getEntityNeighborhood , getRelatedEntities and getLinkingEntities methods Graph history queries tests the performance of the same operations as Graph Queries, but in each case with a non-null asOfTime Entity re-home tests the performance of reHomeEntity method Relationship re-home tests the performance of reHomeRelationship method Entity declassify tests the performance of declassifyEntity and purgeClassificationReferenceCopy methods Entity re-type tests the performance of reTypeEntity method Relationship re-type tests the performance of reTypeRelationship method Entity re-identify tests the performance of reIdentifyEntity method Relationship re-identify tests the performance of reIdentifyRelationship method Relationship delete tests the performance of deleteRelationship method Entity delete tests the performance of deleteEntity method Entity restore tests the performance of restoreEntity method Relationship restore tests the performance of restoreRelationship method Relationship purge tests the performance of purgeRelationship and purgeRelationshipReferenceCopy methods Entity purge tests the performance of purgeEntity and purgeEntityReferenceCopy methods Environment does not actually perform any tests, but rather gives statistics about the environment in which the tests were performed (instance counts, etc) In each profile, the methods being tested will be executed a number of times and the elapsed time of each execution captured. These elapsed times are available through the detailed profile results of the Conformance Test Suite reports, and can be extracted to calculate more detailed statistics (min, max, median, mean, etc). Configuration of the performance test can be done through the properties passed in to the admin services prior to executing it: Property Use instancesPerType controls how many instances of metadata to create (per type supported by the repository) (defaults to 50 ) maxSearchResults controls how many results to retrieve per page for any search operations (defaults to 10 ) waitBetweenScenarios controls an optional wait-point between write and read scenarios, in case you are testing a repository that has an eventually-consistent index (defaults to 0 to avoid any wait) profilesToSkip is an optional array of strings of the profile names that should be skipped during performance testing (for example, to skip very long-running profiles like the graph queries at the larger scales, where thousands or more relationships and entities could be returned by each query)","title":"CTS Overview"},{"location":"guides/cts/overview/#conformance-test-suite-overview","text":"The open metadata conformance suite provides a testing framework to help the developers integrate a specific technology into the open metadata ecosystem. The actual tests are run by an open metadata conformance workbench within the open metadata conformance suite server. Each workbench focuses on testing a specific type of technology, and typically define the set of functionality being tested in a profile . Test cases within profiles The profiles are supported by one or more test cases (described in detail within each profile). Each test case typically focuses on a specific requirement within a profile. However, it may verify other requirements from either the same of different profiles if it is efficient to do so. When a test case encounters errors, it will log them and if possible it will continue testing. However, some failures are blocking and the test case will end when one of these is encountered.","title":"Conformance Test Suite Overview"},{"location":"guides/cts/overview/#platform-workbench","text":"The open metadata conformance platform workbench is responsible for testing the various APIs supported by an Open Metadata and Governance ( OMAG ) Server Platform . This workbench supports the following profiles: Profile Description Platform origin Does the platform support the server-platform-origin API.","title":"Platform workbench"},{"location":"guides/cts/overview/#repository-workbench","text":"The open metadata conformance repository workbench is responsible for testing the ability of an open metadata repository to connect and interact with other open metadata repositories in a conformant way. It tests both the repository's repository services API and its ability to exchange events with the OMRS cohort event topic . The workbench uses the registration information that is passed when the technology under test registers with the same open metadata repository cohort as the conformance suite. It will confirm that the information received in the events matches the information returned by the technology under test's repository services. This workbench works as a pipeline processor, accumulating information from one test and using it to seed subsequent tests. A failure early on in the pipeline may prevent other tests from running. In addition, this workbench dynamically generates tests based on the types returned by the repository. So for example, the repository TypeDef test case runs for each TypeDef returned by the repository. A failure in the early set up test cases will prevent the repository workbench from generating the full suite of test cases for the repository under test. The functions expected of an open metadata repository are numerous. These functions are broken down into the profiles listed below. An open metadata repository needs to support at least one profile to be conformant: in practice, metadata sharing is required in order to support any of the other profiles, so it is mandatory. Profile Description Metadata sharing The technology under test is able to share metadata with other members of the cohort. Reference copies The technology under test is able to store reference copies of metadata from other members of the cohort. Metadata maintenance The technology under test supports requests to create, update and purge metadata instances. Effectivity dating The technology under test supports effectivity dating properties. Dynamic types The technology under test supports changes to the list of its supported types while it is running. Graph queries The technology under test supports graph-like queries that return collections of metadata instances. Historical search The technology under test supports search for the state of the metadata instances at a specific time in the past. Entity proxies The technology under test is able to store stubs for entities to use on relationships when the full entity is not available. Soft-delete and restore The technology under test allows an instance to be soft-deleted and restored. Undo an update The technology under test is able to restore an instance to its previous version (although the version number is updated). Reidentify instance The technology under test supports the command to change the unique identifier (guid) of a metadata instance. Retype instance The technology under test supports the command to change the type of a metadata instance to either its super type or a subtype. Rehome instance The technology under test supports the command to update the metadata collection id for a metadata instance.","title":"Repository workbench"},{"location":"guides/cts/overview/#performance-workbench","text":"The open metadata conformance performance workbench is responsible for testing the performance of various APIs supported by an Open Metadata and Governance ( OMAG ) server repository. Focused purely on measuring performance Note that the workbench is focused purely on measuring performance, and will not extensively test for correctness of results across a variety of edge cases, etc. For that, use the normal repository workbench . This workbench runs the following profiles, in the following order: Profile Description Entity creation tests the performance of addEntity and saveEntityReferenceCopy methods Entity search tests the performance of findEntities , findEntitiesByProperty and findEntitiesByPropertyValue methods Relationship creation tests the performance of addRelationship and saveRelationshipReferenceCopy methods Relationship search tests the performance of findRelationships , findRelationshipsByProperty and findRelationshipsByPropertyValue methods Entity classification tests the performance of classifyEntity and saveClassificationReferenceCopy methods Classification search tests the performance of findEntitiesByClassification method Entity update tests the performance of updateEntityProperties method Relationship update tests the performance of updateRelationshipProperties method Classification update tests the performance of updateEntityClassification method Entity undo tests the performance of undoEntityUpdate method Relationship undo tests the performance of undoRelationshipUpdate method Entity retrieval tests the performance of isEntityKnown , getEntitySummary and getEntityDetail methods Entity history retrieval tests the performance of getEntityDetail (with non-null asOfTime ) and getEntityDetailHistory methods Relationship retrieval tests the performance of isRelationshipKnown and getRelationship methods Relationship history retrieval tests the performance of getRelationship (with non-null asOfTime ) and getRelationshipHistory methods Entity history search tests the performance of the same search operations as Entity Search, but in each case with a non-null asOfTime Relationship history search tests the performance of the same search operations as Relationship Search, but in each case with a non-null asOfTime Graph queries tests the performance of getRelationshipsForEntity , getEntityNeighborhood , getRelatedEntities and getLinkingEntities methods Graph history queries tests the performance of the same operations as Graph Queries, but in each case with a non-null asOfTime Entity re-home tests the performance of reHomeEntity method Relationship re-home tests the performance of reHomeRelationship method Entity declassify tests the performance of declassifyEntity and purgeClassificationReferenceCopy methods Entity re-type tests the performance of reTypeEntity method Relationship re-type tests the performance of reTypeRelationship method Entity re-identify tests the performance of reIdentifyEntity method Relationship re-identify tests the performance of reIdentifyRelationship method Relationship delete tests the performance of deleteRelationship method Entity delete tests the performance of deleteEntity method Entity restore tests the performance of restoreEntity method Relationship restore tests the performance of restoreRelationship method Relationship purge tests the performance of purgeRelationship and purgeRelationshipReferenceCopy methods Entity purge tests the performance of purgeEntity and purgeEntityReferenceCopy methods Environment does not actually perform any tests, but rather gives statistics about the environment in which the tests were performed (instance counts, etc) In each profile, the methods being tested will be executed a number of times and the elapsed time of each execution captured. These elapsed times are available through the detailed profile results of the Conformance Test Suite reports, and can be extracted to calculate more detailed statistics (min, max, median, mean, etc). Configuration of the performance test can be done through the properties passed in to the admin services prior to executing it: Property Use instancesPerType controls how many instances of metadata to create (per type supported by the repository) (defaults to 50 ) maxSearchResults controls how many results to retrieve per page for any search operations (defaults to 10 ) waitBetweenScenarios controls an optional wait-point between write and read scenarios, in case you are testing a repository that has an eventually-consistent index (defaults to 0 to avoid any wait) profilesToSkip is an optional array of strings of the profile names that should be skipped during performance testing (for example, to skip very long-running profiles like the graph queries at the larger scales, where thousands or more relationships and entities could be returned by each query)","title":"Performance workbench"},{"location":"guides/cts/profiles/classification-search/","text":"Classification search profile \u00b6 The performance of programmatically searching for existing entities based on their classification(s). The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for searching for entity instances based on classification: Method Description findEntitiesByClassification searches for entity instances based on specific classifications or properties of classifications with specific values Assertions ID Description repository-classification-search-performance-findEntitiesByClassification-all Repository performs search for both of two classification property values, sorting by most recent update date, of first page of instances for a classification. repository-classification-search-performance-findEntitiesByClassification-alone Repository performs search by classification alone (no properties), sorting by most recent creation date, of first page of instances for a classification. repository-classification-search-performance-findEntitiesByClassification-any Repository performs search for either of two classification property values, sorting by oldest update date, of first page of instances for a classification. repository-classification-search-performance-findEntitiesByClassification-none Repository performs search for neither of two classification property values, sorting by entity GUID , of first page of instances for a classification. repository-classification-search-performance-findEntitiesByClassification-one Repository performs search by a single classification property value, sorting by oldest creation date, of first page of instances for a classification. repository-classification-update-performance-findEntitiesByClassification Repository performs search for unordered first instancesPerType instances with a classification. repository-entity-declassification-performance-findEntitiesByClassification Repository performs search for unordered first instancesPerType instances with a classification. repository-entity-declassification-performance-findEntitiesByClassification-rc Repository performs search for unordered first instancesPerType reference copy classifications.","title":"Classification Search"},{"location":"guides/cts/profiles/classification-search/#classification-search-profile","text":"The performance of programmatically searching for existing entities based on their classification(s). The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for searching for entity instances based on classification: Method Description findEntitiesByClassification searches for entity instances based on specific classifications or properties of classifications with specific values Assertions ID Description repository-classification-search-performance-findEntitiesByClassification-all Repository performs search for both of two classification property values, sorting by most recent update date, of first page of instances for a classification. repository-classification-search-performance-findEntitiesByClassification-alone Repository performs search by classification alone (no properties), sorting by most recent creation date, of first page of instances for a classification. repository-classification-search-performance-findEntitiesByClassification-any Repository performs search for either of two classification property values, sorting by oldest update date, of first page of instances for a classification. repository-classification-search-performance-findEntitiesByClassification-none Repository performs search for neither of two classification property values, sorting by entity GUID , of first page of instances for a classification. repository-classification-search-performance-findEntitiesByClassification-one Repository performs search by a single classification property value, sorting by oldest creation date, of first page of instances for a classification. repository-classification-update-performance-findEntitiesByClassification Repository performs search for unordered first instancesPerType instances with a classification. repository-entity-declassification-performance-findEntitiesByClassification Repository performs search for unordered first instancesPerType instances with a classification. repository-entity-declassification-performance-findEntitiesByClassification-rc Repository performs search for unordered first instancesPerType reference copy classifications.","title":"Classification search profile"},{"location":"guides/cts/profiles/classification-update/","text":"Classification update profile \u00b6 The performance of programmatically updating existing classifications. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for updating classifications: Method Description updateEntityClassification changes one or more values of the properties on an existing classification Assertions ID Description repository-classification-update-performance-updateEntityClassification See (2) in detailed logic below. For every classification type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities with that classification. (This uses findEntitiesByClassification with a condition on the classification's name only and its performance is recorded as part of the classification search profile.) For each of these entity instances, updateEntityClassification is called to update the existing property values of the classification, using a new generated set of properties. Example So, for example, if the technology under test supports 50 classification types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 classifications. (And it will run findEntitiesByClassification 50 times.) The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform Caveats Note the following caveats: Classification type definitions that have no properties will not be updated, since there are no properties to update.","title":"Classification Update"},{"location":"guides/cts/profiles/classification-update/#classification-update-profile","text":"The performance of programmatically updating existing classifications. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for updating classifications: Method Description updateEntityClassification changes one or more values of the properties on an existing classification Assertions ID Description repository-classification-update-performance-updateEntityClassification See (2) in detailed logic below. For every classification type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities with that classification. (This uses findEntitiesByClassification with a condition on the classification's name only and its performance is recorded as part of the classification search profile.) For each of these entity instances, updateEntityClassification is called to update the existing property values of the classification, using a new generated set of properties. Example So, for example, if the technology under test supports 50 classification types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 classifications. (And it will run findEntitiesByClassification 50 times.) The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform Caveats Note the following caveats: Classification type definitions that have no properties will not be updated, since there are no properties to update.","title":"Classification update profile"},{"location":"guides/cts/profiles/entity-classification/","text":"Entity classification profile \u00b6 The performance of programmatically classifying existing entity instances with new classifications. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for classifying entity instances: Method Description classifyEntity adds a new classification to an existing entity instance, where the technology under test is the home repository for that classification saveEntityReferenceCopy adds (or updates) an entity instance with a classification, where the technology under test is not the home repository for that classification Assertions ID Description repository-entity-classification-performance-classifyEntity See (2) in detailed logic below. repository-entity-classification-performance-saveClassificationReferenceCopy See (4) in detailed logic below. For every classification type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities of a type that is valid for the classification. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity instances, classifyEntity is called to add a new classification of this type to that instance, using a generated set of properties. Searches for instancesPerType entities of a type that is valid for the classification, and where the entity is a reference copy. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these reference copy entity instances, saveClassificationReferenceCopy is called to add reference copy classification of this type to that instance, using a generated set of properties. Example So, for example, if the technology under test supports 50 classification types, and the instancesPerType parameter is set to 100, then this profile will create 50 (types) x 100 (instances per type) x 2 (home + reference copy methods) = 10 000 classifications. (And it will run findEntities 50 times, and findEntitiesByProperty 50 times.) The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform","title":"Entity Classification"},{"location":"guides/cts/profiles/entity-classification/#entity-classification-profile","text":"The performance of programmatically classifying existing entity instances with new classifications. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for classifying entity instances: Method Description classifyEntity adds a new classification to an existing entity instance, where the technology under test is the home repository for that classification saveEntityReferenceCopy adds (or updates) an entity instance with a classification, where the technology under test is not the home repository for that classification Assertions ID Description repository-entity-classification-performance-classifyEntity See (2) in detailed logic below. repository-entity-classification-performance-saveClassificationReferenceCopy See (4) in detailed logic below. For every classification type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities of a type that is valid for the classification. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity instances, classifyEntity is called to add a new classification of this type to that instance, using a generated set of properties. Searches for instancesPerType entities of a type that is valid for the classification, and where the entity is a reference copy. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these reference copy entity instances, saveClassificationReferenceCopy is called to add reference copy classification of this type to that instance, using a generated set of properties. Example So, for example, if the technology under test supports 50 classification types, and the instancesPerType parameter is set to 100, then this profile will create 50 (types) x 100 (instances per type) x 2 (home + reference copy methods) = 10 000 classifications. (And it will run findEntities 50 times, and findEntitiesByProperty 50 times.) The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform","title":"Entity classification profile"},{"location":"guides/cts/profiles/entity-creation/","text":"Entity creation profile \u00b6 The performance of programmatically creating new entity instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for creating entity instances: Method Description addEntity adds a new entity instance, where the technology under test is the home repository for that instance saveEntityReferenceCopy adds (or updates) an existing entity instance, where the technology under test is not the home repository for that instance Assertions ID Description repository-entity-creation-performance-addEntity Invocation of the addEntity method during the profile (see detailed logic below). repository-entity-creation-performance-saveEntityReferenceCopy Invocation of the saveEntityReferenceCopy method during the profile (see detailed logic below). For every entity type supported by the technology under test, this profile invokes each of these methods instancesPerType times. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will create 50 (types) x 100 (instances per type) x 2 (home + non-home methods) = 10 000 entity instances. The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, such as qualifiedName , they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform In addition, these tests will record into the environment profile the totalEntitiesCreated .","title":"Entity Creation"},{"location":"guides/cts/profiles/entity-creation/#entity-creation-profile","text":"The performance of programmatically creating new entity instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for creating entity instances: Method Description addEntity adds a new entity instance, where the technology under test is the home repository for that instance saveEntityReferenceCopy adds (or updates) an existing entity instance, where the technology under test is not the home repository for that instance Assertions ID Description repository-entity-creation-performance-addEntity Invocation of the addEntity method during the profile (see detailed logic below). repository-entity-creation-performance-saveEntityReferenceCopy Invocation of the saveEntityReferenceCopy method during the profile (see detailed logic below). For every entity type supported by the technology under test, this profile invokes each of these methods instancesPerType times. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will create 50 (types) x 100 (instances per type) x 2 (home + non-home methods) = 10 000 entity instances. The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, such as qualifiedName , they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform In addition, these tests will record into the environment profile the totalEntitiesCreated .","title":"Entity creation profile"},{"location":"guides/cts/profiles/entity-declassify/","text":"Entity declassification profile \u00b6 The performance of programmatically declassifying existing entity instances from existing classifications. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for declassifying entity instances: Method Description declassifyEntity removes a classification from an existing entity instance, where the technology under test is the home repository for that classification purgeClassificationReferenceCopy removes a classification from an existing entity instance, where the technology under test is not the home repository for that classification Assertions ID Description repository-entity-declassification-performance-declassifyEntity See (2) in detailed logic below. repository-entity-declassification-performance-purgeClassificationReferenceCopy See (4) in detailed logic below. For every classification type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities homed in the technology under test with the classification. (This uses findEntitiesByClassification with a condition on metadataCollectionId and its performance is recorded as part of the classification search profile.) For each of these entity instances, declassifyEntity is called to remove the classification of this type from that instance. Searches for instancesPerType reference copy entities with the classification. (This uses findEntitiesByClassification with a condition on metadataCollectionId and its performance is recorded as part of the classification search profile.) For each of these reference copy entity instances, purgeClassificationReferenceCopy is called to remove the reference copy classification of this type from that instance. Example So, for example, if the technology under test supports 50 classification types, and the instancesPerType parameter is set to 100, then this profile will remove 50 (types) x 100 (instances per type) x 2 (home + reference copy methods) = 10 000 classifications. (And it will run findEntitiesByClassification 100 times.)","title":"Entity Declassify"},{"location":"guides/cts/profiles/entity-declassify/#entity-declassification-profile","text":"The performance of programmatically declassifying existing entity instances from existing classifications. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for declassifying entity instances: Method Description declassifyEntity removes a classification from an existing entity instance, where the technology under test is the home repository for that classification purgeClassificationReferenceCopy removes a classification from an existing entity instance, where the technology under test is not the home repository for that classification Assertions ID Description repository-entity-declassification-performance-declassifyEntity See (2) in detailed logic below. repository-entity-declassification-performance-purgeClassificationReferenceCopy See (4) in detailed logic below. For every classification type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities homed in the technology under test with the classification. (This uses findEntitiesByClassification with a condition on metadataCollectionId and its performance is recorded as part of the classification search profile.) For each of these entity instances, declassifyEntity is called to remove the classification of this type from that instance. Searches for instancesPerType reference copy entities with the classification. (This uses findEntitiesByClassification with a condition on metadataCollectionId and its performance is recorded as part of the classification search profile.) For each of these reference copy entity instances, purgeClassificationReferenceCopy is called to remove the reference copy classification of this type from that instance. Example So, for example, if the technology under test supports 50 classification types, and the instancesPerType parameter is set to 100, then this profile will remove 50 (types) x 100 (instances per type) x 2 (home + reference copy methods) = 10 000 classifications. (And it will run findEntitiesByClassification 100 times.)","title":"Entity declassification profile"},{"location":"guides/cts/profiles/entity-delete/","text":"Entity delete profile \u00b6 The performance of programmatically soft-deleting an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for deleting entity instances: Method Description deleteEntity soft-deletes the current version of an entity Assertions ID Description repository-entity-delete-performance-deleteEntity See (2) in detailed logic below. repository-entity-purge-performance-deleteEntity See detailed logic of entity purge profile. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity instances, deleteEntity is called to soft-delete it. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will soft-delete 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.)","title":"Entity Delete"},{"location":"guides/cts/profiles/entity-delete/#entity-delete-profile","text":"The performance of programmatically soft-deleting an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for deleting entity instances: Method Description deleteEntity soft-deletes the current version of an entity Assertions ID Description repository-entity-delete-performance-deleteEntity See (2) in detailed logic below. repository-entity-purge-performance-deleteEntity See detailed logic of entity purge profile. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity instances, deleteEntity is called to soft-delete it. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will soft-delete 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.)","title":"Entity delete profile"},{"location":"guides/cts/profiles/entity-history-retrieval/","text":"Entity history retrieval profile \u00b6 The performance of programmatically retrieving the history of existing entity instances based on their ID. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving the history of entity instances by their ID: Method Description getEntityDetail retrieves an entity instance's details at a given point in time, if the entity was known at that point in time, or throws an exception if not getEntityDetailHistory retrieves the full history of an entity instance's details Assertions ID Description repository-entity-history-retrieval-performance-getEntityDetail See (2) in detailed logic below. repository-entity-history-retrieval-performance-getEntityDetailHistory See (3) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, getEntityDetail is then called with an asOfTime using the timestamp captured prior to the execution of the Entity Update profile, to retrieve its historical details from that point in time (prior to any updates). For each of these entity GUIDs, getEntityDetailHistory is then called to retrieve its full history (including current version and all historical versions of the instance). Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will retrieve 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 entities. (And it will run findEntities 50 times.)","title":"Entity History Retrieval"},{"location":"guides/cts/profiles/entity-history-retrieval/#entity-history-retrieval-profile","text":"The performance of programmatically retrieving the history of existing entity instances based on their ID. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving the history of entity instances by their ID: Method Description getEntityDetail retrieves an entity instance's details at a given point in time, if the entity was known at that point in time, or throws an exception if not getEntityDetailHistory retrieves the full history of an entity instance's details Assertions ID Description repository-entity-history-retrieval-performance-getEntityDetail See (2) in detailed logic below. repository-entity-history-retrieval-performance-getEntityDetailHistory See (3) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, getEntityDetail is then called with an asOfTime using the timestamp captured prior to the execution of the Entity Update profile, to retrieve its historical details from that point in time (prior to any updates). For each of these entity GUIDs, getEntityDetailHistory is then called to retrieve its full history (including current version and all historical versions of the instance). Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will retrieve 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 entities. (And it will run findEntities 50 times.)","title":"Entity history retrieval profile"},{"location":"guides/cts/profiles/entity-history-search/","text":"Entity history search profile \u00b6 The performance of programmatically searching for entity instances as they existed in the past. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for searching for entity instances based on their details in the past, by passing in an asOfTime parameter (captured during the execution of the entity update profile): Method Description findEntities arbitrarily complex combinations of search criteria including ranges, nested conditions, etc findEntitiesByProperty searches for entity instances based on specific properties with specific values findEntitiesByPropertyValue searches for entity instances based on text that matches any textual property Assertions ID Description repository-entity-search-history-performance-findEntities-all-p... Interrogates the technology under test for each entity type, by calling findEntities for that type GUID with an asOfTime using the timestamp captured prior to the execution of the entity update profile. These searches are performed with basic sorting of results, and all pages of results are retrieved (the p... portion indicates a specific page number): thereby also exercising the efficiency of the technology under test to both sort and cycle through pages of results. repository-entity-search-history-performance-findEntitiesByPropertyValue-exact Repository performs historical search with an exact text value, sorting by oldest creation time, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByPropertyValue-start Repository performs historical search with a text value 'starts-with', sorting by newest creation time, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByPropertyValue-contains Repository performs historical search with a text value 'contains', sorting by oldest update time, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByPropertyValue-end Repository performs historical search with a text value 'ends-with', sorting by newest update time, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByPropertyValue-regex Repository performs historical search with a regular expression text value, sorting by GUID , of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByProperty-one Repository performs historical search by a single property value, sorting by that property, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByProperty-all Repository performs historical search by two property values, sorting by the second property, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByProperty-any Repository performs historical search by two property values, sorting by the second property, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByProperty-none Repository performs historical search by two property value, sorting by the first property, of first page of instances of a type. repository-entity-history-retrieval-performance-findEntities See the detailed logic of the entity retrieval profile. repository-graph-history-query-performance-findEntities See the detailed logic of the graph history query profile. Search variations When findEntitiesByProperty is run by the assertions starting with repository-entity-search-history-performance... , the tests prefer non-string properties (if any exist for the type) given that the findEntitiesByPropertyValue searches will already heavily exercise string-based queries.","title":"Entity History Search"},{"location":"guides/cts/profiles/entity-history-search/#entity-history-search-profile","text":"The performance of programmatically searching for entity instances as they existed in the past. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for searching for entity instances based on their details in the past, by passing in an asOfTime parameter (captured during the execution of the entity update profile): Method Description findEntities arbitrarily complex combinations of search criteria including ranges, nested conditions, etc findEntitiesByProperty searches for entity instances based on specific properties with specific values findEntitiesByPropertyValue searches for entity instances based on text that matches any textual property Assertions ID Description repository-entity-search-history-performance-findEntities-all-p... Interrogates the technology under test for each entity type, by calling findEntities for that type GUID with an asOfTime using the timestamp captured prior to the execution of the entity update profile. These searches are performed with basic sorting of results, and all pages of results are retrieved (the p... portion indicates a specific page number): thereby also exercising the efficiency of the technology under test to both sort and cycle through pages of results. repository-entity-search-history-performance-findEntitiesByPropertyValue-exact Repository performs historical search with an exact text value, sorting by oldest creation time, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByPropertyValue-start Repository performs historical search with a text value 'starts-with', sorting by newest creation time, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByPropertyValue-contains Repository performs historical search with a text value 'contains', sorting by oldest update time, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByPropertyValue-end Repository performs historical search with a text value 'ends-with', sorting by newest update time, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByPropertyValue-regex Repository performs historical search with a regular expression text value, sorting by GUID , of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByProperty-one Repository performs historical search by a single property value, sorting by that property, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByProperty-all Repository performs historical search by two property values, sorting by the second property, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByProperty-any Repository performs historical search by two property values, sorting by the second property, of first page of instances of a type. repository-entity-search-history-performance-findEntitiesByProperty-none Repository performs historical search by two property value, sorting by the first property, of first page of instances of a type. repository-entity-history-retrieval-performance-findEntities See the detailed logic of the entity retrieval profile. repository-graph-history-query-performance-findEntities See the detailed logic of the graph history query profile. Search variations When findEntitiesByProperty is run by the assertions starting with repository-entity-search-history-performance... , the tests prefer non-string properties (if any exist for the type) given that the findEntitiesByPropertyValue searches will already heavily exercise string-based queries.","title":"Entity history search profile"},{"location":"guides/cts/profiles/entity-purge/","text":"Entity purge profile \u00b6 The performance of programmatically hard-deleting (irreversibly) existing entity instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for hard-deleting entity instances: Method Description purgeEntity completely removes an entity instance homed in the technology under test (including all of its history) purgeEntityReferenceCopy completely removes an entity instance that is homed somewhere other than the technology under test (including all of its history) Assertions ID Description repository-entity-purge-performance-purgeEntity See (3) in detailed logic below. repository-entity-purge-performance-purgeEntityReferenceCopy See (5) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs homed in the technology under test. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, deleteEntity is called to soft-delete the instance. (This is necessary before a hard-delete can be done against the instance and its performance is recorded as part of the entity delete profile.) For each of these entity GUIDs, a purgeEntity is then called to hard-delete the instance. Searches for instancesPerType reference copy entities. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these reference copy entity instances, purgeEntityReferenceCopy is called to remove the reference copy instance. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will remove 50 (types) x 100 (instances per type) x 3 (home + reference copy methods) = 15 000 entities. (And it will run findEntitiesByProperty 100 times.)","title":"Entity Purge"},{"location":"guides/cts/profiles/entity-purge/#entity-purge-profile","text":"The performance of programmatically hard-deleting (irreversibly) existing entity instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for hard-deleting entity instances: Method Description purgeEntity completely removes an entity instance homed in the technology under test (including all of its history) purgeEntityReferenceCopy completely removes an entity instance that is homed somewhere other than the technology under test (including all of its history) Assertions ID Description repository-entity-purge-performance-purgeEntity See (3) in detailed logic below. repository-entity-purge-performance-purgeEntityReferenceCopy See (5) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs homed in the technology under test. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, deleteEntity is called to soft-delete the instance. (This is necessary before a hard-delete can be done against the instance and its performance is recorded as part of the entity delete profile.) For each of these entity GUIDs, a purgeEntity is then called to hard-delete the instance. Searches for instancesPerType reference copy entities. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these reference copy entity instances, purgeEntityReferenceCopy is called to remove the reference copy instance. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will remove 50 (types) x 100 (instances per type) x 3 (home + reference copy methods) = 15 000 entities. (And it will run findEntitiesByProperty 100 times.)","title":"Entity purge profile"},{"location":"guides/cts/profiles/entity-re-home/","text":"Entity re-home profile \u00b6 The performance of programmatically changing the home repository of an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the home repository of entity instances: Method Description reHomeEntity changes the home repository of an entity Assertions ID Description repository-entity-re-home-performance-reHomeEntity See (2) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType reference copy entity GUIDs of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, reHomeEntity is called to change the home repository to the technology under test's metadataCollectionId . Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will re-home 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.)","title":"Entity Re-home"},{"location":"guides/cts/profiles/entity-re-home/#entity-re-home-profile","text":"The performance of programmatically changing the home repository of an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the home repository of entity instances: Method Description reHomeEntity changes the home repository of an entity Assertions ID Description repository-entity-re-home-performance-reHomeEntity See (2) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType reference copy entity GUIDs of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, reHomeEntity is called to change the home repository to the technology under test's metadataCollectionId . Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will re-home 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.)","title":"Entity re-home profile"},{"location":"guides/cts/profiles/entity-re-identify/","text":"Entity re-identify profile \u00b6 The performance of programmatically changing the GUID of an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the GUID of entity instances: Method Description reIdentifyEntity changes the GUID of an existing entity Assertions ID Description repository-entity-re-identify-performance-reIdentifyEntity See (2) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType homed entity GUIDs of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, reIdentifyEntity is called to change the GUID of the entity to a new random GUID . Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will re-identify 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.)","title":"Entity Re-identify"},{"location":"guides/cts/profiles/entity-re-identify/#entity-re-identify-profile","text":"The performance of programmatically changing the GUID of an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the GUID of entity instances: Method Description reIdentifyEntity changes the GUID of an existing entity Assertions ID Description repository-entity-re-identify-performance-reIdentifyEntity See (2) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType homed entity GUIDs of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, reIdentifyEntity is called to change the GUID of the entity to a new random GUID . Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will re-identify 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.)","title":"Entity re-identify profile"},{"location":"guides/cts/profiles/entity-restore/","text":"Entity restore profile \u00b6 The performance of programmatically reversing the latest soft-delete of an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for reverting soft-deletes on entity instances: Method Description restoreEntity reverts the last soft-delete that was made to an entity Assertions ID Description repository-entity-restore-performance-restoreEntity See (2) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type that have been soft-deleted. (This uses findEntitiesByProperty with a condition to limit to the status DELETED only and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, restoreEntity is called to revert the soft-delete and make the entity active again. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will re-activate 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.)","title":"Entity Restore"},{"location":"guides/cts/profiles/entity-restore/#entity-restore-profile","text":"The performance of programmatically reversing the latest soft-delete of an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for reverting soft-deletes on entity instances: Method Description restoreEntity reverts the last soft-delete that was made to an entity Assertions ID Description repository-entity-restore-performance-restoreEntity See (2) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type that have been soft-deleted. (This uses findEntitiesByProperty with a condition to limit to the status DELETED only and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, restoreEntity is called to revert the soft-delete and make the entity active again. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will re-activate 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.)","title":"Entity restore profile"},{"location":"guides/cts/profiles/entity-retrieval/","text":"Entity retrieval profile \u00b6 The performance of programmatically retrieving existing entity instances based on their ID. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving entity instances by their ID: Method Description isEntityKnown retrieves an entity instance's details, if available, or returns null if not getEntitySummary retrieves a summary of an entity instance, without its properties getEntityDetail retrieves an entity instance's details, if available, or throws an exception if not Assertions ID Description repository-entity-retrieval-performance-isEntityKnown See (2) in detailed logic below. repository-entity-retrieval-performance-getEntitySummary See (3) in detailed logic below. repository-entity-retrieval-performance-getEntityDetail See (4) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, isEntityKnown is called to retrieve it. For each of these entity GUIDs, getEntitySummary is then called to retrieve its summary. For each of these entity GUIDs, getEntityDetail is then called to retrieve its details. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will retrieve 50 (types) x 100 (instances per type) x 3 (operations) = 15 000 entities. (And it will run findEntities 50 times.) Caveats Note the following caveats: The same GUIDs are used for each retrieval, but each method is run against every GUID before moving onto the next method.","title":"Entity Retrieval"},{"location":"guides/cts/profiles/entity-retrieval/#entity-retrieval-profile","text":"The performance of programmatically retrieving existing entity instances based on their ID. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving entity instances by their ID: Method Description isEntityKnown retrieves an entity instance's details, if available, or returns null if not getEntitySummary retrieves a summary of an entity instance, without its properties getEntityDetail retrieves an entity instance's details, if available, or throws an exception if not Assertions ID Description repository-entity-retrieval-performance-isEntityKnown See (2) in detailed logic below. repository-entity-retrieval-performance-getEntitySummary See (3) in detailed logic below. repository-entity-retrieval-performance-getEntityDetail See (4) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, isEntityKnown is called to retrieve it. For each of these entity GUIDs, getEntitySummary is then called to retrieve its summary. For each of these entity GUIDs, getEntityDetail is then called to retrieve its details. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will retrieve 50 (types) x 100 (instances per type) x 3 (operations) = 15 000 entities. (And it will run findEntities 50 times.) Caveats Note the following caveats: The same GUIDs are used for each retrieval, but each method is run against every GUID before moving onto the next method.","title":"Entity retrieval profile"},{"location":"guides/cts/profiles/entity-retype/","text":"Entity retype profile \u00b6 The performance of programmatically changing the type of an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the type of entity instances: Method Description reTypeEntity changes the type of an existing entity Assertions ID Description repository-entity-retype-performance-reTypeEntity-toSubtype See (3) in detailed logic below. repository-entity-retype-performance-reTypeEntity-toSupertype See (4) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType homed entity GUIDs of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, updateEntityProperties is called to remove all the entity's properties (so it can be easily retyped), and its performance is recorded as part of the entity update profile. For each of these entity GUIDs, reTypeEntity is called to change the type of the entity to one of its subtypes. For each of these entity GUIDs, reTypeEntity is then called to change the type of the entity back to its original type. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will retype 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 entities at most. (And it will run findEntitiesByProperty 50 times.) Caveats Note the following caveats: Instances of a given type will only be retyped if that type has any subtypes: if it has no subtypes, then all retyping operations will be skipped for that type's instances.","title":"Entity Re-type"},{"location":"guides/cts/profiles/entity-retype/#entity-retype-profile","text":"The performance of programmatically changing the type of an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the type of entity instances: Method Description reTypeEntity changes the type of an existing entity Assertions ID Description repository-entity-retype-performance-reTypeEntity-toSubtype See (3) in detailed logic below. repository-entity-retype-performance-reTypeEntity-toSupertype See (4) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType homed entity GUIDs of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, updateEntityProperties is called to remove all the entity's properties (so it can be easily retyped), and its performance is recorded as part of the entity update profile. For each of these entity GUIDs, reTypeEntity is called to change the type of the entity to one of its subtypes. For each of these entity GUIDs, reTypeEntity is then called to change the type of the entity back to its original type. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will retype 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 entities at most. (And it will run findEntitiesByProperty 50 times.) Caveats Note the following caveats: Instances of a given type will only be retyped if that type has any subtypes: if it has no subtypes, then all retyping operations will be skipped for that type's instances.","title":"Entity retype profile"},{"location":"guides/cts/profiles/entity-search/","text":"Entity search profile \u00b6 The performance of programmatically searching for existing entity instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for searching for entity instances: Method Description findEntities arbitrarily complex combinations of search criteria including ranges, nested conditions, etc findEntitiesByProperty searches for entity instances based on specific properties with specific values findEntitiesByPropertyValue searches for entity instances based on text that matches any textual property Assertions ID Description repository-entity-search-performance-findEntities-all-p... Interrogates the technology under test in its entirety, to discover every existing entity instance of every type known to Egeria. The total count of these is tallied to report later under the environment profile. In this way, even for repositories that do not support write operations, we can still calculate some metrics about read performance (including search) while being able to understand that information in light of the volumes of metadata in the repository while the test was executed. These searches are also performed with basic sorting of results, and all pages of results are retrieved (the p... portion indicates a specific page number): thereby also exercising the efficiency of the technology under test to both sort and cycle through pages of results. repository-entity-search-performance-findEntitiesByPropertyValue-exact Repository performs search with an exact text value, sorting by oldest creation time, of first page of instances of a type. repository-entity-search-performance-findEntitiesByPropertyValue-start Repository performs search with a text value 'starts-with', sorting by newest creation time, of first page of instances of a type. repository-entity-search-performance-findEntitiesByPropertyValue-contains Repository performs search with a text value 'contains', sorting by oldest update time, of first page of instances of a type. repository-entity-search-performance-findEntitiesByPropertyValue-end Repository performs search with a text value 'ends-with', sorting by newest update time, of first page of instances of a type. repository-entity-search-performance-findEntitiesByPropertyValue-regex Repository performs search with a regular expression text value, sorting by GUID , of first page of instances of a type. repository-entity-search-performance-findEntitiesByProperty-one Repository performs search by a single property value, sorting by that property, of first page of instances of a type. repository-entity-search-performance-findEntitiesByProperty-all Repository performs search by two property values, sorting by the second property, of first page of instances of a type. repository-entity-search-performance-findEntitiesByProperty-any Repository performs search by two property values, sorting by the second property, of first page of instances of a type. repository-entity-search-performance-findEntitiesByProperty-none Repository performs search by two property value, sorting by the first property, of first page of instances of a type. repository-entity-classification-performance-findEntities See the detailed logic of the entity classification profile. repository-entity-classification-performance-findEntitiesByProperty See the detailed logic of the entity classification profile. repository-entity-delete-performance-findEntitiesByProperty See the detailed logic of the entity delete profile. repository-entity-purge-performance-findEntitiesByProperty See the detailed logic of the entity purge profile. repository-entity-purge-performance-findEntitiesByProperty-rc See the detailed logic of the entity purge profile. repository-entity-re-home-performance-findEntitiesByProperty See the detailed logic of the entity re-home profile. repository-entity-re-identify-performance-findEntitiesByProperty See the detailed logic of the entity re-identify profile. repository-entity-restore-performance-findEntitiesByProperty See the detailed logic of the entity restore profile. repository-entity-retrieval-performance-findEntities See the detailed logic of the entity retrieval profile. repository-entity-retype-performance-findEntitiesByProperty See the detailed logic of the entity retype profile. repository-entity-undo-performance-findEntities See the detailed logic of the entity undo profile. repository-entity-update-performance-findEntitiesByProperty See the detailed logic of the entity update profile. repository-graph-query-performance-findEntities See the detailed logic of the graph query profile. repository-relationship-creation-performance-findEntities See the detailed logic of the relationship creation profile. In addition, these tests will record into the Environment profile the totalEntitiesFound . Search variations When findEntitiesByProperty is run by the assertions starting with repository-entity-search-performance... , the tests prefer non-string properties (if any exist for the type) given that the findEntitiesByPropertyValue searches will already heavily exercise string-based queries. Note that the various other assertions (that do not start with repository-entity-search-performance... ) will search on various other properties than those listed: in particular, including header properties like metadataCollectionId , version , and others.","title":"Entity Search"},{"location":"guides/cts/profiles/entity-search/#entity-search-profile","text":"The performance of programmatically searching for existing entity instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for searching for entity instances: Method Description findEntities arbitrarily complex combinations of search criteria including ranges, nested conditions, etc findEntitiesByProperty searches for entity instances based on specific properties with specific values findEntitiesByPropertyValue searches for entity instances based on text that matches any textual property Assertions ID Description repository-entity-search-performance-findEntities-all-p... Interrogates the technology under test in its entirety, to discover every existing entity instance of every type known to Egeria. The total count of these is tallied to report later under the environment profile. In this way, even for repositories that do not support write operations, we can still calculate some metrics about read performance (including search) while being able to understand that information in light of the volumes of metadata in the repository while the test was executed. These searches are also performed with basic sorting of results, and all pages of results are retrieved (the p... portion indicates a specific page number): thereby also exercising the efficiency of the technology under test to both sort and cycle through pages of results. repository-entity-search-performance-findEntitiesByPropertyValue-exact Repository performs search with an exact text value, sorting by oldest creation time, of first page of instances of a type. repository-entity-search-performance-findEntitiesByPropertyValue-start Repository performs search with a text value 'starts-with', sorting by newest creation time, of first page of instances of a type. repository-entity-search-performance-findEntitiesByPropertyValue-contains Repository performs search with a text value 'contains', sorting by oldest update time, of first page of instances of a type. repository-entity-search-performance-findEntitiesByPropertyValue-end Repository performs search with a text value 'ends-with', sorting by newest update time, of first page of instances of a type. repository-entity-search-performance-findEntitiesByPropertyValue-regex Repository performs search with a regular expression text value, sorting by GUID , of first page of instances of a type. repository-entity-search-performance-findEntitiesByProperty-one Repository performs search by a single property value, sorting by that property, of first page of instances of a type. repository-entity-search-performance-findEntitiesByProperty-all Repository performs search by two property values, sorting by the second property, of first page of instances of a type. repository-entity-search-performance-findEntitiesByProperty-any Repository performs search by two property values, sorting by the second property, of first page of instances of a type. repository-entity-search-performance-findEntitiesByProperty-none Repository performs search by two property value, sorting by the first property, of first page of instances of a type. repository-entity-classification-performance-findEntities See the detailed logic of the entity classification profile. repository-entity-classification-performance-findEntitiesByProperty See the detailed logic of the entity classification profile. repository-entity-delete-performance-findEntitiesByProperty See the detailed logic of the entity delete profile. repository-entity-purge-performance-findEntitiesByProperty See the detailed logic of the entity purge profile. repository-entity-purge-performance-findEntitiesByProperty-rc See the detailed logic of the entity purge profile. repository-entity-re-home-performance-findEntitiesByProperty See the detailed logic of the entity re-home profile. repository-entity-re-identify-performance-findEntitiesByProperty See the detailed logic of the entity re-identify profile. repository-entity-restore-performance-findEntitiesByProperty See the detailed logic of the entity restore profile. repository-entity-retrieval-performance-findEntities See the detailed logic of the entity retrieval profile. repository-entity-retype-performance-findEntitiesByProperty See the detailed logic of the entity retype profile. repository-entity-undo-performance-findEntities See the detailed logic of the entity undo profile. repository-entity-update-performance-findEntitiesByProperty See the detailed logic of the entity update profile. repository-graph-query-performance-findEntities See the detailed logic of the graph query profile. repository-relationship-creation-performance-findEntities See the detailed logic of the relationship creation profile. In addition, these tests will record into the Environment profile the totalEntitiesFound . Search variations When findEntitiesByProperty is run by the assertions starting with repository-entity-search-performance... , the tests prefer non-string properties (if any exist for the type) given that the findEntitiesByPropertyValue searches will already heavily exercise string-based queries. Note that the various other assertions (that do not start with repository-entity-search-performance... ) will search on various other properties than those listed: in particular, including header properties like metadataCollectionId , version , and others.","title":"Entity search profile"},{"location":"guides/cts/profiles/entity-undo/","text":"Entity undo profile \u00b6 The performance of programmatically reversing the latest update to an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for reverting updates on entity instances: Method Description undoEntityUpdate reverts the last update that was made to an entity Assertions ID Description repository-entity-undo-performance-undoEntityUpdate See (2) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities of that type that have at least one change. (This uses findEntities with a condition on both metadataCollectionId and version being greater than 1 , and its performance is recorded as part of the entity search profile.) For each of these entity instances, undoEntityUpdate is called to revert the last change. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntities 50 times.)","title":"Entity Undo"},{"location":"guides/cts/profiles/entity-undo/#entity-undo-profile","text":"The performance of programmatically reversing the latest update to an existing entity instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for reverting updates on entity instances: Method Description undoEntityUpdate reverts the last update that was made to an entity Assertions ID Description repository-entity-undo-performance-undoEntityUpdate See (2) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities of that type that have at least one change. (This uses findEntities with a condition on both metadataCollectionId and version being greater than 1 , and its performance is recorded as part of the entity search profile.) For each of these entity instances, undoEntityUpdate is called to revert the last change. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntities 50 times.)","title":"Entity undo profile"},{"location":"guides/cts/profiles/entity-update/","text":"Entity update profile \u00b6 The performance of programmatically updating existing entity instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for updating entity instances: Method Description updateEntityProperties changes one or more values of the properties on an existing entity updateEntityStatus changes the status of an existing entity Assertions ID Description repository-entity-update-performance-updateEntityProperties See (2) in detailed logic below. repository-entity-retype-performance-updateEntityProperties-remove See the detailed logic of the entity retype profile. Captures timestamp for historical metadata profiles Prior to this profile running, a timestamp is captured by the performance workbench to denote a specific date and time prior to any updates having been made to the entities. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity instances, updateEntityProperties is called to update the existing property values of the entity, using a new generated set of properties. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.) The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform Caveats Note the following caveats: updateEntityStatus is currently not tested (there are very few types that support any status that can be updated outside of a delete or restore operation). Entity type definitions that have no properties will not be updated, since there are no properties to update.","title":"Entity Update"},{"location":"guides/cts/profiles/entity-update/#entity-update-profile","text":"The performance of programmatically updating existing entity instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for updating entity instances: Method Description updateEntityProperties changes one or more values of the properties on an existing entity updateEntityStatus changes the status of an existing entity Assertions ID Description repository-entity-update-performance-updateEntityProperties See (2) in detailed logic below. repository-entity-retype-performance-updateEntityProperties-remove See the detailed logic of the entity retype profile. Captures timestamp for historical metadata profiles Prior to this profile running, a timestamp is captured by the performance workbench to denote a specific date and time prior to any updates having been made to the entities. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entities of that type. (This uses findEntitiesByProperty with a condition on metadataCollectionId and its performance is recorded as part of the entity search profile.) For each of these entity instances, updateEntityProperties is called to update the existing property values of the entity, using a new generated set of properties. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 entities. (And it will run findEntitiesByProperty 50 times.) The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform Caveats Note the following caveats: updateEntityStatus is currently not tested (there are very few types that support any status that can be updated outside of a delete or restore operation). Entity type definitions that have no properties will not be updated, since there are no properties to update.","title":"Entity update profile"},{"location":"guides/cts/profiles/environment/","text":"Environment profile \u00b6 Does not actually run any tests, but rather gathers statistics about the environment in which the other performance tests were executed. This profile currently collects the following information about the technology under test in which the performance tests were executed: Discovered properties Test configuration Property Description instancesPerType the number of instances the test should attempt to create, per type definition maxSearchResults the number of results per page to retrieve for search queries waitBetweenScenarios the time (in seconds) to wait between write and read phases of the performance tests Egeria statistics Property Description totalEntitiesCreated the total number of entity instances that were created by the performance tests totalEntitiesFound the total number of entity instances that were found in the environment (created + pre-existing) totalRelationshipsCreated the total number of relationship instances that were created by the performance tests totalRelationshipsFound the total number of relationship instances that were found in the environment (created + pre-existing) Runtime environment information Caveat Currently these are captured only for the OMAG Server Platform that is actually running the CTS suite itself. If the technology under test is running under this same OMAG Server Platform, then these will still be useful; however, if the technology under test is running on a separate OMAG Server Platform or via a remote system, these will likely be of very limited value. Property Description operatingSystem details about the operating system (name and version) operatingSystemArchitecture the operating system's architecture operatingSystemAvailableProcessors the number of processors available, according to the operating system (likely to include hyperthreads) operatingSystemLoadAverage current load average from the operating system heapUsage current heap memory usage out of total heap memory available (in bytes) nonHeapUsage current non-heap memory usage out of total non-heap memory available (in bytes) jvmSpec details about the Java virtual machine specification jvmImplementation details about the Java virtual machine implementation","title":"Environment"},{"location":"guides/cts/profiles/environment/#environment-profile","text":"Does not actually run any tests, but rather gathers statistics about the environment in which the other performance tests were executed. This profile currently collects the following information about the technology under test in which the performance tests were executed: Discovered properties Test configuration Property Description instancesPerType the number of instances the test should attempt to create, per type definition maxSearchResults the number of results per page to retrieve for search queries waitBetweenScenarios the time (in seconds) to wait between write and read phases of the performance tests Egeria statistics Property Description totalEntitiesCreated the total number of entity instances that were created by the performance tests totalEntitiesFound the total number of entity instances that were found in the environment (created + pre-existing) totalRelationshipsCreated the total number of relationship instances that were created by the performance tests totalRelationshipsFound the total number of relationship instances that were found in the environment (created + pre-existing) Runtime environment information Caveat Currently these are captured only for the OMAG Server Platform that is actually running the CTS suite itself. If the technology under test is running under this same OMAG Server Platform, then these will still be useful; however, if the technology under test is running on a separate OMAG Server Platform or via a remote system, these will likely be of very limited value. Property Description operatingSystem details about the operating system (name and version) operatingSystemArchitecture the operating system's architecture operatingSystemAvailableProcessors the number of processors available, according to the operating system (likely to include hyperthreads) operatingSystemLoadAverage current load average from the operating system heapUsage current heap memory usage out of total heap memory available (in bytes) nonHeapUsage current non-heap memory usage out of total non-heap memory available (in bytes) jvmSpec details about the Java virtual machine specification jvmImplementation details about the Java virtual machine implementation","title":"Environment profile"},{"location":"guides/cts/profiles/graph-history-queries/","text":"Graph history queries profile \u00b6 The performance of programmatically retrieving inter-related instances across potentially multiple degrees of separation, for a given point in time. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving inter-related metadata instances across several degrees at a given point in time in the past, by passing in an asOfTime parameter (captured during the execution of the entity update profile): Method Description getRelationshipsForEntity retrieves the first-degree relationships linked to an entity getEntityNeighborhood retrieves the relationships and entities linked to an entity, up to a specified number of degrees of separation getRelatedEntities retrieves the entities linked to an entity, both directly and indirectly getLinkingEntities retrieves the relationships and entities that exist between (ultimately connecting) two entities Assertions ID Description repository-graph-history-query-performance-getRelationshipsForEntity See (2) in detailed logic below. repository-graph-history-query-performance-getEntityNeighborhood-... See (3) in detailed logic below. repository-graph-history-query-performance-getRelatedEntities See (4) in detailed logic below. repository-graph-history-query-performance-getLinkingEntities See (5) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, getRelationshipsForEntity is called with an asOfTime using the timestamp captured prior to the execution of the entity update profile, to retrieve first-degree relationships. For each of these entity GUIDs, getEntityNeighborhood is then called with an asOfTime using the timestamp captured prior to the execution of the entity update profile, 3 times to retrieve that entity's 1st, 2nd and 3rd degree relationships. For each of these entity GUIDs, getRelatedEntities is then called with an asOfTime using the timestamp captured prior to the execution of the entity update profile, to retrieve all the entities that are either directly or indirectly related to this entity. These results, per entity, are stored in a Map for the next step. For each of these entity GUIDs, getLinkingEntities is then called with an asOfTime using the timestamp captured prior to the execution of the entity update profile, up to 3 times: using the first related entity from the test above, the last related entity from the test above, and an entity from the middle of the list of the results from the test above. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will run 50 (types) x 100 (instances per type) x 8 (maximum operation variations) = 40 000 (at most) queries. (And it will run the initial findEntities 50 times.) Caveats Note the following caveats: The same GUIDs are used for each retrieval, but each method is run against every GUID before moving onto the next method.","title":"Graph History Queries"},{"location":"guides/cts/profiles/graph-history-queries/#graph-history-queries-profile","text":"The performance of programmatically retrieving inter-related instances across potentially multiple degrees of separation, for a given point in time. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving inter-related metadata instances across several degrees at a given point in time in the past, by passing in an asOfTime parameter (captured during the execution of the entity update profile): Method Description getRelationshipsForEntity retrieves the first-degree relationships linked to an entity getEntityNeighborhood retrieves the relationships and entities linked to an entity, up to a specified number of degrees of separation getRelatedEntities retrieves the entities linked to an entity, both directly and indirectly getLinkingEntities retrieves the relationships and entities that exist between (ultimately connecting) two entities Assertions ID Description repository-graph-history-query-performance-getRelationshipsForEntity See (2) in detailed logic below. repository-graph-history-query-performance-getEntityNeighborhood-... See (3) in detailed logic below. repository-graph-history-query-performance-getRelatedEntities See (4) in detailed logic below. repository-graph-history-query-performance-getLinkingEntities See (5) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, getRelationshipsForEntity is called with an asOfTime using the timestamp captured prior to the execution of the entity update profile, to retrieve first-degree relationships. For each of these entity GUIDs, getEntityNeighborhood is then called with an asOfTime using the timestamp captured prior to the execution of the entity update profile, 3 times to retrieve that entity's 1st, 2nd and 3rd degree relationships. For each of these entity GUIDs, getRelatedEntities is then called with an asOfTime using the timestamp captured prior to the execution of the entity update profile, to retrieve all the entities that are either directly or indirectly related to this entity. These results, per entity, are stored in a Map for the next step. For each of these entity GUIDs, getLinkingEntities is then called with an asOfTime using the timestamp captured prior to the execution of the entity update profile, up to 3 times: using the first related entity from the test above, the last related entity from the test above, and an entity from the middle of the list of the results from the test above. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will run 50 (types) x 100 (instances per type) x 8 (maximum operation variations) = 40 000 (at most) queries. (And it will run the initial findEntities 50 times.) Caveats Note the following caveats: The same GUIDs are used for each retrieval, but each method is run against every GUID before moving onto the next method.","title":"Graph history queries profile"},{"location":"guides/cts/profiles/graph-queries/","text":"Graph queries profile \u00b6 The performance of programmatically retrieving inter-related instances across potentially multiple degrees of separation. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving inter-related metadata instances across several degrees: Method Description getRelationshipsForEntity retrieves the first-degree relationships linked to an entity getEntityNeighborhood retrieves the relationships and entities linked to an entity, up to a specified number of degrees of separation getRelatedEntities retrieves the entities linked to an entity, both directly and indirectly getLinkingEntities retrieves the relationships and entities that exist between (ultimately connecting) two entities Assertions ID Description repository-graph-query-performance-getRelationshipsForEntity See (2) in detailed logic below. repository-graph-query-performance-getEntityNeighborhood-... See (3) in detailed logic below. repository-graph-query-performance-getRelatedEntities See (4) in detailed logic below. repository-graph-query-performance-getLinkingEntities See (5) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, getRelationshipsForEntity is called to retrieve first-degree relationships. For each of these entity GUIDs, getEntityNeighborhood is then called 3 times to retrieve that entity's 1st, 2nd and 3rd degree relationships. For each of these entity GUIDs, getRelatedEntities is then called to retrieve all the entities that are either directly or indirectly related to this entity. These results, per entity, are stored in a Map for the next step. For each of these entity GUIDs, getLinkingEntities is then called up to 3 times: using the first related entity from the test above, the last related entity from the test above, and an entity from the middle of the list of the results from the test above. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will run 50 (types) x 100 (instances per type) x 8 (maximum operation variations) = 40 000 (at most) queries. (And it will run the initial findEntities 50 times.) Caveats Note the following caveats: The same GUIDs are used for each retrieval, but each method is run against every GUID before moving onto the next method.","title":"Graph Queries"},{"location":"guides/cts/profiles/graph-queries/#graph-queries-profile","text":"The performance of programmatically retrieving inter-related instances across potentially multiple degrees of separation. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving inter-related metadata instances across several degrees: Method Description getRelationshipsForEntity retrieves the first-degree relationships linked to an entity getEntityNeighborhood retrieves the relationships and entities linked to an entity, up to a specified number of degrees of separation getRelatedEntities retrieves the entities linked to an entity, both directly and indirectly getLinkingEntities retrieves the relationships and entities that exist between (ultimately connecting) two entities Assertions ID Description repository-graph-query-performance-getRelationshipsForEntity See (2) in detailed logic below. repository-graph-query-performance-getEntityNeighborhood-... See (3) in detailed logic below. repository-graph-query-performance-getRelatedEntities See (4) in detailed logic below. repository-graph-query-performance-getLinkingEntities See (5) in detailed logic below. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findEntities and its performance is recorded as part of the entity search profile.) For each of these entity GUIDs, getRelationshipsForEntity is called to retrieve first-degree relationships. For each of these entity GUIDs, getEntityNeighborhood is then called 3 times to retrieve that entity's 1st, 2nd and 3rd degree relationships. For each of these entity GUIDs, getRelatedEntities is then called to retrieve all the entities that are either directly or indirectly related to this entity. These results, per entity, are stored in a Map for the next step. For each of these entity GUIDs, getLinkingEntities is then called up to 3 times: using the first related entity from the test above, the last related entity from the test above, and an entity from the middle of the list of the results from the test above. Example So, for example, if the technology under test supports 50 entity types, and the instancesPerType parameter is set to 100, then this profile will run 50 (types) x 100 (instances per type) x 8 (maximum operation variations) = 40 000 (at most) queries. (And it will run the initial findEntities 50 times.) Caveats Note the following caveats: The same GUIDs are used for each retrieval, but each method is run against every GUID before moving onto the next method.","title":"Graph queries profile"},{"location":"guides/cts/profiles/platform-origin/","text":"Platform origin profile \u00b6 The platform origin profile requires that an Open Metadata and Governance ( OMAG ) Server Platform is able to report its origin. Origin identifier \u00b6 The open metadata standards defines a getServerOrigin operation ( ../open-metadata/admin-services/users/{{adminUserId}}/server-platform-origin ). This operation returns an origin descriptor. Typically, this identifies the vendor, product name and version of the server. It is useful to administrators to be able to validate the platform that is running. This is the test case that validates whether the operation is present. Platform origin test case \u00b6 Validate the retrieval of the origin descriptor from the server platform that hosts one or more open metadata repositories and/or servers. This test uses the getServerPlatformOrigin operation ( ../open-metadata/platform-services/users/{{adminUserId}}/server-platform-origin ) operation to test that the platform knows its origin descriptor. Assertions ID Description platform-origin-01 The origin descriptor has successfully been retrieved from the server platform. If this assertion fails, check that the server platform is started and the open metadata services are activated. Discovered properties ID Description Platform origin id Descriptive name for the server platform implementation. Example output for platform origin test case { \"class\" : \"OpenMetadataTestCaseResult\" , \"testCaseId\" : \"platform-origin\" , \"testCaseName\" : \"Platform origin test case\" , \"testCaseDescriptionURL\" : \"https://egeria.odpi.org/open-metadata-conformance-suite/docs/platform-workbench/platfrom-origin-test-case.md\" , \"assertionMessage\" : \"Platform origin descriptor successfully retrieved\" , \"successfulAssertions\" : [ \"Origin descriptor retrieved from platform.\" ], \"unsuccessfulAssertions\" : [ ], \"discoveredProperties\" : { \"Repository origin id\" : \"Egeria OMAG Server Platform (version 3.1-SNAPSHOT)\" } }","title":"Platform Origin"},{"location":"guides/cts/profiles/platform-origin/#platform-origin-profile","text":"The platform origin profile requires that an Open Metadata and Governance ( OMAG ) Server Platform is able to report its origin.","title":"Platform origin profile"},{"location":"guides/cts/profiles/platform-origin/#origin-identifier","text":"The open metadata standards defines a getServerOrigin operation ( ../open-metadata/admin-services/users/{{adminUserId}}/server-platform-origin ). This operation returns an origin descriptor. Typically, this identifies the vendor, product name and version of the server. It is useful to administrators to be able to validate the platform that is running. This is the test case that validates whether the operation is present.","title":"Origin identifier"},{"location":"guides/cts/profiles/platform-origin/#platform-origin-test-case","text":"Validate the retrieval of the origin descriptor from the server platform that hosts one or more open metadata repositories and/or servers. This test uses the getServerPlatformOrigin operation ( ../open-metadata/platform-services/users/{{adminUserId}}/server-platform-origin ) operation to test that the platform knows its origin descriptor. Assertions ID Description platform-origin-01 The origin descriptor has successfully been retrieved from the server platform. If this assertion fails, check that the server platform is started and the open metadata services are activated. Discovered properties ID Description Platform origin id Descriptive name for the server platform implementation. Example output for platform origin test case { \"class\" : \"OpenMetadataTestCaseResult\" , \"testCaseId\" : \"platform-origin\" , \"testCaseName\" : \"Platform origin test case\" , \"testCaseDescriptionURL\" : \"https://egeria.odpi.org/open-metadata-conformance-suite/docs/platform-workbench/platfrom-origin-test-case.md\" , \"assertionMessage\" : \"Platform origin descriptor successfully retrieved\" , \"successfulAssertions\" : [ \"Origin descriptor retrieved from platform.\" ], \"unsuccessfulAssertions\" : [ ], \"discoveredProperties\" : { \"Repository origin id\" : \"Egeria OMAG Server Platform (version 3.1-SNAPSHOT)\" } }","title":"Platform origin test case"},{"location":"guides/cts/profiles/relationship-creation/","text":"Relationship creation profile \u00b6 The performance of programmatically creating new relationship instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for creating relationship instances: Method Description addRelationship adds a new relationship instance, where the technology under test is the home repository for that instance saveRelationshipReferenceCopy adds (or updates) an existing relationship instance, where the technology under test is not the home repository for that instance Assertions ID Description repository-relationship-creation-performance-addRelationship Invocation of the addRelationship method during the profile (see detailed logic below). repository-relationship-creation-performance-saveRelationshipReferenceCopy Invocation of the saveRelationshipReferenceCopy method during the profile (see detailed logic below). For every relationship type supported by the technology under test, this profile invokes each of these methods instancesPerType times. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will create 50 (types) x 100 (instances per type) x 2 (home + non-home methods) = 10 000 relationship instances. The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform In addition, these tests will record into the Environment profile the totalRelationshipsCreated .","title":"Relationship Creation"},{"location":"guides/cts/profiles/relationship-creation/#relationship-creation-profile","text":"The performance of programmatically creating new relationship instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for creating relationship instances: Method Description addRelationship adds a new relationship instance, where the technology under test is the home repository for that instance saveRelationshipReferenceCopy adds (or updates) an existing relationship instance, where the technology under test is not the home repository for that instance Assertions ID Description repository-relationship-creation-performance-addRelationship Invocation of the addRelationship method during the profile (see detailed logic below). repository-relationship-creation-performance-saveRelationshipReferenceCopy Invocation of the saveRelationshipReferenceCopy method during the profile (see detailed logic below). For every relationship type supported by the technology under test, this profile invokes each of these methods instancesPerType times. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will create 50 (types) x 100 (instances per type) x 2 (home + non-home methods) = 10 000 relationship instances. The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform In addition, these tests will record into the Environment profile the totalRelationshipsCreated .","title":"Relationship creation profile"},{"location":"guides/cts/profiles/relationship-delete/","text":"Relationship delete profile \u00b6 The performance of programmatically soft-deleting an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for deleting relationship instances: Method Description deleteRelationship soft-deletes the current version of a relationship Assertions ID Description repository-relationship-delete-performance-deleteRelationship See (2) in detailed logic below. repository-relationship-purge-performance-deleteRelationship See detailed logic of relationship purge profile. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationships of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship instances, deleteRelationship is called to soft-delete it. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will soft-delete 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.)","title":"Relationship Delete"},{"location":"guides/cts/profiles/relationship-delete/#relationship-delete-profile","text":"The performance of programmatically soft-deleting an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for deleting relationship instances: Method Description deleteRelationship soft-deletes the current version of a relationship Assertions ID Description repository-relationship-delete-performance-deleteRelationship See (2) in detailed logic below. repository-relationship-purge-performance-deleteRelationship See detailed logic of relationship purge profile. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationships of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship instances, deleteRelationship is called to soft-delete it. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will soft-delete 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.)","title":"Relationship delete profile"},{"location":"guides/cts/profiles/relationship-history-retrieval/","text":"Relationship history retrieval profile \u00b6 The performance of programmatically retrieving the history of existing relationship instances based on their ID. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving the history of relationship instances by their ID: Method Description getRelationship retrieves a relationship instance's details at a given point in time, if the relationship was known at that point in time, or throws an exception if not getRelationshipHistory retrieves the full history of a relationship instance's details Assertions ID Description repository-relationship-history-retrieval-performance-getRelationship See (2) in detailed logic below. repository-relationship-history-retrieval-performance-getRelationshipHistory See (3) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findRelationships and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, getRelationship is then called with an asOfTime using the timestamp captured prior to the execution of the Relationship Update profile, to retrieve its historical details from that point in time (prior to any updates). For each of these relationship GUIDs, getRelationshipHistory is then called to retrieve its full history (including current version and all historical versions of the instance). Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will retrieve 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 relationships. (And it will run findRelationships 50 times.)","title":"Relationship History Retrieval"},{"location":"guides/cts/profiles/relationship-history-retrieval/#relationship-history-retrieval-profile","text":"The performance of programmatically retrieving the history of existing relationship instances based on their ID. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving the history of relationship instances by their ID: Method Description getRelationship retrieves a relationship instance's details at a given point in time, if the relationship was known at that point in time, or throws an exception if not getRelationshipHistory retrieves the full history of a relationship instance's details Assertions ID Description repository-relationship-history-retrieval-performance-getRelationship See (2) in detailed logic below. repository-relationship-history-retrieval-performance-getRelationshipHistory See (3) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType entity GUIDs of that type. (This uses findRelationships and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, getRelationship is then called with an asOfTime using the timestamp captured prior to the execution of the Relationship Update profile, to retrieve its historical details from that point in time (prior to any updates). For each of these relationship GUIDs, getRelationshipHistory is then called to retrieve its full history (including current version and all historical versions of the instance). Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will retrieve 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 relationships. (And it will run findRelationships 50 times.)","title":"Relationship history retrieval profile"},{"location":"guides/cts/profiles/relationship-history-search/","text":"Relationship history search profile \u00b6 The performance of programmatically searching for relationship instances as they existed in the past. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for searching for relationship instances based on their details in the past, by passing in an asOfTime parameter (captured during the execution of the relationship update profile): Method Description findRelationships arbitrarily complex combinations of search criteria including ranges, nested conditions, etc findRelationshipsByProperty searches for relationship instances based on specific properties with specific values findRelationshipsByPropertyValue searches for relationship instances based on text that matches any textual property Assertions ID Description repository-relationship-search-history-performance-findRelationships-all-p... Interrogates the technology under test for each relationship type, by calling findRelationships for that type GUID with an asOfTime using the timestamp captured prior to the execution of the relationship update profile. These tests are performed with basic sorting of results, and all pages of results are retrieved (the p... portion indicates a specific page number): thereby also exercising the efficiency of the technology under test to both sort and cycle through pages of results. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-exact Repository performs historical search with an exact text value, sorting by oldest creation time, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-start Repository performs historical search with a text value 'starts-with', sorting by newest creation time, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-contains Repository performs historical search with a text value 'contains', sorting by oldest update time, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-end Repository performs historical search with a text value 'ends-with', sorting by newest update time, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-regex Repository performs historical search with a regular expression text value, sorting by GUID , of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByProperty-one Repository performs historical search by a single property value, sorting by that property, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByProperty-all Repository performs historical search by two property values, sorting by the second property, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByProperty-any Repository performs historical search by two property values, sorting by the second property, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByProperty-none Repository performs historical search by two property value, sorting by the first property, of first page of instances of a type. repository-relationship-history-retrieval-performance-findRelationships See the detailed logic of the relationship retrieval profile. Search variations When findRelationshipsByProperty is run by the assertions starting with repository-relationship-search-history-performance... , the tests prefer non-string properties (if any exist for the type) given that the findRelationshipsByPropertyValue searches will already heavily exercise string-based queries.","title":"Relationship History Search"},{"location":"guides/cts/profiles/relationship-history-search/#relationship-history-search-profile","text":"The performance of programmatically searching for relationship instances as they existed in the past. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for searching for relationship instances based on their details in the past, by passing in an asOfTime parameter (captured during the execution of the relationship update profile): Method Description findRelationships arbitrarily complex combinations of search criteria including ranges, nested conditions, etc findRelationshipsByProperty searches for relationship instances based on specific properties with specific values findRelationshipsByPropertyValue searches for relationship instances based on text that matches any textual property Assertions ID Description repository-relationship-search-history-performance-findRelationships-all-p... Interrogates the technology under test for each relationship type, by calling findRelationships for that type GUID with an asOfTime using the timestamp captured prior to the execution of the relationship update profile. These tests are performed with basic sorting of results, and all pages of results are retrieved (the p... portion indicates a specific page number): thereby also exercising the efficiency of the technology under test to both sort and cycle through pages of results. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-exact Repository performs historical search with an exact text value, sorting by oldest creation time, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-start Repository performs historical search with a text value 'starts-with', sorting by newest creation time, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-contains Repository performs historical search with a text value 'contains', sorting by oldest update time, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-end Repository performs historical search with a text value 'ends-with', sorting by newest update time, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByPropertyValue-regex Repository performs historical search with a regular expression text value, sorting by GUID , of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByProperty-one Repository performs historical search by a single property value, sorting by that property, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByProperty-all Repository performs historical search by two property values, sorting by the second property, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByProperty-any Repository performs historical search by two property values, sorting by the second property, of first page of instances of a type. repository-relationship-search-history-performance-findRelationshipsByProperty-none Repository performs historical search by two property value, sorting by the first property, of first page of instances of a type. repository-relationship-history-retrieval-performance-findRelationships See the detailed logic of the relationship retrieval profile. Search variations When findRelationshipsByProperty is run by the assertions starting with repository-relationship-search-history-performance... , the tests prefer non-string properties (if any exist for the type) given that the findRelationshipsByPropertyValue searches will already heavily exercise string-based queries.","title":"Relationship history search profile"},{"location":"guides/cts/profiles/relationship-purge/","text":"Relationship purge profile \u00b6 The performance of programmatically hard-deleting (irreversibly) existing relationship instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for hard-deleting relationship instances: Method Description purgeRelationship completely removes a relationship instance homed in the technology under test (including all of its history) purgeRelationshipReferenceCopy completely removes a relationship instance that is homed somewhere other than the technology under test (including all of its history) Assertions ID Description repository-relationship-purge-performance-purgeRelationship See (3) in detailed logic below. repository-relationship-purge-performance-purgeRelationshipReferenceCopy See (5) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationship GUIDs homed in the technology under test. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, deleteRelationship is called to soft-delete the instance. (This is necessary before a hard-delete can be done against the instance, and is recorded as part of the relationship delete profile.) For each of these relationship GUIDs, a purgeRelationship is then called to hard-delete the instance. Searches for instancesPerType reference copy relationships. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these reference copy relationship instances, purgeRelationshipReferenceCopy is called to remove the reference copy instance. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will remove 50 (types) x 100 (instances per type) x 3 (home + reference copy methods) = 15 000 relationships. (And it will run findRelationshipsByProperty 100 times.)","title":"Relationship Purge"},{"location":"guides/cts/profiles/relationship-purge/#relationship-purge-profile","text":"The performance of programmatically hard-deleting (irreversibly) existing relationship instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for hard-deleting relationship instances: Method Description purgeRelationship completely removes a relationship instance homed in the technology under test (including all of its history) purgeRelationshipReferenceCopy completely removes a relationship instance that is homed somewhere other than the technology under test (including all of its history) Assertions ID Description repository-relationship-purge-performance-purgeRelationship See (3) in detailed logic below. repository-relationship-purge-performance-purgeRelationshipReferenceCopy See (5) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationship GUIDs homed in the technology under test. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, deleteRelationship is called to soft-delete the instance. (This is necessary before a hard-delete can be done against the instance, and is recorded as part of the relationship delete profile.) For each of these relationship GUIDs, a purgeRelationship is then called to hard-delete the instance. Searches for instancesPerType reference copy relationships. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these reference copy relationship instances, purgeRelationshipReferenceCopy is called to remove the reference copy instance. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will remove 50 (types) x 100 (instances per type) x 3 (home + reference copy methods) = 15 000 relationships. (And it will run findRelationshipsByProperty 100 times.)","title":"Relationship purge profile"},{"location":"guides/cts/profiles/relationship-re-home/","text":"Relationship re-home profile \u00b6 The performance of programmatically changing the home repository of an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the home repository of relationship instances: Method Description reHomeRelationship changes the home repository of a relationship Assertions ID Description repository-relationship-re-home-performance-reHomeRelationship See (2) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType reference copy relationship GUIDs of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, reHomeEntity is called to change the home repository to the technology under test's metadataCollectionId . Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will re-home 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.)","title":"Relationship Re-home"},{"location":"guides/cts/profiles/relationship-re-home/#relationship-re-home-profile","text":"The performance of programmatically changing the home repository of an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the home repository of relationship instances: Method Description reHomeRelationship changes the home repository of a relationship Assertions ID Description repository-relationship-re-home-performance-reHomeRelationship See (2) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType reference copy relationship GUIDs of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, reHomeEntity is called to change the home repository to the technology under test's metadataCollectionId . Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will re-home 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.)","title":"Relationship re-home profile"},{"location":"guides/cts/profiles/relationship-re-identify/","text":"Relationship re-identify profile \u00b6 The performance of programmatically changing the GUID of an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the GUID of relationship instances: Method Description reIdentifyRelationship changes the GUID of an existing relationship Assertions ID Description repository-relationship-re-identify-performance-reIdentifyRelationship See (2) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType homed relationship GUIDs of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, reIdentifyRelationship is called to change its GUID to a new random GUID . Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will re-identify 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.)","title":"Relationship Re-identify"},{"location":"guides/cts/profiles/relationship-re-identify/#relationship-re-identify-profile","text":"The performance of programmatically changing the GUID of an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the GUID of relationship instances: Method Description reIdentifyRelationship changes the GUID of an existing relationship Assertions ID Description repository-relationship-re-identify-performance-reIdentifyRelationship See (2) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType homed relationship GUIDs of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, reIdentifyRelationship is called to change its GUID to a new random GUID . Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will re-identify 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.)","title":"Relationship re-identify profile"},{"location":"guides/cts/profiles/relationship-restore/","text":"Relationship restore profile \u00b6 The performance of programmatically reversing the latest soft-delete of an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for reverting soft-deletes on relationship instances: Method Description restoreRelationship reverts the last soft-delete that was made to a relationship Assertions ID Description repository-relationship-restore-performance-restoreRelationship See (2) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationship GUIDs of that type that have been soft-deleted. (This uses findRelationshipsByProperty with a condition to limit to the status DELETED only and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, restoreRelationship is called to revert the soft-delete and make the relationship active again. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will re-activate 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.)","title":"Relationship Restore"},{"location":"guides/cts/profiles/relationship-restore/#relationship-restore-profile","text":"The performance of programmatically reversing the latest soft-delete of an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for reverting soft-deletes on relationship instances: Method Description restoreRelationship reverts the last soft-delete that was made to a relationship Assertions ID Description repository-relationship-restore-performance-restoreRelationship See (2) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationship GUIDs of that type that have been soft-deleted. (This uses findRelationshipsByProperty with a condition to limit to the status DELETED only and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, restoreRelationship is called to revert the soft-delete and make the relationship active again. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will re-activate 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.)","title":"Relationship restore profile"},{"location":"guides/cts/profiles/relationship-retrieval/","text":"Relationship retrieval profile \u00b6 The performance of programmatically retrieving existing relationship instances based on their ID. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving relationship instances by their ID: Method Description isRelationshipKnown retrieves a relationship instance's details, if available, or returns null if not getRelationship retrieves a relationship instance's details, if available, or throws an exception if not Assertions ID Description repository-relationship-retrieval-performance-isRelationshipKnown See (2) in detailed logic below. repository-relationship-retrieval-performance-getRelationship See (3) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationship GUIDs of that type. (This uses findRelationships and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, isRelationshipKnown is called to retrieve it. For each of these relationship GUIDs, getRelationship is then called to retrieve its details. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will retrieve 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 relationships. (And it will run findRelationships 50 times.) Caveats Note the following caveats: The same GUIDs are used for each retrieval, but each method is run against every GUID before moving onto the next method.","title":"Relationship Retrieval"},{"location":"guides/cts/profiles/relationship-retrieval/#relationship-retrieval-profile","text":"The performance of programmatically retrieving existing relationship instances based on their ID. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines methods for retrieving relationship instances by their ID: Method Description isRelationshipKnown retrieves a relationship instance's details, if available, or returns null if not getRelationship retrieves a relationship instance's details, if available, or throws an exception if not Assertions ID Description repository-relationship-retrieval-performance-isRelationshipKnown See (2) in detailed logic below. repository-relationship-retrieval-performance-getRelationship See (3) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationship GUIDs of that type. (This uses findRelationships and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, isRelationshipKnown is called to retrieve it. For each of these relationship GUIDs, getRelationship is then called to retrieve its details. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will retrieve 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 relationships. (And it will run findRelationships 50 times.) Caveats Note the following caveats: The same GUIDs are used for each retrieval, but each method is run against every GUID before moving onto the next method.","title":"Relationship retrieval profile"},{"location":"guides/cts/profiles/relationship-retype/","text":"Relationship retype profile \u00b6 The performance of programmatically changing the type of an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the type of relationship instances: Method Description reTypeRelationship changes the type of an existing relationship Assertions ID Description repository-relationship-retype-performance-reTypeEntity-toSubtype See (3) in detailed logic below. repository-relationship-retype-performance-reTypeEntity-toSupertype See (4) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType homed relationship GUIDs of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, updateRelationshipProperties is called to remove all the relationship's properties (so it can be easily retyped), and its performance is recorded as part of the relationship update profile. For each of these relationship GUIDs, reTypeRelationship is called to change the type of the relationship to one of its subtypes. For each of these relationship GUIDs, reTypeRelationship is then called to change the type of the relationship back to its original type. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will retype 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 relationships at most. (And it will run findRelationshipsByProperty 50 times.) Caveats Note the following caveats: Instances of a given type will only be retyped if that type has any subtypes: if it has no subtypes, then all retyping operations will be skipped for that type's instances. Currently there are no open metadata relationship types that have supertypes or subtypes, so this profile will not actually have any metadata instance against which to call reTypeRelationship .","title":"Relationship Re-type"},{"location":"guides/cts/profiles/relationship-retype/#relationship-retype-profile","text":"The performance of programmatically changing the type of an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for changing the type of relationship instances: Method Description reTypeRelationship changes the type of an existing relationship Assertions ID Description repository-relationship-retype-performance-reTypeEntity-toSubtype See (3) in detailed logic below. repository-relationship-retype-performance-reTypeEntity-toSupertype See (4) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType homed relationship GUIDs of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship GUIDs, updateRelationshipProperties is called to remove all the relationship's properties (so it can be easily retyped), and its performance is recorded as part of the relationship update profile. For each of these relationship GUIDs, reTypeRelationship is called to change the type of the relationship to one of its subtypes. For each of these relationship GUIDs, reTypeRelationship is then called to change the type of the relationship back to its original type. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will retype 50 (types) x 100 (instances per type) x 2 (operations) = 10 000 relationships at most. (And it will run findRelationshipsByProperty 50 times.) Caveats Note the following caveats: Instances of a given type will only be retyped if that type has any subtypes: if it has no subtypes, then all retyping operations will be skipped for that type's instances. Currently there are no open metadata relationship types that have supertypes or subtypes, so this profile will not actually have any metadata instance against which to call reTypeRelationship .","title":"Relationship retype profile"},{"location":"guides/cts/profiles/relationship-search/","text":"Relationship search profile \u00b6 The performance of programmatically searching for existing relationship instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for searching for relationship instances: Method Description findRelationships arbitrarily complex combinations of search criteria including ranges, nested conditions, etc findRelationshipsByProperty searches for relationship instances based on specific properties with specific values findRelationshipsByPropertyValue searches for relationship instances based on text that matches any textual property Assertions ID Description repository-relationship-search-performance-findRelationships-all-p... This profile begins by interrogating the technology under test in its entirety, to discover every existing relationship instance of every type known to Egeria. The total count of these is tallied to report later under the environment profile. In this way, even for repositories that do not support write operations, we can still calculate some metrics about read performance (including search) while being able to understand that information in light of the volumes of metadata in the repository while the test was executed. These searches are also performed with basic sorting of results, and all pages of results are retrieved (the p... portion indicates a specific page number): thereby also exercising the efficiency of the technology under test to both sort and cycle through pages of results. repository-relationship-search-performance-findRelationshipsByPropertyValue-exact Repository performs search with an exact text value, sorting by oldest creation time, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByPropertyValue-start Repository performs search with a text value 'starts-with', sorting by newest creation time, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByPropertyValue-contains Repository performs search with a text value 'contains', sorting by oldest update time, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByPropertyValue-end Repository performs search with a text value 'ends-with', sorting by newest update time, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByPropertyValue-regex Repository performs search with a regular expression text value, sorting by GUID , of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByProperty-one Repository performs search by a single property value, sorting by that property, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByProperty-all Repository performs search by two property values, sorting by the second property, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByProperty-any Repository performs search by two property values, sorting by the second property, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByProperty-none Repository performs search by two property value, sorting by the first property, of first page of instances of a type. repository-relationship-delete-performance-findRelationshipsByProperty See the detailed logic of the relationship delete profile. repository-relationship-purge-performance-findRelationshipsByProperty See the detailed logic of the relationship purge profile. repository-relationship-purge-performance-findRelationshipsByProperty-rc See the detailed logic of the relationship purge profile. repository-relationship-re-home-performance-findRelationshipsByProperty See the detailed logic of the relationship re-home profile. repository-relationship-re-identify-performance-findRelationshipsByProperty See the detailed logic of the relationship re-identify profile. repository-relationship-restore-performance-findRelationshipsByProperty See the detailed logic of the relationship restore profile. repository-relationship-retrieval-performance-findRelationships See the detailed logic of the relationship retrieval profile. repository-relationship-retype-performance-findRelationshipsByProperty See the detailed logic of the relationship retype profile. repository-relationship-undo-performance-findRelationships See the detailed logic of the relationship undo profile. repository-relationship-update-performance-findRelationshipsByProperty See the detailed logic of the relationship update profile. In addition, these tests will record into the Environment profile the totalRelationshipsFound . Search variations When findRelationshipsByProperty is run by the assertions starting with repository-relationship-search-performance... , the tests prefer non-string properties (if any exist for the type) given that the findRelationshipsByPropertyValue searches will already heavily exercise string-based queries. Note that the various other assertions (that do not start with repository-relationship-search-performance... ) will search on various other properties than those listed: in particular, including header properties like metadataCollectionId , version , and others.","title":"Relationship Search"},{"location":"guides/cts/profiles/relationship-search/#relationship-search-profile","text":"The performance of programmatically searching for existing relationship instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for searching for relationship instances: Method Description findRelationships arbitrarily complex combinations of search criteria including ranges, nested conditions, etc findRelationshipsByProperty searches for relationship instances based on specific properties with specific values findRelationshipsByPropertyValue searches for relationship instances based on text that matches any textual property Assertions ID Description repository-relationship-search-performance-findRelationships-all-p... This profile begins by interrogating the technology under test in its entirety, to discover every existing relationship instance of every type known to Egeria. The total count of these is tallied to report later under the environment profile. In this way, even for repositories that do not support write operations, we can still calculate some metrics about read performance (including search) while being able to understand that information in light of the volumes of metadata in the repository while the test was executed. These searches are also performed with basic sorting of results, and all pages of results are retrieved (the p... portion indicates a specific page number): thereby also exercising the efficiency of the technology under test to both sort and cycle through pages of results. repository-relationship-search-performance-findRelationshipsByPropertyValue-exact Repository performs search with an exact text value, sorting by oldest creation time, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByPropertyValue-start Repository performs search with a text value 'starts-with', sorting by newest creation time, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByPropertyValue-contains Repository performs search with a text value 'contains', sorting by oldest update time, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByPropertyValue-end Repository performs search with a text value 'ends-with', sorting by newest update time, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByPropertyValue-regex Repository performs search with a regular expression text value, sorting by GUID , of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByProperty-one Repository performs search by a single property value, sorting by that property, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByProperty-all Repository performs search by two property values, sorting by the second property, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByProperty-any Repository performs search by two property values, sorting by the second property, of first page of instances of a type. repository-relationship-search-performance-findRelationshipsByProperty-none Repository performs search by two property value, sorting by the first property, of first page of instances of a type. repository-relationship-delete-performance-findRelationshipsByProperty See the detailed logic of the relationship delete profile. repository-relationship-purge-performance-findRelationshipsByProperty See the detailed logic of the relationship purge profile. repository-relationship-purge-performance-findRelationshipsByProperty-rc See the detailed logic of the relationship purge profile. repository-relationship-re-home-performance-findRelationshipsByProperty See the detailed logic of the relationship re-home profile. repository-relationship-re-identify-performance-findRelationshipsByProperty See the detailed logic of the relationship re-identify profile. repository-relationship-restore-performance-findRelationshipsByProperty See the detailed logic of the relationship restore profile. repository-relationship-retrieval-performance-findRelationships See the detailed logic of the relationship retrieval profile. repository-relationship-retype-performance-findRelationshipsByProperty See the detailed logic of the relationship retype profile. repository-relationship-undo-performance-findRelationships See the detailed logic of the relationship undo profile. repository-relationship-update-performance-findRelationshipsByProperty See the detailed logic of the relationship update profile. In addition, these tests will record into the Environment profile the totalRelationshipsFound . Search variations When findRelationshipsByProperty is run by the assertions starting with repository-relationship-search-performance... , the tests prefer non-string properties (if any exist for the type) given that the findRelationshipsByPropertyValue searches will already heavily exercise string-based queries. Note that the various other assertions (that do not start with repository-relationship-search-performance... ) will search on various other properties than those listed: in particular, including header properties like metadataCollectionId , version , and others.","title":"Relationship search profile"},{"location":"guides/cts/profiles/relationship-undo/","text":"Relationship undo profile \u00b6 The performance of programmatically reversing the latest update to an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for reverting updates on relationship instances: Method Description undoRelationshipUpdate reverts the last update that was made to a relationship Assertions ID Description repository-relationship-undo-performance-undoRelationshipUpdate See (2) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationships of that type that have at least one change. (This uses findRelationships with a condition on both metadataCollectionId and version being greater than 1 , and its performance is recorded as part of the relationship search profile.) For each of these relationship instances, undoRelationshipUpdate is called to revert the last change. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationships 50 times.) Caveats Note the following caveats: Relationship type definitions that have no properties will not be reverted: since there are no properties to update, there will not have been any updated version (and thus nothing to revert).","title":"Relationship Undo"},{"location":"guides/cts/profiles/relationship-undo/#relationship-undo-profile","text":"The performance of programmatically reversing the latest update to an existing relationship instance. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines an optional method for reverting updates on relationship instances: Method Description undoRelationshipUpdate reverts the last update that was made to a relationship Assertions ID Description repository-relationship-undo-performance-undoRelationshipUpdate See (2) in detailed logic below. For every relationship type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationships of that type that have at least one change. (This uses findRelationships with a condition on both metadataCollectionId and version being greater than 1 , and its performance is recorded as part of the relationship search profile.) For each of these relationship instances, undoRelationshipUpdate is called to revert the last change. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationships 50 times.) Caveats Note the following caveats: Relationship type definitions that have no properties will not be reverted: since there are no properties to update, there will not have been any updated version (and thus nothing to revert).","title":"Relationship undo profile"},{"location":"guides/cts/profiles/relationship-update/","text":"Relationship update profile \u00b6 The performance of programmatically updating existing relationship instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for updating relationship instances: Method Description updateRelationshipProperties changes one or more values of the properties on an existing relationship updateRelationshipStatus changes the status of an existing relationship Assertions ID Description repository-relationship-update-performance-updateEntityProperties See (2) in detailed logic below. repository-relationship-retype-performance-updateEntityProperties-remove See the detailed logic of the relationship retype profile. Captures timestamp for historical metadata profiles Prior to this profile running, a timestamp is captured by the performance workbench to denote a specific date and time prior to any updates having been made to the relationships. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationships of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship instances, updateRelationshipProperties is called to update the existing property values of the relationship, using a new generated set of properties. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.) The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform Caveats Note the following caveats: updateRelationshipStatus is currently not tested (there are very few types that support any status that can be updated outside of a delete or restore operation). Relationship type definitions that have no properties will not be updated, since there are no properties to update.","title":"Relationship Update"},{"location":"guides/cts/profiles/relationship-update/#relationship-update-profile","text":"The performance of programmatically updating existing relationship instances. The Open Metadata Repository Services ( OMRS ) interface for a metadata repository defines optional methods for updating relationship instances: Method Description updateRelationshipProperties changes one or more values of the properties on an existing relationship updateRelationshipStatus changes the status of an existing relationship Assertions ID Description repository-relationship-update-performance-updateEntityProperties See (2) in detailed logic below. repository-relationship-retype-performance-updateEntityProperties-remove See the detailed logic of the relationship retype profile. Captures timestamp for historical metadata profiles Prior to this profile running, a timestamp is captured by the performance workbench to denote a specific date and time prior to any updates having been made to the relationships. For every entity type supported by the technology under test, this profile does the following (in order): Searches for instancesPerType relationships of that type. (This uses findRelationshipsByProperty with a condition on metadataCollectionId and its performance is recorded as part of the relationship search profile.) For each of these relationship instances, updateRelationshipProperties is called to update the existing property values of the relationship, using a new generated set of properties. Example So, for example, if the technology under test supports 50 relationship types, and the instancesPerType parameter is set to 100, then this profile will update 50 (types) x 100 (instances per type) = 5000 relationships. (And it will run findRelationshipsByProperty 50 times.) The properties of each of these instances will be fully-populated with: Any string properties containing a value representative of the property name itself (and where unique, they will be made unique through appending a unique sequence) Any non-string properties will be randomly generated, in a simple attempt to represent data that is not entirely uniform Caveats Note the following caveats: updateRelationshipStatus is currently not tested (there are very few types that support any status that can be updated outside of a delete or restore operation). Relationship type definitions that have no properties will not be updated, since there are no properties to update.","title":"Relationship update profile"},{"location":"guides/developer/guide/","text":"Developer Guide \u00b6 Egeria is designed to simplify the effort necessary to integrate different technologies so that they can actively share and consume metadata from each other. It focuses on providing five types of integration interfaces. Connectors that translate between third party APIs and open metadata APIs. These connectors are hosted in the Egeria servers and support the active exchange of metadata with these technologies. Connectors for accessing popular type of data sources that also retrieve open metadata about the data source. This allows applications and tools to understand the structure, meaning, profile, quality and lineage of the data they are using. Java clients for applications to call the Open Metadata Access Service ( OMAS ) interfaces, each of which are crafted for particular types of technology. These interfaces support both synchronous APIs, inbound event notifications and outbound asynchronous events. REST APIs for the Egeria Services. These include the access services , admin services and platform services . Kafka topics with JSON payloads for asynchronous communication (both in and out) with the open metadata ecosystem. Learn more ... Using the clients \u00b6 The Egeria clients wrap calls to Egeria's REST APIs and topics. The aim is to provide a language-specific interface that manages the marshalling and de-marshalling of the call parameters and responses to these services. Using the REST APIs \u00b6 Egeria supports REST APIs for making synchronous (request-response) calls between OMAG Servers and between clients and OMAG Servers. REST APIs are intended for internal use The REST APIs are usable directly for calling from non-Java platforms; however, they are designed for the internal use of Egeria and are not guaranteed to be backwards compatible. The structure of the URL for an Egeria REST API varies lightly depending on whether it is a call to an OMAG Server Platform service or an OMAG Server service. What is a connector? \u00b6 Connectors are plug-in Java clients that either perform an additional service, or, more typically, enable Egeria to integrate with a third party technology. The concept of a connector comes from the Open Connector Framework ( OCF ) . The OCF provides a common framework for components that enable one technology to call another, arbitrary technology through a common interface. The implementation of the connector is dynamically loaded based on the connector's configuration. Through the OCF , we can: Plug-in different technologies to Egeria. Plug-in support for open metadata into the client libraries used by applications to access data resources and services. Many subsystems in Egeria's OMAG Server Platform and servers support the first approach. They define a specialized interface for the type of connector they support. One or more connector implementations supporting that interface are then written either by the Egeria community or other organizations. When an Egeria OMAG Server is configured, details of which connector implementation to use is specified in the server's configuration document . At start up, the OMAG Server passes the connector configuration to the OCF to instantiate the required connector instance. Connectors enable Egeria to operate in many environments and with many types of third party technologies, just by managing the configuration of the OMAG Servers. The second approach is used by organizations that want to make use of metadata directly in applications and tools - or to externalize the security and driver properties needed to call the data source or service. In this case the OCF connector typically has the same interface as the data source's client library (unless you can do better ). This minimizes the learning curve for application developers. The configuration for the connector is stored in an open metadata server and the application uses the Asset Consumer OMAS client to request a new instance of the connector . The application uses the returned connector instance to access the data source or server along with the metadata stored about it. Configuration \u00b6 The configuration for a connector is managed in a connection object. A connection contains properties about the specific use of the connector, such as user Id and password, or parameters that control the scope or resources that should be made available to the connector. It links to an optional endpoint and a mandatory connector type object. ConnectorType describes the type of the connector, its supported configuration properties and its factory object (called the connector's provider ). This information is used to create an instance of the connector at runtime. Endpoint describes the server endpoint where the third party data source or service is accessed from. Connector types and endpoints can be reused in multiple connections. Factories \u00b6 Each connector implementation has a factory object called a connector provider . The connector provider has two types of methods: Return a new instance of the connector based on the properties in a supplied Connection object. The Connection object has all the properties needed to create and configure the instance of the connector. Return additional information about the connector's behavior and usage to make it easier to consume. For example, the standard base class for a connector provider has a method to return the ConnectorType object for this connector implementation that can be added to a Connection object used to hold the properties needed to create an instance of the connector. Inside the connector \u00b6 Each connector has its own unique implementation that is structured around a simple lifecycle that is defined by the OCF . The OCF provides the interface for a connector called Connector that has three methods: initialize , start and disconnect . This connector interface supports the basic lifecycle of a connector. There are three phases: Initialization - During this phase, the connector is passed the context in which it is to operate. It should store this information. This phase is initiated by a call to the connector's initialize() method, which is called after the connector's constructor and provides the connector with a unique instance identifier (for logging) and its configuration stored in a connection . After initialize() returns, there may be other calls to pass context to the connector. For example, if the connector implements the AuditLoggingComponent , an audit log is passed to the connector. Running - The connector is completely initialized with its context, and it can start processing. This phase is initiated by a call to the connector's start() method. At this point it should create its client to any third party technology and begin processing. It may also start up threads if it needs to perform any background processing (such as listening for notifications). If the connector throws an exception during start, Egeria knows the connector has a configuration or operational issue and will report the error and move it to disconnected state. Disconnected - The connector must stop processing and release all of its resources. This phase is initiated by a call to the connector's disconnect() method. Depending on the type of connector you are writing, there may be additional initialization calls occurring between the initialize() and the start() method. The connector may also support additional methods for its normal operation that can be called between the start() and disconnect() calls. The OCF also provides the base class for a connector called ConnectorBase . The ConnectorBase base class manages the lifecycle state of the connector. For example, the default implementation of initialize() in the ConnectorBase class stores the supplied unique instance identifier and connection values in protected variables called connectorInstanceId and connectionProperties respectively. Call the base class's methods in any overrides If you override any of the initialize() , start() or disconnect() methods, be sure to call super.xxx() at the start of your implementation to call the appropriate super class method so that the state is properly maintained. Extending Egeria using connectors \u00b6 Egeria has extended the basic concept of the OCF connector and created specialized connectors for different purposes. The following types of connectors are supported by the Egeria subsystems with links to the documentation and implementation examples. Type of Connector Description Documentation Implementation Examples Integration Connector Implements metadata exchange with third party tools. Building Integration Connectors integration-connectors Open Discovery Service Implements automated metadata discovery. Open Discovery Services discovery-service-connectors Governance Action Service Implements automated governance. Governance Action Services governance-action-connectors Configuration Document Store Persists the configuration document for an OMAG Server. Configuration Document Store Connectors configuration-store-connectors Platform Security Connector Manages service authorization for the OMAG Server Platform. Metadata Security Connectors open-metadata-security-samples Server Security Connector Manages service and metadata instance authorization for an OMAG Server. Metadata Security Connectors open-metadata-security-samples Metadata Collection (repository) Store Interfaces with a metadata repository API for retrieving and storing metadata. OMRS Repository Connectors open-metadata-collection-store-connectors Metadata Collection (repository) Event Mapper Maps events from a third party metadata repository to open metadata events. OMRS Event Mappers none Open Metadata Archive Store Reads an open metadata archive from a particular type of store. OMRS Open Metadata Archive Store Connector open-metadata-archive-connectors Audit Log Store Audit logging destination OMRS Audit Log Store Connector audit-log-connectors Cohort Registry Store Local store of membership of an open metadata repository cohort. OMRS Cohort Registry Store cohort-registry-store-connectors Open Metadata Topic Connector Connects to a topic on an external event bus such as Apache Kafka. OMRS Open Metadata Topic Connectors open-metadata- topic-connectors You can write your own connectors to integrate additional types of technology or extend the capabilities of Egeria - and if you think your connector is more generally useful, you could consider contributing it to the Egeria project .","title":"Developer Guide"},{"location":"guides/developer/guide/#developer-guide","text":"Egeria is designed to simplify the effort necessary to integrate different technologies so that they can actively share and consume metadata from each other. It focuses on providing five types of integration interfaces. Connectors that translate between third party APIs and open metadata APIs. These connectors are hosted in the Egeria servers and support the active exchange of metadata with these technologies. Connectors for accessing popular type of data sources that also retrieve open metadata about the data source. This allows applications and tools to understand the structure, meaning, profile, quality and lineage of the data they are using. Java clients for applications to call the Open Metadata Access Service ( OMAS ) interfaces, each of which are crafted for particular types of technology. These interfaces support both synchronous APIs, inbound event notifications and outbound asynchronous events. REST APIs for the Egeria Services. These include the access services , admin services and platform services . Kafka topics with JSON payloads for asynchronous communication (both in and out) with the open metadata ecosystem. Learn more ...","title":"Developer Guide"},{"location":"guides/developer/guide/#using-the-clients","text":"The Egeria clients wrap calls to Egeria's REST APIs and topics. The aim is to provide a language-specific interface that manages the marshalling and de-marshalling of the call parameters and responses to these services.","title":"Using the clients"},{"location":"guides/developer/guide/#using-the-rest-apis","text":"Egeria supports REST APIs for making synchronous (request-response) calls between OMAG Servers and between clients and OMAG Servers. REST APIs are intended for internal use The REST APIs are usable directly for calling from non-Java platforms; however, they are designed for the internal use of Egeria and are not guaranteed to be backwards compatible. The structure of the URL for an Egeria REST API varies lightly depending on whether it is a call to an OMAG Server Platform service or an OMAG Server service.","title":"Using the REST APIs"},{"location":"guides/developer/guide/#what-is-a-connector","text":"Connectors are plug-in Java clients that either perform an additional service, or, more typically, enable Egeria to integrate with a third party technology. The concept of a connector comes from the Open Connector Framework ( OCF ) . The OCF provides a common framework for components that enable one technology to call another, arbitrary technology through a common interface. The implementation of the connector is dynamically loaded based on the connector's configuration. Through the OCF , we can: Plug-in different technologies to Egeria. Plug-in support for open metadata into the client libraries used by applications to access data resources and services. Many subsystems in Egeria's OMAG Server Platform and servers support the first approach. They define a specialized interface for the type of connector they support. One or more connector implementations supporting that interface are then written either by the Egeria community or other organizations. When an Egeria OMAG Server is configured, details of which connector implementation to use is specified in the server's configuration document . At start up, the OMAG Server passes the connector configuration to the OCF to instantiate the required connector instance. Connectors enable Egeria to operate in many environments and with many types of third party technologies, just by managing the configuration of the OMAG Servers. The second approach is used by organizations that want to make use of metadata directly in applications and tools - or to externalize the security and driver properties needed to call the data source or service. In this case the OCF connector typically has the same interface as the data source's client library (unless you can do better ). This minimizes the learning curve for application developers. The configuration for the connector is stored in an open metadata server and the application uses the Asset Consumer OMAS client to request a new instance of the connector . The application uses the returned connector instance to access the data source or server along with the metadata stored about it.","title":"What is a connector?"},{"location":"guides/developer/guide/#configuration","text":"The configuration for a connector is managed in a connection object. A connection contains properties about the specific use of the connector, such as user Id and password, or parameters that control the scope or resources that should be made available to the connector. It links to an optional endpoint and a mandatory connector type object. ConnectorType describes the type of the connector, its supported configuration properties and its factory object (called the connector's provider ). This information is used to create an instance of the connector at runtime. Endpoint describes the server endpoint where the third party data source or service is accessed from. Connector types and endpoints can be reused in multiple connections.","title":"Configuration"},{"location":"guides/developer/guide/#factories","text":"Each connector implementation has a factory object called a connector provider . The connector provider has two types of methods: Return a new instance of the connector based on the properties in a supplied Connection object. The Connection object has all the properties needed to create and configure the instance of the connector. Return additional information about the connector's behavior and usage to make it easier to consume. For example, the standard base class for a connector provider has a method to return the ConnectorType object for this connector implementation that can be added to a Connection object used to hold the properties needed to create an instance of the connector.","title":"Factories"},{"location":"guides/developer/guide/#inside-the-connector","text":"Each connector has its own unique implementation that is structured around a simple lifecycle that is defined by the OCF . The OCF provides the interface for a connector called Connector that has three methods: initialize , start and disconnect . This connector interface supports the basic lifecycle of a connector. There are three phases: Initialization - During this phase, the connector is passed the context in which it is to operate. It should store this information. This phase is initiated by a call to the connector's initialize() method, which is called after the connector's constructor and provides the connector with a unique instance identifier (for logging) and its configuration stored in a connection . After initialize() returns, there may be other calls to pass context to the connector. For example, if the connector implements the AuditLoggingComponent , an audit log is passed to the connector. Running - The connector is completely initialized with its context, and it can start processing. This phase is initiated by a call to the connector's start() method. At this point it should create its client to any third party technology and begin processing. It may also start up threads if it needs to perform any background processing (such as listening for notifications). If the connector throws an exception during start, Egeria knows the connector has a configuration or operational issue and will report the error and move it to disconnected state. Disconnected - The connector must stop processing and release all of its resources. This phase is initiated by a call to the connector's disconnect() method. Depending on the type of connector you are writing, there may be additional initialization calls occurring between the initialize() and the start() method. The connector may also support additional methods for its normal operation that can be called between the start() and disconnect() calls. The OCF also provides the base class for a connector called ConnectorBase . The ConnectorBase base class manages the lifecycle state of the connector. For example, the default implementation of initialize() in the ConnectorBase class stores the supplied unique instance identifier and connection values in protected variables called connectorInstanceId and connectionProperties respectively. Call the base class's methods in any overrides If you override any of the initialize() , start() or disconnect() methods, be sure to call super.xxx() at the start of your implementation to call the appropriate super class method so that the state is properly maintained.","title":"Inside the connector"},{"location":"guides/developer/guide/#extending-egeria-using-connectors","text":"Egeria has extended the basic concept of the OCF connector and created specialized connectors for different purposes. The following types of connectors are supported by the Egeria subsystems with links to the documentation and implementation examples. Type of Connector Description Documentation Implementation Examples Integration Connector Implements metadata exchange with third party tools. Building Integration Connectors integration-connectors Open Discovery Service Implements automated metadata discovery. Open Discovery Services discovery-service-connectors Governance Action Service Implements automated governance. Governance Action Services governance-action-connectors Configuration Document Store Persists the configuration document for an OMAG Server. Configuration Document Store Connectors configuration-store-connectors Platform Security Connector Manages service authorization for the OMAG Server Platform. Metadata Security Connectors open-metadata-security-samples Server Security Connector Manages service and metadata instance authorization for an OMAG Server. Metadata Security Connectors open-metadata-security-samples Metadata Collection (repository) Store Interfaces with a metadata repository API for retrieving and storing metadata. OMRS Repository Connectors open-metadata-collection-store-connectors Metadata Collection (repository) Event Mapper Maps events from a third party metadata repository to open metadata events. OMRS Event Mappers none Open Metadata Archive Store Reads an open metadata archive from a particular type of store. OMRS Open Metadata Archive Store Connector open-metadata-archive-connectors Audit Log Store Audit logging destination OMRS Audit Log Store Connector audit-log-connectors Cohort Registry Store Local store of membership of an open metadata repository cohort. OMRS Cohort Registry Store cohort-registry-store-connectors Open Metadata Topic Connector Connects to a topic on an external event bus such as Apache Kafka. OMRS Open Metadata Topic Connectors open-metadata- topic-connectors You can write your own connectors to integrate additional types of technology or extend the capabilities of Egeria - and if you think your connector is more generally useful, you could consider contributing it to the Egeria project .","title":"Extending Egeria using connectors"},{"location":"guides/developer/implement-a-connector/","text":"Develop a Connector \u00b6 When you want to connect to a tool or system from an existing service, you need to create an open connector for that tool or system. For example, you might want to connect a new metadata repository into Egeria, or connect Egeria with a new data processing engine. To write an open connector you need to complete four steps: Identify the properties for the connection . Write the connector provider . Understand the interface the connector needs to implement. Write the connector itself. All the code you write to implement these should exist in its own module, and as illustrated by the examples could even be in its own independent code repository. Their implementation will have dependencies on Egeria's: Open Connector Framework ( OCF ) Audit Log Framework ( ALF ) Specific interfaces used by the type of connector No dependency on Egeria's OMAG Server Platform Note that there is no dependency on Egeria's OMAG Server Platform for these specific connector implementations: they could run in another runtime that supported the connector APIs. Identify connection properties \u00b6 Begin by identifying and designing the properties needed to connect to your tool or system. These will commonly include a network address, protocol, and user credentials, but could also include other information. Code the connector provider \u00b6 The connector provider is a simple Java factory that implements the creation of the connector type it can instantiate using: a GUID for the connector type a name for the connector type a description of what the connector is for and how to configure it the connector class it instantiates a list of the additional properties, configuration properties and secured properties needed to configure instances of the connector Example: connector provider for IBM DataStage For example, the DataStageConnectorProvider is used to instantiate connectors to IBM DataStage data processing engines. Therefore, its name and description refer to DataStage, and the connectors it instantiates are DataStageConnector s . Example: connector provider for IBM Information Governance Catalog Similarly, the IGCOMRSRepositoryConnectorProvider is used to instantiate connectors to IBM Information Governance Catalog ( IGC ) metadata repositories. In contrast to the DataStageConnectorProvider , the IGCOMRSRepositoryConnectorProvider 's name and description refer to IGC , and the connectors it instantiates are IGCOMRSRepositoryConnector s . Connectors implement Egeria interfaces, not vice versa Note that the code of all of these connector implementations exists outside Egeria itself (in separate code repositories), and there are no direct dependencies within Egeria on these external repositories or connectors. All connectors can be configured with the network address and credential information needed to access the underlying tool or system. Therefore, you do not need to explicitly list properties for such basic details. However, the names of any additional configuration properties that may be useful to a specific type of connector can be described through the recognizedConfigurationProperties of the connector type. Implementation pattern \u00b6 From the two examples ( DataStageConnectorProvider and IGCOMRSRepositoryConnectorProvider ), you will see that writing a connector provider follows a simple pattern: Extend a connector provider base class specific to your connector's interface. Define static final class members for the GUID , name, description and the names of any additional configuration properties. Write a single public constructor, with no parameters, that: Calls super.setConnectorClassName() with the name of your connector class. Creates a new ConnectorType object, sets it characteristics to the static final class members, and uses .setConnectorProviderClassName() to set the name of the connector provider class itself. (Optional) Creates a list of additional configuration properties from the static final class members, and uses .setRecognizedConfigurationProperties() to add these to the connector type. Sets super.connectorTypeBean = connectorType . Understand the connector interface \u00b6 Now that you have the connector provider to instantiate your connector , you need to understand what your connector actually needs to do. For a service to use your connector, the connector must provide a set of methods that are relevant to that service. Example: data engine proxy connector interface For example, the data engine proxy services integrate metadata from data engines with Egeria. To integrate DataStage with Egeria, we want our DataStageConnector to be used by the data engine proxy services. Therefore, the connector needs to extend DataEngineConnectorBase , because this defines the methods needed by the data engine proxy services. Example: OMRS repository connector interface Likewise, we want our IGCOMRSRepositoryConnector to integrate IGC with Egeria as a metadata repository. Therefore, the connector needs to extend OMRSRepositoryConnector , because this defines the methods needed to integrate with Open Metadata Repository Services ( OMRS ) . How would you know to extend these base classes? The connector provider implementations in the previous step each extended a base class specific to the type of connector they provide ( DataEngineConnectorProviderBase and OMRSRepositoryConnectorProviderBase ). These connector base classes ( DataEngineConnectorBase and OMRSRepositoryConnector ) are in the same package structure as those connector provider base classes. In both cases, by extending the abstract classes ( DataEngineConnectorBase and OMRSRepositoryConnector ) your connector must implement the methods these abstract classes define. These general methods implement your services (data engine proxy services and OMRS ), without needing to know anything about the underlying technology. Therefore, you can simply \"plug-in\" the underlying technology: any technology with a connector that implements these methods can run your service. Furthermore, each technology-specific connector can decide how best to implement those methods for itself. Code the connector itself \u00b6 Which brings you to writing the connector itself. Now that you understand the interface your connector must provide, you need to implement the methods defined by that interface. Implement the connector by: Retrieving connection information provided by the configuration. The default method for initialize() saves the connection object used to create the connector. If your connector needs to override the initialize() method, it should call super.initialize() to capture the connection properties for the base classes. Implementing the start() method, where the main logic for your connector runs. Use the configuration details from the connection object to connect to your underlying technology. If the connector is long-running, this may be the time to start up a separate thread. However, this has to conform the rules laid down for the category of connector you are implementing. Using pre-existing, technology-specific clients and APIs to talk to your underlying technology. Translating the underlying technology's representation of information into the open metadata representation used by the connector interface itself. For the first point, you can retrieve general connection information like: the server address and protocol, by first retrieving the embedded EndpointProperties with getEndpoint() : retrieving the protocol by calling getProtocol() on the EndpointProperties retrieving the address by calling getAddress() on the EndpointProperties the user Id, by calling getUserId() on the ConnectionProperties the password, by calling either getClearPassword() or getEncryptedPassword() on the ConnectionProperties , depending on what your underlying technology can handle Use these details to connect to and authenticate against your underlying technology, even when it is running on a different system from the connector itself. Of course, check for null objects (like the EndpointProperties ) as well before blindly operating on them. Retrieve additional properties by: calling getConfigurationProperties() on the ConnectionProperties , which returns a Map<String, Object> calling get(name) against that Map<> with the name of each additional property of interest Implementation of the remaining points (2-3) will vary widely depending on the specific technology being used. See the examples previously linked to delve deeper.","title":"Develop a Connector"},{"location":"guides/developer/implement-a-connector/#develop-a-connector","text":"When you want to connect to a tool or system from an existing service, you need to create an open connector for that tool or system. For example, you might want to connect a new metadata repository into Egeria, or connect Egeria with a new data processing engine. To write an open connector you need to complete four steps: Identify the properties for the connection . Write the connector provider . Understand the interface the connector needs to implement. Write the connector itself. All the code you write to implement these should exist in its own module, and as illustrated by the examples could even be in its own independent code repository. Their implementation will have dependencies on Egeria's: Open Connector Framework ( OCF ) Audit Log Framework ( ALF ) Specific interfaces used by the type of connector No dependency on Egeria's OMAG Server Platform Note that there is no dependency on Egeria's OMAG Server Platform for these specific connector implementations: they could run in another runtime that supported the connector APIs.","title":"Develop a Connector"},{"location":"guides/developer/implement-a-connector/#identify-connection-properties","text":"Begin by identifying and designing the properties needed to connect to your tool or system. These will commonly include a network address, protocol, and user credentials, but could also include other information.","title":"Identify connection properties"},{"location":"guides/developer/implement-a-connector/#code-the-connector-provider","text":"The connector provider is a simple Java factory that implements the creation of the connector type it can instantiate using: a GUID for the connector type a name for the connector type a description of what the connector is for and how to configure it the connector class it instantiates a list of the additional properties, configuration properties and secured properties needed to configure instances of the connector Example: connector provider for IBM DataStage For example, the DataStageConnectorProvider is used to instantiate connectors to IBM DataStage data processing engines. Therefore, its name and description refer to DataStage, and the connectors it instantiates are DataStageConnector s . Example: connector provider for IBM Information Governance Catalog Similarly, the IGCOMRSRepositoryConnectorProvider is used to instantiate connectors to IBM Information Governance Catalog ( IGC ) metadata repositories. In contrast to the DataStageConnectorProvider , the IGCOMRSRepositoryConnectorProvider 's name and description refer to IGC , and the connectors it instantiates are IGCOMRSRepositoryConnector s . Connectors implement Egeria interfaces, not vice versa Note that the code of all of these connector implementations exists outside Egeria itself (in separate code repositories), and there are no direct dependencies within Egeria on these external repositories or connectors. All connectors can be configured with the network address and credential information needed to access the underlying tool or system. Therefore, you do not need to explicitly list properties for such basic details. However, the names of any additional configuration properties that may be useful to a specific type of connector can be described through the recognizedConfigurationProperties of the connector type.","title":"Code the connector provider"},{"location":"guides/developer/implement-a-connector/#implementation-pattern","text":"From the two examples ( DataStageConnectorProvider and IGCOMRSRepositoryConnectorProvider ), you will see that writing a connector provider follows a simple pattern: Extend a connector provider base class specific to your connector's interface. Define static final class members for the GUID , name, description and the names of any additional configuration properties. Write a single public constructor, with no parameters, that: Calls super.setConnectorClassName() with the name of your connector class. Creates a new ConnectorType object, sets it characteristics to the static final class members, and uses .setConnectorProviderClassName() to set the name of the connector provider class itself. (Optional) Creates a list of additional configuration properties from the static final class members, and uses .setRecognizedConfigurationProperties() to add these to the connector type. Sets super.connectorTypeBean = connectorType .","title":"Implementation pattern"},{"location":"guides/developer/implement-a-connector/#understand-the-connector-interface","text":"Now that you have the connector provider to instantiate your connector , you need to understand what your connector actually needs to do. For a service to use your connector, the connector must provide a set of methods that are relevant to that service. Example: data engine proxy connector interface For example, the data engine proxy services integrate metadata from data engines with Egeria. To integrate DataStage with Egeria, we want our DataStageConnector to be used by the data engine proxy services. Therefore, the connector needs to extend DataEngineConnectorBase , because this defines the methods needed by the data engine proxy services. Example: OMRS repository connector interface Likewise, we want our IGCOMRSRepositoryConnector to integrate IGC with Egeria as a metadata repository. Therefore, the connector needs to extend OMRSRepositoryConnector , because this defines the methods needed to integrate with Open Metadata Repository Services ( OMRS ) . How would you know to extend these base classes? The connector provider implementations in the previous step each extended a base class specific to the type of connector they provide ( DataEngineConnectorProviderBase and OMRSRepositoryConnectorProviderBase ). These connector base classes ( DataEngineConnectorBase and OMRSRepositoryConnector ) are in the same package structure as those connector provider base classes. In both cases, by extending the abstract classes ( DataEngineConnectorBase and OMRSRepositoryConnector ) your connector must implement the methods these abstract classes define. These general methods implement your services (data engine proxy services and OMRS ), without needing to know anything about the underlying technology. Therefore, you can simply \"plug-in\" the underlying technology: any technology with a connector that implements these methods can run your service. Furthermore, each technology-specific connector can decide how best to implement those methods for itself.","title":"Understand the connector interface"},{"location":"guides/developer/implement-a-connector/#code-the-connector-itself","text":"Which brings you to writing the connector itself. Now that you understand the interface your connector must provide, you need to implement the methods defined by that interface. Implement the connector by: Retrieving connection information provided by the configuration. The default method for initialize() saves the connection object used to create the connector. If your connector needs to override the initialize() method, it should call super.initialize() to capture the connection properties for the base classes. Implementing the start() method, where the main logic for your connector runs. Use the configuration details from the connection object to connect to your underlying technology. If the connector is long-running, this may be the time to start up a separate thread. However, this has to conform the rules laid down for the category of connector you are implementing. Using pre-existing, technology-specific clients and APIs to talk to your underlying technology. Translating the underlying technology's representation of information into the open metadata representation used by the connector interface itself. For the first point, you can retrieve general connection information like: the server address and protocol, by first retrieving the embedded EndpointProperties with getEndpoint() : retrieving the protocol by calling getProtocol() on the EndpointProperties retrieving the address by calling getAddress() on the EndpointProperties the user Id, by calling getUserId() on the ConnectionProperties the password, by calling either getClearPassword() or getEncryptedPassword() on the ConnectionProperties , depending on what your underlying technology can handle Use these details to connect to and authenticate against your underlying technology, even when it is running on a different system from the connector itself. Of course, check for null objects (like the EndpointProperties ) as well before blindly operating on them. Retrieve additional properties by: calling getConfigurationProperties() on the ConnectionProperties , which returns a Map<String, Object> calling get(name) against that Map<> with the name of each additional property of interest Implementation of the remaining points (2-3) will vary widely depending on the specific technology being used. See the examples previously linked to delve deeper.","title":"Code the connector itself"},{"location":"guides/developer/implement-repository-connector/","text":"A common tripping point for conformance The routing behavior described for homed metadata instances can only be enforced when the requests go through OMRS itself. For third party tools that provide their own services / user interface through which updates can be made, a common tripping point becomes the fact that these services / user interfaces need to adhere to the same protocol principles outlined above -- specifically, ensuring reference copies are also immutable through these product-native interfaces -- in order to conform to the Egeria protocol. For cases where the tool is unable to do so, we are actively investigating other mitigation measures like providing a Smart Repository Proxy to ensure that any changes to metadata that violate the protocol remain isolated in that third party technology and are not inadvertently propagated elsewhere in the cohort.","title":"Develop Repository Connector"},{"location":"guides/developer/using-connectors/","text":"Using Connectors \u00b6 Connectors can be created through the following clients: Asset Consumer OMAS Asset Owner OMAS Example: connecting to CSV files using Asset Consumer OMAS The code sample below uses the Asset Consumer OMAS client to retrieve a list of assets from a metadata server and then create a connector to each one using the getConnectorToAsset() method. This method assumes that there is a connection object with a connector type and endpoint linked to the requested asset in the metadata repository. An exception is thrown if an asset does not have a connection. In the sample, the connector returned by the Asset Consumer OMAS client is then cast to the CSVFileConnector . Assets that are not CSV files will have a different connector implementation and so the casting to CSVFileConnector also results in an exception. Assets that do not have a CSVFileConnector are ignored. The result is that the sample method returns a connector for the first CSV file asset retrieved from the metadata repository. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 /** * This method uses Asset Consumer OMAS to locate and create an Open Connector Framework (OCF) connector * instance. * * @return connector to first CSVFile located in the catalog */ private CSVFileStoreConnector getConnectorUsingMetadata () { try { /* * The Asset Consumer OMAS supports a REST API to extract metadata from the open metadata repositories * linked to the same open metadata cohort as the Asset Consumer OMAS. It also has a Java client that * provides an equivalent interface to the REST API plus connector factory methods supported by an * embedded Connector Broker. The Connector Broker is an Open Connector Framework (OCF) component * that is able to create and configure instances of compliant connectors. It is passed a Connection * object which has all of the properties needed to create the connector. The Asset Consumer OMAS * extracts the Connection object from the open metadata repositories and then calls the Connector Broker. */ AssetConsumer client = new AssetConsumer ( serverName , serverURLRoot ); /* * This call extracts the list of assets stored in the open metadata repositories that have a name * that matches the requested filename. */ List < String > knownAssets = client . findAssets ( clientUserId , \".*\" , 0 , 4 ); if ( knownAssets != null ) { System . out . println ( \"The open metadata repositories have returned \" + knownAssets . size () + \" asset definitions for the requested file name \" + fileName ); for ( String assetGUID : knownAssets ) { if ( assetGUID != null ) { try { /* * The aim is to return a connector for the first matching asset. If an asset of a different * type is returned, on one where it is not possible to create a connector for, then an * exception is thrown and the code moves on to process the next asset. */ return ( CSVFileStoreConnector ) client . getConnectorForAsset ( clientUserId , assetGUID ); } catch ( Exception error ) { System . out . println ( \"Unable to create connector for asset: \" + assetGUID ); } } } } else { System . out . println ( \"The open metadata repositories do not have an asset definition for the requested file name \" + fileName ); } } catch ( Exception error ) { System . out . println ( \"The connector can not be created from metadata. Error message is: \" + error . getMessage ()); } return null ; } Connecting to assets with different levels of security \u00b6 It is possible that an asset can have multiple connections, each with different levels of security access encoded. Egeria is able to determine which one to use by calling the validateUserForAssetConnectionList() method of the Server Security Metadata Connector . Other links to the connection \u00b6 Open metadata is a connected network (graph) of information. The connector type and endpoint that a connection object links to are typically shared with many connections. This creates some interesting insight. For example, there is typically one connector type for each connector implementation. By retrieving the relationships from the connector type to the connections, it is possible to see the extent to which the connector is used. Connector Types \u00b6 The connector types for Egeria's data store connectors are available in an open metadata archive called DataStoreConnectorTypes.json that can be loaded into the server. This approach can be used for all of your connector implementations to create the connector type objects in our metadata repository. See the open-connector-archives for more detail. Endpoints \u00b6 The endpoints are typically linked to the software server that is called by the connector. By navigating from the Endpoint to the linked connections it is possible to trace the callers to the software server. Software servers and endpoints are set up through the IT Infrastructure OMAS . Further information The connector catalog lists the connectors available to digital resources.","title":"Using connectors"},{"location":"guides/developer/using-connectors/#using-connectors","text":"Connectors can be created through the following clients: Asset Consumer OMAS Asset Owner OMAS Example: connecting to CSV files using Asset Consumer OMAS The code sample below uses the Asset Consumer OMAS client to retrieve a list of assets from a metadata server and then create a connector to each one using the getConnectorToAsset() method. This method assumes that there is a connection object with a connector type and endpoint linked to the requested asset in the metadata repository. An exception is thrown if an asset does not have a connection. In the sample, the connector returned by the Asset Consumer OMAS client is then cast to the CSVFileConnector . Assets that are not CSV files will have a different connector implementation and so the casting to CSVFileConnector also results in an exception. Assets that do not have a CSVFileConnector are ignored. The result is that the sample method returns a connector for the first CSV file asset retrieved from the metadata repository. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 /** * This method uses Asset Consumer OMAS to locate and create an Open Connector Framework (OCF) connector * instance. * * @return connector to first CSVFile located in the catalog */ private CSVFileStoreConnector getConnectorUsingMetadata () { try { /* * The Asset Consumer OMAS supports a REST API to extract metadata from the open metadata repositories * linked to the same open metadata cohort as the Asset Consumer OMAS. It also has a Java client that * provides an equivalent interface to the REST API plus connector factory methods supported by an * embedded Connector Broker. The Connector Broker is an Open Connector Framework (OCF) component * that is able to create and configure instances of compliant connectors. It is passed a Connection * object which has all of the properties needed to create the connector. The Asset Consumer OMAS * extracts the Connection object from the open metadata repositories and then calls the Connector Broker. */ AssetConsumer client = new AssetConsumer ( serverName , serverURLRoot ); /* * This call extracts the list of assets stored in the open metadata repositories that have a name * that matches the requested filename. */ List < String > knownAssets = client . findAssets ( clientUserId , \".*\" , 0 , 4 ); if ( knownAssets != null ) { System . out . println ( \"The open metadata repositories have returned \" + knownAssets . size () + \" asset definitions for the requested file name \" + fileName ); for ( String assetGUID : knownAssets ) { if ( assetGUID != null ) { try { /* * The aim is to return a connector for the first matching asset. If an asset of a different * type is returned, on one where it is not possible to create a connector for, then an * exception is thrown and the code moves on to process the next asset. */ return ( CSVFileStoreConnector ) client . getConnectorForAsset ( clientUserId , assetGUID ); } catch ( Exception error ) { System . out . println ( \"Unable to create connector for asset: \" + assetGUID ); } } } } else { System . out . println ( \"The open metadata repositories do not have an asset definition for the requested file name \" + fileName ); } } catch ( Exception error ) { System . out . println ( \"The connector can not be created from metadata. Error message is: \" + error . getMessage ()); } return null ; }","title":"Using Connectors"},{"location":"guides/developer/using-connectors/#connecting-to-assets-with-different-levels-of-security","text":"It is possible that an asset can have multiple connections, each with different levels of security access encoded. Egeria is able to determine which one to use by calling the validateUserForAssetConnectionList() method of the Server Security Metadata Connector .","title":"Connecting to assets with different levels of security"},{"location":"guides/developer/using-connectors/#other-links-to-the-connection","text":"Open metadata is a connected network (graph) of information. The connector type and endpoint that a connection object links to are typically shared with many connections. This creates some interesting insight. For example, there is typically one connector type for each connector implementation. By retrieving the relationships from the connector type to the connections, it is possible to see the extent to which the connector is used.","title":"Other links to the connection"},{"location":"guides/developer/using-connectors/#connector-types","text":"The connector types for Egeria's data store connectors are available in an open metadata archive called DataStoreConnectorTypes.json that can be loaded into the server. This approach can be used for all of your connector implementations to create the connector type objects in our metadata repository. See the open-connector-archives for more detail.","title":"Connector Types"},{"location":"guides/developer/using-connectors/#endpoints","text":"The endpoints are typically linked to the software server that is called by the connector. By navigating from the Endpoint to the linked connections it is possible to trace the callers to the software server. Software servers and endpoints are set up through the IT Infrastructure OMAS . Further information The connector catalog lists the connectors available to digital resources.","title":"Endpoints"},{"location":"guides/developer/integration-connectors/overview/","text":"Integration Connectors \u00b6 An integration connector is a pluggable component that manages the metadata exchange to a third party technology. It is hosted in an integration service which is, in turn, running in an integration daemon . The integration connectors can: Listen on a blocking call for the third party technology to send a notification. Register with an external notification service that sends notifications on its own thread. Register a listener with the OMAS client to act on notifications from the OMAS 's Out Topic . Poll the third party technology each time that the refresh() method is called. Interface \u00b6 The interface that all integration connectors must implement is defined by IntegrationConnectorBase : initialize is a standard method for all connectors that is called by the connector broker when the connector is created. The connector is passed the connection object from the configuration and a unique identifier for this instance of the connector. setAuditLog provides a logging destination (see Audit Log Framework ( ALF ) ). setConnectorName provides the name of the connector for logging. setContext sets up the integration-specific context. This provides an interface to the services of the OMAS that the integration service is paired with. Although the interfaces vary from integration service to integration service, they typically offer the following types of method call for each type of metadata it supports: The ability to register a listener to receive events from the OMAS 's Out Topic , or send events to the OMAS 's In Topic . The ability to create and update metadata instances. For assets, the ability to change an asset's visibility by changing its zone membership using the publish and withdraw methods. The ability to delete metadata. Various retrieval methods to help when comparing the metadata in the open metadata repositories with the metadata in the third party technology. start indicates that the connector is completely configured and can begin processing. This call can be used to register with non-blocking services. For example, it can register a listener with the OMAS Out Topic with the context. engage is used when the connector is configured to need to issue blocking calls to wait for new metadata. It is called from its own thread. It is recommended that the engage() method returns when each blocking call completes. The integration daemon will pause a second and then call engage() again. This pattern enables the calling thread to detect the shutdown of the integration daemon server. refresh requests that the connector does a comparison of the metadata in the third party technology and open metadata repositories. Refresh is called: when the integration connector first starts and then at intervals defined in the connector's configuration as well as any external REST API calls to explicitly refresh the connector. disconnect is called when the server is shutting down. The connector should free up any resources that it holds since it is not needed any more. Further information Open Connector Framework ( OCF ) that defines the behavior of all connectors. Configuring an integration daemon to understand how to set up an integration connector. Developer guide for more information on writing connectors.","title":"Overview"},{"location":"guides/developer/integration-connectors/overview/#integration-connectors","text":"An integration connector is a pluggable component that manages the metadata exchange to a third party technology. It is hosted in an integration service which is, in turn, running in an integration daemon . The integration connectors can: Listen on a blocking call for the third party technology to send a notification. Register with an external notification service that sends notifications on its own thread. Register a listener with the OMAS client to act on notifications from the OMAS 's Out Topic . Poll the third party technology each time that the refresh() method is called.","title":"Integration Connectors"},{"location":"guides/developer/integration-connectors/overview/#interface","text":"The interface that all integration connectors must implement is defined by IntegrationConnectorBase : initialize is a standard method for all connectors that is called by the connector broker when the connector is created. The connector is passed the connection object from the configuration and a unique identifier for this instance of the connector. setAuditLog provides a logging destination (see Audit Log Framework ( ALF ) ). setConnectorName provides the name of the connector for logging. setContext sets up the integration-specific context. This provides an interface to the services of the OMAS that the integration service is paired with. Although the interfaces vary from integration service to integration service, they typically offer the following types of method call for each type of metadata it supports: The ability to register a listener to receive events from the OMAS 's Out Topic , or send events to the OMAS 's In Topic . The ability to create and update metadata instances. For assets, the ability to change an asset's visibility by changing its zone membership using the publish and withdraw methods. The ability to delete metadata. Various retrieval methods to help when comparing the metadata in the open metadata repositories with the metadata in the third party technology. start indicates that the connector is completely configured and can begin processing. This call can be used to register with non-blocking services. For example, it can register a listener with the OMAS Out Topic with the context. engage is used when the connector is configured to need to issue blocking calls to wait for new metadata. It is called from its own thread. It is recommended that the engage() method returns when each blocking call completes. The integration daemon will pause a second and then call engage() again. This pattern enables the calling thread to detect the shutdown of the integration daemon server. refresh requests that the connector does a comparison of the metadata in the third party technology and open metadata repositories. Refresh is called: when the integration connector first starts and then at intervals defined in the connector's configuration as well as any external REST API calls to explicitly refresh the connector. disconnect is called when the server is shutting down. The connector should free up any resources that it holds since it is not needed any more. Further information Open Connector Framework ( OCF ) that defines the behavior of all connectors. Configuring an integration daemon to understand how to set up an integration connector. Developer guide for more information on writing connectors.","title":"Interface"},{"location":"guides/developer/mapping-technology/","text":"Modelling different types of technology \u00b6 Representing File Assets \u00b6 Figure 1: Examples of modelling file-based data sources Figure 2: Mixing files and folders Representing Information Views \u00b6 Figure 3: Overlaying information views on assets Figure 4: Mapping schema elements for an information view Representing APIs \u00b6 Figure 5: Representing APIs Representing Processes \u00b6 Figure 6: Representing Nested Processes","title":"Index"},{"location":"guides/developer/mapping-technology/#modelling-different-types-of-technology","text":"","title":"Modelling different types of technology"},{"location":"guides/developer/mapping-technology/#representing-file-assets","text":"Figure 1: Examples of modelling file-based data sources Figure 2: Mixing files and folders","title":"Representing File Assets"},{"location":"guides/developer/mapping-technology/#representing-information-views","text":"Figure 3: Overlaying information views on assets Figure 4: Mapping schema elements for an information view","title":"Representing Information Views"},{"location":"guides/developer/mapping-technology/#representing-apis","text":"Figure 5: Representing APIs","title":"Representing APIs"},{"location":"guides/developer/mapping-technology/#representing-processes","text":"Figure 6: Representing Nested Processes","title":"Representing Processes"},{"location":"guides/developer/mapping-technology/modelling-schemas/","text":"Modelling Schemas \u00b6 A schema describes the structure of the data associated with an Asset . The technology that supports the asset often limits the structural choices for data. For example: * A relational database organizes data into collections of tables and columns. * Technologies such as JSON or XML, organizes data into nested structures. * Graph databases organizes data in nodes and relationships. These differences need to be represented in the Open Metadata Types. However, at the same time, data governance is concerned with the accuracy and appropriate use of individual data values. This is very expensive if each data item was governed individually so the data governance practices aim to group like data together so it can governed in a consistent way. As such, the open metadata types provide a root set of types that all the specific schema structures inherit from. The schema root type is called Schema Element which is then dividing into a Schema Attribute (think of this as a variable) and a Schema Type . The schema type describes the structure of the data associated with the schema attribute. In the early versions of Egeria, the schema attribute and the schema type were represented as as two separate entities in the open metadata types with a SchemaTypeForAttribute relationship to connect them together. This is shown in figure 1. Figure 1: Original model for SchemaAttribute and its SchemaType However, it became obvious that since these two elements need to retrieved together, it is much more more efficient if the schema type is represented as a classification for the SchemaAttribute since classifications are typically stored, distributed and retrieved with their entity. The new classification is called TypeEmbeddedAttribute and it contains all of the properties found in the schema types plus a typeName property to identify the corresponding schema type. Figure 2 shows the new types for representing a schema attribute and its type. Figure 2: Collapsing SchemaAttribute and SchemaType into an entity with a classification Schema type entities are still used: * to connect Assets and Ports to their schemas * to connect structural schema types such as maps and external schemas to other types that represent their contents. Figure 3 shows the use of the schema type: Figure 3: The SchemaType is still used as the top level element in a schema and for complex structures Specific SchemaTypes \u00b6 The root SchemaType and SchemaAttribute are specialized to support different structures. The diagrams show how the structure is represented for a SchemaAttribute on the left and how it is represented as a SchemaType on the right. Primitives \u00b6 Primitives are single values such a string, characters and numbers. They are represented by the PrimitiveSchemaType . Figure 4: The PrimitiveSchemaType Literals (Constants) \u00b6 Literals are fixed values, also known as constants . They are represented by the LiteralSchemaType . Figure 5: The LiteralSchemaType Enumerations \u00b6 Enumerations (Enums) define a list of valid values. The valid values are recorded in a ValidValuesSet linked to an EnumSchemaType . Figure 6: The EnumSchemaType Linking to a standard schema type \u00b6 External schema types link to a schema type that is reused in multiple assets - typically it is part of a standard. The use of an external schema type is represented by an ExternalSchemaType . Figure 7: The ExternalSchemaType Maps \u00b6 Maps show how one set of values link to another. They are often used for look up tables. The map is represented by a MapSchemaType that then links to two other SchemaTypes, one for the type of the starting value and the other for the type of value it is mapped to. Figure 8: The MapSchemaType Alternative types \u00b6 In some schemas, it is possible that there are multiple choices for the type of an element. This is supported by the SchemaTypeChoice . This links to the options for the SchemaType. Figure 9: The SchemaTypeChoice Structures or Records \u00b6 It is common for an attribute to consist of a collection of other values. For example an attribute called employee may consist of multiple values from employee number, name, address, department, .... These types of attribute are represented by the StructSchemaType . Figure 10: The StructSchemaType The relationship between the schema attribute and its nested schema attributes is NestedSchemaAttribute . The relationship between the StructSchemaType and its nested schema attributes is AttributeForSchema . Related Information \u00b6 Open Metadata types for connecting schemas to other types of elements: 0503 Asset Schema - for the relationship between an Asset and its top level SchemaType. 0520 Process Schemas - showing how a schema type can be attached to a process port. Open Metadata Types for different types of data structures: 0501 Schema Elements - for SchemaElement, SchemaType, PrimitiveSchemaType, LiteralSchemaType, EnumSchemaType and SchemaTypeChoice. 0505 Schema Attributes - for SchemaAttribute, ComplexSchemaType, StructSchemaType. 0507 External Schema Types - for ExternalSchemaType. 0511 Map Schema Element - for MapSchemaType. 0512 Derived Schema Elements for DerivedSchemaTypeQueryTarget Specializations of the main types of schema structures for particular types of technology. They are used to enable retrieval of technology-specific schema elements. For example, a query for relational columns with a particular characteristic. 0530 Tabular Schema - for TabularSchemaType and TabularColumn. 0531 Document Schemas - for DocumentSchemaType and DocumentSchemaAttribute. 0532 Object Schemas - for ObjectSchemaType and ObjectAttribute. 0533 Graph Schema - for types associated with graph stores. 0534 Relational Schema for types associated with relational data 0535 Event Schema - for EventTypeList, EventType and EventSchemaAttribute. 0536 API Schemas - for types associated with APIs. APIs that support the definition of schemas: Asset Owner OMAS Asset Manager OMAS Data Manager OMAS Governance Engine OMAS Database Integrator OMIS Files Integrator OMIS API Integrator OMIS Topic Integrator OMIS Governance Action OMES Other types of information associated with an Asset: The contents of an asset catalog","title":"Modelling schemas"},{"location":"guides/developer/mapping-technology/modelling-schemas/#modelling-schemas","text":"A schema describes the structure of the data associated with an Asset . The technology that supports the asset often limits the structural choices for data. For example: * A relational database organizes data into collections of tables and columns. * Technologies such as JSON or XML, organizes data into nested structures. * Graph databases organizes data in nodes and relationships. These differences need to be represented in the Open Metadata Types. However, at the same time, data governance is concerned with the accuracy and appropriate use of individual data values. This is very expensive if each data item was governed individually so the data governance practices aim to group like data together so it can governed in a consistent way. As such, the open metadata types provide a root set of types that all the specific schema structures inherit from. The schema root type is called Schema Element which is then dividing into a Schema Attribute (think of this as a variable) and a Schema Type . The schema type describes the structure of the data associated with the schema attribute. In the early versions of Egeria, the schema attribute and the schema type were represented as as two separate entities in the open metadata types with a SchemaTypeForAttribute relationship to connect them together. This is shown in figure 1. Figure 1: Original model for SchemaAttribute and its SchemaType However, it became obvious that since these two elements need to retrieved together, it is much more more efficient if the schema type is represented as a classification for the SchemaAttribute since classifications are typically stored, distributed and retrieved with their entity. The new classification is called TypeEmbeddedAttribute and it contains all of the properties found in the schema types plus a typeName property to identify the corresponding schema type. Figure 2 shows the new types for representing a schema attribute and its type. Figure 2: Collapsing SchemaAttribute and SchemaType into an entity with a classification Schema type entities are still used: * to connect Assets and Ports to their schemas * to connect structural schema types such as maps and external schemas to other types that represent their contents. Figure 3 shows the use of the schema type: Figure 3: The SchemaType is still used as the top level element in a schema and for complex structures","title":"Modelling Schemas"},{"location":"guides/developer/mapping-technology/modelling-schemas/#specific-schematypes","text":"The root SchemaType and SchemaAttribute are specialized to support different structures. The diagrams show how the structure is represented for a SchemaAttribute on the left and how it is represented as a SchemaType on the right.","title":"Specific SchemaTypes"},{"location":"guides/developer/mapping-technology/modelling-schemas/#primitives","text":"Primitives are single values such a string, characters and numbers. They are represented by the PrimitiveSchemaType . Figure 4: The PrimitiveSchemaType","title":"Primitives"},{"location":"guides/developer/mapping-technology/modelling-schemas/#literals-constants","text":"Literals are fixed values, also known as constants . They are represented by the LiteralSchemaType . Figure 5: The LiteralSchemaType","title":"Literals (Constants)"},{"location":"guides/developer/mapping-technology/modelling-schemas/#enumerations","text":"Enumerations (Enums) define a list of valid values. The valid values are recorded in a ValidValuesSet linked to an EnumSchemaType . Figure 6: The EnumSchemaType","title":"Enumerations"},{"location":"guides/developer/mapping-technology/modelling-schemas/#linking-to-a-standard-schema-type","text":"External schema types link to a schema type that is reused in multiple assets - typically it is part of a standard. The use of an external schema type is represented by an ExternalSchemaType . Figure 7: The ExternalSchemaType","title":"Linking to a standard schema type"},{"location":"guides/developer/mapping-technology/modelling-schemas/#maps","text":"Maps show how one set of values link to another. They are often used for look up tables. The map is represented by a MapSchemaType that then links to two other SchemaTypes, one for the type of the starting value and the other for the type of value it is mapped to. Figure 8: The MapSchemaType","title":"Maps"},{"location":"guides/developer/mapping-technology/modelling-schemas/#alternative-types","text":"In some schemas, it is possible that there are multiple choices for the type of an element. This is supported by the SchemaTypeChoice . This links to the options for the SchemaType. Figure 9: The SchemaTypeChoice","title":"Alternative types"},{"location":"guides/developer/mapping-technology/modelling-schemas/#structures-or-records","text":"It is common for an attribute to consist of a collection of other values. For example an attribute called employee may consist of multiple values from employee number, name, address, department, .... These types of attribute are represented by the StructSchemaType . Figure 10: The StructSchemaType The relationship between the schema attribute and its nested schema attributes is NestedSchemaAttribute . The relationship between the StructSchemaType and its nested schema attributes is AttributeForSchema .","title":"Structures or Records"},{"location":"guides/developer/mapping-technology/modelling-schemas/#related-information","text":"Open Metadata types for connecting schemas to other types of elements: 0503 Asset Schema - for the relationship between an Asset and its top level SchemaType. 0520 Process Schemas - showing how a schema type can be attached to a process port. Open Metadata Types for different types of data structures: 0501 Schema Elements - for SchemaElement, SchemaType, PrimitiveSchemaType, LiteralSchemaType, EnumSchemaType and SchemaTypeChoice. 0505 Schema Attributes - for SchemaAttribute, ComplexSchemaType, StructSchemaType. 0507 External Schema Types - for ExternalSchemaType. 0511 Map Schema Element - for MapSchemaType. 0512 Derived Schema Elements for DerivedSchemaTypeQueryTarget Specializations of the main types of schema structures for particular types of technology. They are used to enable retrieval of technology-specific schema elements. For example, a query for relational columns with a particular characteristic. 0530 Tabular Schema - for TabularSchemaType and TabularColumn. 0531 Document Schemas - for DocumentSchemaType and DocumentSchemaAttribute. 0532 Object Schemas - for ObjectSchemaType and ObjectAttribute. 0533 Graph Schema - for types associated with graph stores. 0534 Relational Schema for types associated with relational data 0535 Event Schema - for EventTypeList, EventType and EventSchemaAttribute. 0536 API Schemas - for types associated with APIs. APIs that support the definition of schemas: Asset Owner OMAS Asset Manager OMAS Data Manager OMAS Governance Engine OMAS Database Integrator OMIS Files Integrator OMIS API Integrator OMIS Topic Integrator OMIS Governance Action OMES Other types of information associated with an Asset: The contents of an asset catalog","title":"Related Information"},{"location":"guides/developer/repository-connectors/event-mapper-connector/","text":"Event mapper connector \u00b6 The event mapper connector provides a common API for specific implementations of OMRS event mappers to implement. Event mappers are needed in repository proxy servers if the third party technology that it is integrating into the open metadata repository cohort also has its own mechanisms for maintaining metadata. The event mapper's role is to notify the cohort of any changes to the metadata mastered in the third party repository that has occurred through the third party technology's own mechanisms. Since each event mapper is tied to a third party technology, core Egeria does not supply any implementations of this connector. There are, however, the following implementations available: Event mapper for Apache Atlas (Experimental) event mapper for IBM Information Governance Catalog","title":"Event mapper connector"},{"location":"guides/developer/repository-connectors/event-mapper-connector/#event-mapper-connector","text":"The event mapper connector provides a common API for specific implementations of OMRS event mappers to implement. Event mappers are needed in repository proxy servers if the third party technology that it is integrating into the open metadata repository cohort also has its own mechanisms for maintaining metadata. The event mapper's role is to notify the cohort of any changes to the metadata mastered in the third party repository that has occurred through the third party technology's own mechanisms. Since each event mapper is tied to a third party technology, core Egeria does not supply any implementations of this connector. There are, however, the following implementations available: Event mapper for Apache Atlas (Experimental) event mapper for IBM Information Governance Catalog","title":"Event mapper connector"},{"location":"guides/developer/repository-connectors/overview/","text":"Writing Repository Connectors \u00b6 Egeria provides a number of pre-built cohort members . One of them, the repository proxy provides a simple way to integrate a third party server into a cohort by creating an OMRS Repository Connector and optional Event Mapper Connector to map between the third party APIs/events and the repository service's equivalents A more bespoke integration involves: Creating an OMRS repository connector and optional event mapper connector Designing how to configure the OMRS Services for your metadata repository. Typically, this is done by extending the existing administration services of the metadata repository, but Egeria also offers some pre-built administration services that can be used or modified. Plugging the OMRS and any administration services into the metadata repository's security module so that requests to the server can be secured against unauthorized access. Integrating the OMRS , administration and security capability into your product. There are different integration patterns available to help you choose the best approach for your product. Each method is optimized for specific use cases and so the metadata repository can only play a full role in the open metadata use cases if it supports all integration methods. These are: Support for an OMRS repository connector to allow open metadata API calls to the repository to create, query, update and delete metadata stored in the repository. The OMRS connectors support the Open Connector Framework ( OCF ) to provide a call interface to the metadata repositories. The OMRS Repository Connector API is a standard interface for all metadata repositories. This enables services such as the Enterprise OMRS Repository Connector to interact with 1 or many metadata repositories through the same interface. The connection configuration it passes to the OCF determines which type of OMRS connector is returned by the OCF . Support for the OMRS event notifications that are used to synchronize selective metadata between the metadata repositories. You may want to see the OMRS metamodel for more details on the granularity of metadata exchange. \u21a9","title":"Overview"},{"location":"guides/developer/repository-connectors/overview/#writing-repository-connectors","text":"Egeria provides a number of pre-built cohort members . One of them, the repository proxy provides a simple way to integrate a third party server into a cohort by creating an OMRS Repository Connector and optional Event Mapper Connector to map between the third party APIs/events and the repository service's equivalents A more bespoke integration involves: Creating an OMRS repository connector and optional event mapper connector Designing how to configure the OMRS Services for your metadata repository. Typically, this is done by extending the existing administration services of the metadata repository, but Egeria also offers some pre-built administration services that can be used or modified. Plugging the OMRS and any administration services into the metadata repository's security module so that requests to the server can be secured against unauthorized access. Integrating the OMRS , administration and security capability into your product. There are different integration patterns available to help you choose the best approach for your product. Each method is optimized for specific use cases and so the metadata repository can only play a full role in the open metadata use cases if it supports all integration methods. These are: Support for an OMRS repository connector to allow open metadata API calls to the repository to create, query, update and delete metadata stored in the repository. The OMRS connectors support the Open Connector Framework ( OCF ) to provide a call interface to the metadata repositories. The OMRS Repository Connector API is a standard interface for all metadata repositories. This enables services such as the Enterprise OMRS Repository Connector to interact with 1 or many metadata repositories through the same interface. The connection configuration it passes to the OCF determines which type of OMRS connector is returned by the OCF . Support for the OMRS event notifications that are used to synchronize selective metadata between the metadata repositories. You may want to see the OMRS metamodel for more details on the granularity of metadata exchange. \u21a9","title":"Writing Repository Connectors"},{"location":"guides/developer/repository-connectors/metamodel/overview/","text":"OMRS Metamodel \u00b6 OMRS 's metamodel defines the structures used to represent metadata, and can be broadly divided into the following two areas: Type Definitions ( TypeDef s and AttributeTypeDef s) Instances Type definitions \u00b6 TypeDef s define the general characteristics that are used to describe any general type -- whether native or not -- and typically fit into one of the following three general types ( TypeDefCategory ): EntityDef : the definition of a type of entity RelationshipDef : the definition of a type of relationship ClassificationDef : the definition of a type of classification TypeDef s are implemented as Java classes in Egeria (those in italics are abstract). Examples of type definitions For example, the native open metadata types that Egeria defines include: a generic Referenceable entity type, a GlossaryCategory entity type, a GlossaryTerm entity type, (and many others!) Rather than being another set of classes that inherit from the general TypeDef classes ( EntityDef , RelationshipDef , ClassificationDef ), these open types are instantiated objects of one of those TypeDef classes (in the above examples, of the EntityDef class). A set of TypeDefAttribute s within the TypeDef defines the list of additional characteristics (properties) that each of these entity types can possess -- things like names, descriptions, etc -- which may naturally vary from one entity type to another. (These property-level definitions are AttributeTypeDef s.) An example of a RelationshipDef is the linkage between GlossaryTerm and GlossaryCategory known as a TermCategorization , which is further defined to allow any number of linkages between the two, in either direction. Again, the TermCategorization will be an instantiated object of the class RelationshipDef , with various properties configured on it to define the endpoints of the relationship. An example ClassificationDef is Confidentiality : that can apply to any Referenceable entity (hence including both GlossaryTerm and GlossaryCategory , as both of these extend the Referenceable entity type). Example: Referenceable For example, Referenceable is defined as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 final String guid = \"a32316b8-dc8c-48c5-b12b-71c1b2a080bf\" ; final String name = \"Referenceable\" ; final String description = \"An open metadata entity that has a unique identifier.\" ; final String descriptionGUID = null ; // The EntityDef object itself EntityDef entityDef = archiveHelper . getDefaultEntityDef ( guid , name , null , description , descriptionGUID ); List < TypeDefAttribute > properties = new ArrayList <> (); TypeDefAttribute property ; final String attribute1Name = \"qualifiedName\" ; final String attribute1Description = \"Unique identifier for the entity.\" ; final String attribute1DescriptionGUID = null ; final String attribute2Name = \"additionalProperties\" ; final String attribute2Description = \"Additional properties for the element.\" ; final String attribute2DescriptionGUID = null ; // The TypeDefAttributes that define the properties of the Referenceable (EntityDef) object property = archiveHelper . getStringTypeDefAttribute ( attribute1Name , attribute1Description , attribute1DescriptionGUID ); property . setUnique ( true ); properties . add ( property ); property = archiveHelper . getMapStringStringTypeDefAttribute ( attribute2Name , attribute2Description , attribute2DescriptionGUID ); properties . add ( property ); entityDef . setPropertiesDefinition ( properties ); And this results in a JSON structure like the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \"class\" : \"EntityDef\" , \"guid\" : \"a32316b8-dc8c-48c5-b12b-71c1b2a080bf\" , \"name\" : \"Referenceable\" , \"version\" : 1 , \"versionName\" : \"1.0\" , \"category\" : \"ENTITY_DEF\" , \"description\" : \"An open metadata entity that has a unique identifier.\" , \"origin\" : \"bce3b0a0-662a-4f87-b8dc-844078a11a6e\" , \"createdBy\" : \"ODPi Egeria (OMRS)\" , \"createTime\" : 1516313040008 , \"validInstanceStatusList\" : [ \"ACTIVE\" , \"DELETED\" ], \"initialStatus\" : \"ACTIVE\" , \"propertiesDefinition\" : [ { \"attributeName\" : \"qualifiedName\" , \"attributeType\" : { \"class\" : \"PrimitiveDef\" , \"version\" : 1 , \"versionName\" : \"1.0\" , \"category\" : \"PRIMITIVE\" , \"guid\" : \"b34a64b9-554a-42b1-8f8a-7d5c2339f9c4\" , \"name\" : \"string\" , \"primitiveDefCategory\" : \"OM_PRIMITIVE_TYPE_STRING\" }, \"attributeDescription\" : \"Unique identifier for the entity.\" , \"valuesMinCount\" : 0 , \"valuesMaxCount\" : 1 , \"indexable\" : true , \"attributeCardinality\" : \"AT_MOST_ONE\" , \"unique\" : true }, { \"attributeName\" : \"additionalProperties\" , \"attributeType\" : { \"class\" : \"CollectionDef\" , \"version\" : 1 , \"versionName\" : \"1.0\" , \"category\" : \"COLLECTION\" , \"guid\" : \"005c7c14-ac84-4136-beed-959401b041f8\" , \"name\" : \"map<string,string>\" , \"description\" : \"A map from String to String.\" , \"collectionDefCategory\" : \"OM_COLLECTION_MAP\" , \"argumentCount\" : 2 , \"argumentTypes\" : [ \"OM_PRIMITIVE_TYPE_STRING\" , \"OM_PRIMITIVE_TYPE_STRING\" ] }, \"attributeDescription\" : \"Additional properties for the element.\" , \"valuesMinCount\" : 0 , \"valuesMaxCount\" : 1 , \"indexable\" : true , \"attributeCardinality\" : \"AT_MOST_ONE\" , \"unique\" : false } ] } Instances \u00b6 Instances define individual instantiations of the TypeDefs: for example, individual GlossaryTerm entities (like \"Address Line 1\") or GlossaryCategory entities (like \"Coco Pharmaceuticals\"), Confidentiality classifications (like \"Sensitive\"), etc. Implemented instances will generally be objects of one of the following classes: How are entities modeled? EntitySummary , EntityProxy and EntityDetail Egeria models all entities using a general object -- EntitySummary -- from which more detailed representations (like EntityDetail ) are derived. Note that there is a property called type within this object (inherited from InstanceAuditHeader ) that defines the specific type of metadata the entity represents, rather than having a different type-specific object for every different type of entity. How are relationships modeled? Relationship and EntityProxy Egeria models all relationships using a general object -- Relationship -- which links together exactly two entities (using EntityProxy , itself an extension of EntitySummary). These EntityProxy s act as a sort of \"stub\" to which the relationship can point, without needing to be aware of the entire set of details of each entity involved in the relationship, and are therefore an important piece of ensuring that relationships are treated as \"first-class\" objects in their own right. As with entities, there is a property called type within this Relationship object (also inherited from InstanceAuditHeader ) that defines the specific type of metadata the relationship represents, rather than having a different type-specific object for every different type of relationship. How are classifications modeled? Classification Egeria models all classifications using a general object -- Classification -- any instance of which is possessed by exactly one entity (within the EntitySummary 's classifications property). As with the other kinds of instances, note that there is a property called type within this Classification object (also inherited from InstanceAuditHeader ) that defines the specific type of metadata the classification represents, rather than having a different type-specific object for every different type of classification. Furthermore, note that classifications in Egeria exist only as part of an entity: unlike EntitySummary and Relationship , they do not extend InstanceHeader and therefore are not assigned a GUID through which they could be independently retrieved or updated. Classifications are only retrievable or updatable through the entity by which they are possessed. Each of these will typically be further described by an InstanceProperties object that instantiates one or more properties used to describe the entity, classification or relationship. Instances as a concept are implemented as generic Java classes in Egeria (those in italics are abstract). Examples of instances Like TypeDefs, instances are managed as instantiated objects of the classes above (not as new classes that inherit from those above). For example, to represent an \"Address Line 1\" GlossaryTerm , there can be: an instantiated EntitySummary object providing a headline set of information about \"Address Line 1\" (i.e. its classifications), an instantiated EntityDetail object providing the full details of \"Address Line 1\" (all of its classifications and properties), an instantiated EntityProxy object defining the unique properties of \"Address Line 1\" (i.e. a qualifiedName property inherited from Referenceable which must be unique across all instances of the object) The InstanceProperties associated with the EntityDetail , Relationship and Classification objects give the further detail on the object (ie. its name, summary, etc). To represent a \"Sensitive Confidentiality\" concept that can be used to classify other information (like \"Address Line 1\"), we could have a \"Confidentiality\" Classification defined with a specific level (\"Sensitive\") through its InstanceProperties To represent the linkage between \"Address Line 1\" and a specific category location (like \"Coco Pharmaceuticals/Terms\") we could have a Relationship representing the TermCategorization with one end pointing to an EntityProxy for \"Address Line 1\" and one end pointing to an EntityProxy for \"Coco Pharmaceuticals/Terms\" Code example for creating the various types As code, this example could be implemented using something like the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 // ENTITIES // Summary-level entity information (see end of CLASSIFICATION section for adding Classifications) EntitySummary summary = new EntitySummary (); summary . setGUID ( guid ); summary . setCreatedBy ( \"...user...\" ); summary . setCreateTime ( new Date (...)); summary . setUpdatedBy ( \"...user...\" ); summary . setUpdateTime ( new Date (...)); // Detailed-level entity information (see end of CLASSIFICATION section for adding Classifications) EntityDetail detail = repositoryConnector . getRepositoryHelper (). getSkeletonEntity ( sourceName , omrsRepositoryConnector . getMetadataCollectionId (), InstanceProvenanceType . LOCAL_COHORT , userId , \"GlossaryTerm\" ); detail . setStatus ( InstanceStatus . ACTIVE ); detail . setGUID ( guid ); detail . setCreatedBy ( \"...user...\" ); detail . setCreateTime ( new Date (...)); detail . setUpdatedBy ( \"...user...\" ); detail . setUpdateTime ( new Date (...)); InstanceProperties instanceProperties = new InstanceProperties (); PrimitivePropertyValue propertyValue = new PrimitivePropertyValue (); PrimitiveDef primitiveDef = new PrimitiveDef (); primitiveDef . setPrimitiveDefCategory ( PrimitiveDefCategory . OM_PRIMITIVE_TYPE_STRING ); propertyValue . setPrimitiveValue ( \"Address Line 1\" ); propertyValue . setPrimitiveDefCategory ( primitiveDef . getPrimitiveDefCategory ()); propertyValue . setTypeGUID ( primitiveDef . getGUID ()); propertyValue . setTypeName ( primitiveDef . getName ()); instanceProperties . setProperty ( \"qualifiedName\" , propertyValue ); propertyValue . setPrimitiveValue ( \"Street and street number\" ); instanceProperties . setProperty ( \"summary\" , propertyValue ); detail . setProperties ( instanceProperties ); // CLASSIFICATION InstanceProperties properties = new InstanceProperties (); // The \"Sensitive\" level for the classification EnumPropertyValue level = new EnumPropertyValue (); level . setSymbolicName ( \"Sensitive\" ); properties . setProperty ( \"level\" , level ); // Creating a new classification, of \"Confidentiality\", applying to \"Referenceable\", with // the \"Sensitive\" level defined above Classification classification = omrsRepositoryConnector . getRepositoryHelper (). getNewClassification ( sourceName , userId , \"Confidentiality\" , \"Referenceable\" , ClassificationOrigin . ASSIGNED , null , properties ); ArrayList < Classificaton > classifications = new ArrayList <> (); classifications . add ( classification ); // ... adding the Classification(s) to the Entity(Summary|Detail) summary . setClassifications ( classifications ); detail . setClassifications ( classifications ); // RELATIONSHIP // Define the qualifiedName property with the unique name for the first end of the relationship // (the GlossaryCategory end of the relationship) InstanceProperties uniqueProperties1 = new InstanceProperties (); PrimitivePropertyValue propertyValue = new PrimitivePropertyValue (); PrimitiveDef primitiveDef = new PrimitiveDef (); primitiveDef . setPrimitiveDefCategory ( PrimitiveDefCategory . OM_PRIMITIVE_TYPE_STRING ); propertyValue . setPrimitiveValue ( \"Coco Pharmaceuticals/Terms\" ); propertyValue . setPrimitiveDefCategory ( primitiveDef . getPrimitiveDefCategory ()); propertyValue . setTypeGUID ( primitiveDef . getGUID ()); propertyValue . setTypeName ( primitiveDef . getName ()); uniqueProperties1 . setProperty ( \"qualifiedName\" , propertyValue ); EntityProxy entityProxy1 = omrsRepositoryConnector . getRepositoryHelper (). getNewEntityProxy ( sourceName , omrsRepositoryConnector . getMetadataCollectionId (), InstanceProvenanceType . LOCAL_COHORT , userId , \"GlossaryCategory\" , uniqueProperties1 , null ); // Define the qualifiedName property with the unique name of the second end of the relationship // (the GlossaryTerm end of the relationship) InstanceProperties uniqueProperties2 = new InstanceProperties (); primitiveDef . setPrimitiveDefCategory ( PrimitiveDefCategory . OM_PRIMITIVE_TYPE_STRING ); propertyValue . setPrimitiveValue ( \"Address Line 1\" ); propertyValue . setPrimitiveDefCategory ( primitiveDef . getPrimitiveDefCategory ()); propertyValue . setTypeGUID ( primitiveDef . getGUID ()); propertyValue . setTypeName ( primitiveDef . getName ()); uniqueProperties2 . setProperty ( \"qualifiedName\" , propertyValue ); EntityProxy entityProxy2 = omrsRepositoryConnector . getRepositoryHelper (). getNewEntityProxy ( sourceName , omrsRepositoryConnector . getMetadataCollectionId (), InstanceProvenanceType . LOCAL_COHORT , userId , \"GlossaryTerm\" , uniqueProperties2 , null ); // Define the relationship between the two EntityProxy objects instantiated above Relationship omrsRelationship = new Relationship (); InstanceProperties relationshipProperties = new InstanceProperties (); PrimitivePropertyValue relationProperty = new PrimitivePropertyValue (); relationProperty . setTypeGUID ( \"...\" ); relationProperty . setTypeName ( \"???\" ); relationshipProperties . setProperty ( \"TermCategorization\" , relationProperty ); omrsRelationship . setProperties ( relationshipProperties ); omrsRelationship . setEntityOneProxy ( entityProxy1 ); omrsRelationship . setEntityTwoProxy ( entityProxy2 ); omrsRelationship . setGUID ( \"...\" );","title":"Overview"},{"location":"guides/developer/repository-connectors/metamodel/overview/#omrs-metamodel","text":"OMRS 's metamodel defines the structures used to represent metadata, and can be broadly divided into the following two areas: Type Definitions ( TypeDef s and AttributeTypeDef s) Instances","title":"OMRS Metamodel"},{"location":"guides/developer/repository-connectors/metamodel/overview/#type-definitions","text":"TypeDef s define the general characteristics that are used to describe any general type -- whether native or not -- and typically fit into one of the following three general types ( TypeDefCategory ): EntityDef : the definition of a type of entity RelationshipDef : the definition of a type of relationship ClassificationDef : the definition of a type of classification TypeDef s are implemented as Java classes in Egeria (those in italics are abstract). Examples of type definitions For example, the native open metadata types that Egeria defines include: a generic Referenceable entity type, a GlossaryCategory entity type, a GlossaryTerm entity type, (and many others!) Rather than being another set of classes that inherit from the general TypeDef classes ( EntityDef , RelationshipDef , ClassificationDef ), these open types are instantiated objects of one of those TypeDef classes (in the above examples, of the EntityDef class). A set of TypeDefAttribute s within the TypeDef defines the list of additional characteristics (properties) that each of these entity types can possess -- things like names, descriptions, etc -- which may naturally vary from one entity type to another. (These property-level definitions are AttributeTypeDef s.) An example of a RelationshipDef is the linkage between GlossaryTerm and GlossaryCategory known as a TermCategorization , which is further defined to allow any number of linkages between the two, in either direction. Again, the TermCategorization will be an instantiated object of the class RelationshipDef , with various properties configured on it to define the endpoints of the relationship. An example ClassificationDef is Confidentiality : that can apply to any Referenceable entity (hence including both GlossaryTerm and GlossaryCategory , as both of these extend the Referenceable entity type). Example: Referenceable For example, Referenceable is defined as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 final String guid = \"a32316b8-dc8c-48c5-b12b-71c1b2a080bf\" ; final String name = \"Referenceable\" ; final String description = \"An open metadata entity that has a unique identifier.\" ; final String descriptionGUID = null ; // The EntityDef object itself EntityDef entityDef = archiveHelper . getDefaultEntityDef ( guid , name , null , description , descriptionGUID ); List < TypeDefAttribute > properties = new ArrayList <> (); TypeDefAttribute property ; final String attribute1Name = \"qualifiedName\" ; final String attribute1Description = \"Unique identifier for the entity.\" ; final String attribute1DescriptionGUID = null ; final String attribute2Name = \"additionalProperties\" ; final String attribute2Description = \"Additional properties for the element.\" ; final String attribute2DescriptionGUID = null ; // The TypeDefAttributes that define the properties of the Referenceable (EntityDef) object property = archiveHelper . getStringTypeDefAttribute ( attribute1Name , attribute1Description , attribute1DescriptionGUID ); property . setUnique ( true ); properties . add ( property ); property = archiveHelper . getMapStringStringTypeDefAttribute ( attribute2Name , attribute2Description , attribute2DescriptionGUID ); properties . add ( property ); entityDef . setPropertiesDefinition ( properties ); And this results in a JSON structure like the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \"class\" : \"EntityDef\" , \"guid\" : \"a32316b8-dc8c-48c5-b12b-71c1b2a080bf\" , \"name\" : \"Referenceable\" , \"version\" : 1 , \"versionName\" : \"1.0\" , \"category\" : \"ENTITY_DEF\" , \"description\" : \"An open metadata entity that has a unique identifier.\" , \"origin\" : \"bce3b0a0-662a-4f87-b8dc-844078a11a6e\" , \"createdBy\" : \"ODPi Egeria (OMRS)\" , \"createTime\" : 1516313040008 , \"validInstanceStatusList\" : [ \"ACTIVE\" , \"DELETED\" ], \"initialStatus\" : \"ACTIVE\" , \"propertiesDefinition\" : [ { \"attributeName\" : \"qualifiedName\" , \"attributeType\" : { \"class\" : \"PrimitiveDef\" , \"version\" : 1 , \"versionName\" : \"1.0\" , \"category\" : \"PRIMITIVE\" , \"guid\" : \"b34a64b9-554a-42b1-8f8a-7d5c2339f9c4\" , \"name\" : \"string\" , \"primitiveDefCategory\" : \"OM_PRIMITIVE_TYPE_STRING\" }, \"attributeDescription\" : \"Unique identifier for the entity.\" , \"valuesMinCount\" : 0 , \"valuesMaxCount\" : 1 , \"indexable\" : true , \"attributeCardinality\" : \"AT_MOST_ONE\" , \"unique\" : true }, { \"attributeName\" : \"additionalProperties\" , \"attributeType\" : { \"class\" : \"CollectionDef\" , \"version\" : 1 , \"versionName\" : \"1.0\" , \"category\" : \"COLLECTION\" , \"guid\" : \"005c7c14-ac84-4136-beed-959401b041f8\" , \"name\" : \"map<string,string>\" , \"description\" : \"A map from String to String.\" , \"collectionDefCategory\" : \"OM_COLLECTION_MAP\" , \"argumentCount\" : 2 , \"argumentTypes\" : [ \"OM_PRIMITIVE_TYPE_STRING\" , \"OM_PRIMITIVE_TYPE_STRING\" ] }, \"attributeDescription\" : \"Additional properties for the element.\" , \"valuesMinCount\" : 0 , \"valuesMaxCount\" : 1 , \"indexable\" : true , \"attributeCardinality\" : \"AT_MOST_ONE\" , \"unique\" : false } ] }","title":"Type definitions"},{"location":"guides/developer/repository-connectors/metamodel/overview/#instances","text":"Instances define individual instantiations of the TypeDefs: for example, individual GlossaryTerm entities (like \"Address Line 1\") or GlossaryCategory entities (like \"Coco Pharmaceuticals\"), Confidentiality classifications (like \"Sensitive\"), etc. Implemented instances will generally be objects of one of the following classes: How are entities modeled? EntitySummary , EntityProxy and EntityDetail Egeria models all entities using a general object -- EntitySummary -- from which more detailed representations (like EntityDetail ) are derived. Note that there is a property called type within this object (inherited from InstanceAuditHeader ) that defines the specific type of metadata the entity represents, rather than having a different type-specific object for every different type of entity. How are relationships modeled? Relationship and EntityProxy Egeria models all relationships using a general object -- Relationship -- which links together exactly two entities (using EntityProxy , itself an extension of EntitySummary). These EntityProxy s act as a sort of \"stub\" to which the relationship can point, without needing to be aware of the entire set of details of each entity involved in the relationship, and are therefore an important piece of ensuring that relationships are treated as \"first-class\" objects in their own right. As with entities, there is a property called type within this Relationship object (also inherited from InstanceAuditHeader ) that defines the specific type of metadata the relationship represents, rather than having a different type-specific object for every different type of relationship. How are classifications modeled? Classification Egeria models all classifications using a general object -- Classification -- any instance of which is possessed by exactly one entity (within the EntitySummary 's classifications property). As with the other kinds of instances, note that there is a property called type within this Classification object (also inherited from InstanceAuditHeader ) that defines the specific type of metadata the classification represents, rather than having a different type-specific object for every different type of classification. Furthermore, note that classifications in Egeria exist only as part of an entity: unlike EntitySummary and Relationship , they do not extend InstanceHeader and therefore are not assigned a GUID through which they could be independently retrieved or updated. Classifications are only retrievable or updatable through the entity by which they are possessed. Each of these will typically be further described by an InstanceProperties object that instantiates one or more properties used to describe the entity, classification or relationship. Instances as a concept are implemented as generic Java classes in Egeria (those in italics are abstract). Examples of instances Like TypeDefs, instances are managed as instantiated objects of the classes above (not as new classes that inherit from those above). For example, to represent an \"Address Line 1\" GlossaryTerm , there can be: an instantiated EntitySummary object providing a headline set of information about \"Address Line 1\" (i.e. its classifications), an instantiated EntityDetail object providing the full details of \"Address Line 1\" (all of its classifications and properties), an instantiated EntityProxy object defining the unique properties of \"Address Line 1\" (i.e. a qualifiedName property inherited from Referenceable which must be unique across all instances of the object) The InstanceProperties associated with the EntityDetail , Relationship and Classification objects give the further detail on the object (ie. its name, summary, etc). To represent a \"Sensitive Confidentiality\" concept that can be used to classify other information (like \"Address Line 1\"), we could have a \"Confidentiality\" Classification defined with a specific level (\"Sensitive\") through its InstanceProperties To represent the linkage between \"Address Line 1\" and a specific category location (like \"Coco Pharmaceuticals/Terms\") we could have a Relationship representing the TermCategorization with one end pointing to an EntityProxy for \"Address Line 1\" and one end pointing to an EntityProxy for \"Coco Pharmaceuticals/Terms\" Code example for creating the various types As code, this example could be implemented using something like the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 // ENTITIES // Summary-level entity information (see end of CLASSIFICATION section for adding Classifications) EntitySummary summary = new EntitySummary (); summary . setGUID ( guid ); summary . setCreatedBy ( \"...user...\" ); summary . setCreateTime ( new Date (...)); summary . setUpdatedBy ( \"...user...\" ); summary . setUpdateTime ( new Date (...)); // Detailed-level entity information (see end of CLASSIFICATION section for adding Classifications) EntityDetail detail = repositoryConnector . getRepositoryHelper (). getSkeletonEntity ( sourceName , omrsRepositoryConnector . getMetadataCollectionId (), InstanceProvenanceType . LOCAL_COHORT , userId , \"GlossaryTerm\" ); detail . setStatus ( InstanceStatus . ACTIVE ); detail . setGUID ( guid ); detail . setCreatedBy ( \"...user...\" ); detail . setCreateTime ( new Date (...)); detail . setUpdatedBy ( \"...user...\" ); detail . setUpdateTime ( new Date (...)); InstanceProperties instanceProperties = new InstanceProperties (); PrimitivePropertyValue propertyValue = new PrimitivePropertyValue (); PrimitiveDef primitiveDef = new PrimitiveDef (); primitiveDef . setPrimitiveDefCategory ( PrimitiveDefCategory . OM_PRIMITIVE_TYPE_STRING ); propertyValue . setPrimitiveValue ( \"Address Line 1\" ); propertyValue . setPrimitiveDefCategory ( primitiveDef . getPrimitiveDefCategory ()); propertyValue . setTypeGUID ( primitiveDef . getGUID ()); propertyValue . setTypeName ( primitiveDef . getName ()); instanceProperties . setProperty ( \"qualifiedName\" , propertyValue ); propertyValue . setPrimitiveValue ( \"Street and street number\" ); instanceProperties . setProperty ( \"summary\" , propertyValue ); detail . setProperties ( instanceProperties ); // CLASSIFICATION InstanceProperties properties = new InstanceProperties (); // The \"Sensitive\" level for the classification EnumPropertyValue level = new EnumPropertyValue (); level . setSymbolicName ( \"Sensitive\" ); properties . setProperty ( \"level\" , level ); // Creating a new classification, of \"Confidentiality\", applying to \"Referenceable\", with // the \"Sensitive\" level defined above Classification classification = omrsRepositoryConnector . getRepositoryHelper (). getNewClassification ( sourceName , userId , \"Confidentiality\" , \"Referenceable\" , ClassificationOrigin . ASSIGNED , null , properties ); ArrayList < Classificaton > classifications = new ArrayList <> (); classifications . add ( classification ); // ... adding the Classification(s) to the Entity(Summary|Detail) summary . setClassifications ( classifications ); detail . setClassifications ( classifications ); // RELATIONSHIP // Define the qualifiedName property with the unique name for the first end of the relationship // (the GlossaryCategory end of the relationship) InstanceProperties uniqueProperties1 = new InstanceProperties (); PrimitivePropertyValue propertyValue = new PrimitivePropertyValue (); PrimitiveDef primitiveDef = new PrimitiveDef (); primitiveDef . setPrimitiveDefCategory ( PrimitiveDefCategory . OM_PRIMITIVE_TYPE_STRING ); propertyValue . setPrimitiveValue ( \"Coco Pharmaceuticals/Terms\" ); propertyValue . setPrimitiveDefCategory ( primitiveDef . getPrimitiveDefCategory ()); propertyValue . setTypeGUID ( primitiveDef . getGUID ()); propertyValue . setTypeName ( primitiveDef . getName ()); uniqueProperties1 . setProperty ( \"qualifiedName\" , propertyValue ); EntityProxy entityProxy1 = omrsRepositoryConnector . getRepositoryHelper (). getNewEntityProxy ( sourceName , omrsRepositoryConnector . getMetadataCollectionId (), InstanceProvenanceType . LOCAL_COHORT , userId , \"GlossaryCategory\" , uniqueProperties1 , null ); // Define the qualifiedName property with the unique name of the second end of the relationship // (the GlossaryTerm end of the relationship) InstanceProperties uniqueProperties2 = new InstanceProperties (); primitiveDef . setPrimitiveDefCategory ( PrimitiveDefCategory . OM_PRIMITIVE_TYPE_STRING ); propertyValue . setPrimitiveValue ( \"Address Line 1\" ); propertyValue . setPrimitiveDefCategory ( primitiveDef . getPrimitiveDefCategory ()); propertyValue . setTypeGUID ( primitiveDef . getGUID ()); propertyValue . setTypeName ( primitiveDef . getName ()); uniqueProperties2 . setProperty ( \"qualifiedName\" , propertyValue ); EntityProxy entityProxy2 = omrsRepositoryConnector . getRepositoryHelper (). getNewEntityProxy ( sourceName , omrsRepositoryConnector . getMetadataCollectionId (), InstanceProvenanceType . LOCAL_COHORT , userId , \"GlossaryTerm\" , uniqueProperties2 , null ); // Define the relationship between the two EntityProxy objects instantiated above Relationship omrsRelationship = new Relationship (); InstanceProperties relationshipProperties = new InstanceProperties (); PrimitivePropertyValue relationProperty = new PrimitivePropertyValue (); relationProperty . setTypeGUID ( \"...\" ); relationProperty . setTypeName ( \"???\" ); relationshipProperties . setProperty ( \"TermCategorization\" , relationProperty ); omrsRelationship . setProperties ( relationshipProperties ); omrsRelationship . setEntityOneProxy ( entityProxy1 ); omrsRelationship . setEntityTwoProxy ( entityProxy2 ); omrsRelationship . setGUID ( \"...\" );","title":"Instances"},{"location":"guides/developer/runtime-connectors/audit-log-store-connector/","text":"Audit Log Store Connectors \u00b6 The audit log store connectors provide a common interface to an audit log destination. It is used by the OMAG Server's 's audit log . The audit log supports multiple instances of the audit log store and will pass audit log records to each configured instance of the audit log store connectors. Implementations of this type of connector are located in the adapters/open-connectors/repository-services-connectors/audit-log-connectors module.","title":"Audit log store connector"},{"location":"guides/developer/runtime-connectors/audit-log-store-connector/#audit-log-store-connectors","text":"The audit log store connectors provide a common interface to an audit log destination. It is used by the OMAG Server's 's audit log . The audit log supports multiple instances of the audit log store and will pass audit log records to each configured instance of the audit log store connectors. Implementations of this type of connector are located in the adapters/open-connectors/repository-services-connectors/audit-log-connectors module.","title":"Audit Log Store Connectors"},{"location":"guides/developer/runtime-connectors/cohort-registry-store-connector/","text":"Cohort Registry Store Connectors \u00b6 The cohort registry store stores information about the repositories registered in the open metadata repository cohort . Each server in the open metadata repository cohort has a cohort registry component to manage its registration with the cohort and maintain the contents of its local cohort registry store. The following diagram shows a cohort with two members: notice that each server has its own cohort registry store - there is no central store. The logical structure within the cohort registry store is as follows: There is one local registration record describing the information sent to the other members of the cohort and a list of remote registration records received from the other members of the cohort. An implementations of this type of connector is located in the adapters/open-connectors/repository-services-connectors/cohort-registry-store-connectors module.","title":"Cohort registry store connector"},{"location":"guides/developer/runtime-connectors/cohort-registry-store-connector/#cohort-registry-store-connectors","text":"The cohort registry store stores information about the repositories registered in the open metadata repository cohort . Each server in the open metadata repository cohort has a cohort registry component to manage its registration with the cohort and maintain the contents of its local cohort registry store. The following diagram shows a cohort with two members: notice that each server has its own cohort registry store - there is no central store. The logical structure within the cohort registry store is as follows: There is one local registration record describing the information sent to the other members of the cohort and a list of remote registration records received from the other members of the cohort. An implementations of this type of connector is located in the adapters/open-connectors/repository-services-connectors/cohort-registry-store-connectors module.","title":"Cohort Registry Store Connectors"},{"location":"guides/developer/runtime-connectors/open-metadata-archive-store-connector/","text":"Open Metadata Archive Store Connectors \u00b6 The open archive store connectors provide a common interface for managing stores of open metadata archives . Its interface is defined in OpenMetadataArchiveStore The open metadata archive structure is defined by OpenMetadataArchive :material-github . There are 3 sections: Section Description archiveProperties provides details of the source and contents of the archive archiveTypeStore a list of new AttributeTypeDefs, new TypeDefs and patches to existing TypeDefs archiveInstanceStore a list of new metadata instances (Entities, Relationships and Classifications) An implementations of this type of connector is located in the adapters/open-connectors/repository-services-connectors/open-metadata-archive-connectors module.","title":"Open metadata archive store connector"},{"location":"guides/developer/runtime-connectors/open-metadata-archive-store-connector/#open-metadata-archive-store-connectors","text":"The open archive store connectors provide a common interface for managing stores of open metadata archives . Its interface is defined in OpenMetadataArchiveStore The open metadata archive structure is defined by OpenMetadataArchive :material-github . There are 3 sections: Section Description archiveProperties provides details of the source and contents of the archive archiveTypeStore a list of new AttributeTypeDefs, new TypeDefs and patches to existing TypeDefs archiveInstanceStore a list of new metadata instances (Entities, Relationships and Classifications) An implementations of this type of connector is located in the adapters/open-connectors/repository-services-connectors/open-metadata-archive-connectors module.","title":"Open Metadata Archive Store Connectors"},{"location":"guides/developer/runtime-connectors/open-metadata-topic-connector/","text":"Open Metadata Topic Connector \u00b6 The open metadata topic connector provides a topic interface to a generic string event. It is the interface implemented by specific event buses . Topic connectors for specific types of events (such as the OMRS Topic Connector ) are configured with an instance of an open metadata topic connector embedded inside it. The open metadata topic connector means that only one connector need be implemented for each type of event bus - rather than one for each type of topic that Egeria supports. Implementations of this type of connector are located in the adapters/open-connectors/repository-services-connectors/audit-log-connectors module.","title":"Open metadata topic connector"},{"location":"guides/developer/runtime-connectors/open-metadata-topic-connector/#open-metadata-topic-connector","text":"The open metadata topic connector provides a topic interface to a generic string event. It is the interface implemented by specific event buses . Topic connectors for specific types of events (such as the OMRS Topic Connector ) are configured with an instance of an open metadata topic connector embedded inside it. The open metadata topic connector means that only one connector need be implemented for each type of event bus - rather than one for each type of topic that Egeria supports. Implementations of this type of connector are located in the adapters/open-connectors/repository-services-connectors/audit-log-connectors module.","title":"Open Metadata Topic Connector"},{"location":"guides/documentation/formatting/","text":"Formatting Standards \u00b6 These formatting standards exist to keep the content of the documentation consistent. Links \u00b6 Link within docs using absolute links \u00b6 When linking between pages in the documentation use the regular Markdown linking syntax, but with the absolute path to the Markdown document or area you wish to link to. For example: ... is a type of [ OMAG Server ]( /egeria-docs/concepts/omag-server ) that ... Note that we do not need to point at a specific Markdown file Note from the example above that we do not need to point at a specific Markdown file. In the example above, the actual file is omag-server.md ; however, MkDocs will automatically generate an omag-server/index.html output for this Markdown which our URL above refers to. This syntax is useful because it means that if we start with a simple single file for some content (like omag-server.md ) but later decide it needs additional explanation across various other files, we can simply turn this area of documentation into a directory ( omag-server ) with many files within it. The link above does not need to change and will simply point to the omag-server/index.md that should exist after moving from single-file to a directory-based documentation for that area. This ensures certain contexts in the documentation hierarchy are retained, even if deeply-nested documentation itself happens to move around, and takes advantage of the way MkDocs works to give us additional flexibility in extending the documentation later on without needing to retroactively go back and fix links everywhere that refers to that content. Link to code with a GitHub icon \u00b6 When linking to one of the code repositories, add both a :material-github: icon to the end of the link name, and a target to the link: [ `Foo` :material-github:](https://github.com/.../Foo.java){ target=gh } This ensures that a reader clicking the link ( Foo ) will know that they will be directed to code, and that it will open in a new tab / window. Link to other sites with a window icon \u00b6 When linking to some other non-Egeria site, add both a :material-dock-window: icon to the end of the link name, and a target to the link: [ some example :material-dock-window: ]( https://example.com ){ target=example } This ensures that a reader clicking the link will know that they will be going to some non-Egeria site, and it will open in a new tab / window. Prefer SVG format for diagrams \u00b6 Use regular Markdown syntax for images. For example: ![ Description of what the image depicts ]( image-filename.svg ) To make localization easier and enhance accessibility, the preferred image format is SVG. Use draw.io for creating images and diagrams. To save, follow these steps: Select everything you want to include in the diagram (e.g. Ctrl + A / Cmd + A ). Use File , Export as , SVG... to save your image in SVG format. Check the Selection Only box, and ensure that the Size drop-down changes to Selection Only . Check the Transparent Background box. Keep the Include a copy of my diagram option checked to allow later loading the SVG in draw.io. If your diagram contains any embedded images (rare), be sure to check Embed Images as well. Click the Export button to save the file. The SVG format allows the diagram to be dynamically scaled in the browser without introducing various image artifacts that create noise or otherwise impair visibility of the image: making the diagrams easier to understand. Give each diagram a unique figure number and use this number to refer to the diagram rather than using positional phrases such as \"in the diagram above\" which presupposes a particular layout that may not be appropriate for all devices. Avoiding text descriptions and explanations embedded in the diagrams means that the content is also more accessible (again for screen-readers), but also more broadly in that it is then indexed by the documentation site and can be searched. (Text embedded inside a diagram or image is not searchable.) In addition, be sure to provide enough description about the diagram in the text so that if the diagram is not visible to the reader for some reason, they can still understand the message. Providing a description of the image is required for accessibility purposes, as it will act as the alternative text for e.g. screen-readers for anyone who is unable to see the image itself. Be sure to include the figure number in the description so it can be easily associated with the text. If your diagram depicts a process, try to avoid adding the descriptions of the steps to the diagram. Instead, only add the numbers of the steps to the diagram and add the descriptions of the steps as a numbered list in the document. Ensure that the numbers on the list match the numbers on your diagram. Do not wrap lines \u00b6 Avoid wrapping lines after a fixed number of characters or in a middle of a sentence. Instead, configure your editor to soft-wrap when editing documentation. Do Don't This is a long line. This is a long line. This enhances the maintainability of the documentation by a broader audience: different people will inevitably have different preferences for screen sizes and widths (we do not need to worry about constantly reformatting or scrolling what one or another contributor has decided is their own optimal line-break size) reviewing a diff of changes will be easier to identify actual content vs spacing / newline positioning changes changes in indentation that may be needed for e.g. bullet lists, inclusion within an admonition, etc will only require indenting the single wrapped line including content into a table in Markdown (which does not allow newlines within it) will be easier Use angle brackets for placeholders in commands \u00b6 Use angle brackets for placeholders in commands or code samples. Tell the reader what the placeholder represents. For example: Display information about a pod: $ kubectl describe pod <pod-name> Where <pod-name> is the name of one of your pods. We may revise this approach in the future We may revise this approach if / when we start to make use of the theme's extensive code annotation capabilities that allow such descriptions of the placeholders to be embedded more directly within the code block itself. Use double curly braces for placeholders in REST API urls \u00b6 Use double curly braces for placeholders in REST API urls. Tell the reader what the placeholder represents. For example: Start the server: POST {{ baseURL }} /open-metadata/admin-services/users/ {{ adminUserId }} /servers/ {{ server }} /instance Where {{baseURL}} is the host name and port of the platform where the server is to run; {{adminUserId}} is the user id of the administrator and {{server}} is the name of the server to start. We may revise this approach in the future We may revise this approach if / when we start to make use of the theme's extensive code annotation capabilities that allow such descriptions of the placeholders to be embedded more directly within the code block itself. Use bold to emphasize user interface elements \u00b6 Use Markdown's double-asterisk to indicate bold : Click **Fork** . Do Don't Click Fork . Click \"Fork\". Select Other . Select 'Other'. This enhances the readability of the key actions that a user is expected to take through a user interface. Why use double-asterisk ( ** ) and not double-underscore ( __ )? Markdown applications in general do not agree on how to handle underscores in the middle of words. While we would expect this need to be rare, the double-asterisk form allows bold to be used even within the middle of a word. Use bold to emphasize important text \u00b6 Use bold to emphasize text that is particularly important. Avoid overusing bold as it reduces its impact and readability. Do Don't Examples of bad configurations: Examples of bad configurations : The maximum length of the name field is 256 characters . The maximum length of the name field is 256 characters. Do not use capitalization for emphasis \u00b6 Only use the original capitalization found in the code or configuration files when referencing those values directly. Use back-ticks ` ` around the referenced value to make the connection explicit. For example, use InstanceHeader , not Instance Header or instance header . If you are not referencing values or code directly, use normal sentence capitalization, for example, \"The instance header captures key information about the metadata instance like its GUID .\" For code, the back-tick form is intended to represent exactly what you're referring to, so you should specify it exactly as it is defined: with precisely the same spacing, capitalization, etc. For non-code values, mixing capitalization makes the text harder to scan and comprehend, as well as more difficult and therefore stressful to read . Therefore, using normal sentence capitalization greatly enhances the readability of the content. The only exceptions to this should be as follows: Proper nouns (i.e. Egeria) Any phrase that is prefixed or suffixed with Open Metadata (or an OMxx abbreviation) Any phrase that we commonly abbreviate using an acronym (i.e. frameworks like Open Discovery Framework): check the snippets/abbr.md for a list of such common abbreviations. Do Don't Egeria egeria Open Metadata Repository Services ( OMRS ) open metadata repository services repository services Repository Services Asset Consumer OMAS asset consumer OMAS OMAG Server Platform OMAG server platform OMAG Server OMAG server metadata access point Metadata Access Point Metadata Access Point OMAG Server metadata access point OMAG Server Open Discovery Framework ( ODF ) open discovery framework Audit Log Framework ( ALF ) audit log framework Avoid using acronyms \u00b6 Avoid using acronyms in the text unless they are part of the name of a component or the acronym has been spelt out in full on the page along with its acronym. Acronyms are convenient short-cuts for experts but they overload novices with the need to constantly look up the meaning of the term. Do Don't The Open Connector Framework ( OCF ) ... an OCF connector The OCF ... An OMAG Server ... or An Open Metadata and Governance ( OMAG ) Server An Open Metadata and Governance Server Use italics to emphasize new terms \u00b6 Use Markdown's single-asterisk to indicate italics : Do Don't A cluster is a set of nodes ... A \"cluster\" is a set of nodes ... These components form the control plane . These components form the control plane . Why use single-asterisk ( * ) and not single-underscore ( _ )? Markdown applications in general do not agree on how to handle underscores in the middle of words. While we would expect this need to be rare, the single-asterisk form allows italics to be used even within the middle of a word. Use back-ticks around file names, directories, and paths \u00b6 Do Don't Open the foo.yaml file. Open the foo.yaml file. Go to the /content/docs/architecture directory. Go to the /content/docs/architecture directory. Open the /data/args.yaml file. Open the /data/args.yaml file. Go to the /docs directory. Go to the \"/docs\" directory. Use back-ticks around inline code, commands, objects and field names \u00b6 Do Don't The foo run command creates a Deployment . The \"foo run\" command creates a Deployment . For declarative management, use foo apply . For declarative management, use foo apply . Set the value of the ports field in the configuration file. Set the value of the \"ports\" field in the configuration file. The value of the rule field is a Rule object. The value of the rule field is a Rule object. Only use inline code and commands to mention specific labels, flags, values, functions, objects, variables, modules, or commands. Code blocks \u00b6 Use the provided custom admonitions for code and configuration blocks, within which the standard Markdown triple back-tick approach can be used to give the code block itself. Using the triple back-tick approach ensures that we can include syntax highlighting for the specific language being shown within the code block, and provides a simple single-click link mechanism for the reader to copy the entire content of that code block for further revision or pasting elsewhere. Each admonition wraps these to give a distinct visual cue as to its content: allowing us to avoid other cues that we might otherwise need to embed within the code block itself (for example, the $ or # command-line prompts). Avoiding the inclusion of this visual cue information in the text means that readers who copy the text do not need to manually remove this from what's been copied before making use of it. Finally, by using admonitions we not only have the visual cue but can easily make use of the distinct capabilities of the !!! , ??? and ???+ syntax to always display the content, start with the content collapsed but allow it to be expanded, or start with it expanded but allow it to be collapsed (respectively). Use cli admonition for commands \u00b6 Use the cli admonition to wrap the code block in a visual cue that indicates a command: ???+ cli \"Brief description of command\" ```shell kubectl get pods ``` Leave out any command-line prompt ( $ , # , etc). Brief description of command kubectl get pods Use post , get , put , delete admonitions for APIs \u00b6 For APIs, use the distinct admonition that represents the type of operation: post , get , put , delete . ???+ get \"GET - brief description of API call\" ``` {{platformURLRoot}}/open-metadata/... ``` While the colors have been chosen to align with the Swagger documentation colors for each operation, for accessibility purposes always start the description of the API call with the operation type. For parameters in the URL, always do the following: Specify the platform URL variable at the beginning, always named {{platformURLRoot}} Specify the administrative user variable as {{adminUserId}} Specify the server's name variable as {{serverName}} Specify any other parameters or variables in the URL using the double-curly-brace formatting {{...}} . This ensures that the endpoint can be quickly copied into tools like Postman, and by using the same variable names consistently someone can setup their own environment definition once and make use of all the API calls they decide to copy into the tool without needing to manually make each parameter consistent. GET - brief description of API call {{platformURLRoot}}/open-metadata/... POST - brief description of API call {{platformURLRoot}}/open-metadata/... PUT - brief description of API call {{platformURLRoot}}/open-metadata/... DELETE - brief description of API call {{platformURLRoot}}/open-metadata/... Use example admonition for file content \u00b6 Use the example admonition to wrap a code block that represents a file's contents, and include both the type of content ( json , etc) and the linenums=\"1\" directives next to the opening triple back-tick . Use two spaces for indentation of lines. ???+ example \"Name or brief description of file's purpose\" ```json linenums=\"1\" { \"foo\": \"bar\", \"baz\": { } } ``` This ensures that the syntax of the file is appropriately highlighted, that line numbers are printed for ease of reference, and that the indentation is not overly-intrusive (causing horizontal scrolling within the code block to become necessary). Name or brief description of file's purpose 1 2 3 4 5 { \"foo\" : \"bar\" , \"baz\" : { } } Use hyphen ( - ) for unordered lists \u00b6 Use a single hyphen ( - ) for unordered lists rather than a single asterisk ( * ). This should avoid the potential for misinterpretation by the generator that a bulleted list is text that we intended (or not) to be either bolded or italicized. Include license header \u00b6 Every Markdown document should include a license header with the CC-BY-4.0 attribute license: License header for documentation files 1 2 <!-- SPDX-License-Identifier: CC-BY-4.0 --> <!-- Copyright Contributors to the Egeria project. --> Remove license footer \u00b6 The MkDocs generator automatically includes a footer at the bottom of every page on the site, which includes displaying overall copyright information and the CC-BY-4.0 license (and link). Therefore, these footers should be removed from the Markdown files themselves. Include abbreviations snippet \u00b6 A list of abbreviations is being maintained under snippets/abbr.md . This snippet should therefore be included in every Markdown document to automatically highlight and provide a hover-over expansion for acronyms. Add this line, on its own, to the end of every (non-snippet) Markdown document: --8<-- \"snippets/abbr.md\"","title":"Formatting Standards"},{"location":"guides/documentation/formatting/#formatting-standards","text":"These formatting standards exist to keep the content of the documentation consistent.","title":"Formatting Standards"},{"location":"guides/documentation/formatting/#links","text":"","title":"Links"},{"location":"guides/documentation/formatting/#link-within-docs-using-absolute-links","text":"When linking between pages in the documentation use the regular Markdown linking syntax, but with the absolute path to the Markdown document or area you wish to link to. For example: ... is a type of [ OMAG Server ]( /egeria-docs/concepts/omag-server ) that ... Note that we do not need to point at a specific Markdown file Note from the example above that we do not need to point at a specific Markdown file. In the example above, the actual file is omag-server.md ; however, MkDocs will automatically generate an omag-server/index.html output for this Markdown which our URL above refers to. This syntax is useful because it means that if we start with a simple single file for some content (like omag-server.md ) but later decide it needs additional explanation across various other files, we can simply turn this area of documentation into a directory ( omag-server ) with many files within it. The link above does not need to change and will simply point to the omag-server/index.md that should exist after moving from single-file to a directory-based documentation for that area. This ensures certain contexts in the documentation hierarchy are retained, even if deeply-nested documentation itself happens to move around, and takes advantage of the way MkDocs works to give us additional flexibility in extending the documentation later on without needing to retroactively go back and fix links everywhere that refers to that content.","title":"Link within docs using absolute links"},{"location":"guides/documentation/formatting/#link-to-code-with-a-github-icon","text":"When linking to one of the code repositories, add both a :material-github: icon to the end of the link name, and a target to the link: [ `Foo` :material-github:](https://github.com/.../Foo.java){ target=gh } This ensures that a reader clicking the link ( Foo ) will know that they will be directed to code, and that it will open in a new tab / window.","title":"Link to code with a GitHub icon"},{"location":"guides/documentation/formatting/#link-to-other-sites-with-a-window-icon","text":"When linking to some other non-Egeria site, add both a :material-dock-window: icon to the end of the link name, and a target to the link: [ some example :material-dock-window: ]( https://example.com ){ target=example } This ensures that a reader clicking the link will know that they will be going to some non-Egeria site, and it will open in a new tab / window.","title":"Link to other sites with a window icon"},{"location":"guides/documentation/formatting/#prefer-svg-format-for-diagrams","text":"Use regular Markdown syntax for images. For example: ![ Description of what the image depicts ]( image-filename.svg ) To make localization easier and enhance accessibility, the preferred image format is SVG. Use draw.io for creating images and diagrams. To save, follow these steps: Select everything you want to include in the diagram (e.g. Ctrl + A / Cmd + A ). Use File , Export as , SVG... to save your image in SVG format. Check the Selection Only box, and ensure that the Size drop-down changes to Selection Only . Check the Transparent Background box. Keep the Include a copy of my diagram option checked to allow later loading the SVG in draw.io. If your diagram contains any embedded images (rare), be sure to check Embed Images as well. Click the Export button to save the file. The SVG format allows the diagram to be dynamically scaled in the browser without introducing various image artifacts that create noise or otherwise impair visibility of the image: making the diagrams easier to understand. Give each diagram a unique figure number and use this number to refer to the diagram rather than using positional phrases such as \"in the diagram above\" which presupposes a particular layout that may not be appropriate for all devices. Avoiding text descriptions and explanations embedded in the diagrams means that the content is also more accessible (again for screen-readers), but also more broadly in that it is then indexed by the documentation site and can be searched. (Text embedded inside a diagram or image is not searchable.) In addition, be sure to provide enough description about the diagram in the text so that if the diagram is not visible to the reader for some reason, they can still understand the message. Providing a description of the image is required for accessibility purposes, as it will act as the alternative text for e.g. screen-readers for anyone who is unable to see the image itself. Be sure to include the figure number in the description so it can be easily associated with the text. If your diagram depicts a process, try to avoid adding the descriptions of the steps to the diagram. Instead, only add the numbers of the steps to the diagram and add the descriptions of the steps as a numbered list in the document. Ensure that the numbers on the list match the numbers on your diagram.","title":"Prefer SVG format for diagrams"},{"location":"guides/documentation/formatting/#do-not-wrap-lines","text":"Avoid wrapping lines after a fixed number of characters or in a middle of a sentence. Instead, configure your editor to soft-wrap when editing documentation. Do Don't This is a long line. This is a long line. This enhances the maintainability of the documentation by a broader audience: different people will inevitably have different preferences for screen sizes and widths (we do not need to worry about constantly reformatting or scrolling what one or another contributor has decided is their own optimal line-break size) reviewing a diff of changes will be easier to identify actual content vs spacing / newline positioning changes changes in indentation that may be needed for e.g. bullet lists, inclusion within an admonition, etc will only require indenting the single wrapped line including content into a table in Markdown (which does not allow newlines within it) will be easier","title":"Do not wrap lines"},{"location":"guides/documentation/formatting/#use-angle-brackets-for-placeholders-in-commands","text":"Use angle brackets for placeholders in commands or code samples. Tell the reader what the placeholder represents. For example: Display information about a pod: $ kubectl describe pod <pod-name> Where <pod-name> is the name of one of your pods. We may revise this approach in the future We may revise this approach if / when we start to make use of the theme's extensive code annotation capabilities that allow such descriptions of the placeholders to be embedded more directly within the code block itself.","title":"Use angle brackets for placeholders in commands"},{"location":"guides/documentation/formatting/#use-double-curly-braces-for-placeholders-in-rest-api-urls","text":"Use double curly braces for placeholders in REST API urls. Tell the reader what the placeholder represents. For example: Start the server: POST {{ baseURL }} /open-metadata/admin-services/users/ {{ adminUserId }} /servers/ {{ server }} /instance Where {{baseURL}} is the host name and port of the platform where the server is to run; {{adminUserId}} is the user id of the administrator and {{server}} is the name of the server to start. We may revise this approach in the future We may revise this approach if / when we start to make use of the theme's extensive code annotation capabilities that allow such descriptions of the placeholders to be embedded more directly within the code block itself.","title":"Use double curly braces for placeholders in REST API urls"},{"location":"guides/documentation/formatting/#use-bold-to-emphasize-user-interface-elements","text":"Use Markdown's double-asterisk to indicate bold : Click **Fork** . Do Don't Click Fork . Click \"Fork\". Select Other . Select 'Other'. This enhances the readability of the key actions that a user is expected to take through a user interface. Why use double-asterisk ( ** ) and not double-underscore ( __ )? Markdown applications in general do not agree on how to handle underscores in the middle of words. While we would expect this need to be rare, the double-asterisk form allows bold to be used even within the middle of a word.","title":"Use bold to emphasize user interface elements"},{"location":"guides/documentation/formatting/#use-bold-to-emphasize-important-text","text":"Use bold to emphasize text that is particularly important. Avoid overusing bold as it reduces its impact and readability. Do Don't Examples of bad configurations: Examples of bad configurations : The maximum length of the name field is 256 characters . The maximum length of the name field is 256 characters.","title":"Use bold to emphasize important text"},{"location":"guides/documentation/formatting/#do-not-use-capitalization-for-emphasis","text":"Only use the original capitalization found in the code or configuration files when referencing those values directly. Use back-ticks ` ` around the referenced value to make the connection explicit. For example, use InstanceHeader , not Instance Header or instance header . If you are not referencing values or code directly, use normal sentence capitalization, for example, \"The instance header captures key information about the metadata instance like its GUID .\" For code, the back-tick form is intended to represent exactly what you're referring to, so you should specify it exactly as it is defined: with precisely the same spacing, capitalization, etc. For non-code values, mixing capitalization makes the text harder to scan and comprehend, as well as more difficult and therefore stressful to read . Therefore, using normal sentence capitalization greatly enhances the readability of the content. The only exceptions to this should be as follows: Proper nouns (i.e. Egeria) Any phrase that is prefixed or suffixed with Open Metadata (or an OMxx abbreviation) Any phrase that we commonly abbreviate using an acronym (i.e. frameworks like Open Discovery Framework): check the snippets/abbr.md for a list of such common abbreviations. Do Don't Egeria egeria Open Metadata Repository Services ( OMRS ) open metadata repository services repository services Repository Services Asset Consumer OMAS asset consumer OMAS OMAG Server Platform OMAG server platform OMAG Server OMAG server metadata access point Metadata Access Point Metadata Access Point OMAG Server metadata access point OMAG Server Open Discovery Framework ( ODF ) open discovery framework Audit Log Framework ( ALF ) audit log framework","title":"Do not use capitalization for emphasis"},{"location":"guides/documentation/formatting/#avoid-using-acronyms","text":"Avoid using acronyms in the text unless they are part of the name of a component or the acronym has been spelt out in full on the page along with its acronym. Acronyms are convenient short-cuts for experts but they overload novices with the need to constantly look up the meaning of the term. Do Don't The Open Connector Framework ( OCF ) ... an OCF connector The OCF ... An OMAG Server ... or An Open Metadata and Governance ( OMAG ) Server An Open Metadata and Governance Server","title":"Avoid using acronyms"},{"location":"guides/documentation/formatting/#use-italics-to-emphasize-new-terms","text":"Use Markdown's single-asterisk to indicate italics : Do Don't A cluster is a set of nodes ... A \"cluster\" is a set of nodes ... These components form the control plane . These components form the control plane . Why use single-asterisk ( * ) and not single-underscore ( _ )? Markdown applications in general do not agree on how to handle underscores in the middle of words. While we would expect this need to be rare, the single-asterisk form allows italics to be used even within the middle of a word.","title":"Use italics to emphasize new terms"},{"location":"guides/documentation/formatting/#use-back-ticks-around-file-names-directories-and-paths","text":"Do Don't Open the foo.yaml file. Open the foo.yaml file. Go to the /content/docs/architecture directory. Go to the /content/docs/architecture directory. Open the /data/args.yaml file. Open the /data/args.yaml file. Go to the /docs directory. Go to the \"/docs\" directory.","title":"Use back-ticks around file names, directories, and paths"},{"location":"guides/documentation/formatting/#use-back-ticks-around-inline-code-commands-objects-and-field-names","text":"Do Don't The foo run command creates a Deployment . The \"foo run\" command creates a Deployment . For declarative management, use foo apply . For declarative management, use foo apply . Set the value of the ports field in the configuration file. Set the value of the \"ports\" field in the configuration file. The value of the rule field is a Rule object. The value of the rule field is a Rule object. Only use inline code and commands to mention specific labels, flags, values, functions, objects, variables, modules, or commands.","title":"Use back-ticks around inline code, commands, objects and field names"},{"location":"guides/documentation/formatting/#code-blocks","text":"Use the provided custom admonitions for code and configuration blocks, within which the standard Markdown triple back-tick approach can be used to give the code block itself. Using the triple back-tick approach ensures that we can include syntax highlighting for the specific language being shown within the code block, and provides a simple single-click link mechanism for the reader to copy the entire content of that code block for further revision or pasting elsewhere. Each admonition wraps these to give a distinct visual cue as to its content: allowing us to avoid other cues that we might otherwise need to embed within the code block itself (for example, the $ or # command-line prompts). Avoiding the inclusion of this visual cue information in the text means that readers who copy the text do not need to manually remove this from what's been copied before making use of it. Finally, by using admonitions we not only have the visual cue but can easily make use of the distinct capabilities of the !!! , ??? and ???+ syntax to always display the content, start with the content collapsed but allow it to be expanded, or start with it expanded but allow it to be collapsed (respectively).","title":"Code blocks"},{"location":"guides/documentation/formatting/#use-cli-admonition-for-commands","text":"Use the cli admonition to wrap the code block in a visual cue that indicates a command: ???+ cli \"Brief description of command\" ```shell kubectl get pods ``` Leave out any command-line prompt ( $ , # , etc). Brief description of command kubectl get pods","title":"Use cli admonition for commands"},{"location":"guides/documentation/formatting/#use-post-get-put-delete-admonitions-for-apis","text":"For APIs, use the distinct admonition that represents the type of operation: post , get , put , delete . ???+ get \"GET - brief description of API call\" ``` {{platformURLRoot}}/open-metadata/... ``` While the colors have been chosen to align with the Swagger documentation colors for each operation, for accessibility purposes always start the description of the API call with the operation type. For parameters in the URL, always do the following: Specify the platform URL variable at the beginning, always named {{platformURLRoot}} Specify the administrative user variable as {{adminUserId}} Specify the server's name variable as {{serverName}} Specify any other parameters or variables in the URL using the double-curly-brace formatting {{...}} . This ensures that the endpoint can be quickly copied into tools like Postman, and by using the same variable names consistently someone can setup their own environment definition once and make use of all the API calls they decide to copy into the tool without needing to manually make each parameter consistent. GET - brief description of API call {{platformURLRoot}}/open-metadata/... POST - brief description of API call {{platformURLRoot}}/open-metadata/... PUT - brief description of API call {{platformURLRoot}}/open-metadata/... DELETE - brief description of API call {{platformURLRoot}}/open-metadata/...","title":"Use post, get, put, delete admonitions for APIs"},{"location":"guides/documentation/formatting/#use-example-admonition-for-file-content","text":"Use the example admonition to wrap a code block that represents a file's contents, and include both the type of content ( json , etc) and the linenums=\"1\" directives next to the opening triple back-tick . Use two spaces for indentation of lines. ???+ example \"Name or brief description of file's purpose\" ```json linenums=\"1\" { \"foo\": \"bar\", \"baz\": { } } ``` This ensures that the syntax of the file is appropriately highlighted, that line numbers are printed for ease of reference, and that the indentation is not overly-intrusive (causing horizontal scrolling within the code block to become necessary). Name or brief description of file's purpose 1 2 3 4 5 { \"foo\" : \"bar\" , \"baz\" : { } }","title":"Use example admonition for file content"},{"location":"guides/documentation/formatting/#use-hyphen-for-unordered-lists","text":"Use a single hyphen ( - ) for unordered lists rather than a single asterisk ( * ). This should avoid the potential for misinterpretation by the generator that a bulleted list is text that we intended (or not) to be either bolded or italicized.","title":"Use hyphen (-) for unordered lists"},{"location":"guides/documentation/formatting/#include-license-header","text":"Every Markdown document should include a license header with the CC-BY-4.0 attribute license: License header for documentation files 1 2 <!-- SPDX-License-Identifier: CC-BY-4.0 --> <!-- Copyright Contributors to the Egeria project. -->","title":"Include license header"},{"location":"guides/documentation/formatting/#remove-license-footer","text":"The MkDocs generator automatically includes a footer at the bottom of every page on the site, which includes displaying overall copyright information and the CC-BY-4.0 license (and link). Therefore, these footers should be removed from the Markdown files themselves.","title":"Remove license footer"},{"location":"guides/documentation/formatting/#include-abbreviations-snippet","text":"A list of abbreviations is being maintained under snippets/abbr.md . This snippet should therefore be included in every Markdown document to automatically highlight and provide a hover-over expansion for acronyms. Add this line, on its own, to the end of every (non-snippet) Markdown document: --8<-- \"snippets/abbr.md\"","title":"Include abbreviations snippet"},{"location":"guides/documentation/guide/","text":"Documentation Guide \u00b6 We strive to provide complete, concise and maintainable documentation for the project. To achieve these goals, all contributed documentation should adhere to the guidance provided in this documentation guide , split into the following sub-guides: Formatting standards to keep the content of the documentation consistent. Style guide to keep the documentation clear and understandable. Technical context \u00b6 The repository hosting the documentation for Egeria is separate from the individual code repositories, and is maintained at odpi/egeria-docs . The documentation itself is all managed as Markdown files for ease of maintenance and readability. We use the MkDocs generator along with the Material for MkDocs theme to generate a static website from these Markdown files. This static website is deployed to the gh-pages branch of the documentation repository, from which GitHub pages then hosts the documentation website itself. Adding to the documentation \u00b6 When contributing to the documentation, you can easily use this to test documentation changes out on your own machine locally before committing them in a PR : On a Mac, just do a brew install mkdocs (requires HomeBrew ). Then do a pip3 install mkdocs-material [--upgrade] (the last bit you might want to add and re-run periodically to keep things up-to-date). From the site directory of your local clone of this repository, you can then just run: $ mkdocs serve ... and you'll shortly have a local documentation site running on your local machine, complete with any changes you make (each change you make will auto-refresh the content and your browser). Look for warnings As part of running its generator, MkDocs will automatically warn you if it finds any broken links within your documentation. Pay close attention to these, as the PR merge mechanism for documentation will strictly enforce that no broken links are found in order to merge any changes into the main documentation. Special handling of index.md Be aware that the specific theme we use will treat every index.md as an index page for a section: these behave in special ways depending on the level of the navigation in which they appear. Unless you mean to create an overview of some section of the navigation, do not name your Markdown file index.md .","title":"Documentation Guide"},{"location":"guides/documentation/guide/#documentation-guide","text":"We strive to provide complete, concise and maintainable documentation for the project. To achieve these goals, all contributed documentation should adhere to the guidance provided in this documentation guide , split into the following sub-guides: Formatting standards to keep the content of the documentation consistent. Style guide to keep the documentation clear and understandable.","title":"Documentation Guide"},{"location":"guides/documentation/guide/#technical-context","text":"The repository hosting the documentation for Egeria is separate from the individual code repositories, and is maintained at odpi/egeria-docs . The documentation itself is all managed as Markdown files for ease of maintenance and readability. We use the MkDocs generator along with the Material for MkDocs theme to generate a static website from these Markdown files. This static website is deployed to the gh-pages branch of the documentation repository, from which GitHub pages then hosts the documentation website itself.","title":"Technical context"},{"location":"guides/documentation/guide/#adding-to-the-documentation","text":"When contributing to the documentation, you can easily use this to test documentation changes out on your own machine locally before committing them in a PR : On a Mac, just do a brew install mkdocs (requires HomeBrew ). Then do a pip3 install mkdocs-material [--upgrade] (the last bit you might want to add and re-run periodically to keep things up-to-date). From the site directory of your local clone of this repository, you can then just run: $ mkdocs serve ... and you'll shortly have a local documentation site running on your local machine, complete with any changes you make (each change you make will auto-refresh the content and your browser). Look for warnings As part of running its generator, MkDocs will automatically warn you if it finds any broken links within your documentation. Pay close attention to these, as the PR merge mechanism for documentation will strictly enforce that no broken links are found in order to merge any changes into the main documentation. Special handling of index.md Be aware that the specific theme we use will treat every index.md as an index page for a section: these behave in special ways depending on the level of the navigation in which they appear. Unless you mean to create an overview of some section of the navigation, do not name your Markdown file index.md .","title":"Adding to the documentation"},{"location":"guides/documentation/style/","text":"Style Guide \u00b6 The style guidelines exist to keep the documentation clear and understandable. Choose the right title \u00b6 Use a short, keyword-rich title that captures the intent of the document and draws the reader in. Ensure that the title clearly and concisely conveys the content or subject matter and is meaningful to a global audience. The text for the title of the document must use title case. Capitalize the first letter of every word except conjunctions and prepositions. Do Don't # Security Architecture # Security architecture # Code of Conduct # Code Of Conduct Use sentence case for headings \u00b6 Use sentence case for the headings in your document. Only capitalize the first word of the heading, except for proper nouns or acronyms. Do Don't Configuring rate limits Configuring Rate Limits Using Envoy for ingress Using envoy for ingress Using HTTPS Using https Use present tense \u00b6 Do Don't This command starts a proxy. This command will start a proxy. Exception Use future or past tense if it is required to convey the correct meaning. This exception is extremely rare and should be avoided. Use active voice \u00b6 Do Don't You can explore the API using a browser. The API can be explored using a browser. The YAML file specifies the replica count. The replica count is specified in the YAML file. Use simple and direct language \u00b6 Use simple and direct language. Avoid using unnecessary phrases, such as saying \"please.\" Do Don't To create a ReplicaSet , ... In order to create a ReplicaSet , ... See the configuration file. Please see the configuration file. View the Pods. With this next command, we'll view the Pods. Prefer shorter words over longer alternatives \u00b6 Do Don't This tool helps scaling up pods. This tool facilitates scaling up pods. Pilot uses the purpose field to ... Pilot utilizes the purpose field to ... Address the reader as \"you\" \u00b6 Do Don't You can create a Deployment by ... We'll create a Deployment by ... In the preceding output, you can see... In the preceding output, we can see ... Avoid using \"we\" \u00b6 Using \"we\" in a sentence can be confusing, because the reader might not know whether they're part of the \"we\" you're describing. Do Don't Version 1.4 includes ... In version 1.4, we have added ... Egeria provides a new feature for ... We provide a new feature ... This page teaches you how to use pods. In this page, we are going to learn about pods. Avoid jargon and idioms \u00b6 Some readers speak English as a second language. Avoid jargon and idioms to help make their understanding easier. Do Don't Internally, ... Under the hood, ... Create a new cluster. Turn up a new cluster. Initially, ... Out of the box, ... Avoid statements that will soon be out of date \u00b6 Avoid using wording that becomes outdated quickly like \"currently\" and \"new\". A feature that is new today is not new for long. Do Don't In version 1.4, ... In the current version, ... The Federation feature provides ... The new Federation feature provides ... Create useful links \u00b6 Don't use here , click here or URLs as the text for a hyperlink. Do Don't ... in a metadata server you can ... ... in a metadata server, which you can read more about here . The metadata access point ... Read more about metadata access points ... The FooBar class ... The FooBar class ( https://example.com/somewhere/something/FooBar.java ) ... There are numerous articles explaining what makes a good hyperlink , but fundamentally the \"Don't\" examples above: Decrease the overall usability of links. Decrease the overall accessibility of the links. Decrease search engine performance and content find-ability.","title":"Style Guide"},{"location":"guides/documentation/style/#style-guide","text":"The style guidelines exist to keep the documentation clear and understandable.","title":"Style Guide"},{"location":"guides/documentation/style/#choose-the-right-title","text":"Use a short, keyword-rich title that captures the intent of the document and draws the reader in. Ensure that the title clearly and concisely conveys the content or subject matter and is meaningful to a global audience. The text for the title of the document must use title case. Capitalize the first letter of every word except conjunctions and prepositions. Do Don't # Security Architecture # Security architecture # Code of Conduct # Code Of Conduct","title":"Choose the right title"},{"location":"guides/documentation/style/#use-sentence-case-for-headings","text":"Use sentence case for the headings in your document. Only capitalize the first word of the heading, except for proper nouns or acronyms. Do Don't Configuring rate limits Configuring Rate Limits Using Envoy for ingress Using envoy for ingress Using HTTPS Using https","title":"Use sentence case for headings"},{"location":"guides/documentation/style/#use-present-tense","text":"Do Don't This command starts a proxy. This command will start a proxy. Exception Use future or past tense if it is required to convey the correct meaning. This exception is extremely rare and should be avoided.","title":"Use present tense"},{"location":"guides/documentation/style/#use-active-voice","text":"Do Don't You can explore the API using a browser. The API can be explored using a browser. The YAML file specifies the replica count. The replica count is specified in the YAML file.","title":"Use active voice"},{"location":"guides/documentation/style/#use-simple-and-direct-language","text":"Use simple and direct language. Avoid using unnecessary phrases, such as saying \"please.\" Do Don't To create a ReplicaSet , ... In order to create a ReplicaSet , ... See the configuration file. Please see the configuration file. View the Pods. With this next command, we'll view the Pods.","title":"Use simple and direct language"},{"location":"guides/documentation/style/#prefer-shorter-words-over-longer-alternatives","text":"Do Don't This tool helps scaling up pods. This tool facilitates scaling up pods. Pilot uses the purpose field to ... Pilot utilizes the purpose field to ...","title":"Prefer shorter words over longer alternatives"},{"location":"guides/documentation/style/#address-the-reader-as-you","text":"Do Don't You can create a Deployment by ... We'll create a Deployment by ... In the preceding output, you can see... In the preceding output, we can see ...","title":"Address the reader as \"you\""},{"location":"guides/documentation/style/#avoid-using-we","text":"Using \"we\" in a sentence can be confusing, because the reader might not know whether they're part of the \"we\" you're describing. Do Don't Version 1.4 includes ... In version 1.4, we have added ... Egeria provides a new feature for ... We provide a new feature ... This page teaches you how to use pods. In this page, we are going to learn about pods.","title":"Avoid using \"we\""},{"location":"guides/documentation/style/#avoid-jargon-and-idioms","text":"Some readers speak English as a second language. Avoid jargon and idioms to help make their understanding easier. Do Don't Internally, ... Under the hood, ... Create a new cluster. Turn up a new cluster. Initially, ... Out of the box, ...","title":"Avoid jargon and idioms"},{"location":"guides/documentation/style/#avoid-statements-that-will-soon-be-out-of-date","text":"Avoid using wording that becomes outdated quickly like \"currently\" and \"new\". A feature that is new today is not new for long. Do Don't In version 1.4, ... In the current version, ... The Federation feature provides ... The new Federation feature provides ...","title":"Avoid statements that will soon be out of date"},{"location":"guides/documentation/style/#create-useful-links","text":"Don't use here , click here or URLs as the text for a hyperlink. Do Don't ... in a metadata server you can ... ... in a metadata server, which you can read more about here . The metadata access point ... Read more about metadata access points ... The FooBar class ... The FooBar class ( https://example.com/somewhere/something/FooBar.java ) ... There are numerous articles explaining what makes a good hyperlink , but fundamentally the \"Don't\" examples above: Decrease the overall usability of links. Decrease the overall accessibility of the links. Decrease search engine performance and content find-ability.","title":"Create useful links"},{"location":"guides/migration/migrating-configuration-documents/","text":"Migrating configuration documents \u00b6 As ODPi Egeria evolves, the content of the configuration document expands. Many of the changes are pure additions and are therefore backward compatible. However, from time to time the structure of the configuration document needs to change. When this happens the OMAG Server Platform is not able to load the configuration document and a message similar to this is returned: { \"class\" : \"VoidResponse\" , \"relatedHTTPCode\" : 400 , \"exceptionClassName\" : \"org.odpi.openmetadata.adminservices.ffdc.exception.OMAGInvalidParameterException\" , \"exceptionErrorMessage\" : \"OMAG-ADMIN-400-022 The configuration document for OMAG server cocoMDS1 is at version V1.0 which is not compatible with this OMAG Server Platform which supports versions [V2.0]\" , \"exceptionSystemAction\" : \"The system is unable to configure the local server because it can not read the configuration document.\" , \"exceptionUserAction\" : \"Migrate the configuration document to a compatible version (or delete and recreate it). See https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user/migrating-configuration-documents.html\" } The guidance for each version change is below ... Migrating a configuration document from V1.0 to V2.0 \u00b6 The additionalProperties property name changed to configurationProperties . To migrate the configuration document, make a global change from additionalProperties to configurationProperties throughout the configuration document. Release 2.x+ of Egeria \u00b6 Release 2.0 encrypts the configuration document by default. This includes automatically detecting and encrypting any clear-text (unencrypted) configuration document that may already exist. No user action is required for this migration, the encryption will be handled automatically when the clear-text configuration document is first opened by the platform in these releases.","title":"Configuration Documents"},{"location":"guides/migration/migrating-configuration-documents/#migrating-configuration-documents","text":"As ODPi Egeria evolves, the content of the configuration document expands. Many of the changes are pure additions and are therefore backward compatible. However, from time to time the structure of the configuration document needs to change. When this happens the OMAG Server Platform is not able to load the configuration document and a message similar to this is returned: { \"class\" : \"VoidResponse\" , \"relatedHTTPCode\" : 400 , \"exceptionClassName\" : \"org.odpi.openmetadata.adminservices.ffdc.exception.OMAGInvalidParameterException\" , \"exceptionErrorMessage\" : \"OMAG-ADMIN-400-022 The configuration document for OMAG server cocoMDS1 is at version V1.0 which is not compatible with this OMAG Server Platform which supports versions [V2.0]\" , \"exceptionSystemAction\" : \"The system is unable to configure the local server because it can not read the configuration document.\" , \"exceptionUserAction\" : \"Migrate the configuration document to a compatible version (or delete and recreate it). See https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user/migrating-configuration-documents.html\" } The guidance for each version change is below ...","title":"Migrating configuration documents"},{"location":"guides/migration/migrating-configuration-documents/#migrating-a-configuration-document-from-v10-to-v20","text":"The additionalProperties property name changed to configurationProperties . To migrate the configuration document, make a global change from additionalProperties to configurationProperties throughout the configuration document.","title":"Migrating a configuration document from V1.0 to V2.0"},{"location":"guides/migration/migrating-configuration-documents/#release-2x-of-egeria","text":"Release 2.0 encrypts the configuration document by default. This includes automatically detecting and encrypting any clear-text (unencrypted) configuration document that may already exist. No user action is required for this migration, the encryption will be handled automatically when the clear-text configuration document is first opened by the platform in these releases.","title":"Release 2.x+ of Egeria"},{"location":"guides/operations/adding-archive-to-running-server/","text":"Adding an archive to a running OMAG Server \u00b6 Open Metadata Archives contain pre-canned metadata types and instances for Cohort Members . Archives can be added to the configuration document of a server to ensure their content is loaded each time the server is started. This is intended for repositories that do not store the archive content but keep it in memory. Although, if an archive is loaded multiple times, its content is only added to the local repository if the repository does not have the content already. Archives can also be loaded to a running server using the following commands. Typically open metadata archives are stored as files. If the archive is stored as JSON in a file, it can be loaded into a running server as follows. The file should be specified either as a fully qualified path name or as a path name relative to the start up directory of the OMAG Server Platform. Note the file name should not have any quotes around its name. POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/open-metadata-archives/file { path name of file } Alternatively it is possible to set up the list of open metadata archives as a list of Connections . These connections refer to open metadata archive connectors that can read and retrieve the open metadata archive content. POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/open-metadata-archives/connection { connection } This option can be used when the open metadata archives are not stored in a file, or a different file format from the default JSON is required.","title":"Adding archive to running server"},{"location":"guides/operations/adding-archive-to-running-server/#adding-an-archive-to-a-running-omag-server","text":"Open Metadata Archives contain pre-canned metadata types and instances for Cohort Members . Archives can be added to the configuration document of a server to ensure their content is loaded each time the server is started. This is intended for repositories that do not store the archive content but keep it in memory. Although, if an archive is loaded multiple times, its content is only added to the local repository if the repository does not have the content already. Archives can also be loaded to a running server using the following commands. Typically open metadata archives are stored as files. If the archive is stored as JSON in a file, it can be loaded into a running server as follows. The file should be specified either as a fully qualified path name or as a path name relative to the start up directory of the OMAG Server Platform. Note the file name should not have any quotes around its name. POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/open-metadata-archives/file { path name of file } Alternatively it is possible to set up the list of open metadata archives as a list of Connections . These connections refer to open metadata archive connectors that can read and retrieve the open metadata archive content. POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/open-metadata-archives/connection { connection } This option can be used when the open metadata archives are not stored in a file, or a different file format from the default JSON is required.","title":"Adding an archive to a running OMAG Server"},{"location":"guides/operations/operating-omag-server/","text":"Operating an OMAG Server \u00b6 Once an OMAG Server is configured it can be started and stopped multiple times. Starting and stopping an OMAG Server It is possible to load an OpenMetadata Archive into running OMAG Servers that are of type Cohort Member . Adding an Open Metadata Archive to a running server In addition there are different platform services that can be used to find out more about the operation of the servers. Querying the servers and services running in an OMAG Server Platform Egeria also has an interactive graph-based user interface (UI) that enables you to explore the open metadata ecosystem. This includes the OMAG Server Platforms and Servers, the types of metadata supported by each metadata repository and the contents of the metadata repositories. It is also possible to maintain the configuration of the OMAG Servers through this UI. Using the ecosystem user interface","title":"Operating omag server"},{"location":"guides/operations/operating-omag-server/#operating-an-omag-server","text":"Once an OMAG Server is configured it can be started and stopped multiple times. Starting and stopping an OMAG Server It is possible to load an OpenMetadata Archive into running OMAG Servers that are of type Cohort Member . Adding an Open Metadata Archive to a running server In addition there are different platform services that can be used to find out more about the operation of the servers. Querying the servers and services running in an OMAG Server Platform Egeria also has an interactive graph-based user interface (UI) that enables you to explore the open metadata ecosystem. This includes the OMAG Server Platforms and Servers, the types of metadata supported by each metadata repository and the contents of the metadata repositories. It is also possible to maintain the configuration of the OMAG Servers through this UI. Using the ecosystem user interface","title":"Operating an OMAG Server"},{"location":"guides/operations/querying-server-and-services/","text":"Adding an archive to a running OMAG Server \u00b6 Open Metadata Archives contain pre-canned metadata types and instances for Cohort Members . Archives can be added to the configuration document of a server to ensure their content is loaded each time the server is started. This is intended for repositories that do not store the archive content but keep it in memory. Although, if an archive is loaded multiple times, its content is only added to the local repository if the repository does not have the content already. Archives can also be loaded to a running server using the following commands. Typically open metadata archives are stored as files. If the archive is stored as JSON in a file, it can be loaded into a running server as follows. The file should be specified either as a fully qualified path name or as a path name relative to the start up directory of the OMAG Server Platform. Note the file name should not have any quotes around its name. POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/open-metadata-archives/file { path name of file } Alternatively it is possible to set up the list of open metadata archives as a list of Connections . These connections refer to open metadata archive connectors that can read and retrieve the open metadata archive content. POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/open-metadata-archives/connection { connection } This option can be used when the open metadata archives are not stored in a file, or a different file format from the default JSON is required.","title":"Querying server and services"},{"location":"guides/operations/querying-server-and-services/#adding-an-archive-to-a-running-omag-server","text":"Open Metadata Archives contain pre-canned metadata types and instances for Cohort Members . Archives can be added to the configuration document of a server to ensure their content is loaded each time the server is started. This is intended for repositories that do not store the archive content but keep it in memory. Although, if an archive is loaded multiple times, its content is only added to the local repository if the repository does not have the content already. Archives can also be loaded to a running server using the following commands. Typically open metadata archives are stored as files. If the archive is stored as JSON in a file, it can be loaded into a running server as follows. The file should be specified either as a fully qualified path name or as a path name relative to the start up directory of the OMAG Server Platform. Note the file name should not have any quotes around its name. POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/open-metadata-archives/file { path name of file } Alternatively it is possible to set up the list of open metadata archives as a list of Connections . These connections refer to open metadata archive connectors that can read and retrieve the open metadata archive content. POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/open-metadata-archives/connection { connection } This option can be used when the open metadata archives are not stored in a file, or a different file format from the default JSON is required.","title":"Adding an archive to a running OMAG Server"},{"location":"guides/operations/starting-and-stopping-omag-server/","text":"Starting and Stopping the OMAG server \u00b6 Once a configuration document has been completed for an OMAG Server , it can be started using the following REST call: POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance and stopped, as follows: DELETE {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance The configuration document is not changed by these calls. It is possible to query the running server's configuration using the following REST API: GET {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/configuration If you want to delete the server's configuration document then issue: DELETE {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName} If the OMAG server is running, this command also unregisters the named server from the cohorts it is connected to. Only use this command if the server is being permanently removed.","title":"Starting and stopping omag server"},{"location":"guides/operations/starting-and-stopping-omag-server/#starting-and-stopping-the-omag-server","text":"Once a configuration document has been completed for an OMAG Server , it can be started using the following REST call: POST {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance and stopped, as follows: DELETE {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance The configuration document is not changed by these calls. It is possible to query the running server's configuration using the following REST API: GET {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName}/instance/configuration If you want to delete the server's configuration document then issue: DELETE {platformURLRoot}/open-metadata/admin-services/users/{adminUserId}/servers/{serverName} If the OMAG server is running, this command also unregisters the named server from the cohorts it is connected to. Only use this command if the server is being permanently removed.","title":"Starting and Stopping the OMAG server"},{"location":"guides/planning/guide/","text":"Planning Guide \u00b6 The planning guide provides information to help you plan the deployment of Egeria in your organization. Egeria is highly flexible and configurable and so the first piece of advice is to start small and simple and then expand as your experience and understanding of your workloads grows. Platforms and servers \u00b6 Egeria exchanges metadata between many types of tools distributed across different data centers and cloud platforms. The green clouds represent each of the deployment locations. The different technologies are shown as grey boxes and Egeria itself is shown in blue and orange. The blue rounded boxes are Egeria's Open Metadata and Governance ( OMAG ) Server Platform . This platform is the heart of Egeria's implementation. Typically you would expect to have at least one OMAG Server Platform deployed in each location. However, when you are experimenting with Egeria, it is often sufficient to start with one OMAG Server Platform and expand the number of platforms as you expand the technologies being integrated. The OMAG Server Platform is capable of hosting one or more Open Metadata and Governance ( OMAG ) Servers . The OMAG Servers are the orange circles in the illustration above. They manage the connectors to third party technology as well as the frameworks and intelligence that Egeria brings to distributed metadata management. It is a simple command to move an OMAG Server from one platform instance to another. This means you can start experimenting with a single platform and then add more as your deployment grows. The platform can also run as a node in container technologies such as Docker and Kubernetes. Different types of technology need different types of integration and Egeria has OMAG Servers to match. Each type of OMAG Server is focused on the integration of a specific type of tool, engine or platform: The way to understand the diagram is that the arrows should be read as is a . For example, the repository proxy is a cohort member and the cohort member is a OMAG Server . This means that everything documented about a particular type of server is also true for all server types that point to it through the is a arrow, all the way down the hierarchy. Object-oriented software engineers would know of this type of relationship as behavior inheritance . OMAG Server interactions \u00b6 The cohort members communicate with one another via an open metadata repository cohort . This means that they exchange metadata through a low level, fine-grained API supported by the Open Metadata Repository Services ( OMRS ) . The Open Metadata Access Services ( OMAS ) are built on top of the repository services. They live in the metadata access point / metadata servers . They offer more course-grained interfaces, specialized for particular types of technology. The governance servers are again specialized for particular types of metadata integration or additional governance activity. They connect to a metadata access point / metadata server. Finally, the view servers support the services for the solution user interfaces. They also connect to a metadata access point / metadata server. Suggested incremental deployment approach \u00b6 The servers' integration can be viewed as a series of nested spheres. The inner sphere involves the cohort members and provides metadata exchange between metadata repositories (and conformance test the integrations). The next level out adds the governance servers to automate the exchange of metadata between the metadata repositories and third party tools, engines and platforms. Finally, adding the view server and user interfaces delivers a governance solution to an organization. This architecture means that you can incrementally add function to your deployment. Here is a suggested approach: Start with creating an Egeria graph metadata server . This will provide a metadata repository that can store any type of open metadata. Decide on a name for an open metadata repository cohort and configure your graph metadata repository to join it. If you want to have other third party metadata repositories that you want to share metadata with, configure repository proxies for each including registering them to the same cohort as the metadata server. If you then want to add in metadata synchronization with other types of technology beyond metadata repositories, work out which integration daemons you need and configure them to connect to the metadata server . Make sure the appropriate access services for these integration daemons are enabled in the metadata server. If you want to use the discovery or governance action services then these run in an engine host server and connect to the metadata server via the Discovery Engine OMAS and Governance Engine OMAS respectively. Finally, if you want to deploy the user interfaces, make sure you have at least one view server for the presentation server that hosts the UI application. Working through this exercise gives you an understanding of the Egeria technology that you need for your deployment and how it connects together. The Solutions Guide describes different solutions that you can build with Egeria, how they work and the configuration that you will need. Building connectors \u00b6 If you discover that there is a third party technology that is not currently supported by Egeria then you need to build a connector to translate between the APIs and events of that technology and the open metadata APIs and events. Identify the scope of the metadata integration \u00b6 Another useful planning exercise is to identify the community of users and the tools that they use that need to share metadata. This gives you a view of the technology that needs to be integrated. If each community is fairly self-contained with their own tools deployment then you may want to consider deploying an OMAG Server platform for this community and deploying the servers they need onto it. This means they can control their access to open metadata along with the delivery of open metadata to the rest of the organization. More importantly, it helps with the definition of the organization's governance zones . Deployment checklist \u00b6 This is a checklist of planning tasks for the deployment of your OMAG Server Platforms and OMAG Servers: Set up unique certificates for your OMAG Server Platforms. Use an encrypted configuration document store for your platforms since configuration documents can have certificates and passwords in them. Implement the metadata security connectors for your organization to ensure only authorized users access metadata. Choose and configure the audit log destinations for your OMAG Servers. Ensure you have at least one Egeria metadata server in each of your open metadata repository cohorts . Assign a separate user id for each of your servers and ensure they are defined in your user directory and are authorized users according to the metadata security connectors. Consider where you need to have multiple instances of the same server running to give continuous availability . Plan your use of the event bus : which technology to use (Apache Kafka is the default) and the names of the topics that your OMAG Servers will use. Design the governance zones that you want to use to control the visibility of assets to different communities of users - or processes. More detail to follow... \u00b6 The text above is a very high level overview of the planning process. More detail will be added to this guide as time permits.","title":"Planning Guide"},{"location":"guides/planning/guide/#planning-guide","text":"The planning guide provides information to help you plan the deployment of Egeria in your organization. Egeria is highly flexible and configurable and so the first piece of advice is to start small and simple and then expand as your experience and understanding of your workloads grows.","title":"Planning Guide"},{"location":"guides/planning/guide/#platforms-and-servers","text":"Egeria exchanges metadata between many types of tools distributed across different data centers and cloud platforms. The green clouds represent each of the deployment locations. The different technologies are shown as grey boxes and Egeria itself is shown in blue and orange. The blue rounded boxes are Egeria's Open Metadata and Governance ( OMAG ) Server Platform . This platform is the heart of Egeria's implementation. Typically you would expect to have at least one OMAG Server Platform deployed in each location. However, when you are experimenting with Egeria, it is often sufficient to start with one OMAG Server Platform and expand the number of platforms as you expand the technologies being integrated. The OMAG Server Platform is capable of hosting one or more Open Metadata and Governance ( OMAG ) Servers . The OMAG Servers are the orange circles in the illustration above. They manage the connectors to third party technology as well as the frameworks and intelligence that Egeria brings to distributed metadata management. It is a simple command to move an OMAG Server from one platform instance to another. This means you can start experimenting with a single platform and then add more as your deployment grows. The platform can also run as a node in container technologies such as Docker and Kubernetes. Different types of technology need different types of integration and Egeria has OMAG Servers to match. Each type of OMAG Server is focused on the integration of a specific type of tool, engine or platform: The way to understand the diagram is that the arrows should be read as is a . For example, the repository proxy is a cohort member and the cohort member is a OMAG Server . This means that everything documented about a particular type of server is also true for all server types that point to it through the is a arrow, all the way down the hierarchy. Object-oriented software engineers would know of this type of relationship as behavior inheritance .","title":"Platforms and servers"},{"location":"guides/planning/guide/#omag-server-interactions","text":"The cohort members communicate with one another via an open metadata repository cohort . This means that they exchange metadata through a low level, fine-grained API supported by the Open Metadata Repository Services ( OMRS ) . The Open Metadata Access Services ( OMAS ) are built on top of the repository services. They live in the metadata access point / metadata servers . They offer more course-grained interfaces, specialized for particular types of technology. The governance servers are again specialized for particular types of metadata integration or additional governance activity. They connect to a metadata access point / metadata server. Finally, the view servers support the services for the solution user interfaces. They also connect to a metadata access point / metadata server.","title":"OMAG Server interactions"},{"location":"guides/planning/guide/#suggested-incremental-deployment-approach","text":"The servers' integration can be viewed as a series of nested spheres. The inner sphere involves the cohort members and provides metadata exchange between metadata repositories (and conformance test the integrations). The next level out adds the governance servers to automate the exchange of metadata between the metadata repositories and third party tools, engines and platforms. Finally, adding the view server and user interfaces delivers a governance solution to an organization. This architecture means that you can incrementally add function to your deployment. Here is a suggested approach: Start with creating an Egeria graph metadata server . This will provide a metadata repository that can store any type of open metadata. Decide on a name for an open metadata repository cohort and configure your graph metadata repository to join it. If you want to have other third party metadata repositories that you want to share metadata with, configure repository proxies for each including registering them to the same cohort as the metadata server. If you then want to add in metadata synchronization with other types of technology beyond metadata repositories, work out which integration daemons you need and configure them to connect to the metadata server . Make sure the appropriate access services for these integration daemons are enabled in the metadata server. If you want to use the discovery or governance action services then these run in an engine host server and connect to the metadata server via the Discovery Engine OMAS and Governance Engine OMAS respectively. Finally, if you want to deploy the user interfaces, make sure you have at least one view server for the presentation server that hosts the UI application. Working through this exercise gives you an understanding of the Egeria technology that you need for your deployment and how it connects together. The Solutions Guide describes different solutions that you can build with Egeria, how they work and the configuration that you will need.","title":"Suggested incremental deployment approach"},{"location":"guides/planning/guide/#building-connectors","text":"If you discover that there is a third party technology that is not currently supported by Egeria then you need to build a connector to translate between the APIs and events of that technology and the open metadata APIs and events.","title":"Building connectors"},{"location":"guides/planning/guide/#identify-the-scope-of-the-metadata-integration","text":"Another useful planning exercise is to identify the community of users and the tools that they use that need to share metadata. This gives you a view of the technology that needs to be integrated. If each community is fairly self-contained with their own tools deployment then you may want to consider deploying an OMAG Server platform for this community and deploying the servers they need onto it. This means they can control their access to open metadata along with the delivery of open metadata to the rest of the organization. More importantly, it helps with the definition of the organization's governance zones .","title":"Identify the scope of the metadata integration"},{"location":"guides/planning/guide/#deployment-checklist","text":"This is a checklist of planning tasks for the deployment of your OMAG Server Platforms and OMAG Servers: Set up unique certificates for your OMAG Server Platforms. Use an encrypted configuration document store for your platforms since configuration documents can have certificates and passwords in them. Implement the metadata security connectors for your organization to ensure only authorized users access metadata. Choose and configure the audit log destinations for your OMAG Servers. Ensure you have at least one Egeria metadata server in each of your open metadata repository cohorts . Assign a separate user id for each of your servers and ensure they are defined in your user directory and are authorized users according to the metadata security connectors. Consider where you need to have multiple instances of the same server running to give continuous availability . Plan your use of the event bus : which technology to use (Apache Kafka is the default) and the names of the topics that your OMAG Servers will use. Design the governance zones that you want to use to control the visibility of assets to different communities of users - or processes.","title":"Deployment checklist"},{"location":"guides/planning/guide/#more-detail-to-follow","text":"The text above is a very high level overview of the planning process. More detail will be added to this guide as time permits.","title":"More detail to follow..."},{"location":"introduction/challenge/","text":"The challenge \u00b6 Every week we hear of new tools, data platforms and opportunities for organizations to embrace advanced digital technologies such as artificial intelligence. Yet despite investment and the focus of smart people, few organizations succeed in making wide and systematic use of their data. Today's IT is at the heart of the problem. Many tools and data platforms recognize the value of metadata, but manage it in a siloed, proprietary way that assumes they are the only technology employed by the organization. The result is that knowledge is not shared between people that use different tool sets. Egeria is an open source project dedicated to making metadata open and automatically exchanged between tools and platforms, no matter which vendor they come from. Open metadata and governance manifesto \u00b6 Our guiding beliefs: The maintenance of metadata must be automated to scale to the sheer volumes and variety of data involved in modern business. Similarly, metadata should be used to drive the governance of data and create a business-friendly logical interface to the data landscape. The availability of metadata management must become ubiquitous in cloud platforms and large data platforms, such as Apache Hadoop, so that the processing engines on these platforms can rely on its availability and build capability around it. Metadata access must become open and remotely accessible so that tools from different vendors can work with metadata located on different platforms. This implies unique identifiers for metadata elements, some level of standardization in the types and formats for metadata and standard interfaces for manipulating metadata. Wherever possible, discovery and maintenance of metadata has to be an integral part of all tools that access, change and move information. Code talks Egeria provides an Apache 2.0 licensed platform to support vendors that sign up to the open metadata and governance manifesto.","title":"The Challenge"},{"location":"introduction/challenge/#the-challenge","text":"Every week we hear of new tools, data platforms and opportunities for organizations to embrace advanced digital technologies such as artificial intelligence. Yet despite investment and the focus of smart people, few organizations succeed in making wide and systematic use of their data. Today's IT is at the heart of the problem. Many tools and data platforms recognize the value of metadata, but manage it in a siloed, proprietary way that assumes they are the only technology employed by the organization. The result is that knowledge is not shared between people that use different tool sets. Egeria is an open source project dedicated to making metadata open and automatically exchanged between tools and platforms, no matter which vendor they come from.","title":"The challenge"},{"location":"introduction/challenge/#open-metadata-and-governance-manifesto","text":"Our guiding beliefs: The maintenance of metadata must be automated to scale to the sheer volumes and variety of data involved in modern business. Similarly, metadata should be used to drive the governance of data and create a business-friendly logical interface to the data landscape. The availability of metadata management must become ubiquitous in cloud platforms and large data platforms, such as Apache Hadoop, so that the processing engines on these platforms can rely on its availability and build capability around it. Metadata access must become open and remotely accessible so that tools from different vendors can work with metadata located on different platforms. This implies unique identifiers for metadata elements, some level of standardization in the types and formats for metadata and standard interfaces for manipulating metadata. Wherever possible, discovery and maintenance of metadata has to be an integral part of all tools that access, change and move information. Code talks Egeria provides an Apache 2.0 licensed platform to support vendors that sign up to the open metadata and governance manifesto.","title":"Open metadata and governance manifesto"},{"location":"introduction/key-concepts/","text":"Key concepts \u00b6 To further explain some key concepts of Egeria, let us delve deeper into an example. In figure 1, the inner ring, titled Integrated Metadata , illustrates the exchange of metadata between metadata servers. The servers are connected together through an Open Metadata Repository Cohort or just cohort for short. Figure 1: Different types of OMAG servers connected together in a solution. They are organized into three rings. The inner-ring comprising of the metadata access server, repository proxy and conformance test server are cohort members communicating via Egeria's peer-to-peer protocols. In the next ring out are the governance servers connected to the metadata access server and in the outer ring are the view server and presentation server also connected to the metadata access server Cohorts \u00b6 A cohort 1 can support the exchange of many metadata servers: both internal to Egeria and third party. A cohort is a group of servers that are exchanging metadata using a peer-to-peer replication protocol and federated queries. The cohort is self-configuring. At the core it is between one and four shared topics. Each server publishes a registration request on the appropriate topic when they want to join. This is picked up by the existing members who add this new server to their registry of members and re-send their registration through the same topic to allow the new member to build up its own registry of cohort members. There is no central cohort controller Note that there is no central cohort control or coordination logic: the registration and so on are all handled in a peer-to-peer manner with each participant communicating with all other participants. The cohort operations feature describes the protocol in more detail. When a server permanently leaves the cohort, it sends an unregistration request. This enables the other members to remove the parting member from their registries. Federation \u00b6 The purpose of the registry in each member is to configure its federated query capability. The registration information includes the URL root and server name of the member. The federation capability in each OMAG Server allows it to issue metadata create, update, delete and search requests to each and every member of the cohort. This is the primary mechanism for accessing metadata. Replication \u00b6 In addition, any change to metadata made by a member is replicated to the other members of the cohort through the relevant cohort topic. This gives the other members an opportunity to maintain cached copies of the metadata for performance / availability reasons. Refresh requests A member may also request that metadata is \"refreshed\" across the cohort. The originator of the requested metadata then sends the latest version of this metadata to the rest of the cohort through the cohort topic. This mechanism is useful to seed the cache in a new member of the cohort and is invoked as a result of a federated query issued from the new member. (A federated query occurs automatically whenever an access service makes a request for metadata.) Exchange protocol \u00b6 The exchange of metadata uses the cohort events to give fine-grained metadata notifications and updates 2 . The server's metadata security connector provides fine-grained control on which metadata is sent, received and/or stored by the server. This level of control is necessary for metadata repositories that are managing specific collections of valuable objects such as assets . Members \u00b6 A third party metadata server can embed the Egeria libraries in its own runtime or, more commonly, use a special OMAG Server called the repository proxy to host connectors that map between the events and APIs of the third party metadata server and the Open Metadata events and APIs. The repository proxy manages all the interaction with the other members of the cohort. The cohort protocols are peer-to-peer and the membership is dynamic. When a third party metadata server connects to the cohort, either directly or through its repository proxy, it automatically begins receiving metadata from all the other members. When it shares metadata, it is shared with all the other members. Each member is free to choose what to share and what to process from the other members of the cohort. Other types of OMAG Servers that can be members of the cohort: The metadata access server supports Egeria's Open Metadata Access Services ( OMAS ) , or access services, for short. These access services provide specialized APIs and events for different types of technologies. The metadata access server optionally provides a native metadata repository that supports any type of open metadata. It is a valuable member of the cohort because it is a metadata gap-filler. By that we mean that is can store relationships between metadata from different third party repositories along with additional types of metadata not supported by any of the third party metadata repositories. It may optionally have the access services enabled so it can also act as a metadata access point. The conformance test server is used to verify that a member of the cohort is operating correctly. It is typically only used in test environments because it sends out a lot of test metadata on the cohort and validates the responses from the cohort member it is testing. Integrating metadata into solutions \u00b6 The metadata access server is the bridge to the governance servers (the middle ring in Figure 1). The governance servers provide active metadata exchange and governance of any type of third party technology, not just metadata servers. We call this integrated governance . For the most part, Egeria is a background technology. However, once metadata is being exchanged and linked, new governance solutions may emerge that bring value directly to individuals working in an organization. Therefore, we have added servers to support browser-based user interfaces: The view server provides REST APIs specifically for user interfaces. They are consumed by the Egeria UIs but can also be used by other UIs and tools. The presentation server hosts the JavaScript applications that provide an interactive browser-based user interface for Egeria. Metadata objects \u00b6 When referring to metadata, we distinguish between the level of granularity at which you may be thinking about that metadata. For Egeria, that level of granularity broadly splits between: The granular repository services level, used for the cohort's underlying metadata federation, replication and exchange. The more coarse-grained access services level, where most tool- and user-oriented consumption of and integration with metadata would occur. Metadata elements \u00b6 At the more coarse-grained level of the access services metadata objects are simply referred to as metadata elements . Each access service describes its own model for the metadata elements it handles, and the access service itself determines how these coarse-grained representations are transformed to and from the more granular representations described below. Metadata instances \u00b6 At the granular level of the repository services, we refer to specific metadata objects as metadata instances , which can only be one of the following: An entity is capable of describing a metadata object on its own: for example, a business vocabulary term, database, field in a schema, and so on. If you think about metadata as a graph, these are the nodes (vertices) in the graph. They typically describe concepts, people, places and things. A relationship describes a (typically) directional association between two entities: for example, the semantic meaning of a relational database column by relating a business vocabulary term with the relational database column. In a graph sense, these are the links (edges) that show how entities are related. While not strictly speaking a kind of metadata instance, a classification provides a means to extend an entity with additional facets of information: for example, describing the level of confidentiality with which a particular relational database column should be treated. Classifications describe additional attributes of an entity and can be used to identify entities that are similar in a specific aspect. Metadata types \u00b6 Every metadata instance is linked to an open metadata type definition (sometimes referred to as a TypeDef ) that describes what it represents and the properties that further describe and differentiate it from other instances of that same type. TypeDef inheritance TypeDefs can inherit from other TypeDefs from the same category: open metadata supports single inheritance. An example: GlossaryTerm, RelationalColumn and SemanticAssignment For example, GlossaryTerm is a type of entity that can be used to describe a specific term of business vocabulary. As a type of entity, GlossaryTerm is defined using an EntityDef (a subtype of TypeDef specific to entities). It has a number of properties like a displayName , itself defined as a PrimitiveDef of type string. And GlossaryTerm as a type extends a base entity type called Referenceable which defines common characteristics that many entities possess such as a qualifiedName (another PrimitiveDef of type string). RelationalColumn is another example of an entity, in this case one that can be used to describe relational database columns. Once again it is defined using an EntityDef , has a number of properties, and also extends the base type called Referenceable and therefore also gains common properties like the qualifiedName . Finally, let's consider a different type: SemanticAssignment is a type of relationship that can be used to describe the meaning of something. Because it is a type of relationship, it is defined using a RelationshipDef (another subtype of EntityDef , this time specific to relationships). As a relationship, the RelationshipDef defines the entities that it can inter-relate: in this example a GlossaryTerm and any other Referenceable (for example, a RelationalColumn ). Where are the types modeled? The TypeDef s themselves are described in detail under the types reference area, and the canonical definitions ultimately live in the code itself . Homed metadata \u00b6 The metadata repository where a metadata instance is created is called its home repository . Metadata in its home repository is mutable : it can be updated and deleted. Each instance of metadata can be independently homed Note that each instance of metadata -- whether an entity, relationship or classification -- can be homed independently from any other instance of metadata. For example: if we have a business vocabulary term Address that is related to a relational database column ADDR and given a Confidentiality classification, each of these could be homed in a different repository. That is, Address (entity) could be homed in repository A, ADDR (another entity) in repository B, the relationship between them in repository C, and the Confidentiality classification in repository D. As such, not only can a query for metadata be federated, but indeed even the holistic representation of a given piece of metadata (its instance and directly-related instances) is federated across the cohort. The Open Metadata Repository Services ( OMRS ) is responsible for sharing this metadata with other metadata repositories who are members of the same cohort. Reference copies \u00b6 The shared copies are called reference copies and are read-only ( immutable ). Update requests to a reference copy are automatically redirected to the home repository by the OMRS , without the caller being aware. Distinguishing homed metadata from reference copies Every metadata repository in a cohort has a unique identifier called the local metadata collection id . This identifier is set up in the server configuration and shared when this server connects to a cohort. When metadata is shared by OMRS , each instance is tagged with the metadata collection id of its home repository. OMRS is able to route update requests to the right server by comparing the metadata collection id in the metadata instance with the cohort registration information passed between members of the cohort when they connect. Unique identifiers (GUIDs) \u00b6 Every open metadata instance has a unique identifier called the GUID . GUIDs must be unique This identifier needs to be globally unique -- so even if two metadata repositories simultaneously created a metadata instance about the same thing, the GUIDs of these two instances should be different. For example, in Egeria new GUIDs are created using the UUID.randomUUID().toString() method to produce something like: 87b06ffe-9db2-4ef5-ba6e-8127480cf30d Egeria does not mandate the use this or any other particular algorithm for generating GUIDs, only that the principle of uniqueness is adhered to. There should be, at most, a tiny chance 3 that two servers will generate the same GUID . Egeria expects this to be exceedingly rare, but not impossible, and therefore if it does happen it is detected by the repository services and at a minimum messages are output on the detecting server's audit log. The repository services also have APIs for re-identifying (changing the GUID ) for a metadata instance to automate the resolution of such conflicts. We can expect that such an operation could be resource-intensive; however, this is balanced against the exceeding rareness with which it should need to be used. Conformance \u00b6 Adhering to these concepts and the principles by which they behave is the subject of conformance . Egeria provides an automated testing suite to validate that a given repository or third party integration behaves according to these expectations , the successful completion of which is a necessary input to a tool being granted the use of an Egeria conformance mark. You may want to see the cohort interactions walkthrough for more details on how cohort participants interact. \u21a9 You may want to see the OMRS metamodel for more details on the granularity of metadata exchange. \u21a9 The rarity will depend on the specific algorithm used, but as an example the algorithm used within Egeria generates type 4 UUIDs, for which the probability of a collision is so small that it can almost be ignored . But as it is not impossible , Egeria does still provide the mechanisms to detect and resolve such conflicts. \u21a9","title":"Key Concepts"},{"location":"introduction/key-concepts/#key-concepts","text":"To further explain some key concepts of Egeria, let us delve deeper into an example. In figure 1, the inner ring, titled Integrated Metadata , illustrates the exchange of metadata between metadata servers. The servers are connected together through an Open Metadata Repository Cohort or just cohort for short. Figure 1: Different types of OMAG servers connected together in a solution. They are organized into three rings. The inner-ring comprising of the metadata access server, repository proxy and conformance test server are cohort members communicating via Egeria's peer-to-peer protocols. In the next ring out are the governance servers connected to the metadata access server and in the outer ring are the view server and presentation server also connected to the metadata access server","title":"Key concepts"},{"location":"introduction/key-concepts/#cohorts","text":"A cohort 1 can support the exchange of many metadata servers: both internal to Egeria and third party. A cohort is a group of servers that are exchanging metadata using a peer-to-peer replication protocol and federated queries. The cohort is self-configuring. At the core it is between one and four shared topics. Each server publishes a registration request on the appropriate topic when they want to join. This is picked up by the existing members who add this new server to their registry of members and re-send their registration through the same topic to allow the new member to build up its own registry of cohort members. There is no central cohort controller Note that there is no central cohort control or coordination logic: the registration and so on are all handled in a peer-to-peer manner with each participant communicating with all other participants. The cohort operations feature describes the protocol in more detail. When a server permanently leaves the cohort, it sends an unregistration request. This enables the other members to remove the parting member from their registries.","title":"Cohorts"},{"location":"introduction/key-concepts/#federation","text":"The purpose of the registry in each member is to configure its federated query capability. The registration information includes the URL root and server name of the member. The federation capability in each OMAG Server allows it to issue metadata create, update, delete and search requests to each and every member of the cohort. This is the primary mechanism for accessing metadata.","title":"Federation"},{"location":"introduction/key-concepts/#replication","text":"In addition, any change to metadata made by a member is replicated to the other members of the cohort through the relevant cohort topic. This gives the other members an opportunity to maintain cached copies of the metadata for performance / availability reasons. Refresh requests A member may also request that metadata is \"refreshed\" across the cohort. The originator of the requested metadata then sends the latest version of this metadata to the rest of the cohort through the cohort topic. This mechanism is useful to seed the cache in a new member of the cohort and is invoked as a result of a federated query issued from the new member. (A federated query occurs automatically whenever an access service makes a request for metadata.)","title":"Replication"},{"location":"introduction/key-concepts/#exchange-protocol","text":"The exchange of metadata uses the cohort events to give fine-grained metadata notifications and updates 2 . The server's metadata security connector provides fine-grained control on which metadata is sent, received and/or stored by the server. This level of control is necessary for metadata repositories that are managing specific collections of valuable objects such as assets .","title":"Exchange protocol"},{"location":"introduction/key-concepts/#members","text":"A third party metadata server can embed the Egeria libraries in its own runtime or, more commonly, use a special OMAG Server called the repository proxy to host connectors that map between the events and APIs of the third party metadata server and the Open Metadata events and APIs. The repository proxy manages all the interaction with the other members of the cohort. The cohort protocols are peer-to-peer and the membership is dynamic. When a third party metadata server connects to the cohort, either directly or through its repository proxy, it automatically begins receiving metadata from all the other members. When it shares metadata, it is shared with all the other members. Each member is free to choose what to share and what to process from the other members of the cohort. Other types of OMAG Servers that can be members of the cohort: The metadata access server supports Egeria's Open Metadata Access Services ( OMAS ) , or access services, for short. These access services provide specialized APIs and events for different types of technologies. The metadata access server optionally provides a native metadata repository that supports any type of open metadata. It is a valuable member of the cohort because it is a metadata gap-filler. By that we mean that is can store relationships between metadata from different third party repositories along with additional types of metadata not supported by any of the third party metadata repositories. It may optionally have the access services enabled so it can also act as a metadata access point. The conformance test server is used to verify that a member of the cohort is operating correctly. It is typically only used in test environments because it sends out a lot of test metadata on the cohort and validates the responses from the cohort member it is testing.","title":"Members"},{"location":"introduction/key-concepts/#integrating-metadata-into-solutions","text":"The metadata access server is the bridge to the governance servers (the middle ring in Figure 1). The governance servers provide active metadata exchange and governance of any type of third party technology, not just metadata servers. We call this integrated governance . For the most part, Egeria is a background technology. However, once metadata is being exchanged and linked, new governance solutions may emerge that bring value directly to individuals working in an organization. Therefore, we have added servers to support browser-based user interfaces: The view server provides REST APIs specifically for user interfaces. They are consumed by the Egeria UIs but can also be used by other UIs and tools. The presentation server hosts the JavaScript applications that provide an interactive browser-based user interface for Egeria.","title":"Integrating metadata into solutions"},{"location":"introduction/key-concepts/#metadata-objects","text":"When referring to metadata, we distinguish between the level of granularity at which you may be thinking about that metadata. For Egeria, that level of granularity broadly splits between: The granular repository services level, used for the cohort's underlying metadata federation, replication and exchange. The more coarse-grained access services level, where most tool- and user-oriented consumption of and integration with metadata would occur.","title":"Metadata objects"},{"location":"introduction/key-concepts/#metadata-elements","text":"At the more coarse-grained level of the access services metadata objects are simply referred to as metadata elements . Each access service describes its own model for the metadata elements it handles, and the access service itself determines how these coarse-grained representations are transformed to and from the more granular representations described below.","title":"Metadata elements"},{"location":"introduction/key-concepts/#metadata-instances","text":"At the granular level of the repository services, we refer to specific metadata objects as metadata instances , which can only be one of the following: An entity is capable of describing a metadata object on its own: for example, a business vocabulary term, database, field in a schema, and so on. If you think about metadata as a graph, these are the nodes (vertices) in the graph. They typically describe concepts, people, places and things. A relationship describes a (typically) directional association between two entities: for example, the semantic meaning of a relational database column by relating a business vocabulary term with the relational database column. In a graph sense, these are the links (edges) that show how entities are related. While not strictly speaking a kind of metadata instance, a classification provides a means to extend an entity with additional facets of information: for example, describing the level of confidentiality with which a particular relational database column should be treated. Classifications describe additional attributes of an entity and can be used to identify entities that are similar in a specific aspect.","title":"Metadata instances"},{"location":"introduction/key-concepts/#metadata-types","text":"Every metadata instance is linked to an open metadata type definition (sometimes referred to as a TypeDef ) that describes what it represents and the properties that further describe and differentiate it from other instances of that same type. TypeDef inheritance TypeDefs can inherit from other TypeDefs from the same category: open metadata supports single inheritance. An example: GlossaryTerm, RelationalColumn and SemanticAssignment For example, GlossaryTerm is a type of entity that can be used to describe a specific term of business vocabulary. As a type of entity, GlossaryTerm is defined using an EntityDef (a subtype of TypeDef specific to entities). It has a number of properties like a displayName , itself defined as a PrimitiveDef of type string. And GlossaryTerm as a type extends a base entity type called Referenceable which defines common characteristics that many entities possess such as a qualifiedName (another PrimitiveDef of type string). RelationalColumn is another example of an entity, in this case one that can be used to describe relational database columns. Once again it is defined using an EntityDef , has a number of properties, and also extends the base type called Referenceable and therefore also gains common properties like the qualifiedName . Finally, let's consider a different type: SemanticAssignment is a type of relationship that can be used to describe the meaning of something. Because it is a type of relationship, it is defined using a RelationshipDef (another subtype of EntityDef , this time specific to relationships). As a relationship, the RelationshipDef defines the entities that it can inter-relate: in this example a GlossaryTerm and any other Referenceable (for example, a RelationalColumn ). Where are the types modeled? The TypeDef s themselves are described in detail under the types reference area, and the canonical definitions ultimately live in the code itself .","title":"Metadata types"},{"location":"introduction/key-concepts/#homed-metadata","text":"The metadata repository where a metadata instance is created is called its home repository . Metadata in its home repository is mutable : it can be updated and deleted. Each instance of metadata can be independently homed Note that each instance of metadata -- whether an entity, relationship or classification -- can be homed independently from any other instance of metadata. For example: if we have a business vocabulary term Address that is related to a relational database column ADDR and given a Confidentiality classification, each of these could be homed in a different repository. That is, Address (entity) could be homed in repository A, ADDR (another entity) in repository B, the relationship between them in repository C, and the Confidentiality classification in repository D. As such, not only can a query for metadata be federated, but indeed even the holistic representation of a given piece of metadata (its instance and directly-related instances) is federated across the cohort. The Open Metadata Repository Services ( OMRS ) is responsible for sharing this metadata with other metadata repositories who are members of the same cohort.","title":"Homed metadata"},{"location":"introduction/key-concepts/#reference-copies","text":"The shared copies are called reference copies and are read-only ( immutable ). Update requests to a reference copy are automatically redirected to the home repository by the OMRS , without the caller being aware. Distinguishing homed metadata from reference copies Every metadata repository in a cohort has a unique identifier called the local metadata collection id . This identifier is set up in the server configuration and shared when this server connects to a cohort. When metadata is shared by OMRS , each instance is tagged with the metadata collection id of its home repository. OMRS is able to route update requests to the right server by comparing the metadata collection id in the metadata instance with the cohort registration information passed between members of the cohort when they connect.","title":"Reference copies"},{"location":"introduction/key-concepts/#unique-identifiers-guids","text":"Every open metadata instance has a unique identifier called the GUID . GUIDs must be unique This identifier needs to be globally unique -- so even if two metadata repositories simultaneously created a metadata instance about the same thing, the GUIDs of these two instances should be different. For example, in Egeria new GUIDs are created using the UUID.randomUUID().toString() method to produce something like: 87b06ffe-9db2-4ef5-ba6e-8127480cf30d Egeria does not mandate the use this or any other particular algorithm for generating GUIDs, only that the principle of uniqueness is adhered to. There should be, at most, a tiny chance 3 that two servers will generate the same GUID . Egeria expects this to be exceedingly rare, but not impossible, and therefore if it does happen it is detected by the repository services and at a minimum messages are output on the detecting server's audit log. The repository services also have APIs for re-identifying (changing the GUID ) for a metadata instance to automate the resolution of such conflicts. We can expect that such an operation could be resource-intensive; however, this is balanced against the exceeding rareness with which it should need to be used.","title":"Unique identifiers (GUIDs)"},{"location":"introduction/key-concepts/#conformance","text":"Adhering to these concepts and the principles by which they behave is the subject of conformance . Egeria provides an automated testing suite to validate that a given repository or third party integration behaves according to these expectations , the successful completion of which is a necessary input to a tool being granted the use of an Egeria conformance mark. You may want to see the cohort interactions walkthrough for more details on how cohort participants interact. \u21a9 You may want to see the OMRS metamodel for more details on the granularity of metadata exchange. \u21a9 The rarity will depend on the specific algorithm used, but as an example the algorithm used within Egeria generates type 4 UUIDs, for which the probability of a collision is so small that it can almost be ignored . But as it is not impossible , Egeria does still provide the mechanisms to detect and resolve such conflicts. \u21a9","title":"Conformance"},{"location":"introduction/overview/","text":"Our solution (overview) \u00b6 Today's organizations have their tools and technologies distributed across multiple data centres and cloud providers (green clouds). Within each location, we can run a platform (blue boxes) that provides integration services tailored to specific types of tools (orange circles). Peer-to-peer network of metadata The resulting exchange of metadata (blue arrows) creates a peer-to-peer network that spans both locations and vendor tools. Egeria implements a set of open metadata types , frameworks , connectors , APIs , event payloads and interchange protocols to allow all types of tools and metadata repositories to share and exchange metadata. It also provides this platform and pre-built integration services that can run within it to provide a comprehensive toolkit for integrating and distributing metadata between different tools and technologies. OMAG Server Platform \u00b6 Egeria provides the platform (the blue boxes), called the Open Metadata and Governance Server Platform (or OMAG Server Platform ) . The OMAG Server Platform is a multi-tenant platform that supports horizontal scale-out in Kubernetes and yet is light enough to run as an edge server on a Raspberry Pi. This platform is used to host the actual metadata integration and automation capabilities. OMAG Servers \u00b6 Within an instance of the OMAG Server Platform , one or more OMAG Servers can be configured (the orange circles). These servers are collections of activated services that host connectors to the different technologies with which Egeria exchanges metadata. Summary Combined, the OMAG Server Platforms and servers running within them provide an enterprise catalog of data and IT resources that are transparently assessed, governed and consumed through many types of tools and technologies. The enterprise catalog is not a physically-centralized one, but a logical one composed of federated metadata from across this peer-to-peer network. Why open source? Delivering this capability as open source is a critical part of the project, since multiple vendors must buy into this ecosystem. They are not going to do this if one organization dominates the technology base. Thus, the open metadata and governance technology must be freely available with an open source governance model that allows a community of organizations and practitioners to develop and evolve the base, and then use it in their offerings and deployments.","title":"Our Solution"},{"location":"introduction/overview/#our-solution-overview","text":"Today's organizations have their tools and technologies distributed across multiple data centres and cloud providers (green clouds). Within each location, we can run a platform (blue boxes) that provides integration services tailored to specific types of tools (orange circles). Peer-to-peer network of metadata The resulting exchange of metadata (blue arrows) creates a peer-to-peer network that spans both locations and vendor tools. Egeria implements a set of open metadata types , frameworks , connectors , APIs , event payloads and interchange protocols to allow all types of tools and metadata repositories to share and exchange metadata. It also provides this platform and pre-built integration services that can run within it to provide a comprehensive toolkit for integrating and distributing metadata between different tools and technologies.","title":"Our solution (overview)"},{"location":"introduction/overview/#omag-server-platform","text":"Egeria provides the platform (the blue boxes), called the Open Metadata and Governance Server Platform (or OMAG Server Platform ) . The OMAG Server Platform is a multi-tenant platform that supports horizontal scale-out in Kubernetes and yet is light enough to run as an edge server on a Raspberry Pi. This platform is used to host the actual metadata integration and automation capabilities.","title":"OMAG Server Platform"},{"location":"introduction/overview/#omag-servers","text":"Within an instance of the OMAG Server Platform , one or more OMAG Servers can be configured (the orange circles). These servers are collections of activated services that host connectors to the different technologies with which Egeria exchanges metadata. Summary Combined, the OMAG Server Platforms and servers running within them provide an enterprise catalog of data and IT resources that are transparently assessed, governed and consumed through many types of tools and technologies. The enterprise catalog is not a physically-centralized one, but a logical one composed of federated metadata from across this peer-to-peer network. Why open source? Delivering this capability as open source is a critical part of the project, since multiple vendors must buy into this ecosystem. They are not going to do this if one organization dominates the technology base. Thus, the open metadata and governance technology must be freely available with an open source governance model that allows a community of organizations and practitioners to develop and evolve the base, and then use it in their offerings and deployments.","title":"OMAG Servers"},{"location":"patterns/metadata-exchange/overview/","text":"Egeria for Metadata Exchange \u00b6 The metadata server exchange solution describes how third party metadata servers can exchange metadata through an Open Metadata Repository Cohort or Cohort for short. A cohort uses a peer-to-peer exchange protocol. Servers that implement the protocol's open metadata APIs and event exchange sequences can become a member of one or more cohorts. Each member of a cohort can send notifications about updates to its metadata to the other members of the cohort as well as query/update metadata from all of the member repositories. Since the cohort protocols are open, they can be implemented by any technology. However this pattern focuses on integrating third party metadata servers that use Egeria to implement the protocol. Introducing the Repository Proxy \u00b6 Third party metadata servers that do not directly support any of the open metadata APIs and protocols need an adapter to convert their events and APIs into open metadata events and APIs as well as manage the protocol event sequencing. This first option uses a special OMAG Server called the Repository Proxy as the adapter for third party metadata servers. Inside the repository proxy are plug points for two repository connectors: The OMRS Repository Connector - translates calls to the OMRS Repository REST API to calls to the third party metadata server's API. The OMRS Event Mapper - translates events from the third party metadata server to open metadata events. The repository proxy represents the third party metadata server in the cohort and calls the connectors as required. You need one repository proxy for each third party metadata server that you want to be in the solution. Figure 1 shows the repository proxy in action: Figure 1: showing a repository proxy acting as an adapter for a third party metadata server You can create your own implementation of the repository connectors for your favorite metadata server. Alternatively Egeria provides repository connector implementations for two third party metadata servers: IBM Information Governance Catalog ( IGC ) Apache Atlas We will use these implementations to illustrate how the repository proxies work. We are also assuming that in this example, glossary terms are being maintained in IGC and the organization wants to connect these terms to the Hadoop data sources described in Apache Atlas. Working with read-only third party metadata repository connectors \u00b6 Most third party metadata servers do not support the storing of metadata from other metadata servers. The sticking point is typically that it can not store information about where the metadata came from and it can not guarantee that metadata from another metadata server is not updatable through its APIs and user interfaces. There can also be more subtle issues in the the scale (size) of metadata descriptions or or errors caused by unexpected values they contain. This is why it is common that the repository connectors for third party metadata servers only support what we call read-only operation. They can publish information about metadata stored in the third party metadata server, and support open metadata queries to that repository. However, they do not pass metadata from other metadata servers to the third party metadata server. Both IGC 's and Atlas's repository connectors are read-only. Figure 2 shows them connected to their repository proxies and how the operate. Figure 2: Read only repository connector operation Because of their read-only nature, if we just connected them together in a cohort, it would be like two people talking and no-one listening. There would be no value to the solution. Creating an enterprise view \u00b6 Figure 3 shows a possible extension using an OMAG Server called the Metadata Access Point . This provides specialist APIs and events for retrieving and maintaining open metadata. The metadata access point can be augmented with a View Server to support a UI, or provide services to other third party tools. Figure 3: Using a metadata access point to create an enterprise view With this approach it is possible to issue queries that return metadata content content from both Atlas and IGC as if they were one metadata repository. However, there is no support for updates or linking this metadata together. Linking metadata from different metadata servers \u00b6 Figure 4 adds an Egeria metadata access store to the cohort enabling the storage of new metadata. This means that the APIs of the metadata access point can be used to link glossary terms from IGC to asset definitions from Atlas. These links (called relationships) are stored in the metadata access store. When queries for metadata are made through the metadata access point, the IGC glossary terms are shown linked to the Atlas assets as if all of the metadata is stored in a single repository. Figure 4: Using a metadata access store to provide storage for relationships between IGC and Atlas metadata Expanding the scope of metadata being captured \u00b6 With the metadata access store in place, it is possible to connect an Integration Daemon to the metadata access store to provide metadata synchronization to/from additional third party technologies as shown in figure 5. Figure 5: Using a metadata server to provide storage for new metadata With the above capabilities deployed, there is now a rich source of metadata visible through the metadata access point. Metadata from the IGC and Atlas repositories can be retrieved, combined together and used in new ways without needing to change their implementation. However, there is no additional metadata being made available through either the IGC or Atlas UIs since they only access metadata stored in their own private metadata repositories. Integrating third party metadata servers through the integration daemon \u00b6 There is an alternative integration path for third party metadata servers to integrate into the open metadata ecosystem even when they do not meet the requirements to have their repository connectors write metadata into their private metadata repository. Figure 6 shows IGC connected using this alternative approach. IGC is now connecting through an integration daemon in a similar way to the other third party technologies shown in Figure 5. Storing metadata from other repositories is now possible because IGC is no longer providing metadata services to the broader metadata ecosystem as part of the cohort federated queries, removing the requirement to store information about where the metadata came from . The downside is that the metadata in the IGC 's xMeta repository is no longer visible to the metadata access point because IGC is no longer a member of the cohort. IGC 's metadata will have to be extracted by the integration daemon and stored in the metadata access store for it to be more broadly used. With this approach, IGC can update its own metadata, and any metadata created through the metadata access point. However, an attempt to update metadata that originated in Atlas would fail when the integration daemon attempted to publish this update into the metadata access store. (See metadata provenance to understand why.) Figure 6: Integrating a third party metadata server through the integration daemon Note: this pattern could be repeated to move Apache Atlas to connect through an integration daemon too. Summary \u00b6 In these patterns, you have seen different mechanisms for integrating third party metadata servers together and then build out the metadata ecosystem to enable new use cases. There are two main integration approaches: Integrating using a repository proxy, brings the third party metadata server into the heart of the open metadata ecosystem, enabling queries to its repository to be made by other open metadata services. Integrating via an integration daemon has the third party metadata server on the edge of the open metadata ecosystem. It is not being queried directly, but can engage in two-way metadata exchange through the integration daemon. Further information \u00b6 More about the different types of Cohort Members including information on how to configure them. Specifically - Repository Proxy to host repository connectors to a third party metadata repository. - Integration Daemon to host integration connectors to a third party metadata repository. - Metadata Access Point to provide new APIs to the federated metadata. - Metadata Access Store to provide the store for new metadata. There is also specific configuration information for the IBM Information Governance catalog ( IGC ) and Apache Atlas setup below: IBM Information Governance Catalog ( IGC ) Apache Atlas These are links to more information about cohorts - Operation of the Open Metadata Repository Cohort - Querying the members of an Open Metadata Repository Cohort This link provides guidance if you are interested in writing your own repository connectors: - Writing repository connectors for a third party metadata repository","title":"Metadata Exchange"},{"location":"patterns/metadata-exchange/overview/#egeria-for-metadata-exchange","text":"The metadata server exchange solution describes how third party metadata servers can exchange metadata through an Open Metadata Repository Cohort or Cohort for short. A cohort uses a peer-to-peer exchange protocol. Servers that implement the protocol's open metadata APIs and event exchange sequences can become a member of one or more cohorts. Each member of a cohort can send notifications about updates to its metadata to the other members of the cohort as well as query/update metadata from all of the member repositories. Since the cohort protocols are open, they can be implemented by any technology. However this pattern focuses on integrating third party metadata servers that use Egeria to implement the protocol.","title":"Egeria for Metadata Exchange"},{"location":"patterns/metadata-exchange/overview/#introducing-the-repository-proxy","text":"Third party metadata servers that do not directly support any of the open metadata APIs and protocols need an adapter to convert their events and APIs into open metadata events and APIs as well as manage the protocol event sequencing. This first option uses a special OMAG Server called the Repository Proxy as the adapter for third party metadata servers. Inside the repository proxy are plug points for two repository connectors: The OMRS Repository Connector - translates calls to the OMRS Repository REST API to calls to the third party metadata server's API. The OMRS Event Mapper - translates events from the third party metadata server to open metadata events. The repository proxy represents the third party metadata server in the cohort and calls the connectors as required. You need one repository proxy for each third party metadata server that you want to be in the solution. Figure 1 shows the repository proxy in action: Figure 1: showing a repository proxy acting as an adapter for a third party metadata server You can create your own implementation of the repository connectors for your favorite metadata server. Alternatively Egeria provides repository connector implementations for two third party metadata servers: IBM Information Governance Catalog ( IGC ) Apache Atlas We will use these implementations to illustrate how the repository proxies work. We are also assuming that in this example, glossary terms are being maintained in IGC and the organization wants to connect these terms to the Hadoop data sources described in Apache Atlas.","title":"Introducing the Repository Proxy"},{"location":"patterns/metadata-exchange/overview/#working-with-read-only-third-party-metadata-repository-connectors","text":"Most third party metadata servers do not support the storing of metadata from other metadata servers. The sticking point is typically that it can not store information about where the metadata came from and it can not guarantee that metadata from another metadata server is not updatable through its APIs and user interfaces. There can also be more subtle issues in the the scale (size) of metadata descriptions or or errors caused by unexpected values they contain. This is why it is common that the repository connectors for third party metadata servers only support what we call read-only operation. They can publish information about metadata stored in the third party metadata server, and support open metadata queries to that repository. However, they do not pass metadata from other metadata servers to the third party metadata server. Both IGC 's and Atlas's repository connectors are read-only. Figure 2 shows them connected to their repository proxies and how the operate. Figure 2: Read only repository connector operation Because of their read-only nature, if we just connected them together in a cohort, it would be like two people talking and no-one listening. There would be no value to the solution.","title":"Working with read-only third party metadata repository connectors"},{"location":"patterns/metadata-exchange/overview/#creating-an-enterprise-view","text":"Figure 3 shows a possible extension using an OMAG Server called the Metadata Access Point . This provides specialist APIs and events for retrieving and maintaining open metadata. The metadata access point can be augmented with a View Server to support a UI, or provide services to other third party tools. Figure 3: Using a metadata access point to create an enterprise view With this approach it is possible to issue queries that return metadata content content from both Atlas and IGC as if they were one metadata repository. However, there is no support for updates or linking this metadata together.","title":"Creating an enterprise view"},{"location":"patterns/metadata-exchange/overview/#linking-metadata-from-different-metadata-servers","text":"Figure 4 adds an Egeria metadata access store to the cohort enabling the storage of new metadata. This means that the APIs of the metadata access point can be used to link glossary terms from IGC to asset definitions from Atlas. These links (called relationships) are stored in the metadata access store. When queries for metadata are made through the metadata access point, the IGC glossary terms are shown linked to the Atlas assets as if all of the metadata is stored in a single repository. Figure 4: Using a metadata access store to provide storage for relationships between IGC and Atlas metadata","title":"Linking metadata from different metadata servers"},{"location":"patterns/metadata-exchange/overview/#expanding-the-scope-of-metadata-being-captured","text":"With the metadata access store in place, it is possible to connect an Integration Daemon to the metadata access store to provide metadata synchronization to/from additional third party technologies as shown in figure 5. Figure 5: Using a metadata server to provide storage for new metadata With the above capabilities deployed, there is now a rich source of metadata visible through the metadata access point. Metadata from the IGC and Atlas repositories can be retrieved, combined together and used in new ways without needing to change their implementation. However, there is no additional metadata being made available through either the IGC or Atlas UIs since they only access metadata stored in their own private metadata repositories.","title":"Expanding the scope of metadata being captured"},{"location":"patterns/metadata-exchange/overview/#integrating-third-party-metadata-servers-through-the-integration-daemon","text":"There is an alternative integration path for third party metadata servers to integrate into the open metadata ecosystem even when they do not meet the requirements to have their repository connectors write metadata into their private metadata repository. Figure 6 shows IGC connected using this alternative approach. IGC is now connecting through an integration daemon in a similar way to the other third party technologies shown in Figure 5. Storing metadata from other repositories is now possible because IGC is no longer providing metadata services to the broader metadata ecosystem as part of the cohort federated queries, removing the requirement to store information about where the metadata came from . The downside is that the metadata in the IGC 's xMeta repository is no longer visible to the metadata access point because IGC is no longer a member of the cohort. IGC 's metadata will have to be extracted by the integration daemon and stored in the metadata access store for it to be more broadly used. With this approach, IGC can update its own metadata, and any metadata created through the metadata access point. However, an attempt to update metadata that originated in Atlas would fail when the integration daemon attempted to publish this update into the metadata access store. (See metadata provenance to understand why.) Figure 6: Integrating a third party metadata server through the integration daemon Note: this pattern could be repeated to move Apache Atlas to connect through an integration daemon too.","title":"Integrating third party metadata servers through the integration daemon"},{"location":"patterns/metadata-exchange/overview/#summary","text":"In these patterns, you have seen different mechanisms for integrating third party metadata servers together and then build out the metadata ecosystem to enable new use cases. There are two main integration approaches: Integrating using a repository proxy, brings the third party metadata server into the heart of the open metadata ecosystem, enabling queries to its repository to be made by other open metadata services. Integrating via an integration daemon has the third party metadata server on the edge of the open metadata ecosystem. It is not being queried directly, but can engage in two-way metadata exchange through the integration daemon.","title":"Summary"},{"location":"patterns/metadata-exchange/overview/#further-information","text":"More about the different types of Cohort Members including information on how to configure them. Specifically - Repository Proxy to host repository connectors to a third party metadata repository. - Integration Daemon to host integration connectors to a third party metadata repository. - Metadata Access Point to provide new APIs to the federated metadata. - Metadata Access Store to provide the store for new metadata. There is also specific configuration information for the IBM Information Governance catalog ( IGC ) and Apache Atlas setup below: IBM Information Governance Catalog ( IGC ) Apache Atlas These are links to more information about cohorts - Operation of the Open Metadata Repository Cohort - Querying the members of an Open Metadata Repository Cohort This link provides guidance if you are interested in writing your own repository connectors: - Writing repository connectors for a third party metadata repository","title":"Further information"},{"location":"patterns/metadata-governance/overview/","text":"Egeria for Metadata Governance \u00b6","title":"Metadata Governance"},{"location":"patterns/metadata-governance/overview/#egeria-for-metadata-governance","text":"","title":"Egeria for Metadata Governance"},{"location":"patterns/metadata-manager/overview/","text":"Egeria as a Metadata Manager \u00b6 Metadata is collected together, organized and maintained within a catalog service to enable both individuals and automated services to search for, select and retrieve information about relevant resources necessary to perform a specific task. These resources could be data, systems, applications, software components, processes, ... Each of these types of resources are represented in open metadata as Assets . The contents of an asset catalog \u00b6 Asset catalogs can start simple and evolve into a rich and valuable source of knowledge for your organization. They are assembled like a jigsaw puzzle from many sources and as the picture emerges and grows, new value is realized: Making it easier to locate the right asset for a task. Improving an individual's understanding about how an asset can be used and how it should be maintained. Identifying assets that are supporting specific situations and business contexts. Providing a perspective on how many assets of a certain type or situation are owned by the organization. Providing encoded information that enables automation to be used to maintain and protect the assets. Egeria offers the services to build a catalog with the following types of information. Basic Asset Properties Asset Connections Asset Schemas Asset Ownership Asset Zone Membership Asset Location Asset External Identifiers Asset Licenses and Certifications Asset Classifiers Asset Feedback Asset Note Logs Asset External Descriptions Asset Lineage Related Assets This is built on an extensible type system that allows further information to be catalogued. Automation is used to expand the contents of your asset catalog without creating a huge workload for your people. Basic Asset Properties \u00b6 Each instance of an asset, no matter what its physical type, is represented by an Asset (or a subtype of this element - see Assets for a list of the supported sub types) in the catalog. The Asset contains the following properties: Open Metadata Unique identifier ( GUID ) - this a globally unique id across all metadata instances. It is a string of letters and numbers and typically looks something like this 40d9520b-dbc0-4cc4-9bad-03ab72d027f3 and is assigned by Egeria. Qualified Name - this is a globally unique name of the asset - it is unique across all assets. It is assigned by the creator of the asset. Display Name - typically qualified names are long in order to make them unique. The display name is a short name used in reports and other displays of asset information. Description - description of the asset. Additional Properties - names and values of additional properties that the organization wants to record about the asset. Usage \u00b6 With the basic asset properties defined, the asset catalog provides a searchable list of the assets of the organization. The content provides in the names, descriptions and additional properties will determine how easy it is to retrieve specific assets. Asset Connections \u00b6 A connection can be attached to the asset. This provides the information necessary to create a connector to the asset. The connector is a client to both the data and the information about the asset stored in open metadata. Some connectors use the metadata about the asset to control what data can be retrieved from the asset depending on the caller. The connection object includes a connector type - containing information about the type of connector to create - and an endpoint detailing the network address and access protocol of the physical asset. There are API options to request that Egeria creates a default connection that matches the specific asset type. In addition there are options to explicitly set up the connection object, or leave the asset with no connection attached. Usage \u00b6 The connector that is generated from the connection object enables both tools and applications to use the asset through a governed interface that provides metadata, data and, in some cases, metadata-driven access control. Asset Schemas \u00b6 A schema describes the individual data fields and operations of the asset.It is organized to reflect the internal organization of the asset and so acts as a guide to the types of content in the asset and how to navigate around it. Usage \u00b6 With the schema in place, it is possible to search for assets based on the type of data, or type of operations that the asset supports. More information \u00b6 Modelling Schema Asset Ownership \u00b6 Asset ownership defines who is responsible for the asset. This covers ensuring the catalog entry is correct, the contents of the asset are complete and correct and controlling access to the asset. The owner can be defined as a user identity, an actor profile or a person's role. These definitions are managed by the Community Profile OMAS and Governance Program OMAS . Usage \u00b6 With an owner established, it records who is responsible for the protection and quality of the asset. It is possible to route requests from the consumers of the asset to the owner. An example of this is in managing queries about the content of the asset and requests for access to its contents. Asset Zone Membership \u00b6 Governance zones group assets according to their usage. Governance Zones are defined by the Governance Program OMAS . It is possible to assign SupportedZones to OMASs to limit the scope of assets that are returned from searches. More information on the use of governance zones is described in the governance zoning feature. Usage \u00b6 Using governance zones allows the organization to scope the assets that are returned to a community of users who are using the asset catalog. The governance zones can also be used to define the group of assets that an automated process should process. Asset Location \u00b6 Egeria supports the definition of a location model that divides both physical and digital space into hierarchies with cross links between the hierarchies. This means it is possible to link the assets to their location(s). Usage \u00b6 Attaching assets to location definitions means it is possible to use details of the location as part of the search for assets. Knowing the asset location, whether it is a physical or digital location can also help with demonstrating that data sovereignty is being respected and the level of risk that is allocated in a location. Asset External Identifiers \u00b6 A specific asset may be represented in different tools using different names. It is possible to add details of `these external identifiers to the Asset. Usage \u00b6 Knowing the names of an asset means that the asset catalog can support searches for assets using the name that specific communities of people know. It also helps automated process that are operating on the physical asset through a tool or API can look up the appropriate identifier for the asset for that tool/API. Asset Licenses and Certifications \u00b6 An asset can have its license and/or certifications attached to it. The license determines the terms and conditions of use for the asset. This becomes important particularly when assets come from an external organization. Certifications typically relate to a regulation or standard. When the certification is tied to the asset it means that the asset has passed the requirements. Usage \u00b6 Attaching licences and certifications to assets raises awareness of the any restrictions on the use of the assets and to what standards they are managed to. If the licenses and certifications are machine readable, automated processes can used them to control the way that they manage the assets. Asset Classifiers \u00b6 Classifiers add labels and properties to the asset that identifies them as part of a specific group, or having specific characteristics. The classifiers can be added to the whole asset or a field or operation in the schema. The types of classifiers are: Glossary terms define the meaning of concepts and activities. When a glossary term is attached to a data field in the assets schema, it signifies that the data stored in that field has the meaning described in the glossary term. Reference values identify sets of valid values of specific characteristics of the assets. For example, attaching a reference code for \"personal data\" to an asset indicates that it contains personal data. Informal tags are labels that asset consumers create and attach to the asset and its data fields/operations. This is effectively a way of crowd sourcing knowledge about the asset. Search keywords are typically attached to an asset by the asset owner to improve the findability of an asset - particularly if it has a name that is difficult to remember. Governance classifications provide formal classifiers for confidentiality, retention, confidence and criticality for the asset. The impact classification is typically used with reports that link to the asst such as incident reports. Usage \u00b6 Classifiers help to make assets more findable. They also identify which assets should be treated to certain types of processing. For example, data fields marked as sensitive could be masked when added to a sandbox. Asset Feedback \u00b6 Feedback, such as comments, likes, star ratings and reviews can be added to an asset, typically by consumers of the asset to share experiences, expertise and concerns about the asset. The author of the feedback can choose whether it is public or private feedback. Public feedback is visible by everyone. Private feedback is visible to the author of the feedback and the owner of the asset. Feedback can only be changed by the author of the feedback. It can be added to an asset through Asset Consumer OMAS , Asset Owner OMAS and Digital Architecture OMAS . Usage \u00b6 Feedback helps to share expertise and use the experience of the assets' consumers to improve the quality of both the asset contents and its description. Asset Note Logs \u00b6 Note logs consist of a series of posts (called notes) that are added over time (like a blog). An asset's note log can be maintained through the Asset Owner OMAS , Digital Architecture OMAS and IT Infrastructure OMAS . Usage \u00b6 Note logs can be used by the asset owner or operations team to post status or usage information about the asset to inform individuals who are using the asset of important information. Asset External Descriptions \u00b6 Not everything that is known about an asset is stored in Egeria. There may be documents, web resources, images, videos and audio files that provide more detail. Through Asset Owner OMAS it is possible to add links to external resources and media. Usage \u00b6 Using the links to external resources, an individual is able to learn a lot more about the asset they are considering to use to complete their task. Asset Lineage \u00b6 Lineage describes the origin of the data that is held by the asset. There are different perspectives on what is meant by 'origin'. In general an asset is being accessed by processes. They are either adding/updating/deleting data or reading it. So one perspective of lineage is to see the processes that are providing and using the asset. Data often flows from asset to asset via the processes, as they read data from one asset, do some processing and store the results in a different asset. The end-to-end flow of data is called an information supply chain. Information supply chains can be modeled and linked to the processes through the Digital Architecture OMAS . This offers more of an enterprise view of where the data originated from. The asset itself is hosted by a software capability that is part of a server. Another perspective on the asset's origin is the server capability that is hosting it. Software server capabilities can be linked to a solution component by the Digital Architecture OMAS . Solution components are descriptions produced by architects to document the purpose and behavior of a component. These descriptions add business context to the software server capability definitions. They are linked to the software server capability when it is deployed into the IT landscape. Similarly, the software server capability hosting an asset can be linked to the digital service it is a part of. Digital Services are anchors for information about the digital services (also known as offerings or products) that the organization is operating. This is a business view of the service that the asset is a part of. Finally, the asset can include identifiers of other metadata elements from the catalog and related properties in the AssetOrigin Classification. This includes: * Unique identifier ( GUID ) of the business capability that owns the asset. Examples of a business capabilities include \"Finance\", \"Human Resources\", \"Manufacturing\", \"Sales\", etc * Unique identifier ( GUID ) of the organization that owns the asset. This could be a unit within the organization or an external organization. Both organization and business capability information is maintained through the Community Profile OMAS and documented in the asset by the Asset Owner OMAS . Usage \u00b6 Lineage information helps consumers (individuals and/or automated processes) make choices about which is the appropriate asset to use for a certain task. It gives a sense of whether the asset contains data from an authoritative source/business capability/organization/process. Regulations that require specific types of reports often require lineage as well as the report to help the regulators validate that the report is correct. Related Assets \u00b6 Related assets returns other assets that are linked together or are part of the same collection. Collections allow individuals and automated processes to maintain groups of related assets. For example, an individual may maintain a collection of their favorite assets. A project team may maintain a collection of the assets in use by the project. An automated process may use the retention classification to build a collection of assets that need to be archived. These types of collections are maintained through the following Open Metadata Access Services (OMASs): Asset Consumer OMAS Community Profile OMAS Project Management OMAS In addition, there are natural relationships between assets that are created as the asset is cataloged. For example, a file is related to the folder (also known as a directory) it is located in. Both the file and the folder could be assets in the asset catalog and they would be automatically linked together by the Asset Owner OMAS when these assets were created. Usage \u00b6 The related assets enables individuals or automated services to locate assets that are related. For example, a process may use the related assets to step through and process the cataloged files in a folder, or the assets in a specific collection. Manual cataloguing \u00b6 Manual cataloging uses no automation beyond the management of the metadata once it is created. Individuals enter information about the assets into Egeria through tools that call Egeria's Open Metadata Access Services (OMASs). The Asset Owner OMAS is the principle interface for manual cataloging. It is possible to catalog any type of asset through this interface although it is biased towards cataloging data assets such as data stores, data feeds, files, data sets, APIs and events. In addition there are specific cataloging interfaces for particular types of subject matter expert. IT Infrastructure OMAS provides specialist interfaces for cataloging infrastructure such as servers, host systems and applications. Digital Architecture OMAS provides specialist interfaces for architects and integration engineers to manually catalog reference data sets and processes. Reference data sets are assets in their own right, and their content can be used as classifiers to augment the description of other assets. Processes are also assets that, when linked together, show the lineage of the assets they are partly responsible for maintaining. Adding automation \u00b6 Below are three types of automation to minimise the effort in managing your asset catalog. Templated cataloging - copying predefined assets. Integrated cataloging - automated extraction of metadata from third party technologies. Discovery and stewardship - analysis of asset contents to create metadata Scaling the asset catalog through automation \u00b6 Automation is critical when it comes to managing an asset catalog. It reduces the administrative work of subject matter experts and asset owners, increases the reliability, reach and richness of the asset catalog whilst reducing the cost of its maintenance. Some automation is easy and reliable, particularly for information that can be extracted directly from the digital technologies used to implement the assets. Other automation involves analytics to create a candidate result that may need to be confirmed and approved by a subject matter expert. However, even when this human validation is necessary, the effort required is significantly less that manual maintenance of the catalog. Whenever subject matter experts are involved, it typically requires a change to their role in order to accommodate the time spent on the catalog. Often these experts are from a different part of the organization to the people receiving the benefit of their expertise, and so the organization's appreciation and use of the asset catalog needs to have matured to allow this to happen. Therefore as we look at the different types of automation, each comes with its own organizational maturity required to make it successful. What automation is possible? \u00b6 Egeria offers the following approaches to cataloging assets: Manual cataloging - calling the access services to set up each asset. Templated cataloging - copying predefined assets. Integrated cataloging - automated extraction of metadata from third party technologies. Discovery and stewardship - analysis of asset contents to create metadata The idea is that these approaches are selected for each type of asset and blended together to balance the investment in the automation, against the time commitment of subject matter experts, against the business value of the resulting catalog. Asset catalog services \u00b6 Once the asset catalog is established, it can offer search interfaces through the following mechanisms. Asset Catalog OMAS provides support a comprehensive search interface for all types of asset. It is designed to support a catalog tool. Asset Consumer OMAS provides simple string-based searches for assets and their related information along with support to create connectors to access the content of the actual physical asset and browse through all of the information known about the asset. Digital Architecture OMAS provides specialist interfaces for querying reference data and processes. IT Infrastructure OMAS provides specialist catalog search capabilities for infrastructure such as servers, host systems and applications. Governance Program OMAS provides the ability to browse assets in a governance zone to assess the effectiveness of the governance program. Related information \u00b6 The Asset page provides more information on the different types of assets supported by open metadata. The asset types can be extended dynamically if needed. The type definition for the Asset entity is found in model 0010 Basic Model . Examples of representing different types of assets using the open metadata types are found in Mapping Technology . The Open Metadata Labs provide practical examples showing all of the techniques to manage an asset catalog, allowing you to try each of the features to assess how they could work in your organization.","title":"Metadata Manager"},{"location":"patterns/metadata-manager/overview/#egeria-as-a-metadata-manager","text":"Metadata is collected together, organized and maintained within a catalog service to enable both individuals and automated services to search for, select and retrieve information about relevant resources necessary to perform a specific task. These resources could be data, systems, applications, software components, processes, ... Each of these types of resources are represented in open metadata as Assets .","title":"Egeria as a Metadata Manager"},{"location":"patterns/metadata-manager/overview/#the-contents-of-an-asset-catalog","text":"Asset catalogs can start simple and evolve into a rich and valuable source of knowledge for your organization. They are assembled like a jigsaw puzzle from many sources and as the picture emerges and grows, new value is realized: Making it easier to locate the right asset for a task. Improving an individual's understanding about how an asset can be used and how it should be maintained. Identifying assets that are supporting specific situations and business contexts. Providing a perspective on how many assets of a certain type or situation are owned by the organization. Providing encoded information that enables automation to be used to maintain and protect the assets. Egeria offers the services to build a catalog with the following types of information. Basic Asset Properties Asset Connections Asset Schemas Asset Ownership Asset Zone Membership Asset Location Asset External Identifiers Asset Licenses and Certifications Asset Classifiers Asset Feedback Asset Note Logs Asset External Descriptions Asset Lineage Related Assets This is built on an extensible type system that allows further information to be catalogued. Automation is used to expand the contents of your asset catalog without creating a huge workload for your people.","title":"The contents of an asset catalog"},{"location":"patterns/metadata-manager/overview/#basic-asset-properties","text":"Each instance of an asset, no matter what its physical type, is represented by an Asset (or a subtype of this element - see Assets for a list of the supported sub types) in the catalog. The Asset contains the following properties: Open Metadata Unique identifier ( GUID ) - this a globally unique id across all metadata instances. It is a string of letters and numbers and typically looks something like this 40d9520b-dbc0-4cc4-9bad-03ab72d027f3 and is assigned by Egeria. Qualified Name - this is a globally unique name of the asset - it is unique across all assets. It is assigned by the creator of the asset. Display Name - typically qualified names are long in order to make them unique. The display name is a short name used in reports and other displays of asset information. Description - description of the asset. Additional Properties - names and values of additional properties that the organization wants to record about the asset.","title":"Basic Asset Properties"},{"location":"patterns/metadata-manager/overview/#usage","text":"With the basic asset properties defined, the asset catalog provides a searchable list of the assets of the organization. The content provides in the names, descriptions and additional properties will determine how easy it is to retrieve specific assets.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-connections","text":"A connection can be attached to the asset. This provides the information necessary to create a connector to the asset. The connector is a client to both the data and the information about the asset stored in open metadata. Some connectors use the metadata about the asset to control what data can be retrieved from the asset depending on the caller. The connection object includes a connector type - containing information about the type of connector to create - and an endpoint detailing the network address and access protocol of the physical asset. There are API options to request that Egeria creates a default connection that matches the specific asset type. In addition there are options to explicitly set up the connection object, or leave the asset with no connection attached.","title":"Asset Connections"},{"location":"patterns/metadata-manager/overview/#usage_1","text":"The connector that is generated from the connection object enables both tools and applications to use the asset through a governed interface that provides metadata, data and, in some cases, metadata-driven access control.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-schemas","text":"A schema describes the individual data fields and operations of the asset.It is organized to reflect the internal organization of the asset and so acts as a guide to the types of content in the asset and how to navigate around it.","title":"Asset Schemas"},{"location":"patterns/metadata-manager/overview/#usage_2","text":"With the schema in place, it is possible to search for assets based on the type of data, or type of operations that the asset supports.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#more-information","text":"Modelling Schema","title":"More information"},{"location":"patterns/metadata-manager/overview/#asset-ownership","text":"Asset ownership defines who is responsible for the asset. This covers ensuring the catalog entry is correct, the contents of the asset are complete and correct and controlling access to the asset. The owner can be defined as a user identity, an actor profile or a person's role. These definitions are managed by the Community Profile OMAS and Governance Program OMAS .","title":"Asset Ownership"},{"location":"patterns/metadata-manager/overview/#usage_3","text":"With an owner established, it records who is responsible for the protection and quality of the asset. It is possible to route requests from the consumers of the asset to the owner. An example of this is in managing queries about the content of the asset and requests for access to its contents.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-zone-membership","text":"Governance zones group assets according to their usage. Governance Zones are defined by the Governance Program OMAS . It is possible to assign SupportedZones to OMASs to limit the scope of assets that are returned from searches. More information on the use of governance zones is described in the governance zoning feature.","title":"Asset Zone Membership"},{"location":"patterns/metadata-manager/overview/#usage_4","text":"Using governance zones allows the organization to scope the assets that are returned to a community of users who are using the asset catalog. The governance zones can also be used to define the group of assets that an automated process should process.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-location","text":"Egeria supports the definition of a location model that divides both physical and digital space into hierarchies with cross links between the hierarchies. This means it is possible to link the assets to their location(s).","title":"Asset Location"},{"location":"patterns/metadata-manager/overview/#usage_5","text":"Attaching assets to location definitions means it is possible to use details of the location as part of the search for assets. Knowing the asset location, whether it is a physical or digital location can also help with demonstrating that data sovereignty is being respected and the level of risk that is allocated in a location.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-external-identifiers","text":"A specific asset may be represented in different tools using different names. It is possible to add details of `these external identifiers to the Asset.","title":"Asset External Identifiers"},{"location":"patterns/metadata-manager/overview/#usage_6","text":"Knowing the names of an asset means that the asset catalog can support searches for assets using the name that specific communities of people know. It also helps automated process that are operating on the physical asset through a tool or API can look up the appropriate identifier for the asset for that tool/API.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-licenses-and-certifications","text":"An asset can have its license and/or certifications attached to it. The license determines the terms and conditions of use for the asset. This becomes important particularly when assets come from an external organization. Certifications typically relate to a regulation or standard. When the certification is tied to the asset it means that the asset has passed the requirements.","title":"Asset Licenses and Certifications"},{"location":"patterns/metadata-manager/overview/#usage_7","text":"Attaching licences and certifications to assets raises awareness of the any restrictions on the use of the assets and to what standards they are managed to. If the licenses and certifications are machine readable, automated processes can used them to control the way that they manage the assets.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-classifiers","text":"Classifiers add labels and properties to the asset that identifies them as part of a specific group, or having specific characteristics. The classifiers can be added to the whole asset or a field or operation in the schema. The types of classifiers are: Glossary terms define the meaning of concepts and activities. When a glossary term is attached to a data field in the assets schema, it signifies that the data stored in that field has the meaning described in the glossary term. Reference values identify sets of valid values of specific characteristics of the assets. For example, attaching a reference code for \"personal data\" to an asset indicates that it contains personal data. Informal tags are labels that asset consumers create and attach to the asset and its data fields/operations. This is effectively a way of crowd sourcing knowledge about the asset. Search keywords are typically attached to an asset by the asset owner to improve the findability of an asset - particularly if it has a name that is difficult to remember. Governance classifications provide formal classifiers for confidentiality, retention, confidence and criticality for the asset. The impact classification is typically used with reports that link to the asst such as incident reports.","title":"Asset Classifiers"},{"location":"patterns/metadata-manager/overview/#usage_8","text":"Classifiers help to make assets more findable. They also identify which assets should be treated to certain types of processing. For example, data fields marked as sensitive could be masked when added to a sandbox.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-feedback","text":"Feedback, such as comments, likes, star ratings and reviews can be added to an asset, typically by consumers of the asset to share experiences, expertise and concerns about the asset. The author of the feedback can choose whether it is public or private feedback. Public feedback is visible by everyone. Private feedback is visible to the author of the feedback and the owner of the asset. Feedback can only be changed by the author of the feedback. It can be added to an asset through Asset Consumer OMAS , Asset Owner OMAS and Digital Architecture OMAS .","title":"Asset Feedback"},{"location":"patterns/metadata-manager/overview/#usage_9","text":"Feedback helps to share expertise and use the experience of the assets' consumers to improve the quality of both the asset contents and its description.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-note-logs","text":"Note logs consist of a series of posts (called notes) that are added over time (like a blog). An asset's note log can be maintained through the Asset Owner OMAS , Digital Architecture OMAS and IT Infrastructure OMAS .","title":"Asset Note Logs"},{"location":"patterns/metadata-manager/overview/#usage_10","text":"Note logs can be used by the asset owner or operations team to post status or usage information about the asset to inform individuals who are using the asset of important information.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-external-descriptions","text":"Not everything that is known about an asset is stored in Egeria. There may be documents, web resources, images, videos and audio files that provide more detail. Through Asset Owner OMAS it is possible to add links to external resources and media.","title":"Asset External Descriptions"},{"location":"patterns/metadata-manager/overview/#usage_11","text":"Using the links to external resources, an individual is able to learn a lot more about the asset they are considering to use to complete their task.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#asset-lineage","text":"Lineage describes the origin of the data that is held by the asset. There are different perspectives on what is meant by 'origin'. In general an asset is being accessed by processes. They are either adding/updating/deleting data or reading it. So one perspective of lineage is to see the processes that are providing and using the asset. Data often flows from asset to asset via the processes, as they read data from one asset, do some processing and store the results in a different asset. The end-to-end flow of data is called an information supply chain. Information supply chains can be modeled and linked to the processes through the Digital Architecture OMAS . This offers more of an enterprise view of where the data originated from. The asset itself is hosted by a software capability that is part of a server. Another perspective on the asset's origin is the server capability that is hosting it. Software server capabilities can be linked to a solution component by the Digital Architecture OMAS . Solution components are descriptions produced by architects to document the purpose and behavior of a component. These descriptions add business context to the software server capability definitions. They are linked to the software server capability when it is deployed into the IT landscape. Similarly, the software server capability hosting an asset can be linked to the digital service it is a part of. Digital Services are anchors for information about the digital services (also known as offerings or products) that the organization is operating. This is a business view of the service that the asset is a part of. Finally, the asset can include identifiers of other metadata elements from the catalog and related properties in the AssetOrigin Classification. This includes: * Unique identifier ( GUID ) of the business capability that owns the asset. Examples of a business capabilities include \"Finance\", \"Human Resources\", \"Manufacturing\", \"Sales\", etc * Unique identifier ( GUID ) of the organization that owns the asset. This could be a unit within the organization or an external organization. Both organization and business capability information is maintained through the Community Profile OMAS and documented in the asset by the Asset Owner OMAS .","title":"Asset Lineage"},{"location":"patterns/metadata-manager/overview/#usage_12","text":"Lineage information helps consumers (individuals and/or automated processes) make choices about which is the appropriate asset to use for a certain task. It gives a sense of whether the asset contains data from an authoritative source/business capability/organization/process. Regulations that require specific types of reports often require lineage as well as the report to help the regulators validate that the report is correct.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#related-assets","text":"Related assets returns other assets that are linked together or are part of the same collection. Collections allow individuals and automated processes to maintain groups of related assets. For example, an individual may maintain a collection of their favorite assets. A project team may maintain a collection of the assets in use by the project. An automated process may use the retention classification to build a collection of assets that need to be archived. These types of collections are maintained through the following Open Metadata Access Services (OMASs): Asset Consumer OMAS Community Profile OMAS Project Management OMAS In addition, there are natural relationships between assets that are created as the asset is cataloged. For example, a file is related to the folder (also known as a directory) it is located in. Both the file and the folder could be assets in the asset catalog and they would be automatically linked together by the Asset Owner OMAS when these assets were created.","title":"Related Assets"},{"location":"patterns/metadata-manager/overview/#usage_13","text":"The related assets enables individuals or automated services to locate assets that are related. For example, a process may use the related assets to step through and process the cataloged files in a folder, or the assets in a specific collection.","title":"Usage"},{"location":"patterns/metadata-manager/overview/#manual-cataloguing","text":"Manual cataloging uses no automation beyond the management of the metadata once it is created. Individuals enter information about the assets into Egeria through tools that call Egeria's Open Metadata Access Services (OMASs). The Asset Owner OMAS is the principle interface for manual cataloging. It is possible to catalog any type of asset through this interface although it is biased towards cataloging data assets such as data stores, data feeds, files, data sets, APIs and events. In addition there are specific cataloging interfaces for particular types of subject matter expert. IT Infrastructure OMAS provides specialist interfaces for cataloging infrastructure such as servers, host systems and applications. Digital Architecture OMAS provides specialist interfaces for architects and integration engineers to manually catalog reference data sets and processes. Reference data sets are assets in their own right, and their content can be used as classifiers to augment the description of other assets. Processes are also assets that, when linked together, show the lineage of the assets they are partly responsible for maintaining.","title":"Manual cataloguing"},{"location":"patterns/metadata-manager/overview/#adding-automation","text":"Below are three types of automation to minimise the effort in managing your asset catalog. Templated cataloging - copying predefined assets. Integrated cataloging - automated extraction of metadata from third party technologies. Discovery and stewardship - analysis of asset contents to create metadata","title":"Adding automation"},{"location":"patterns/metadata-manager/overview/#scaling-the-asset-catalog-through-automation","text":"Automation is critical when it comes to managing an asset catalog. It reduces the administrative work of subject matter experts and asset owners, increases the reliability, reach and richness of the asset catalog whilst reducing the cost of its maintenance. Some automation is easy and reliable, particularly for information that can be extracted directly from the digital technologies used to implement the assets. Other automation involves analytics to create a candidate result that may need to be confirmed and approved by a subject matter expert. However, even when this human validation is necessary, the effort required is significantly less that manual maintenance of the catalog. Whenever subject matter experts are involved, it typically requires a change to their role in order to accommodate the time spent on the catalog. Often these experts are from a different part of the organization to the people receiving the benefit of their expertise, and so the organization's appreciation and use of the asset catalog needs to have matured to allow this to happen. Therefore as we look at the different types of automation, each comes with its own organizational maturity required to make it successful.","title":"Scaling the asset catalog through automation"},{"location":"patterns/metadata-manager/overview/#what-automation-is-possible","text":"Egeria offers the following approaches to cataloging assets: Manual cataloging - calling the access services to set up each asset. Templated cataloging - copying predefined assets. Integrated cataloging - automated extraction of metadata from third party technologies. Discovery and stewardship - analysis of asset contents to create metadata The idea is that these approaches are selected for each type of asset and blended together to balance the investment in the automation, against the time commitment of subject matter experts, against the business value of the resulting catalog.","title":"What automation is possible?"},{"location":"patterns/metadata-manager/overview/#asset-catalog-services","text":"Once the asset catalog is established, it can offer search interfaces through the following mechanisms. Asset Catalog OMAS provides support a comprehensive search interface for all types of asset. It is designed to support a catalog tool. Asset Consumer OMAS provides simple string-based searches for assets and their related information along with support to create connectors to access the content of the actual physical asset and browse through all of the information known about the asset. Digital Architecture OMAS provides specialist interfaces for querying reference data and processes. IT Infrastructure OMAS provides specialist catalog search capabilities for infrastructure such as servers, host systems and applications. Governance Program OMAS provides the ability to browse assets in a governance zone to assess the effectiveness of the governance program.","title":"Asset catalog services"},{"location":"patterns/metadata-manager/overview/#related-information","text":"The Asset page provides more information on the different types of assets supported by open metadata. The asset types can be extended dynamically if needed. The type definition for the Asset entity is found in model 0010 Basic Model . Examples of representing different types of assets using the open metadata types are found in Mapping Technology . The Open Metadata Labs provide practical examples showing all of the techniques to manage an asset catalog, allowing you to try each of the features to assess how they could work in your organization.","title":"Related information"},{"location":"release-notes/1-0/","text":"Release 1.0 (February 2019) \u00b6 Release 1.0 provides the open metadata integration and exchange between metadata repositories: The Open Connector Framework ( OCF ) provides standard interfaces for implementing connectors. These are used to access the data stored in Assets and to plug in platform capabilities into the Open Metadata Repository Services ( OMRS ). The implementation of the Open Metadata Repository Services ( OMRS ) . The repository services provide support for the open metadata types , the interfaces used by a repository technology the wants to support the open metadata protocols, the event management for open metadata replication and the cohort registration and management. The repository services can be used as embeddable libraries in technologies that wish to participate in an open metadata repository cohort . Egeria Implementation Status at Release 1.0 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":1.0},{"location":"release-notes/1-0/#release-10-february-2019","text":"Release 1.0 provides the open metadata integration and exchange between metadata repositories: The Open Connector Framework ( OCF ) provides standard interfaces for implementing connectors. These are used to access the data stored in Assets and to plug in platform capabilities into the Open Metadata Repository Services ( OMRS ). The implementation of the Open Metadata Repository Services ( OMRS ) . The repository services provide support for the open metadata types , the interfaces used by a repository technology the wants to support the open metadata protocols, the event management for open metadata replication and the cohort registration and management. The repository services can be used as embeddable libraries in technologies that wish to participate in an open metadata repository cohort .","title":"Release 1.0 (February 2019)"},{"location":"release-notes/1-0/#egeria-implementation-status-at-release-10","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 1.0"},{"location":"release-notes/1-1/","text":"Release 1.1 (November 2019) \u00b6 Release 1.1 focuses on establishing a secure, multi-tenant platform for metadata servers and governance servers. There is also a new JanusGraph based metadata repository. Below are the highlights: A persistent metadata repository based on JanusGraph. A multi-tenant OMAG Server Platform that is able to host one to many metadata servers and/or governance servers. This platform supports APIs to administer servers, start and stop servers and query their status. The platform offers a connector to change the store used for configuration documents and to control who can issue platform API calls. There are now tutorials and hands-on labs demonstrating the configuring and start up of servers on the OMAG Server Platform. The aim is to help people to get up and running with the Egeria technology. In addition, there are both docker scripts and Kubernetes helm charts to deploy the platforms and related technology used in the tutorials, samples and labs. Note that currently we do not push release specific docker containers to dockerhub. If you are using the docker/kubernetes environments it is recommended to work from the 'master' branch instead of this release. This will be addressed in a future release. The Open Metadata Repository Services ( OMRS ) shipped in the first release have been enhanced with REST APIs to query the cohorts that a server is connected to. There are also REST APIs to issue federated queries across the cohorts that a metadata server is connected to. There is a new user interface to explore the open metadata types. It is called the Type Explorer . Code fixes and changes to released function \u00b6 Release 1.1 fixes a problem in the open metadata cohort registration when there was a metadata server without a local repository. The wrong registration message was being used which meant that the registration details were not being properly distributed around the cohort. Release 1.1 changed the type of the AdditionalProperties from a map of String to Object to a map of String to String in order to match the open metadata types. There is a new property called ConfigurationProperties which is a map from String to Object. Release 1.1 changed the implementation of the data primitive type from a Java Date object to a Java Long object. This was to overcome a problem deserialization dates from JSON to Java. Egeria Implementation Status at Release 1.1 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":1.1},{"location":"release-notes/1-1/#release-11-november-2019","text":"Release 1.1 focuses on establishing a secure, multi-tenant platform for metadata servers and governance servers. There is also a new JanusGraph based metadata repository. Below are the highlights: A persistent metadata repository based on JanusGraph. A multi-tenant OMAG Server Platform that is able to host one to many metadata servers and/or governance servers. This platform supports APIs to administer servers, start and stop servers and query their status. The platform offers a connector to change the store used for configuration documents and to control who can issue platform API calls. There are now tutorials and hands-on labs demonstrating the configuring and start up of servers on the OMAG Server Platform. The aim is to help people to get up and running with the Egeria technology. In addition, there are both docker scripts and Kubernetes helm charts to deploy the platforms and related technology used in the tutorials, samples and labs. Note that currently we do not push release specific docker containers to dockerhub. If you are using the docker/kubernetes environments it is recommended to work from the 'master' branch instead of this release. This will be addressed in a future release. The Open Metadata Repository Services ( OMRS ) shipped in the first release have been enhanced with REST APIs to query the cohorts that a server is connected to. There are also REST APIs to issue federated queries across the cohorts that a metadata server is connected to. There is a new user interface to explore the open metadata types. It is called the Type Explorer .","title":"Release 1.1 (November 2019)"},{"location":"release-notes/1-1/#code-fixes-and-changes-to-released-function","text":"Release 1.1 fixes a problem in the open metadata cohort registration when there was a metadata server without a local repository. The wrong registration message was being used which meant that the registration details were not being properly distributed around the cohort. Release 1.1 changed the type of the AdditionalProperties from a map of String to Object to a map of String to String in order to match the open metadata types. There is a new property called ConfigurationProperties which is a map from String to Object. Release 1.1 changed the implementation of the data primitive type from a Java Date object to a Java Long object. This was to overcome a problem deserialization dates from JSON to Java.","title":"Code fixes and changes to released function"},{"location":"release-notes/1-1/#egeria-implementation-status-at-release-11","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 1.1"},{"location":"release-notes/1-2/","text":"Release 1.2 (December 2019) \u00b6 Release 1.2 provides the ability to build an asset catalog, search for assets and also access the data and function provided by these assets. It is also possible to group Assets into governance zones to control the discoverability and visibility of the Assets. In addition, we release the Egeria conformance test suite and four conformant repositories. Below are the highlights: A conformance test suite that validates implementations of open metadata repository connectors. In addition we are highlighting the repositories that are conformant. These are: The JanusGraph metadata repository . The In-memory metadata repository used for testing and demos. The Apache Atlas repository proxy . The IBM Information Governance Catalog repository proxy . There are new access services to support the cataloging of assets: The Asset Consumer OMAS supports the access to both the data and metadata associated with an asset. The Asset Owner OMAS supports the manual cataloging of new Assets. The assets cataloged by these access services can be scoped by governance zones. The metadata servers and future governance servers running on the OMAG Server Platform support metadata-centric security that is controlled by a connector. This connector can validate access to individual servers, services, and assets based on the identity of the caller and the service or asset they wish to access. The Open Metadata Repository Services ( OMRS ) have been enhanced to support support dynamic types and type patching. There is also function to load archives of metadata instances. There are tutorials , hands-on labs and samples demonstrating the new Asset cataloging capabilities. Egeria Implementation Status at Release 1.2 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":1.2},{"location":"release-notes/1-2/#release-12-december-2019","text":"Release 1.2 provides the ability to build an asset catalog, search for assets and also access the data and function provided by these assets. It is also possible to group Assets into governance zones to control the discoverability and visibility of the Assets. In addition, we release the Egeria conformance test suite and four conformant repositories. Below are the highlights: A conformance test suite that validates implementations of open metadata repository connectors. In addition we are highlighting the repositories that are conformant. These are: The JanusGraph metadata repository . The In-memory metadata repository used for testing and demos. The Apache Atlas repository proxy . The IBM Information Governance Catalog repository proxy . There are new access services to support the cataloging of assets: The Asset Consumer OMAS supports the access to both the data and metadata associated with an asset. The Asset Owner OMAS supports the manual cataloging of new Assets. The assets cataloged by these access services can be scoped by governance zones. The metadata servers and future governance servers running on the OMAG Server Platform support metadata-centric security that is controlled by a connector. This connector can validate access to individual servers, services, and assets based on the identity of the caller and the service or asset they wish to access. The Open Metadata Repository Services ( OMRS ) have been enhanced to support support dynamic types and type patching. There is also function to load archives of metadata instances. There are tutorials , hands-on labs and samples demonstrating the new Asset cataloging capabilities.","title":"Release 1.2 (December 2019)"},{"location":"release-notes/1-2/#egeria-implementation-status-at-release-12","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 1.2"},{"location":"release-notes/1-3/","text":"Release 1.3 (January 2020) \u00b6 Release 1.3 focuses on the support for open metadata archives, and formal versioning of open metadata types. It includes much of the ground-work for supporting design lineage and the detection and management of duplicate assets but that function is officially released in 1.4 . Below are the highlights of the 1.3 release: The hands-on labs have been updated to provide reusable Python functions for working with Egeria. The management of open metadata types includes formal versioning and patching of types. This makes it clearer where additions and updates are being made to the open metadata types. See open metadata types archive . There are the following changes to the open metadata types: The EmbeddedConnection has a new property called position . The OpenDiscoveryAnalysisReport has a new property called discoveryRequestStep . There is a new collection of Annotations for recording suspected duplicates and divergent values in acknowledged duplicates. This is to support the asset deduplication work scheduled for the next release. There are new open metadata archive utilities for creating your own open metadata archives. See the open connector archives and design model archives . The Conformance Suite Repository Workbench is now at Version 1.1, with the following enhancements: Tests for relationship searches have moved into a separate, optional RELATIONSHIP_SEARCH profile. A repository connector can be fully conformant with the (mandatory) METADATA_SHARING profile despite not supporting the findRelationshipsByProperty or findRelationshipsByPropertyValue methods. The ADVANCED_SEARCH profile is now divided into two profiles: ENTITY_ADVANCED _SEARCH and RELATIONSHIP_ADVANCED_SEARCH. They are both optional profiles. A repository connector can be fully conformant with the ENTITY_ADVANCED _SEARCH profile, despite not supporting either of the RELATIONSHIP_SEARCH or RELATIONSHIP_ADVANCED_SEARCH profiles. New test verify the correct handling of mappingProperties in the InstanceAuditHeader. The tests for 're-home' of a reference copy now use an instance mastered by a third (virtual) repository rather than the CTS Server's repository. Type verification of relationship end types now cater for connectors that do not support all the supertypes of an entity type. Search result checking is improved. The CTS notebook (under open-metadata-resources/open-metadata-labs) has been enhanced: The Conformance Profile Results cell there is additional reporting for the new profiles A new cell \"Polling for Status\" shows how to determine whether the repository-workbench has completed its synchronous tests. The new API it demonstrates could be used to support automated testing A new cell \"Monitoring Progress\" show how progress can be monitored based on workbench results retrieved during a test run. Improvements to HTTP response checking and reporting of errors Egeria Implementation Status at Release 1.3 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":1.3},{"location":"release-notes/1-3/#release-13-january-2020","text":"Release 1.3 focuses on the support for open metadata archives, and formal versioning of open metadata types. It includes much of the ground-work for supporting design lineage and the detection and management of duplicate assets but that function is officially released in 1.4 . Below are the highlights of the 1.3 release: The hands-on labs have been updated to provide reusable Python functions for working with Egeria. The management of open metadata types includes formal versioning and patching of types. This makes it clearer where additions and updates are being made to the open metadata types. See open metadata types archive . There are the following changes to the open metadata types: The EmbeddedConnection has a new property called position . The OpenDiscoveryAnalysisReport has a new property called discoveryRequestStep . There is a new collection of Annotations for recording suspected duplicates and divergent values in acknowledged duplicates. This is to support the asset deduplication work scheduled for the next release. There are new open metadata archive utilities for creating your own open metadata archives. See the open connector archives and design model archives . The Conformance Suite Repository Workbench is now at Version 1.1, with the following enhancements: Tests for relationship searches have moved into a separate, optional RELATIONSHIP_SEARCH profile. A repository connector can be fully conformant with the (mandatory) METADATA_SHARING profile despite not supporting the findRelationshipsByProperty or findRelationshipsByPropertyValue methods. The ADVANCED_SEARCH profile is now divided into two profiles: ENTITY_ADVANCED _SEARCH and RELATIONSHIP_ADVANCED_SEARCH. They are both optional profiles. A repository connector can be fully conformant with the ENTITY_ADVANCED _SEARCH profile, despite not supporting either of the RELATIONSHIP_SEARCH or RELATIONSHIP_ADVANCED_SEARCH profiles. New test verify the correct handling of mappingProperties in the InstanceAuditHeader. The tests for 're-home' of a reference copy now use an instance mastered by a third (virtual) repository rather than the CTS Server's repository. Type verification of relationship end types now cater for connectors that do not support all the supertypes of an entity type. Search result checking is improved. The CTS notebook (under open-metadata-resources/open-metadata-labs) has been enhanced: The Conformance Profile Results cell there is additional reporting for the new profiles A new cell \"Polling for Status\" shows how to determine whether the repository-workbench has completed its synchronous tests. The new API it demonstrates could be used to support automated testing A new cell \"Monitoring Progress\" show how progress can be monitored based on workbench results retrieved during a test run. Improvements to HTTP response checking and reporting of errors","title":"Release 1.3 (January 2020)"},{"location":"release-notes/1-3/#egeria-implementation-status-at-release-13","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 1.3"},{"location":"release-notes/1-4/","text":"Release 1.4 (February 2020) \u00b6 Release 1.4 focused on bug fixes and documentation. Egeria Implementation Status at Release 1.4 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":1.4},{"location":"release-notes/1-4/#release-14-february-2020","text":"Release 1.4 focused on bug fixes and documentation.","title":"Release 1.4 (February 2020)"},{"location":"release-notes/1-4/#egeria-implementation-status-at-release-14","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 1.4"},{"location":"release-notes/1-5/","text":"Release 1.5 (March 2020) \u00b6 Release 1.5 delivers the automatic metadata discovery of duplicate assets. Additional, in Tech Preview, Data Engine OMAS , and a data engine proxy server. Released Components \u00b6 The first governance server is released: The Discovery Server supports the scanning of assets and the notification when duplicate suspects are detected. This server is supported by: * The Discovery Engine OMAS supports the detection, recording and notification of exceptions and duplicate suspects. The Open Discovery Framework ( ODF ) is now defined and implemented to support the interfaces for automated discovery services. It complements the Open Connector Framework ( OCF ) delivered in release 1.0. There are new tutorials , hands-on labs and samples demonstrating the new de-duplication detection features. Technical Previews \u00b6 The Data Engine OMAS supports the processing of notifications from data engines such as ETL platforms in order to catalog information about the data movement, transformation and copying they are engaged in. The Data Engine Proxy Server is also included in the technical preview. It supports the polling of data engines such as ETL platforms in order to catalog information about the data movement, transformation and copying they are engaged in. It calls the Data Engine OMAS . Egeria Implementation Status at Release 1.5 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":1.5},{"location":"release-notes/1-5/#release-15-march-2020","text":"Release 1.5 delivers the automatic metadata discovery of duplicate assets. Additional, in Tech Preview, Data Engine OMAS , and a data engine proxy server.","title":"Release 1.5 (March 2020)"},{"location":"release-notes/1-5/#released-components","text":"The first governance server is released: The Discovery Server supports the scanning of assets and the notification when duplicate suspects are detected. This server is supported by: * The Discovery Engine OMAS supports the detection, recording and notification of exceptions and duplicate suspects. The Open Discovery Framework ( ODF ) is now defined and implemented to support the interfaces for automated discovery services. It complements the Open Connector Framework ( OCF ) delivered in release 1.0. There are new tutorials , hands-on labs and samples demonstrating the new de-duplication detection features.","title":"Released Components"},{"location":"release-notes/1-5/#technical-previews","text":"The Data Engine OMAS supports the processing of notifications from data engines such as ETL platforms in order to catalog information about the data movement, transformation and copying they are engaged in. The Data Engine Proxy Server is also included in the technical preview. It supports the polling of data engines such as ETL platforms in order to catalog information about the data movement, transformation and copying they are engaged in. It calls the Data Engine OMAS .","title":"Technical Previews"},{"location":"release-notes/1-5/#egeria-implementation-status-at-release-15","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 1.5"},{"location":"release-notes/1-6/","text":"Release 1.6 (April 2020) \u00b6 Release 1.6 adds support for: * Audit Log Framework ( ALF ) technical preview * Repository Explorer (REX) Below are the highlights: There is a new framework: The Audit Log Framework ( ALF ) provides interface definitions and classes to enable connectors to support natural language enabled diagnostics such as exception messages and audit log messages. There is a new user interface module: The Repository Explorer (Rex) can help you explore and visualize the metadata in a repository. It retrieves entities and relationships from the repository and displays them. A details panel also shows the properties and other information about an object. Each entity or relationship is added to a network diagram, which shows how they are connected. The Swagger-based API documentation for the Egeria server chassis has been reorganized to align with our modules structure & to provide links into our other documentation which also will clarify if the module is released, in Tech Preview, or still in development. The docs can be found at https://<server>:<port>/swagger-ui.htm . Further enhancements will follow in future releases. Many dependencies have been updated including: Kafka client upgraded to 2.4.1 Spring updated to 5.2.4, spring boot to 2.2.5 & other spring components accordingly. For a full list refer to the git commit logs. Egeria Implementation Status at Release 1.6 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":1.6},{"location":"release-notes/1-6/#release-16-april-2020","text":"Release 1.6 adds support for: * Audit Log Framework ( ALF ) technical preview * Repository Explorer (REX) Below are the highlights: There is a new framework: The Audit Log Framework ( ALF ) provides interface definitions and classes to enable connectors to support natural language enabled diagnostics such as exception messages and audit log messages. There is a new user interface module: The Repository Explorer (Rex) can help you explore and visualize the metadata in a repository. It retrieves entities and relationships from the repository and displays them. A details panel also shows the properties and other information about an object. Each entity or relationship is added to a network diagram, which shows how they are connected. The Swagger-based API documentation for the Egeria server chassis has been reorganized to align with our modules structure & to provide links into our other documentation which also will clarify if the module is released, in Tech Preview, or still in development. The docs can be found at https://<server>:<port>/swagger-ui.htm . Further enhancements will follow in future releases. Many dependencies have been updated including: Kafka client upgraded to 2.4.1 Spring updated to 5.2.4, spring boot to 2.2.5 & other spring components accordingly. For a full list refer to the git commit logs.","title":"Release 1.6 (April 2020)"},{"location":"release-notes/1-6/#egeria-implementation-status-at-release-16","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 1.6"},{"location":"release-notes/1-7/","text":"Release 1.7 (May 2020) \u00b6 Release 1.7 contains many bug fixes & preparatory development work for future new features. Below are the highlights: There is support for loading standard glossaries and design models coded in OWL/JSON-LD into the open metadata ecosystem. The input file is converted to an Open Metadata Archive which can be loaded directly into a metadata server. Many dependencies have been updated including: Kafka client upgraded to 2.5 Spring security updated to 5.3.1, spring boot,data to 2.2.6, spring to 5.2.5 For a full list refer to the git commit logs. Known Issues \u00b6 (https://github.com/odpi/egeria/issues/2935)[2935] - Governance Engine OMAS reports exception when entities added (https://github.com/odpi/egeria/issues/3005)[3005] - Occasional failure in 'Building a Data Catalog' notebook Egeria Implementation Status at Release 1.7 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":1.7},{"location":"release-notes/1-7/#release-17-may-2020","text":"Release 1.7 contains many bug fixes & preparatory development work for future new features. Below are the highlights: There is support for loading standard glossaries and design models coded in OWL/JSON-LD into the open metadata ecosystem. The input file is converted to an Open Metadata Archive which can be loaded directly into a metadata server. Many dependencies have been updated including: Kafka client upgraded to 2.5 Spring security updated to 5.3.1, spring boot,data to 2.2.6, spring to 5.2.5 For a full list refer to the git commit logs.","title":"Release 1.7 (May 2020)"},{"location":"release-notes/1-7/#known-issues","text":"(https://github.com/odpi/egeria/issues/2935)[2935] - Governance Engine OMAS reports exception when entities added (https://github.com/odpi/egeria/issues/3005)[3005] - Occasional failure in 'Building a Data Catalog' notebook","title":"Known Issues"},{"location":"release-notes/1-7/#egeria-implementation-status-at-release-17","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 1.7"},{"location":"release-notes/1-8/","text":"Release 1.8 (June 2020) \u00b6 Below are the highlights of Release 1.8: New tutorial information has been added in the form of the Egeria Dojo Usability & Capability improvements to Repository Explorer Samples & utilities are now also packaged into jars with dependencies to make them easier to use (java -jar) Connections to kafka will now retry to improve availability. See 'Bring up Issues' in the connector documentation \\ New dependencies has been included: Spring Boot Actuator - Provides features to help you monitor and manage your application when you push it to production micrometer-registry-prometheus - Exposes metrics in a format that can be scraped by a Prometheus server Many dependencies have been updated. The most relevant include: Spring has been updated to 5.2.6 Spring Boot, Spring Security, Spring Security, Spring Data have been updated to 2.3.0 Egeria Implementation Status at Release 1.8 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":1.8},{"location":"release-notes/1-8/#release-18-june-2020","text":"Below are the highlights of Release 1.8: New tutorial information has been added in the form of the Egeria Dojo Usability & Capability improvements to Repository Explorer Samples & utilities are now also packaged into jars with dependencies to make them easier to use (java -jar) Connections to kafka will now retry to improve availability. See 'Bring up Issues' in the connector documentation \\ New dependencies has been included: Spring Boot Actuator - Provides features to help you monitor and manage your application when you push it to production micrometer-registry-prometheus - Exposes metrics in a format that can be scraped by a Prometheus server Many dependencies have been updated. The most relevant include: Spring has been updated to 5.2.6 Spring Boot, Spring Security, Spring Security, Spring Data have been updated to 2.3.0","title":"Release 1.8 (June 2020)"},{"location":"release-notes/1-8/#egeria-implementation-status-at-release-18","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 1.8"},{"location":"release-notes/2-0/","text":"Release 2.0 (July 2020) \u00b6 Release 2.0 adds support for: Encryption by default (HTTPS/SSL, encrypted configuration file) bug fixes dependency updates Below are the highlights: The Egeria server chassis default URL is now https://localhost:9443 - the server now listens on port 9443 and supports https only. All clients have been updated accordingly. At this point SSL certificate validation is disabled. This will be enabled in a future release. Docker containers, docker-compose scripts, kubernetes deployments have all been updated to use https accordingly. The Encrypted Configuration File Store Connector is now used by default to ensure security of sensitive configuration details like credentials. Egeria Implementation Status at Release 2.0 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":2.0},{"location":"release-notes/2-0/#release-20-july-2020","text":"Release 2.0 adds support for: Encryption by default (HTTPS/SSL, encrypted configuration file) bug fixes dependency updates Below are the highlights: The Egeria server chassis default URL is now https://localhost:9443 - the server now listens on port 9443 and supports https only. All clients have been updated accordingly. At this point SSL certificate validation is disabled. This will be enabled in a future release. Docker containers, docker-compose scripts, kubernetes deployments have all been updated to use https accordingly. The Encrypted Configuration File Store Connector is now used by default to ensure security of sensitive configuration details like credentials.","title":"Release 2.0 (July 2020)"},{"location":"release-notes/2-0/#egeria-implementation-status-at-release-20","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.0"},{"location":"release-notes/2-1/","text":"Release 2.1 (August 2020) \u00b6 Release 2.1 primarily contains bug fixes and preparatory work for future capabilities. A full list of changes can be seen by comparing on github . The highlights include: Bug fixes Subject Area OMAS has added testing including automated FVTs, code cleanup & bug fixes User Interface fixes & usability improvements Dependency Updates Spring updated to 5.2.8 additional dependencies to remain current Egeria Implementation Status at Release 2.1 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":2.1},{"location":"release-notes/2-1/#release-21-august-2020","text":"Release 2.1 primarily contains bug fixes and preparatory work for future capabilities. A full list of changes can be seen by comparing on github . The highlights include: Bug fixes Subject Area OMAS has added testing including automated FVTs, code cleanup & bug fixes User Interface fixes & usability improvements Dependency Updates Spring updated to 5.2.8 additional dependencies to remain current","title":"Release 2.1 (August 2020)"},{"location":"release-notes/2-1/#egeria-implementation-status-at-release-21","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.1"},{"location":"release-notes/2-10/","text":"Release 2.10 (June 2021) \u00b6 Release 2.10 adds: * New and improved open metadata types for governance * New API for Governance Program OMAS See also an important notice about removal of Java 8 support in a future release. Details of these and other changes are in the sections that follow. Description of Changes \u00b6 Metadata Types \u00b6 Correction to the Campaign classification. The Campaign classification is supposed to connect to a Project entity to indicate the project is a grouping of a series of projects designed to achieve a large goal. Unfortunately it was coded to connect to the Collection entity. In 2.10, the Campaign classification has been changed to attach to Referenceable to allow it to be connected to Project without affecting backward compatibility. See new type description in model 0130 . Extension of the UsedInContext relationship. The UsedInContext relationship linked two GlossaryTerm entities together to show that one glossary term described the context in which the other was valid. This relationship has been updated to allow the end that describes the context to be a Referenceable . This means that the context where glossary terms are valid can be expressed as elements such as projects, business capabilities, parts of an organization, subject areas, zones and many more. See new type description in model 0360 . Allowing ownership to be expressed as a PersonRole . Issue #5104 described the problem that the governance open metadata types allowed owners to be expressed as PersonalProfile or UserIdentity entities. The properties did not identify if the owner was identified as a GUID or as a qualifiedName. In 2.10, a new classification for expressing ownership called, not surprisingly, Ownership , was introduced which allows and type and property name for the owner to be specified with the owner's identifier. The types for entities such as GovernanceActionType and IncidentReport that include ownership properties in them have been updated to deprecate these properties in favor of using the Ownership classification. The AssetOwnership classification is also deprecated. See new type description in model 0445 . Update to Certification relationship. The Certification relationship supports the identification of the people involved in the certification of an element. 2.10 adds new attributes to specify the type and property names of the identifier used to identify these people. This is consistent with the new Ownership classification. See new type descriptions in model 0482 . Update to License relationship. The License relationship supports the identification of the people involved in the licencing of an element. 2.10 adds new attributes to specify the type and property names of the identifier used to identify these people. This is consistent with the new Ownership classification. See new type descriptions in model 0481 . Governance role updates. The GovernanceOfficer entity now inherits from GovernanceRole rather than PersonRole . This means it is just another governance role that can be linked with GovernanceResponsibility definitions. In addition there are new types for different types of owners. These are ComponentOwner and DataItemOwner . See new type descriptions in model 0445 . Extend the GovernanceResponsibilityAssignment The GovernanceResponsibilityAssignment relationship identifies the responsibilities for a particular role. It used to link to a GovernanceRole and in 2.10, it has been updated to link to a PersonRole . This means that governance responsibilities can be added to any role, such as ProjectManager and CommunityMember , rather than just specialized governance roles. See new type descriptions in model 0445 . Deprecating the domain attribute in various governance types. The domain attribute is typed by the GovernanceDomain enum. This provides a fixed list of governance domains. An extensible mechanism for expressing the governance domain was added in release 2.4 using the GovernanceDomainDescription entity and the domainIdentifier attribute. In this release, the use of domain is deprecated in GovernanceDefinition , GovernanceZone , SubjectAreaDefinition , GovernanceMetric , GovernanceRole and GovernanceOfficer . See new type descriptions in model 0401 . Extensions to governance drivers. There are now new subtypes of the GovernanceDriver entity called RegulationArticle and BusinessImperative . It is also possible to link governance drivers using the new GovernanceDriverLink relationship. See new type descriptions in model 0405 . Update to AssetOrigin classification. The AssetOrigin classification supports the identification of the origin of an asset. This can be in terms of the organization, business capability and other values. 2.10 adds new attributes to identify if the organization or business capability is identified by its GUID or qualifiedName. See new type descriptions in model 0440 . Improve IncidentClassifiers. If is possible to define multiple sets of IncidentClassifier values that can be used on IncidentReport entities to help to group and prioritize them. The IncidentClassifier entity now inherits from Referencable and there is a new classification called IncidentClassifierSet to mark a Collection entity as containing IncidentClassifier definitions. See new type descriptions in model 0470 . Deprecation of ResponsibilityStaffContact . The ResponsibilityStaffContact relationship has been deprecated in favor of the GovernanceResponsibilityAssignment relationship. New Services for Governance Program OMAS \u00b6 The APIs defined for Governance Program OMAS have been updated to reflect the changes to the open metadata types described above. The APIs and client implementations are in place. The server-side is coming in a future release. Bug fixes and other updates \u00b6 Additional Bug Fixes Cascaded deletes for entities grouped using the Anchors classification are now deleting the correct entities. Prior to this release, some entities were missed and others were deleted incorrectly. Dependency Updates For details on both see the commit history in GitHub. Known Issues \u00b6 It is recommended to use a chromium-based browser such as Google Chrome or Microsoft Edge, or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . When running the 'Understanding Platform Services' lab, ensure you run the 'egeria-service-config' notebook first and do not restart the python kernel before running this lab. See #4842 . When logging in to the react UI for the coco pharma lab demo, ensure to use http://myhost.mydomain/coco/login as otherwise the login will not work. see odpi/egeria#41 A few further bugs are noted at https://github.com/odpi/egeria/issues/5211#issuecomment-850321243 including for samples and UI. Removal of Java 8 Support \u00b6 Egeria will drop support for Java 8 in a forthcoming release within the next few months. We have been building and testing with Java 11 for over a year and will move to build all packages with Java 11, and require Java 11. At this point Java 8 will no longer be supported for new releases. Egeria Implementation Status at Release 2.10 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content. Further Help and Support \u00b6 See the Community Guide .","title":"2.10"},{"location":"release-notes/2-10/#release-210-june-2021","text":"Release 2.10 adds: * New and improved open metadata types for governance * New API for Governance Program OMAS See also an important notice about removal of Java 8 support in a future release. Details of these and other changes are in the sections that follow.","title":"Release 2.10 (June 2021)"},{"location":"release-notes/2-10/#description-of-changes","text":"","title":"Description of Changes"},{"location":"release-notes/2-10/#metadata-types","text":"Correction to the Campaign classification. The Campaign classification is supposed to connect to a Project entity to indicate the project is a grouping of a series of projects designed to achieve a large goal. Unfortunately it was coded to connect to the Collection entity. In 2.10, the Campaign classification has been changed to attach to Referenceable to allow it to be connected to Project without affecting backward compatibility. See new type description in model 0130 . Extension of the UsedInContext relationship. The UsedInContext relationship linked two GlossaryTerm entities together to show that one glossary term described the context in which the other was valid. This relationship has been updated to allow the end that describes the context to be a Referenceable . This means that the context where glossary terms are valid can be expressed as elements such as projects, business capabilities, parts of an organization, subject areas, zones and many more. See new type description in model 0360 . Allowing ownership to be expressed as a PersonRole . Issue #5104 described the problem that the governance open metadata types allowed owners to be expressed as PersonalProfile or UserIdentity entities. The properties did not identify if the owner was identified as a GUID or as a qualifiedName. In 2.10, a new classification for expressing ownership called, not surprisingly, Ownership , was introduced which allows and type and property name for the owner to be specified with the owner's identifier. The types for entities such as GovernanceActionType and IncidentReport that include ownership properties in them have been updated to deprecate these properties in favor of using the Ownership classification. The AssetOwnership classification is also deprecated. See new type description in model 0445 . Update to Certification relationship. The Certification relationship supports the identification of the people involved in the certification of an element. 2.10 adds new attributes to specify the type and property names of the identifier used to identify these people. This is consistent with the new Ownership classification. See new type descriptions in model 0482 . Update to License relationship. The License relationship supports the identification of the people involved in the licencing of an element. 2.10 adds new attributes to specify the type and property names of the identifier used to identify these people. This is consistent with the new Ownership classification. See new type descriptions in model 0481 . Governance role updates. The GovernanceOfficer entity now inherits from GovernanceRole rather than PersonRole . This means it is just another governance role that can be linked with GovernanceResponsibility definitions. In addition there are new types for different types of owners. These are ComponentOwner and DataItemOwner . See new type descriptions in model 0445 . Extend the GovernanceResponsibilityAssignment The GovernanceResponsibilityAssignment relationship identifies the responsibilities for a particular role. It used to link to a GovernanceRole and in 2.10, it has been updated to link to a PersonRole . This means that governance responsibilities can be added to any role, such as ProjectManager and CommunityMember , rather than just specialized governance roles. See new type descriptions in model 0445 . Deprecating the domain attribute in various governance types. The domain attribute is typed by the GovernanceDomain enum. This provides a fixed list of governance domains. An extensible mechanism for expressing the governance domain was added in release 2.4 using the GovernanceDomainDescription entity and the domainIdentifier attribute. In this release, the use of domain is deprecated in GovernanceDefinition , GovernanceZone , SubjectAreaDefinition , GovernanceMetric , GovernanceRole and GovernanceOfficer . See new type descriptions in model 0401 . Extensions to governance drivers. There are now new subtypes of the GovernanceDriver entity called RegulationArticle and BusinessImperative . It is also possible to link governance drivers using the new GovernanceDriverLink relationship. See new type descriptions in model 0405 . Update to AssetOrigin classification. The AssetOrigin classification supports the identification of the origin of an asset. This can be in terms of the organization, business capability and other values. 2.10 adds new attributes to identify if the organization or business capability is identified by its GUID or qualifiedName. See new type descriptions in model 0440 . Improve IncidentClassifiers. If is possible to define multiple sets of IncidentClassifier values that can be used on IncidentReport entities to help to group and prioritize them. The IncidentClassifier entity now inherits from Referencable and there is a new classification called IncidentClassifierSet to mark a Collection entity as containing IncidentClassifier definitions. See new type descriptions in model 0470 . Deprecation of ResponsibilityStaffContact . The ResponsibilityStaffContact relationship has been deprecated in favor of the GovernanceResponsibilityAssignment relationship.","title":"Metadata Types"},{"location":"release-notes/2-10/#new-services-for-governance-program-omas","text":"The APIs defined for Governance Program OMAS have been updated to reflect the changes to the open metadata types described above. The APIs and client implementations are in place. The server-side is coming in a future release.","title":"New Services for Governance Program OMAS"},{"location":"release-notes/2-10/#bug-fixes-and-other-updates","text":"Additional Bug Fixes Cascaded deletes for entities grouped using the Anchors classification are now deleting the correct entities. Prior to this release, some entities were missed and others were deleted incorrectly. Dependency Updates For details on both see the commit history in GitHub.","title":"Bug fixes and other updates"},{"location":"release-notes/2-10/#known-issues","text":"It is recommended to use a chromium-based browser such as Google Chrome or Microsoft Edge, or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . When running the 'Understanding Platform Services' lab, ensure you run the 'egeria-service-config' notebook first and do not restart the python kernel before running this lab. See #4842 . When logging in to the react UI for the coco pharma lab demo, ensure to use http://myhost.mydomain/coco/login as otherwise the login will not work. see odpi/egeria#41 A few further bugs are noted at https://github.com/odpi/egeria/issues/5211#issuecomment-850321243 including for samples and UI.","title":"Known Issues"},{"location":"release-notes/2-10/#removal-of-java-8-support","text":"Egeria will drop support for Java 8 in a forthcoming release within the next few months. We have been building and testing with Java 11 for over a year and will move to build all packages with Java 11, and require Java 11. At this point Java 8 will no longer be supported for new releases.","title":"Removal of Java 8 Support"},{"location":"release-notes/2-10/#egeria-implementation-status-at-release-210","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.10"},{"location":"release-notes/2-10/#further-help-and-support","text":"See the Community Guide .","title":"Further Help and Support"},{"location":"release-notes/2-11/","text":"2.11 (July 2021) \u00b6 Special note on Java support This is expected to be the last release supporting Java 8. The next release will commence the 3.x series of releases and will require Java 11. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes Multiple topics for a cohort An open metadata repository cohort uses three types of events to enable peer-to-peer sharing of metadata. In previous releases, these events have all been exchanged through a single event topic. Release 2.11 provides the option for a cohort to use a dedicated topic for each type of event. This improves the time to register a new member in the cohort and allows multiple instances of a metadata access server to access the cohort. Details of these new options can be found in the administration guide . Data Manager OMAS extension to support capture of event metadata The Data Manager OMAS has been extended to support the capture of metadata from Event Brokers such as Apache Kafka and API Managers such as an API Gateway. There are two new associated Open Metadata Integration Services (OMISs) to support integration connectors that extract metadata from these types of data managers: Topic Integrator OMIS supports integration connectors extracting metadata from Event Brokers. API Integrator OMIS supports integration connectors extracting API information from API managers. For more information on the use of the Data Manager OMAS with these integration services, see the Data Manager Integration solution. Information View OMAS , Virtualization Services, Security Officer Services, Gaian connector The following capabilities have now been removed (they were previously deprecated and/or in not in 'Released' status): Information View OMAS Virtualization Services and associated connectors Security Officer Services, Security sync services and associated connectors including for Apache Ranger Gaian database connector and additional authentication/impersonation support Much of the above capability can be implemented via Integration Services . Hadoop specifics may be developed in the future within the Egeria Hadoop GitHub repository. For more details of this change see #5314 . Data Platform Services, Data Platform OMAS , and Cassandra connectors Similarly, the following services have been deleted: Data Platform Services and Data Platform OMAS . For more details see #5344 . Data Platform capabilities are already available in Database Integrator and Files Integrator already part of Integration Services. Cassandra connectors: cassandra-data-store-connector and cassandra-metadata-extractor-connector will be introduced back in the Data Connectors GitHub repository. For more information see #2671 . Type changes: added, modified, deprecated APIManager, EventBroker New types for APIManager and EventBroker . These types inherit from SoftwareServerCapability . These are used in the new Data Manager OMAS APIs. See new type descriptions in model 0050 . Threat And a relationship to connect a GovernanceDefinition with a metadata element that defines the scope where it is applicable. See new type descriptions in models 0401 and 0405 . TabularFileColumn A new subtype for TabularColumn called TabularFileColumn is added to be able to distinguish between tabular columns from files and RelationalColumn (which also inherits from TabularColumn ). See type descriptions in model 0530 . EventTypeList New type called EventTypeList to allow a list of event types to be associated with a topic and a specific subtype of SchemaAttribute for an attribute in an event type to make it easier to search for data fields that are exclusively found in events. See new type descriptions in model 0535 . APIParameter, APIOperation New types for APIParameter to allow the capture of properties related to the API's treatment of the parameters. There are also properties for APIOperation . See new type descriptions in model 0536 . Types for display of data to end users New types for DisplayDataSchemaType , DisplayDataContainer , DisplayDataField , QuerySchemaType , QueryDataContainer and QueryDataField to allow the capture of properties related to the display of data to end users. See new type descriptions in model 0537 . RelationalTableType Updated supertype of RelationalTableType to inherit from ComplexSchemaType rather than TabularColumnType since TabularColumnType is now deprecated. See type descriptions in model 0534 . Asset properties A number of properties that where originally defined in Asset were moved to classifications to allow them to be managed independently of the original asset. This occurred before the TypeDefPatch support was in place and so these properties were not marked as deprecated at that time. In 2.11, this deprecation has now been officially recorded in the Asset TypeDef. The properties are: owner - now captured in the Ownership classification ownerType - also captured in the Ownership classification zoneMembership - now captured in the AssetZoneMembership classification latestChange - now captures]d in the LatestChange classification See new type description in model 0010 . TabularColumnType Deprecated type called TabularColumnType because it restricts tabular columns to primitive types when it could be a literal for example. See type descriptions in model 0530 . SimpleDocumentType, StructDocumentType, MapDocumentType Deprecated types called SimpleDocumentType , StructDocumentType and MapDocumentType because they offer little value since the type is typically stored in the TypeEmbeddedAttribute classification. This change makes the document schemas consistent with other types of schema. See type descriptions in model 0531 . TermISATypeOFRelationship Deprecated TermISATypeOFRelationship because the ends are defined the wrong way round. When visualizing end1 should point to end2. This relationship incorrectly has the super type pointing to the subtype. Use the new IsATypeOfRelationship instead to represent an is-a-type-of relationship between two spine objects. See new type descriptions in model 0380 . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":2.11},{"location":"release-notes/2-11/#211-july-2021","text":"Special note on Java support This is expected to be the last release supporting Java 8. The next release will commence the 3.x series of releases and will require Java 11. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes Multiple topics for a cohort An open metadata repository cohort uses three types of events to enable peer-to-peer sharing of metadata. In previous releases, these events have all been exchanged through a single event topic. Release 2.11 provides the option for a cohort to use a dedicated topic for each type of event. This improves the time to register a new member in the cohort and allows multiple instances of a metadata access server to access the cohort. Details of these new options can be found in the administration guide . Data Manager OMAS extension to support capture of event metadata The Data Manager OMAS has been extended to support the capture of metadata from Event Brokers such as Apache Kafka and API Managers such as an API Gateway. There are two new associated Open Metadata Integration Services (OMISs) to support integration connectors that extract metadata from these types of data managers: Topic Integrator OMIS supports integration connectors extracting metadata from Event Brokers. API Integrator OMIS supports integration connectors extracting API information from API managers. For more information on the use of the Data Manager OMAS with these integration services, see the Data Manager Integration solution. Information View OMAS , Virtualization Services, Security Officer Services, Gaian connector The following capabilities have now been removed (they were previously deprecated and/or in not in 'Released' status): Information View OMAS Virtualization Services and associated connectors Security Officer Services, Security sync services and associated connectors including for Apache Ranger Gaian database connector and additional authentication/impersonation support Much of the above capability can be implemented via Integration Services . Hadoop specifics may be developed in the future within the Egeria Hadoop GitHub repository. For more details of this change see #5314 . Data Platform Services, Data Platform OMAS , and Cassandra connectors Similarly, the following services have been deleted: Data Platform Services and Data Platform OMAS . For more details see #5344 . Data Platform capabilities are already available in Database Integrator and Files Integrator already part of Integration Services. Cassandra connectors: cassandra-data-store-connector and cassandra-metadata-extractor-connector will be introduced back in the Data Connectors GitHub repository. For more information see #2671 . Type changes: added, modified, deprecated APIManager, EventBroker New types for APIManager and EventBroker . These types inherit from SoftwareServerCapability . These are used in the new Data Manager OMAS APIs. See new type descriptions in model 0050 . Threat And a relationship to connect a GovernanceDefinition with a metadata element that defines the scope where it is applicable. See new type descriptions in models 0401 and 0405 . TabularFileColumn A new subtype for TabularColumn called TabularFileColumn is added to be able to distinguish between tabular columns from files and RelationalColumn (which also inherits from TabularColumn ). See type descriptions in model 0530 . EventTypeList New type called EventTypeList to allow a list of event types to be associated with a topic and a specific subtype of SchemaAttribute for an attribute in an event type to make it easier to search for data fields that are exclusively found in events. See new type descriptions in model 0535 . APIParameter, APIOperation New types for APIParameter to allow the capture of properties related to the API's treatment of the parameters. There are also properties for APIOperation . See new type descriptions in model 0536 . Types for display of data to end users New types for DisplayDataSchemaType , DisplayDataContainer , DisplayDataField , QuerySchemaType , QueryDataContainer and QueryDataField to allow the capture of properties related to the display of data to end users. See new type descriptions in model 0537 . RelationalTableType Updated supertype of RelationalTableType to inherit from ComplexSchemaType rather than TabularColumnType since TabularColumnType is now deprecated. See type descriptions in model 0534 . Asset properties A number of properties that where originally defined in Asset were moved to classifications to allow them to be managed independently of the original asset. This occurred before the TypeDefPatch support was in place and so these properties were not marked as deprecated at that time. In 2.11, this deprecation has now been officially recorded in the Asset TypeDef. The properties are: owner - now captured in the Ownership classification ownerType - also captured in the Ownership classification zoneMembership - now captured in the AssetZoneMembership classification latestChange - now captures]d in the LatestChange classification See new type description in model 0010 . TabularColumnType Deprecated type called TabularColumnType because it restricts tabular columns to primitive types when it could be a literal for example. See type descriptions in model 0530 . SimpleDocumentType, StructDocumentType, MapDocumentType Deprecated types called SimpleDocumentType , StructDocumentType and MapDocumentType because they offer little value since the type is typically stored in the TypeEmbeddedAttribute classification. This change makes the document schemas consistent with other types of schema. See type descriptions in model 0531 . TermISATypeOFRelationship Deprecated TermISATypeOFRelationship because the ends are defined the wrong way round. When visualizing end1 should point to end2. This relationship incorrectly has the super type pointing to the subtype. Use the new IsATypeOfRelationship instead to represent an is-a-type-of relationship between two spine objects. See new type descriptions in model 0380 . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":"2.11 (July 2021)"},{"location":"release-notes/2-2/","text":"Release 2.2 (September 2020) \u00b6 Below are the highlights of this release: Additional connectors are now placed in our assembly under server/lib without dependencies. If you need to use a connector that requires additional dependencies that are not already part of the server chassis, you will need to add those libraries here. The docker image has been updated to use a later openjdk alpine base image due to incompatibilities with our JanusGraph support in the old images for java 8. In the VDC chart, 2 new values have been added, 'ibmigc.connectorversion' and 'atlas.connectorversion'. In this release these are set to use the 2.1 connectors, since the connectors run to a different release cycle than the main Egeria code. Once new connectors are released you can update these values to get the latest connectors Further code to support lineage has been added, but in this release it remains in development and is not yet ready for use in production. User interface improvements. Ongoing bug fixes and refactoring especially in subject-area omas. Known Issues \u00b6 In the VDC helm chart, the Apache Atlas initialization job fails to complete. This is due to a problem with the Apache Atlas server and Apache SOLR. See https://github.com/odpi/egeria/issues/3587 for more information. Dependencies \u00b6 Spring Boot is updated to 2.3.3. Egeria Implementation Status at Release 2.2 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":2.2},{"location":"release-notes/2-2/#release-22-september-2020","text":"Below are the highlights of this release: Additional connectors are now placed in our assembly under server/lib without dependencies. If you need to use a connector that requires additional dependencies that are not already part of the server chassis, you will need to add those libraries here. The docker image has been updated to use a later openjdk alpine base image due to incompatibilities with our JanusGraph support in the old images for java 8. In the VDC chart, 2 new values have been added, 'ibmigc.connectorversion' and 'atlas.connectorversion'. In this release these are set to use the 2.1 connectors, since the connectors run to a different release cycle than the main Egeria code. Once new connectors are released you can update these values to get the latest connectors Further code to support lineage has been added, but in this release it remains in development and is not yet ready for use in production. User interface improvements. Ongoing bug fixes and refactoring especially in subject-area omas.","title":"Release 2.2 (September 2020)"},{"location":"release-notes/2-2/#known-issues","text":"In the VDC helm chart, the Apache Atlas initialization job fails to complete. This is due to a problem with the Apache Atlas server and Apache SOLR. See https://github.com/odpi/egeria/issues/3587 for more information.","title":"Known Issues"},{"location":"release-notes/2-2/#dependencies","text":"Spring Boot is updated to 2.3.3.","title":"Dependencies"},{"location":"release-notes/2-2/#egeria-implementation-status-at-release-22","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.2"},{"location":"release-notes/2-3/","text":"Release 2.3 (October 2020) \u00b6 New capabilities & Major changes \u00b6 A new Presentation Server User interface has been added, making use of React & Carbon Presentation Server is still in development For developers not contributing to Presentation Server, running in a container under Kubernetes or docker-compose is the easiest way to get started See the last section of the Presentation Server README for instructions on running Presentation Server For contributors, The Presentation Server README also documents 'Configuring the Presentation Server' - this is done automatically in our k8s/compose environment. However if doing this manually note (4th point) that the environment variable is called EGERIA_PRESENTATIONSERVER_SERVER_<ui server name> where the <ui server name> is the tenant's serverName.. The examples in the document are correct. The Dino User Interface for presentation server now allows an Egeria operations user to display a graph and details of Egeria resources including platforms, servers, services and cohort memberships. Type Explorer & Repository Explorer, previously found in the Polymer based UI, are now available in Presentation Server. Raise a github issue or Contact the Egeria team via slack at slack.odpi.com if you experience issues or have questions. The Egeria Docker image is now based on Redhat's UBI-8 openjdk-11 image, to improve security & operational support. See issue #3580 Bug Fixes & ongoing feature work Known Issues \u00b6 Several maven artifacts have not been published to maven central/JCenter. See issue #3675 They can be retrieved from JFrog Artifactory at 'https://odpi.jfrog.io/odpi/egeria-release-local' if needed and it is not possible to build locally. org.odpi.egeria:presentation-server org.odpi.egeria:subject-area-fvt org.odpi.egeria:dev-ops-api org.odpi.egeria:digital-service-spring Dependencies \u00b6 Spring has been updated to 2.3.9 Spring Security has been updated to 5.4.0 For a full list run 'mvn dependency:tree' against top level directory and/or review the top level pom.xml ## Egeria Implementation Status at Release 2.3 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":2.3},{"location":"release-notes/2-3/#release-23-october-2020","text":"","title":"Release 2.3 (October 2020)"},{"location":"release-notes/2-3/#new-capabilities-major-changes","text":"A new Presentation Server User interface has been added, making use of React & Carbon Presentation Server is still in development For developers not contributing to Presentation Server, running in a container under Kubernetes or docker-compose is the easiest way to get started See the last section of the Presentation Server README for instructions on running Presentation Server For contributors, The Presentation Server README also documents 'Configuring the Presentation Server' - this is done automatically in our k8s/compose environment. However if doing this manually note (4th point) that the environment variable is called EGERIA_PRESENTATIONSERVER_SERVER_<ui server name> where the <ui server name> is the tenant's serverName.. The examples in the document are correct. The Dino User Interface for presentation server now allows an Egeria operations user to display a graph and details of Egeria resources including platforms, servers, services and cohort memberships. Type Explorer & Repository Explorer, previously found in the Polymer based UI, are now available in Presentation Server. Raise a github issue or Contact the Egeria team via slack at slack.odpi.com if you experience issues or have questions. The Egeria Docker image is now based on Redhat's UBI-8 openjdk-11 image, to improve security & operational support. See issue #3580 Bug Fixes & ongoing feature work","title":"New capabilities &amp; Major changes"},{"location":"release-notes/2-3/#known-issues","text":"Several maven artifacts have not been published to maven central/JCenter. See issue #3675 They can be retrieved from JFrog Artifactory at 'https://odpi.jfrog.io/odpi/egeria-release-local' if needed and it is not possible to build locally. org.odpi.egeria:presentation-server org.odpi.egeria:subject-area-fvt org.odpi.egeria:dev-ops-api org.odpi.egeria:digital-service-spring","title":"Known Issues"},{"location":"release-notes/2-3/#dependencies","text":"Spring has been updated to 2.3.9 Spring Security has been updated to 5.4.0 For a full list run 'mvn dependency:tree' against top level directory and/or review the top level pom.xml ## Egeria Implementation Status at Release 2.3 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Dependencies"},{"location":"release-notes/2-4/","text":"Release 2.4 (November 2020) \u00b6 The Integration Daemon now makes it simpler to exchange metadata with third party technology such as catalogs and databases. The Repository Explorer User Interface ('REX') must now be configured with a list of available platforms and servers to improve security and usability. The latest version of Repository Explorer, Type Explorer and Dino, is found in the 'Presentation Server' UI. The Repository Explorer User Interface ('REX') must now be configured with a list of available platforms and servers to improve security and usability. See Presentation Server component documentation and Configuring the Presentation Server . The UI Server Chassis no longer includes static content. It is now required to deploy the egeria-ui project in addition to the spring application. A docker image is available, and the docker-compose & Kubernetes lab environments include this pre-configured. Additional Access Services Functional Verification tests have been added to improve code quality Bug fixes Dependency updates Spring has been updated to 5.2.9 Spring Security has been updated to 5.4.1 Spring Boot has been updated to 2.3.3 For a full list run 'mvn dependency:tree' against top level directory and/or review the top level pom.xml Known Issues \u00b6 The docker-compose based lab environment is incorrectly pulling docker images from the wrong repository. To correct this change open-metadata-resources/open-metadata-deployment/compose/tutorials/.env to egeria_repo=odpi . The original repository has however been updated to include 2.4 images, so will now work even if unchanged. Egeria Implementation Status at Release 2.4 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":2.4},{"location":"release-notes/2-4/#release-24-november-2020","text":"The Integration Daemon now makes it simpler to exchange metadata with third party technology such as catalogs and databases. The Repository Explorer User Interface ('REX') must now be configured with a list of available platforms and servers to improve security and usability. The latest version of Repository Explorer, Type Explorer and Dino, is found in the 'Presentation Server' UI. The Repository Explorer User Interface ('REX') must now be configured with a list of available platforms and servers to improve security and usability. See Presentation Server component documentation and Configuring the Presentation Server . The UI Server Chassis no longer includes static content. It is now required to deploy the egeria-ui project in addition to the spring application. A docker image is available, and the docker-compose & Kubernetes lab environments include this pre-configured. Additional Access Services Functional Verification tests have been added to improve code quality Bug fixes Dependency updates Spring has been updated to 5.2.9 Spring Security has been updated to 5.4.1 Spring Boot has been updated to 2.3.3 For a full list run 'mvn dependency:tree' against top level directory and/or review the top level pom.xml","title":"Release 2.4 (November 2020)"},{"location":"release-notes/2-4/#known-issues","text":"The docker-compose based lab environment is incorrectly pulling docker images from the wrong repository. To correct this change open-metadata-resources/open-metadata-deployment/compose/tutorials/.env to egeria_repo=odpi . The original repository has however been updated to include 2.4 images, so will now work even if unchanged.","title":"Known Issues"},{"location":"release-notes/2-4/#egeria-implementation-status-at-release-24","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.4"},{"location":"release-notes/2-5/","text":"Release 2.5 (December 2020) \u00b6 Below are the highlights of the 2.5 release: The following improvements to the presentation-server user interface: The Type Explorer UI supports options to show/hide deprecated types and/or deprecated attributes. Please refer to the Type Explorer help.md for details. preserves the user-selected focus type across reloads of type information from the repository server. The Repository Explorer UI has the Enterprise option enabled by default. It can be disabled to perform more specific, localized queries. now indicates whether an instance was returned by an enterprise or local scope operation against its home repository or is a reference copy or proxy. has a user-settable limit on the number of search results (and a warning to the user if it is exceeded) now colors nodes based on their home metadata collection's ID. This previously used metadata collection's name but a metadata collection's name can be changed, whereas the metadata collection's ID is permanent. has improved help information covering search The Dino UI displays a server's status history in a separate dialog instead of inline in the server details view. The following improvements to the repositories: The Graph Repository find methods have reinstated support for core properties, previously temporarily disabled due to property name clashes that are now resolved A new type OpenMetadataRoot has been added as the root type for all Open Metadata Types. See the base model The admin services guide has some additional information on configuring TLS security Improvements to the gradle build scripts, but at this point it remains incomplete and build of egeria still requires maven Bug Fixes Dependency Updates Egeria Implementation Status at Release 2.5 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":2.5},{"location":"release-notes/2-5/#release-25-december-2020","text":"Below are the highlights of the 2.5 release: The following improvements to the presentation-server user interface: The Type Explorer UI supports options to show/hide deprecated types and/or deprecated attributes. Please refer to the Type Explorer help.md for details. preserves the user-selected focus type across reloads of type information from the repository server. The Repository Explorer UI has the Enterprise option enabled by default. It can be disabled to perform more specific, localized queries. now indicates whether an instance was returned by an enterprise or local scope operation against its home repository or is a reference copy or proxy. has a user-settable limit on the number of search results (and a warning to the user if it is exceeded) now colors nodes based on their home metadata collection's ID. This previously used metadata collection's name but a metadata collection's name can be changed, whereas the metadata collection's ID is permanent. has improved help information covering search The Dino UI displays a server's status history in a separate dialog instead of inline in the server details view. The following improvements to the repositories: The Graph Repository find methods have reinstated support for core properties, previously temporarily disabled due to property name clashes that are now resolved A new type OpenMetadataRoot has been added as the root type for all Open Metadata Types. See the base model The admin services guide has some additional information on configuring TLS security Improvements to the gradle build scripts, but at this point it remains incomplete and build of egeria still requires maven Bug Fixes Dependency Updates","title":"Release 2.5 (December 2020)"},{"location":"release-notes/2-5/#egeria-implementation-status-at-release-25","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.5"},{"location":"release-notes/2-6/","text":"Release 2.6 (February 2021) \u00b6 Release 2.6 adds support for: * New Governance Server called Engine Host with associated Open Metadata Engine Services ( OMES ) . This Governance Server replaces the Discovery Server, Stewardship Server, Virtualizer and Security Officer Server. Extensions to Open Metadata Types for lineage, duplicate processing, governance actions, the software development lifecycle and analytics models. The release also changes the default location of some important files in order to facilitate deployment and seperate program files from writeable data. Details of these and other changes are in the sections that follow. Description of Changes \u00b6 Changes to data files created/used by Egeria \u00b6 Up to and including release 2.5, various data files were created in the current working directory when Egeria was run. This included configuration files, cohort information, graph repositories etc. This made it difficult to manage Egeria in a container environment where we want to manage persistent data explicitly - for example via a docker volume, or a kubernetes persistent volume (claim). Because of this the default locations of a number of files have changed, so when deploying release 2.6 make sure you copy any existing files you need to preserve over to their new locations. If this is not done server configs and repository data may not be found, or configuration files may not be decrytable. usage old new variables Server configuration omag.server.{0}.config data/servers/{0}/config/{0}.config 0 = server Name File based audit log omag.server.{0}.auditlog/ data/servers/{0}/logs/auditlog/ 0 = server Name cohort registry {0}.{1}.registrystore data/servers/{0}/cohorts/{1}.registrystore 0 = server Name, 1 = cohort name Graph repository {0}-graph-repository/ data/servers/{0}/repository/graph/ 0 = server Name Encrypted config key keystore_* data/platform/keys/keystore_* The result of this is that all the dynamic data created by egeria locally in the filesystem is restricted to the 'data' directory so this can be mapped to a volume easily. If you have already explicitly configured the relevant connector yourself there will be no change. this updates the defaults only. Removal of the Discovery Server and Stewardship Server \u00b6 The Discovery Server, Stewardship Server, Virtualizer and Security Officer Server have been consolidated into a new type of server called the Engine Host OMAG Server . The Engine Host runs one-to-many Open Metadata Engine Services ( OMES ) . Each engine services hosts a specific type of governance engine. The first engine service called Asset Analysis OMES will be for discovery engines and others for the different types of governance action engines . from the Governance Action Framework ( GAF ) . The reason for this change is that there is a lot of duplicated code in the original servers and this change simplifies the Governance Server Services and Server Administration . With this change it will also be easier for Egeria to host other types of governance engines such as Palisade and Gaian. New open metadata types for Governance Actions \u00b6 The following types have been added to support the governance action engines: 0461 Governance Action Engines 0462 Governance Action Types 0463 Governance Actions Updates to open metadata types for Lineage Mapping \u00b6 The LineageMapping open metadata relationship type has been updated to link Referenceables rather than SchemaElements . This is to capture lineage between components at different levels of detail since the data field mappings may not always be available. Lineage mapping is described in more detail here . New open metadata types for Duplicate Processing \u00b6 Since Egeria is integrating and distributing metadata from many different sources, it is inevitable that there will be multiple metadata instances that represent the same real-world \"thing\". The 0465 Duplicate Processing types allow these elements to be linked together. Presentation Server / React UI \u00b6 The node based User Interface component known as 'Presentation Server' has now fully moved to it's own GitHub Repository . The docker image has been renamed to egeria-react-ui Dino - Adds display of integration servers\u2019 integration services and engine hosts\u2019 engine services, including display of a dependency on a partnerOMAS. Rex - Improved error reporting and geometry management plus more consistent handling of focus objects. Enterprise queries are now the default, but can be over-ridden to perform a local operation. At this time 'Server Author' and 'Glossary Author' are still in development. New Helm Chart \u00b6 In addition to our 'lab' helm chart to support the Coco Pharmaceuticals environment, we have now added an additional helm chart which provides a simpler environment with just a single platform, and a single server, but configured with persistence and auto start. This offers an example of a simple Kubernetes deployment. Graph Repository \u00b6 Now implements the findEntities and fnidRelationships methods of the OMRS MetadataCollection API. Added detailed documentation for the graph repository Conformance Test Suite \u00b6 CTS now has tests for findEntities and findRelationships methods and search tests have been realigned into profiles so that all search operations are in optional profiles, with basic and advanced profiles for each of entities and relationships. Other changes \u00b6 Release 2.6 also contains many bug fixes and minor improvements & dependency updates Removals and Deprecations \u00b6 Discovery Server, Stewardship Server, Virtualizer and Security Officer Server have been replaced with more extensive capability - see above. Information View OMAS has now been removed following earlier deprecation. Egeria Implementation Status at Release 2.6 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content. Further Help and Support \u00b6 As part of the Linux AI & Data Foundation, our slack channels have moved to the LF AI & Data Slack workspace , and our mailing lists can now be found at https://lists.lfaidata.foundation/groups Continue to use these resources, along with GitHub to report bugs or ask questions.","title":2.6},{"location":"release-notes/2-6/#release-26-february-2021","text":"Release 2.6 adds support for: * New Governance Server called Engine Host with associated Open Metadata Engine Services ( OMES ) . This Governance Server replaces the Discovery Server, Stewardship Server, Virtualizer and Security Officer Server. Extensions to Open Metadata Types for lineage, duplicate processing, governance actions, the software development lifecycle and analytics models. The release also changes the default location of some important files in order to facilitate deployment and seperate program files from writeable data. Details of these and other changes are in the sections that follow.","title":"Release 2.6 (February 2021)"},{"location":"release-notes/2-6/#description-of-changes","text":"","title":"Description of Changes"},{"location":"release-notes/2-6/#changes-to-data-files-createdused-by-egeria","text":"Up to and including release 2.5, various data files were created in the current working directory when Egeria was run. This included configuration files, cohort information, graph repositories etc. This made it difficult to manage Egeria in a container environment where we want to manage persistent data explicitly - for example via a docker volume, or a kubernetes persistent volume (claim). Because of this the default locations of a number of files have changed, so when deploying release 2.6 make sure you copy any existing files you need to preserve over to their new locations. If this is not done server configs and repository data may not be found, or configuration files may not be decrytable. usage old new variables Server configuration omag.server.{0}.config data/servers/{0}/config/{0}.config 0 = server Name File based audit log omag.server.{0}.auditlog/ data/servers/{0}/logs/auditlog/ 0 = server Name cohort registry {0}.{1}.registrystore data/servers/{0}/cohorts/{1}.registrystore 0 = server Name, 1 = cohort name Graph repository {0}-graph-repository/ data/servers/{0}/repository/graph/ 0 = server Name Encrypted config key keystore_* data/platform/keys/keystore_* The result of this is that all the dynamic data created by egeria locally in the filesystem is restricted to the 'data' directory so this can be mapped to a volume easily. If you have already explicitly configured the relevant connector yourself there will be no change. this updates the defaults only.","title":"Changes to data files created/used by Egeria"},{"location":"release-notes/2-6/#removal-of-the-discovery-server-and-stewardship-server","text":"The Discovery Server, Stewardship Server, Virtualizer and Security Officer Server have been consolidated into a new type of server called the Engine Host OMAG Server . The Engine Host runs one-to-many Open Metadata Engine Services ( OMES ) . Each engine services hosts a specific type of governance engine. The first engine service called Asset Analysis OMES will be for discovery engines and others for the different types of governance action engines . from the Governance Action Framework ( GAF ) . The reason for this change is that there is a lot of duplicated code in the original servers and this change simplifies the Governance Server Services and Server Administration . With this change it will also be easier for Egeria to host other types of governance engines such as Palisade and Gaian.","title":"Removal of the Discovery Server and Stewardship Server"},{"location":"release-notes/2-6/#new-open-metadata-types-for-governance-actions","text":"The following types have been added to support the governance action engines: 0461 Governance Action Engines 0462 Governance Action Types 0463 Governance Actions","title":"New open metadata types for Governance Actions"},{"location":"release-notes/2-6/#updates-to-open-metadata-types-for-lineage-mapping","text":"The LineageMapping open metadata relationship type has been updated to link Referenceables rather than SchemaElements . This is to capture lineage between components at different levels of detail since the data field mappings may not always be available. Lineage mapping is described in more detail here .","title":"Updates to open metadata types for Lineage Mapping"},{"location":"release-notes/2-6/#new-open-metadata-types-for-duplicate-processing","text":"Since Egeria is integrating and distributing metadata from many different sources, it is inevitable that there will be multiple metadata instances that represent the same real-world \"thing\". The 0465 Duplicate Processing types allow these elements to be linked together.","title":"New open metadata types for Duplicate Processing"},{"location":"release-notes/2-6/#presentation-server-react-ui","text":"The node based User Interface component known as 'Presentation Server' has now fully moved to it's own GitHub Repository . The docker image has been renamed to egeria-react-ui Dino - Adds display of integration servers\u2019 integration services and engine hosts\u2019 engine services, including display of a dependency on a partnerOMAS. Rex - Improved error reporting and geometry management plus more consistent handling of focus objects. Enterprise queries are now the default, but can be over-ridden to perform a local operation. At this time 'Server Author' and 'Glossary Author' are still in development.","title":"Presentation Server / React UI"},{"location":"release-notes/2-6/#new-helm-chart","text":"In addition to our 'lab' helm chart to support the Coco Pharmaceuticals environment, we have now added an additional helm chart which provides a simpler environment with just a single platform, and a single server, but configured with persistence and auto start. This offers an example of a simple Kubernetes deployment.","title":"New Helm Chart"},{"location":"release-notes/2-6/#graph-repository","text":"Now implements the findEntities and fnidRelationships methods of the OMRS MetadataCollection API. Added detailed documentation for the graph repository","title":"Graph Repository"},{"location":"release-notes/2-6/#conformance-test-suite","text":"CTS now has tests for findEntities and findRelationships methods and search tests have been realigned into profiles so that all search operations are in optional profiles, with basic and advanced profiles for each of entities and relationships.","title":"Conformance Test Suite"},{"location":"release-notes/2-6/#other-changes","text":"Release 2.6 also contains many bug fixes and minor improvements & dependency updates","title":"Other changes"},{"location":"release-notes/2-6/#removals-and-deprecations","text":"Discovery Server, Stewardship Server, Virtualizer and Security Officer Server have been replaced with more extensive capability - see above. Information View OMAS has now been removed following earlier deprecation.","title":"Removals and Deprecations"},{"location":"release-notes/2-6/#egeria-implementation-status-at-release-26","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.6"},{"location":"release-notes/2-6/#further-help-and-support","text":"As part of the Linux AI & Data Foundation, our slack channels have moved to the LF AI & Data Slack workspace , and our mailing lists can now be found at https://lists.lfaidata.foundation/groups Continue to use these resources, along with GitHub to report bugs or ask questions.","title":"Further Help and Support"},{"location":"release-notes/2-7/","text":"Release 2.7 (March 2021) \u00b6 Release 2.7 adds: * Performance improvements in the graph repo * Changes to metadata types * Changes to the distribution process Details of these and other changes are in the sections that follow. Description of Changes \u00b6 Build & Release changes \u00b6 Previously release maven artifacts have been pushed to JCenter (in addition to Maven Central), and snapshots have been pushed to odpi.jfrog.io/odpi/egeria-snapshot. As of 2.7 this no longer occurs and release and snapshots are pushed only to Maven Central. Due to the above, maven artifacts may be signed by a different user to previously (and this may change in a future release). Performance Improvements \u00b6 Release 2.7 includes performance improvements to the graph repository's search methods, which select an efficient query strategy based on the properties and type filters supplied to the search. Metadata Types \u00b6 We have removed overloaded properties that existed at multiple levels in a type definition: for example, length was defined both on SchemaAttribute and again on RelationalColumn (which is a subtype of SchemaAttribute). This change removes them from being defined again the lower level (RelationalColumn in this example); however, the property itself will still be available at the lower level due to inheriting it from the supertype. Bug fixes and other updates \u00b6 Additional Bug Fixes Dependency Updates For details on both see the commit history in GitHub. Known Issues \u00b6 It is recommended to use a chromium-based browser such as Google Chrome or Microsoft Edge, or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . When running the 'Understanding Platform Services' lab, ensure you run the 'egeria-service-config' notebook first and do not restart the python kernel before running this lab. See #4842 . Egeria Implementation Status at Release 2.7 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content. Further Help and Support \u00b6 As part of the Linux AI & Data Foundation, our slack channels have moved to the LF AI & Data Slack workspace , and our mailing lists can now be found at https://lists.lfaidata.foundation/groups Continue to use these resources, along with GitHub to report bugs or ask questions.","title":2.7},{"location":"release-notes/2-7/#release-27-march-2021","text":"Release 2.7 adds: * Performance improvements in the graph repo * Changes to metadata types * Changes to the distribution process Details of these and other changes are in the sections that follow.","title":"Release 2.7 (March 2021)"},{"location":"release-notes/2-7/#description-of-changes","text":"","title":"Description of Changes"},{"location":"release-notes/2-7/#build-release-changes","text":"Previously release maven artifacts have been pushed to JCenter (in addition to Maven Central), and snapshots have been pushed to odpi.jfrog.io/odpi/egeria-snapshot. As of 2.7 this no longer occurs and release and snapshots are pushed only to Maven Central. Due to the above, maven artifacts may be signed by a different user to previously (and this may change in a future release).","title":"Build &amp; Release changes"},{"location":"release-notes/2-7/#performance-improvements","text":"Release 2.7 includes performance improvements to the graph repository's search methods, which select an efficient query strategy based on the properties and type filters supplied to the search.","title":"Performance Improvements"},{"location":"release-notes/2-7/#metadata-types","text":"We have removed overloaded properties that existed at multiple levels in a type definition: for example, length was defined both on SchemaAttribute and again on RelationalColumn (which is a subtype of SchemaAttribute). This change removes them from being defined again the lower level (RelationalColumn in this example); however, the property itself will still be available at the lower level due to inheriting it from the supertype.","title":"Metadata Types"},{"location":"release-notes/2-7/#bug-fixes-and-other-updates","text":"Additional Bug Fixes Dependency Updates For details on both see the commit history in GitHub.","title":"Bug fixes and other updates"},{"location":"release-notes/2-7/#known-issues","text":"It is recommended to use a chromium-based browser such as Google Chrome or Microsoft Edge, or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . When running the 'Understanding Platform Services' lab, ensure you run the 'egeria-service-config' notebook first and do not restart the python kernel before running this lab. See #4842 .","title":"Known Issues"},{"location":"release-notes/2-7/#egeria-implementation-status-at-release-27","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.7"},{"location":"release-notes/2-7/#further-help-and-support","text":"As part of the Linux AI & Data Foundation, our slack channels have moved to the LF AI & Data Slack workspace , and our mailing lists can now be found at https://lists.lfaidata.foundation/groups Continue to use these resources, along with GitHub to report bugs or ask questions.","title":"Further Help and Support"},{"location":"release-notes/2-8/","text":"Release 2.8 (April 2021) \u00b6 Release 2.8 adds: * New support for event and property filtering for the open metadata server security connector * Changes to metadata types * New performance workbench for the CTS (technical preview) * New interface for retrieving the complete history of a single metadata instance * Splitting of CTS results into multiple smaller files Details of these and other changes are in the sections that follow. Description of Changes \u00b6 Updates to the Open Metadata Security Connector \u00b6 Before this release, the repository services support 3 filtering points for managing events for the OMRS Cohort Topic. Should an event be sent to the cohort Should an event be retrieved from the cohort Should a received event be stored in the local repository These filtering points are set up in the configuration document of the server. It is possible to specify rules to determine which types of events and which types of metadata elements are filtered out. However this configuration provides no control to allow filtering of events for specific instances. This release extends the metadata server security connector so it can be called at these same filter points. This will be through optional interfaces that the security connector can choose to implement. If the current rules are set up, they will still be executed. This change complements the existing filtering. The server security connector also implements the repository security interface called when metadata is being added/updated/deleted/retrieved through the APIs. Extending the security connector for event filtering means that it can make consistent decisions on the sharing of metadata through the cohorts and through the APIs. Configuring the server security connector \u00b6 Configuring the server security connector will not change with this feature. If the connector needs custom attributes to select rule sets etc, these can be specified in the configuration properties. See https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user/configuring-the-server-security-connector.html . Implementing the server security connector \u00b6 The security server connector will have two new interfaces that it can implement: one for the cohort events and one for saving events to the local repository. The event interface will have two methods, one for sending and one for receiving. The parameters will include the cohort name and the event contents. It can return the event unchanged, return a modified event (eg with sensitive content removed) or return null to say that the event is filtered out. The event saving interface will receive the instance header and can return a boolean to indicate if the local repository should store it. If true is returned, the refresh event sequence is initiated. The repository connector then has the ultimate choice when the refreshed instance is returned from the home repository as to whether to store it or not. There is a single instance of the connector in the server so it is able to maintain counts and cache rules etc. It can also be implemented as a facade to a proprietary service. More information on the security connector can be found on this page: https://egeria.odpi.org/open-metadata-implementation/common-services/metadata-security/metadata-security-apis Metadata Types \u00b6 Updates to the location types in model 0025 : Add the mapProjection property to the FixedLocation classification Change the address property to networkAddress in the CyberLocation classification Deprecated HostLocation in favor of the AssetLocation relationship Deprecate the RuntimeForProcess relationship since it is superfluous - use ServerAssetUse since Application is a SoftwareServerCapability . See model 0045 . Replace the deployedImplementationType property with the businessCapabilityType in the BusinessCapability since it is a more descriptive name. See model 0440 . Performance workbench \u00b6 The performance workbench intends to test the response time of all repository (metadata collection) methods for the technology under test. The volume of the test can be easily configured to also test scalability. More information is available in the workbench's documentation . Instance history interface \u00b6 Two new (optional) methods have been introduced to the metadata collection interface: getEntityDetailHistory getRelationshipHistory Both methods take the GUID of the instance for which to retrieve history, an optional range of times between which to retrieve the historical versions (or if both are null to retrieve all historical versions), and a set of paging parameters. If not implemented by a repository, these will simply throw FunctionNotSupported exceptions by default to indicate that they are not implemented. CTS results output \u00b6 Up to this release, the detailed results of a CTS run could only be be retrieved by pulling a huge (100's of MB) file across the REST interface for the CTS . Aside from not typically working with most REST clients (like Postman), this had the additional impact of a sudden huge hit on the JVM heap to serialize such a large JSON structure (immediately grabbing ~1GB of the heap). While this old interface still exists for backwards compatibility, the new default interface provided in this release allows users to pull down just an overall summary of the results separately from the full detailed results, and the detailed results are now broken down into separate files by profile and test case: each of which can therefore be retrieved individually. (So, for example, if you see from the summary that only 1-2 profiles are not conformant, you can retrieve just the details for those profiles rather than all details.) Changes to deployment of the Polymer based UI \u00b6 In previous releases, a zuul router component was used within the UI server chassis to route requests for static content to a separate server. In this release any routing needs to be setup externally, for example by placing a nginx proxy in front of both the ui chassis and static content server. This is now done by our docker-compose environment & helm charts so to access the UI you need to go to the nginx proxy. Further summary information can be found in the documentation for those assets. Bug fixes and other updates \u00b6 Additional Bug Fixes Dependency Updates For details on both see the commit history in GitHub. Known Issues \u00b6 It is recommended to use a chromium-based browser such as Google Chrome or Microsoft Edge, or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Egeria source code currently fails to build on Windows natively. Please use Linux, MacOS, or compile under WSL/WSL2 on Windows. See #4917 Several Java samples fail (governance, admin) - #4656 , #4662 , #4056 The React UI used by the helm charts and compose is based on react UI release 2.7.0 due to layout issues found with 2.8.0. See #5022 The platform services notebook may fail to query servers correctly. See #5023 The building a data catalog notebook may fail if run quickly. See #2688 The data curation notebook is incomplete and still being developed. The final steps may fail to work in a container environment. See #5021 Egeria Implementation Status at Release 2.8 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content. Further Help and Support \u00b6 As part of the Linux AI & Data Foundation, our slack channels have moved to the LF AI & Data Slack workspace , and our mailing lists can now be found at https://lists.lfaidata.foundation/groups Continue to use these resources, along with GitHub to report bugs or ask questions.","title":2.8},{"location":"release-notes/2-8/#release-28-april-2021","text":"Release 2.8 adds: * New support for event and property filtering for the open metadata server security connector * Changes to metadata types * New performance workbench for the CTS (technical preview) * New interface for retrieving the complete history of a single metadata instance * Splitting of CTS results into multiple smaller files Details of these and other changes are in the sections that follow.","title":"Release 2.8 (April 2021)"},{"location":"release-notes/2-8/#description-of-changes","text":"","title":"Description of Changes"},{"location":"release-notes/2-8/#updates-to-the-open-metadata-security-connector","text":"Before this release, the repository services support 3 filtering points for managing events for the OMRS Cohort Topic. Should an event be sent to the cohort Should an event be retrieved from the cohort Should a received event be stored in the local repository These filtering points are set up in the configuration document of the server. It is possible to specify rules to determine which types of events and which types of metadata elements are filtered out. However this configuration provides no control to allow filtering of events for specific instances. This release extends the metadata server security connector so it can be called at these same filter points. This will be through optional interfaces that the security connector can choose to implement. If the current rules are set up, they will still be executed. This change complements the existing filtering. The server security connector also implements the repository security interface called when metadata is being added/updated/deleted/retrieved through the APIs. Extending the security connector for event filtering means that it can make consistent decisions on the sharing of metadata through the cohorts and through the APIs.","title":"Updates to the Open Metadata Security Connector"},{"location":"release-notes/2-8/#configuring-the-server-security-connector","text":"Configuring the server security connector will not change with this feature. If the connector needs custom attributes to select rule sets etc, these can be specified in the configuration properties. See https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user/configuring-the-server-security-connector.html .","title":"Configuring the server security connector"},{"location":"release-notes/2-8/#implementing-the-server-security-connector","text":"The security server connector will have two new interfaces that it can implement: one for the cohort events and one for saving events to the local repository. The event interface will have two methods, one for sending and one for receiving. The parameters will include the cohort name and the event contents. It can return the event unchanged, return a modified event (eg with sensitive content removed) or return null to say that the event is filtered out. The event saving interface will receive the instance header and can return a boolean to indicate if the local repository should store it. If true is returned, the refresh event sequence is initiated. The repository connector then has the ultimate choice when the refreshed instance is returned from the home repository as to whether to store it or not. There is a single instance of the connector in the server so it is able to maintain counts and cache rules etc. It can also be implemented as a facade to a proprietary service. More information on the security connector can be found on this page: https://egeria.odpi.org/open-metadata-implementation/common-services/metadata-security/metadata-security-apis","title":"Implementing the server security connector"},{"location":"release-notes/2-8/#metadata-types","text":"Updates to the location types in model 0025 : Add the mapProjection property to the FixedLocation classification Change the address property to networkAddress in the CyberLocation classification Deprecated HostLocation in favor of the AssetLocation relationship Deprecate the RuntimeForProcess relationship since it is superfluous - use ServerAssetUse since Application is a SoftwareServerCapability . See model 0045 . Replace the deployedImplementationType property with the businessCapabilityType in the BusinessCapability since it is a more descriptive name. See model 0440 .","title":"Metadata Types"},{"location":"release-notes/2-8/#performance-workbench","text":"The performance workbench intends to test the response time of all repository (metadata collection) methods for the technology under test. The volume of the test can be easily configured to also test scalability. More information is available in the workbench's documentation .","title":"Performance workbench"},{"location":"release-notes/2-8/#instance-history-interface","text":"Two new (optional) methods have been introduced to the metadata collection interface: getEntityDetailHistory getRelationshipHistory Both methods take the GUID of the instance for which to retrieve history, an optional range of times between which to retrieve the historical versions (or if both are null to retrieve all historical versions), and a set of paging parameters. If not implemented by a repository, these will simply throw FunctionNotSupported exceptions by default to indicate that they are not implemented.","title":"Instance history interface"},{"location":"release-notes/2-8/#cts-results-output","text":"Up to this release, the detailed results of a CTS run could only be be retrieved by pulling a huge (100's of MB) file across the REST interface for the CTS . Aside from not typically working with most REST clients (like Postman), this had the additional impact of a sudden huge hit on the JVM heap to serialize such a large JSON structure (immediately grabbing ~1GB of the heap). While this old interface still exists for backwards compatibility, the new default interface provided in this release allows users to pull down just an overall summary of the results separately from the full detailed results, and the detailed results are now broken down into separate files by profile and test case: each of which can therefore be retrieved individually. (So, for example, if you see from the summary that only 1-2 profiles are not conformant, you can retrieve just the details for those profiles rather than all details.)","title":"CTS results output"},{"location":"release-notes/2-8/#changes-to-deployment-of-the-polymer-based-ui","text":"In previous releases, a zuul router component was used within the UI server chassis to route requests for static content to a separate server. In this release any routing needs to be setup externally, for example by placing a nginx proxy in front of both the ui chassis and static content server. This is now done by our docker-compose environment & helm charts so to access the UI you need to go to the nginx proxy. Further summary information can be found in the documentation for those assets.","title":"Changes to deployment of the Polymer based UI"},{"location":"release-notes/2-8/#bug-fixes-and-other-updates","text":"Additional Bug Fixes Dependency Updates For details on both see the commit history in GitHub.","title":"Bug fixes and other updates"},{"location":"release-notes/2-8/#known-issues","text":"It is recommended to use a chromium-based browser such as Google Chrome or Microsoft Edge, or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Egeria source code currently fails to build on Windows natively. Please use Linux, MacOS, or compile under WSL/WSL2 on Windows. See #4917 Several Java samples fail (governance, admin) - #4656 , #4662 , #4056 The React UI used by the helm charts and compose is based on react UI release 2.7.0 due to layout issues found with 2.8.0. See #5022 The platform services notebook may fail to query servers correctly. See #5023 The building a data catalog notebook may fail if run quickly. See #2688 The data curation notebook is incomplete and still being developed. The final steps may fail to work in a container environment. See #5021","title":"Known Issues"},{"location":"release-notes/2-8/#egeria-implementation-status-at-release-28","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.8"},{"location":"release-notes/2-8/#further-help-and-support","text":"As part of the Linux AI & Data Foundation, our slack channels have moved to the LF AI & Data Slack workspace , and our mailing lists can now be found at https://lists.lfaidata.foundation/groups Continue to use these resources, along with GitHub to report bugs or ask questions.","title":"Further Help and Support"},{"location":"release-notes/2-9/","text":"Release 2.9 (May 2021) \u00b6 Release 2.9 adds: * Changes to metadata types * Changes to building Egeria on Windows Details of these and other changes are in the sections that follow. Description of Changes \u00b6 Metadata Types \u00b6 The UserProfileManager , UserAccessDirectory and MasterDataManager classification for Referenceables has been added to model 0056 Asset Managers . A new relationship called ActionTarget to link a To Do to the elements that need work has been added to model 0137 Actions for People . A new attribute called filterExpression has been added to the Port entity in model 0217 Ports . A new classification called PrimaryCategory has been added to model 0335 Primary Category . A new classification called GovernanceMeasurements has been added to model 0450 Governance Rollout . The RelationalColumnType entity in model 0534 Relational Schema . only allows for a column to be primitive. It could be a literal, enum or external and so this type has been deprecated and the appropriate schema types should be used directly. Building Egeria on Windows \u00b6 To build Egeria on Windows you should use Windows Subsystem for Linux Version 2 or above & install an appropriate Linux distribution. Egeria should then be built & run within this environment. IDEs such as IntelliJ and VSCode support editing and code management within the Windows GUI alongside build and execution in Linux. See PR #5084 for more information. Bug fixes and other updates \u00b6 Additional Bug Fixes Dependency Updates For details on both see the commit history in GitHub. Known Issues \u00b6 It is recommended to use a chromium-based browser such as Google Chrome or Microsoft Edge, or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . When running the 'Understanding Platform Services' lab, ensure you run the 'egeria-service-config' notebook first and do not restart the python kernel before running this lab. See #4842 . Egeria Implementation Status at Release 2.9 \u00b6 Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content. Further Help and Support \u00b6 See the Community Guide .","title":2.9},{"location":"release-notes/2-9/#release-29-may-2021","text":"Release 2.9 adds: * Changes to metadata types * Changes to building Egeria on Windows Details of these and other changes are in the sections that follow.","title":"Release 2.9 (May 2021)"},{"location":"release-notes/2-9/#description-of-changes","text":"","title":"Description of Changes"},{"location":"release-notes/2-9/#metadata-types","text":"The UserProfileManager , UserAccessDirectory and MasterDataManager classification for Referenceables has been added to model 0056 Asset Managers . A new relationship called ActionTarget to link a To Do to the elements that need work has been added to model 0137 Actions for People . A new attribute called filterExpression has been added to the Port entity in model 0217 Ports . A new classification called PrimaryCategory has been added to model 0335 Primary Category . A new classification called GovernanceMeasurements has been added to model 0450 Governance Rollout . The RelationalColumnType entity in model 0534 Relational Schema . only allows for a column to be primitive. It could be a literal, enum or external and so this type has been deprecated and the appropriate schema types should be used directly.","title":"Metadata Types"},{"location":"release-notes/2-9/#building-egeria-on-windows","text":"To build Egeria on Windows you should use Windows Subsystem for Linux Version 2 or above & install an appropriate Linux distribution. Egeria should then be built & run within this environment. IDEs such as IntelliJ and VSCode support editing and code management within the Windows GUI alongside build and execution in Linux. See PR #5084 for more information.","title":"Building Egeria on Windows"},{"location":"release-notes/2-9/#bug-fixes-and-other-updates","text":"Additional Bug Fixes Dependency Updates For details on both see the commit history in GitHub.","title":"Bug fixes and other updates"},{"location":"release-notes/2-9/#known-issues","text":"It is recommended to use a chromium-based browser such as Google Chrome or Microsoft Edge, or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . When running the 'Understanding Platform Services' lab, ensure you run the 'egeria-service-config' notebook first and do not restart the python kernel before running this lab. See #4842 .","title":"Known Issues"},{"location":"release-notes/2-9/#egeria-implementation-status-at-release-29","text":"Link to Egeria's Roadmap for more details about the Open Metadata and Governance vision, strategy and content.","title":"Egeria Implementation Status at Release 2.9"},{"location":"release-notes/2-9/#further-help-and-support","text":"See the Community Guide .","title":"Further Help and Support"},{"location":"release-notes/3-0/","text":"3.0 (August 2021) \u00b6 Special note on Java support Java 11 is now required to build and run Egeria. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes Java 11 required As of Release 3.0 of Egeria, Java 11 is required to build and run Egeria. Egeria will not build / run / be supported on Java 8. Developers are now able to use Java 11 only functionality. Java releases beyond Java 11 up to the current release have some informal testing, and we do build verification on the current release (currently 16). See Java for further information. Defaults to multiple topics for cohorts The option added in release 2.11 to allow multiple topics per cohort now becomes the default in release 3.0. Changed passwords Passwords for the sample Coco Pharmaceuticals users were changed to secret . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":"3 0"},{"location":"release-notes/3-0/#30-august-2021","text":"Special note on Java support Java 11 is now required to build and run Egeria. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes Java 11 required As of Release 3.0 of Egeria, Java 11 is required to build and run Egeria. Egeria will not build / run / be supported on Java 8. Developers are now able to use Java 11 only functionality. Java releases beyond Java 11 up to the current release have some informal testing, and we do build verification on the current release (currently 16). See Java for further information. Defaults to multiple topics for cohorts The option added in release 2.11 to allow multiple topics per cohort now becomes the default in release 3.0. Changed passwords Passwords for the sample Coco Pharmaceuticals users were changed to secret . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":"3.0 (August 2021)"},{"location":"release-notes/3-1/","text":"3.1 (expected September 2021) \u00b6 Special note on Java support Java 11 is now required to build and run Egeria. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes docker-compose The docker-compose environment for running our Coco Pharmaceuticals lab demo/tutorial is now deprecated. The configuration is still available, but will not be further developed or tested, and will be removed in a future release. Our Kubernetes Helm charts are now recommended to quickly setup the same lab environment, and the documentation for these has been improved to cover a Kubernetes introduction, and example based on 'microk8s' which are suited to an end-user desktop environment (and can also be run in enterprise/cloud environments). Type changes: added, modified, deprecated Data processing purposes See new type descriptions in model 0485 . Distinguishing between virtual machines, containers and bare metal hardware There are now types for distinguishing between virtual machines and virtual containers as well as bare metal hardware. There are also new types for specific technologies such as HadoopCluster , KubernetesCluster and DockerContainer to provide concrete examples of different types of hosts using popular technologies. Storage volumes There are new types for defining a storage volume that has been attached to a host. See description in model 0036 . ApplicationService A new subtype of software server for reusable business functions (such as microservices) has been added called ApplicationService . See description in model 0057 . ServerEndpoint The ServerEndpoint relationship can now connect to any ITInfrastructure elements, not just SoftwareServers . See description in model 0040 . OperatingPlatform The OperatingPlatform entity can now record the patch level of the operating system. There are also new types for describing the contents of an operating platform. See description in model 0030 . DeployedVirtualContainer The DeployedVirtualContainer relationship has been deprecated in favor of a more generic HostedHost relationship. See description in model 0035 . BoundedSchemaType, BoundedSchemaElementType, ArraySchemaType, SetSchemaType See description in model 0507 . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":"3 1"},{"location":"release-notes/3-1/#31-expected-september-2021","text":"Special note on Java support Java 11 is now required to build and run Egeria. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes docker-compose The docker-compose environment for running our Coco Pharmaceuticals lab demo/tutorial is now deprecated. The configuration is still available, but will not be further developed or tested, and will be removed in a future release. Our Kubernetes Helm charts are now recommended to quickly setup the same lab environment, and the documentation for these has been improved to cover a Kubernetes introduction, and example based on 'microk8s' which are suited to an end-user desktop environment (and can also be run in enterprise/cloud environments). Type changes: added, modified, deprecated Data processing purposes See new type descriptions in model 0485 . Distinguishing between virtual machines, containers and bare metal hardware There are now types for distinguishing between virtual machines and virtual containers as well as bare metal hardware. There are also new types for specific technologies such as HadoopCluster , KubernetesCluster and DockerContainer to provide concrete examples of different types of hosts using popular technologies. Storage volumes There are new types for defining a storage volume that has been attached to a host. See description in model 0036 . ApplicationService A new subtype of software server for reusable business functions (such as microservices) has been added called ApplicationService . See description in model 0057 . ServerEndpoint The ServerEndpoint relationship can now connect to any ITInfrastructure elements, not just SoftwareServers . See description in model 0040 . OperatingPlatform The OperatingPlatform entity can now record the patch level of the operating system. There are also new types for describing the contents of an operating platform. See description in model 0030 . DeployedVirtualContainer The DeployedVirtualContainer relationship has been deprecated in favor of a more generic HostedHost relationship. See description in model 0035 . BoundedSchemaType, BoundedSchemaElementType, ArraySchemaType, SetSchemaType See description in model 0507 . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":"3.1 (expected September 2021)"},{"location":"release-notes/content-status/","text":"Content status \u00b6 The Egeria Community is constantly innovating in the field of metadata integration and governance. The code is developed using an agile process. As such, new code is continuously introduced. The benefit is that there is plenty of opportunity to feedback and influence the development process. The downside is that the master branch contains code at different stages of development. The aim of this page is to document how we label the different modules, so you can choose what to consume. These labels are found in the README.md files at the top level of each module. Basically, a module will go through the phases in this order: In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Technical preview Technical preview function is in a state that it can be tried. The development is complete, there is documentation and there are samples, tutorials and hands-on labs as appropriate. The community is looking for feedback on the function before releasing it. This feedback may result in changes to the external interfaces. Released This function is complete and can be used. The interfaces will be supported until the function is removed from the project via the deprecation process. There will be ongoing extensions to this function, but it will be done to ensure backward compatibility as far as possible. If there is a need to break backward compatibility, this will be discussed and reviewed in the community, with a documented timeline. Deprecated This function has been previously released. However, the maintainers believe there is no one interested in using, maintaining and developing this function. It may be removed in the future if there is consensus in the community. The README for this module will describe the timeline for this process. If you see deprecated function that you need, please contact the community and vote for its continued support. The current phase is shown at the top of the page. The history of the phases that the module has gone through is shown towards the end of the page.","title":"Content Status"},{"location":"release-notes/content-status/#content-status","text":"The Egeria Community is constantly innovating in the field of metadata integration and governance. The code is developed using an agile process. As such, new code is continuously introduced. The benefit is that there is plenty of opportunity to feedback and influence the development process. The downside is that the master branch contains code at different stages of development. The aim of this page is to document how we label the different modules, so you can choose what to consume. These labels are found in the README.md files at the top level of each module. Basically, a module will go through the phases in this order: In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Technical preview Technical preview function is in a state that it can be tried. The development is complete, there is documentation and there are samples, tutorials and hands-on labs as appropriate. The community is looking for feedback on the function before releasing it. This feedback may result in changes to the external interfaces. Released This function is complete and can be used. The interfaces will be supported until the function is removed from the project via the deprecation process. There will be ongoing extensions to this function, but it will be done to ensure backward compatibility as far as possible. If there is a need to break backward compatibility, this will be discussed and reviewed in the community, with a documented timeline. Deprecated This function has been previously released. However, the maintainers believe there is no one interested in using, maintaining and developing this function. It may be removed in the future if there is consensus in the community. The README for this module will describe the timeline for this process. If you see deprecated function that you need, please contact the community and vote for its continued support. The current phase is shown at the top of the page. The history of the phases that the module has gone through is shown towards the end of the page.","title":"Content status"},{"location":"release-notes/latest/","text":"3.0 (August 2021) \u00b6 Special note on Java support Java 11 is now required to build and run Egeria. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes Java 11 required As of Release 3.0 of Egeria, Java 11 is required to build and run Egeria. Egeria will not build / run / be supported on Java 8. Developers are now able to use Java 11 only functionality. Java releases beyond Java 11 up to the current release have some informal testing, and we do build verification on the current release (currently 16). See Java for further information. Defaults to multiple topics for cohorts The option added in release 2.11 to allow multiple topics per cohort now becomes the default in release 3.0. Changed passwords Passwords for the sample Coco Pharmaceuticals users were changed to secret . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":"Latest Release"},{"location":"release-notes/latest/#30-august-2021","text":"Special note on Java support Java 11 is now required to build and run Egeria. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes Java 11 required As of Release 3.0 of Egeria, Java 11 is required to build and run Egeria. Egeria will not build / run / be supported on Java 8. Developers are now able to use Java 11 only functionality. Java releases beyond Java 11 up to the current release have some informal testing, and we do build verification on the current release (currently 16). See Java for further information. Defaults to multiple topics for cohorts The option added in release 2.11 to allow multiple topics per cohort now becomes the default in release 3.0. Changed passwords Passwords for the sample Coco Pharmaceuticals users were changed to secret . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":"3.0 (August 2021)"},{"location":"release-notes/next/","text":"3.1 (expected September 2021) \u00b6 Special note on Java support Java 11 is now required to build and run Egeria. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes docker-compose The docker-compose environment for running our Coco Pharmaceuticals lab demo/tutorial is now deprecated. The configuration is still available, but will not be further developed or tested, and will be removed in a future release. Our Kubernetes Helm charts are now recommended to quickly setup the same lab environment, and the documentation for these has been improved to cover a Kubernetes introduction, and example based on 'microk8s' which are suited to an end-user desktop environment (and can also be run in enterprise/cloud environments). Type changes: added, modified, deprecated Data processing purposes See new type descriptions in model 0485 . Distinguishing between virtual machines, containers and bare metal hardware There are now types for distinguishing between virtual machines and virtual containers as well as bare metal hardware. There are also new types for specific technologies such as HadoopCluster , KubernetesCluster and DockerContainer to provide concrete examples of different types of hosts using popular technologies. Storage volumes There are new types for defining a storage volume that has been attached to a host. See description in model 0036 . ApplicationService A new subtype of software server for reusable business functions (such as microservices) has been added called ApplicationService . See description in model 0057 . ServerEndpoint The ServerEndpoint relationship can now connect to any ITInfrastructure elements, not just SoftwareServers . See description in model 0040 . OperatingPlatform The OperatingPlatform entity can now record the patch level of the operating system. There are also new types for describing the contents of an operating platform. See description in model 0030 . DeployedVirtualContainer The DeployedVirtualContainer relationship has been deprecated in favor of a more generic HostedHost relationship. See description in model 0035 . BoundedSchemaType, BoundedSchemaElementType, ArraySchemaType, SetSchemaType See description in model 0507 . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":"Next Release"},{"location":"release-notes/next/#31-expected-september-2021","text":"Special note on Java support Java 11 is now required to build and run Egeria. Known issue: use chromium-based browser for UIs It is recommended to use a chromium-based browser such as Google Chrome, Microsoft Edge or Apple Safari for the Egeria React UI. Some parts of the UI experience such as Dino currently experience problems with Firefox. See odpi/egeria-react-ui#96 . Functional changes docker-compose The docker-compose environment for running our Coco Pharmaceuticals lab demo/tutorial is now deprecated. The configuration is still available, but will not be further developed or tested, and will be removed in a future release. Our Kubernetes Helm charts are now recommended to quickly setup the same lab environment, and the documentation for these has been improved to cover a Kubernetes introduction, and example based on 'microk8s' which are suited to an end-user desktop environment (and can also be run in enterprise/cloud environments). Type changes: added, modified, deprecated Data processing purposes See new type descriptions in model 0485 . Distinguishing between virtual machines, containers and bare metal hardware There are now types for distinguishing between virtual machines and virtual containers as well as bare metal hardware. There are also new types for specific technologies such as HadoopCluster , KubernetesCluster and DockerContainer to provide concrete examples of different types of hosts using popular technologies. Storage volumes There are new types for defining a storage volume that has been attached to a host. See description in model 0036 . ApplicationService A new subtype of software server for reusable business functions (such as microservices) has been added called ApplicationService . See description in model 0057 . ServerEndpoint The ServerEndpoint relationship can now connect to any ITInfrastructure elements, not just SoftwareServers . See description in model 0040 . OperatingPlatform The OperatingPlatform entity can now record the patch level of the operating system. There are also new types for describing the contents of an operating platform. See description in model 0030 . DeployedVirtualContainer The DeployedVirtualContainer relationship has been deprecated in favor of a more generic HostedHost relationship. See description in model 0035 . BoundedSchemaType, BoundedSchemaElementType, ArraySchemaType, SetSchemaType See description in model 0507 . Bug fixes and other updates For details, see the commit history in GitHub . Implementation status","title":"3.1 (expected September 2021)"},{"location":"release-notes/overview/","text":"Release Notes Overview \u00b6 The project aims to produce a new release about once a month. Each release includes new features and fixes to existing function. Backwards compatibility The team aims to provide complete backward compatibility for all components that are officially released 1 . If backwards compatible changes are not possible, it will be called out explicitly in the release notes with an explanation on how to upgrade. Each release will also upgrade the level of its dependencies to ensure Egeria is running with all the latest security patches. We therefore recommend that you keep moving forward with us to get the best Egeria experience possible. Feedback One way you can help us is to feedback on your experiences, both good and bad. We would love to hear from you! If you discover an issue in the release you are using, we recommend first upgrading to the latest available release. If this does not resolve the problem, please raise a new GitHub issue . You can also follow our discussions by joining us on Slack . Our master branch is currently taking code for all future releases. Many of the features are large and the teams integrate code for partial function as soon as it is stable and has no impact on released function. So you will see support for much more function than is officially released. This way you can monitor and feedback on future items as they are developed. The roadmap for Egeria describes the end vision for Egeria and our current status. To understand more about what it means to have \"released function\" see Egeria content status . \u21a9","title":"Release Notes"},{"location":"release-notes/overview/#release-notes-overview","text":"The project aims to produce a new release about once a month. Each release includes new features and fixes to existing function. Backwards compatibility The team aims to provide complete backward compatibility for all components that are officially released 1 . If backwards compatible changes are not possible, it will be called out explicitly in the release notes with an explanation on how to upgrade. Each release will also upgrade the level of its dependencies to ensure Egeria is running with all the latest security patches. We therefore recommend that you keep moving forward with us to get the best Egeria experience possible. Feedback One way you can help us is to feedback on your experiences, both good and bad. We would love to hear from you! If you discover an issue in the release you are using, we recommend first upgrading to the latest available release. If this does not resolve the problem, please raise a new GitHub issue . You can also follow our discussions by joining us on Slack . Our master branch is currently taking code for all future releases. Many of the features are large and the teams integrate code for partial function as soon as it is stable and has no impact on released function. So you will see support for much more function than is officially released. This way you can monitor and feedback on future items as they are developed. The roadmap for Egeria describes the end vision for Egeria and our current status. To understand more about what it means to have \"released function\" see Egeria content status . \u21a9","title":"Release Notes Overview"},{"location":"release-notes/roadmap/","text":"Roadmap \u00b6 Egeria is a large project with many different activities adding content to the project. This page provides an overview of the aims of the project and a reflection of where we are today. Capability layers \u00b6 Egeria aims to deliver against 5 capability layers: Governance solutions \u00b6 Support the leadership team for a governance program providing the ability to create common definitions and monitor the success of the governance efforts across the enterprise. The implementation of a governance solution is focused mainly on the extension of the Egeria UI to support additional roles and functions. They make use of the services provided by the developer platform and may exploit additional content, utilities and connector implementations from the integration platform. Education \u00b6 Provides educational resources for different personas and starting points. Egeria's education aims to broaden the knowledge of people who need to work with digital resources about metadata, governance practices and the use of Egeria. Since there are many types of professionals involved with different skill levels, there are different choices: The Egeria dojo is a deep dive into the Egeria code and community. It is aimed at individuals who wish to become contributors. The hands-on labs provide practical experiences in running the Egeria code and using the different services. It is based around the Coco Pharmaceuticals use case and is organized by persona so you can target your learning to your interests. The guidance on governance provides governance best practices and training using the same Coco Pharmaceuticals use cases as the hands-on labs. They aim to guide a team that is setting up or revising their governance program through common governance tasks. They link to the Egeria code samples and hands-on labs to show how these best practices could be implemented using Egeria. The edX courses are a new idea to provide a full curriculum and certification for governance professionals and architects. It is in the early phases of design. Integration platform \u00b6 Supports integration of popular technologies by installing and configuring Egeria. Minimal coding is still required around unusual and home-grown tools and technologies. Ecosystem UIs: server and platform configuration, ecosystem monitoring, type explorer and repository explorer. Utilities and converters: support for different standard formats to load industry standard definitions, models, glossaries, and other content packs built on industry standard definitions, models, glossaries and other content packs. Examples include JSON-LD, OWL/RDF, XML, ... Pre-canned connectors to third party technologies: popular metadata repositories, databases, data formats and platforms; data movement engines, data virtualization engines, dev ops tools, analytics/AI tools, data catalogs, MDM and user directories, CMDBs, SDLC tools, ... Conformance test suite : Supports the testing of third party connectors. Each type of connector or service is supported by its own test workbench. Developer platform \u00b6 Provides frameworks, APIs, and hosting platforms for building an integrated metadata and distributed governance solutions. The developer platform contains the core Egeria implementation and provides support for integrating third party technology into the open metadata ecosystem and extending Egeria to run in different environments or to use different infrastructure services. Its use is described in the developer's guide . Open Metadata and Governance ( OMAG ) registered services are dynamically loaded in the OMAG Server Platform. This means they can be added and removed as needed to create a customized platform. This may include registered services written by the Egeria community and supplied by third parties. The access services provide provide specialist APIs / events for different types of tools. They work with the pre-defined open metadata types and use the repository services to access metadata. Engine services provide the services that host a specific type of governance engine. The governance engines collectively provide active governance to the assets and their associated metadata. Integration services each provide a specialized API to integration connectors. These are hosted in an integration daemon . The purpose of the integration services is to simplify the implementation and management of connectors that integrate metadata exchange with third party technologies. View services provide the services used by UIs. They are typically fine-grained services and they run in the view server . The use of the separate server (and server platform) enables an extra firewall to be erected between the view servers and the metadata servers and governance servers, hiding the internal systems from end users. The open metadata types provide common definitions for the different types of metadata needed by an organization. The open metadata type system is extendable; however, by providing a comprehensive starter set, and encouraging tools to use them, Egeria ensures metadata can be seamlessly shared amongst them. The OMAG Server Platform provides a multi-tenant runtime platform for OMAG Servers . Each OMAG Server hosts the connectors along with the Egeria services to integrate third party technology. The server chassis uses Spring Boot to provide the web server and REST API support for the platform. The administration services supports configuring and operating the OMAG Platform and Servers. Details of how to use the admin services are provided in the administration guide The platform services provide the means to query the OMAG Servers and services running on an OMAG Server Platform. The multi-tenancy management module supports multiple OMAG Servers running on an OMAG Server Platform. The repository services provide the basic ability to share metadata between metadata repositories. The metadata repositories are organized into open metadata repository cohorts . These cohorts define the scope of the metadata sharing and ensure metadata is available to all consumers within the cohort. The metadata security module provides customizable authorization checks for calls to the OMAG Server Platform, OMAG Server and the open metadata instances themselves. A governance server makes use of open metadata to actively manage an aspect of the digital landscape. The governance server services each provide the principle subsystem of a type of governance server . The generic handlers provide support for the type specific maintenance and retrieval of metadata that follows the open metadata types . This includes managing visibility of metadata through the Governance Zones , calls to Open Metadata Security and metadata management using templates . The open metadata frameworks define the interfaces implemented by components that \"plug-in\" to Egeria, either to integrate calls to third party technology or extend the function of Egeria. The frameworks are as follows: Open Connector Framework ( OCF ) - base framework for all types of plug-in components called connectors. Open Discovery Framework ( ODF ) - specialized connectors called discovery services that support automated metadata discovery, Governance Action Framework ( GAF ) - specialized connectors for the triage and remediation of issues found in the digital landscape. Audit Log Framework ( ALF ) - extensions for all types of connectors to enable natural language diagnostics such as exceptions and audit log messages. Deployment resources \u00b6 Aim to simplify the process of deploying the OMAG Server Platform and its connectors into an operational environment. The Egeria docker image is built daily and pushed to DockerHub. It contains an OMAG Server Platform. You can download it and use it in your own container environments. The Kubernetes Helm charts make use of the docker image to create a rich Egeria deployment used in the hands-on labs . The Kubernetes operators are in development. They will provide an easy way to control an Egeria deployment running on Kubernetes. Understanding the roadmap \u00b6 Current status \u00b6 Following is an overview of the current status of the functions in Egeria today: Green means that there is function that is either released or in technical preview . Orange means there is work in progress. Red means it is planned but not started. This chart is being updated with each release. As you can see, some progress has been made on all layers. However, since they do build on one another, most of the early work has been focused on establishing the frameworks, connector APIs and other services to provide the developer platform. The developer platform provides the libraries and interfaces to build connectors to integrate third party tools along with the runtime to host these connectors and manage the metadata exchange. Today we have a robust OMAG Server Platform and the ability to configure OMAG Servers that host specific types of connectors to third party tools. The initial focus was to enable third party metadata servers to connect together in the peer-to-peer open metadata repository cohort. This capability is delivered along with two repository connectors for the following third party connectors: IBM Information Governance Catalog ( IGC ) Apache Atlas History \u00b6 Through 2020, our focus shifted to the integration platform as we added connector implementations for popular third party technologies and standards (see connector catalog ) and built out the ecosystem user interface (UI) that enables an organization to: configure OMAG Servers on OMAG Server Platforms visualize the open metadata types through the type explorer (TEX) visualize open metadata instances in a single repository or across the open metadata repository cohorts that a server is connected to. visualize to cohort and query the operational status of the OMAG Servers and services operating in the open metadata ecosystem configure OMAG Servers and deploy them to OMAG Server Platforms The ecosystem UI makes calls to specialized REST services supported by a type of OMAG Server called the view server . The view server is new for 2020 and enables the REST APIs to the UIs to be deployed in a DMZ and the metadata servers to be behind an additional firewall. It also takes much of the load for supporting end users off of the metadata servers. In 2020 support for a new type of OMAG Server called the integration daemon was also added. This server supports integration services that can host integration connectors dedicated to exchanging metadata with specific third party technologies. Plans \u00b6 2021 has a focus on governing metadata. There is a new OMAG Server called the engine host that runs metadata discovery engines and governance engines. These are supported by new access services for governance. Support for the governance solutions naturally follows along, building on the two lower levels. The governance solutions themselves complement specific metadata and governance solutions available in the market today. Egeria is focused on filling in the gaps to support individuals that are setting up and running an open metadata ecosystem and wish to take advantage of the enterprise perspective it brings. The first solution is Historical Lineage Exploration . This was made available as a tech preview in late 2020. This provides a user interface for finding assets and viewing their lineage along with a dedicated governance server called the open lineage server . Next will be the Subject Area Management solution closely followed by the others in 2021 and beyond.","title":"Roadmap"},{"location":"release-notes/roadmap/#roadmap","text":"Egeria is a large project with many different activities adding content to the project. This page provides an overview of the aims of the project and a reflection of where we are today.","title":"Roadmap"},{"location":"release-notes/roadmap/#capability-layers","text":"Egeria aims to deliver against 5 capability layers:","title":"Capability layers"},{"location":"release-notes/roadmap/#governance-solutions","text":"Support the leadership team for a governance program providing the ability to create common definitions and monitor the success of the governance efforts across the enterprise. The implementation of a governance solution is focused mainly on the extension of the Egeria UI to support additional roles and functions. They make use of the services provided by the developer platform and may exploit additional content, utilities and connector implementations from the integration platform.","title":"Governance solutions"},{"location":"release-notes/roadmap/#education","text":"Provides educational resources for different personas and starting points. Egeria's education aims to broaden the knowledge of people who need to work with digital resources about metadata, governance practices and the use of Egeria. Since there are many types of professionals involved with different skill levels, there are different choices: The Egeria dojo is a deep dive into the Egeria code and community. It is aimed at individuals who wish to become contributors. The hands-on labs provide practical experiences in running the Egeria code and using the different services. It is based around the Coco Pharmaceuticals use case and is organized by persona so you can target your learning to your interests. The guidance on governance provides governance best practices and training using the same Coco Pharmaceuticals use cases as the hands-on labs. They aim to guide a team that is setting up or revising their governance program through common governance tasks. They link to the Egeria code samples and hands-on labs to show how these best practices could be implemented using Egeria. The edX courses are a new idea to provide a full curriculum and certification for governance professionals and architects. It is in the early phases of design.","title":"Education"},{"location":"release-notes/roadmap/#integration-platform","text":"Supports integration of popular technologies by installing and configuring Egeria. Minimal coding is still required around unusual and home-grown tools and technologies. Ecosystem UIs: server and platform configuration, ecosystem monitoring, type explorer and repository explorer. Utilities and converters: support for different standard formats to load industry standard definitions, models, glossaries, and other content packs built on industry standard definitions, models, glossaries and other content packs. Examples include JSON-LD, OWL/RDF, XML, ... Pre-canned connectors to third party technologies: popular metadata repositories, databases, data formats and platforms; data movement engines, data virtualization engines, dev ops tools, analytics/AI tools, data catalogs, MDM and user directories, CMDBs, SDLC tools, ... Conformance test suite : Supports the testing of third party connectors. Each type of connector or service is supported by its own test workbench.","title":"Integration platform"},{"location":"release-notes/roadmap/#developer-platform","text":"Provides frameworks, APIs, and hosting platforms for building an integrated metadata and distributed governance solutions. The developer platform contains the core Egeria implementation and provides support for integrating third party technology into the open metadata ecosystem and extending Egeria to run in different environments or to use different infrastructure services. Its use is described in the developer's guide . Open Metadata and Governance ( OMAG ) registered services are dynamically loaded in the OMAG Server Platform. This means they can be added and removed as needed to create a customized platform. This may include registered services written by the Egeria community and supplied by third parties. The access services provide provide specialist APIs / events for different types of tools. They work with the pre-defined open metadata types and use the repository services to access metadata. Engine services provide the services that host a specific type of governance engine. The governance engines collectively provide active governance to the assets and their associated metadata. Integration services each provide a specialized API to integration connectors. These are hosted in an integration daemon . The purpose of the integration services is to simplify the implementation and management of connectors that integrate metadata exchange with third party technologies. View services provide the services used by UIs. They are typically fine-grained services and they run in the view server . The use of the separate server (and server platform) enables an extra firewall to be erected between the view servers and the metadata servers and governance servers, hiding the internal systems from end users. The open metadata types provide common definitions for the different types of metadata needed by an organization. The open metadata type system is extendable; however, by providing a comprehensive starter set, and encouraging tools to use them, Egeria ensures metadata can be seamlessly shared amongst them. The OMAG Server Platform provides a multi-tenant runtime platform for OMAG Servers . Each OMAG Server hosts the connectors along with the Egeria services to integrate third party technology. The server chassis uses Spring Boot to provide the web server and REST API support for the platform. The administration services supports configuring and operating the OMAG Platform and Servers. Details of how to use the admin services are provided in the administration guide The platform services provide the means to query the OMAG Servers and services running on an OMAG Server Platform. The multi-tenancy management module supports multiple OMAG Servers running on an OMAG Server Platform. The repository services provide the basic ability to share metadata between metadata repositories. The metadata repositories are organized into open metadata repository cohorts . These cohorts define the scope of the metadata sharing and ensure metadata is available to all consumers within the cohort. The metadata security module provides customizable authorization checks for calls to the OMAG Server Platform, OMAG Server and the open metadata instances themselves. A governance server makes use of open metadata to actively manage an aspect of the digital landscape. The governance server services each provide the principle subsystem of a type of governance server . The generic handlers provide support for the type specific maintenance and retrieval of metadata that follows the open metadata types . This includes managing visibility of metadata through the Governance Zones , calls to Open Metadata Security and metadata management using templates . The open metadata frameworks define the interfaces implemented by components that \"plug-in\" to Egeria, either to integrate calls to third party technology or extend the function of Egeria. The frameworks are as follows: Open Connector Framework ( OCF ) - base framework for all types of plug-in components called connectors. Open Discovery Framework ( ODF ) - specialized connectors called discovery services that support automated metadata discovery, Governance Action Framework ( GAF ) - specialized connectors for the triage and remediation of issues found in the digital landscape. Audit Log Framework ( ALF ) - extensions for all types of connectors to enable natural language diagnostics such as exceptions and audit log messages.","title":"Developer platform"},{"location":"release-notes/roadmap/#deployment-resources","text":"Aim to simplify the process of deploying the OMAG Server Platform and its connectors into an operational environment. The Egeria docker image is built daily and pushed to DockerHub. It contains an OMAG Server Platform. You can download it and use it in your own container environments. The Kubernetes Helm charts make use of the docker image to create a rich Egeria deployment used in the hands-on labs . The Kubernetes operators are in development. They will provide an easy way to control an Egeria deployment running on Kubernetes.","title":"Deployment resources"},{"location":"release-notes/roadmap/#understanding-the-roadmap","text":"","title":"Understanding the roadmap"},{"location":"release-notes/roadmap/#current-status","text":"Following is an overview of the current status of the functions in Egeria today: Green means that there is function that is either released or in technical preview . Orange means there is work in progress. Red means it is planned but not started. This chart is being updated with each release. As you can see, some progress has been made on all layers. However, since they do build on one another, most of the early work has been focused on establishing the frameworks, connector APIs and other services to provide the developer platform. The developer platform provides the libraries and interfaces to build connectors to integrate third party tools along with the runtime to host these connectors and manage the metadata exchange. Today we have a robust OMAG Server Platform and the ability to configure OMAG Servers that host specific types of connectors to third party tools. The initial focus was to enable third party metadata servers to connect together in the peer-to-peer open metadata repository cohort. This capability is delivered along with two repository connectors for the following third party connectors: IBM Information Governance Catalog ( IGC ) Apache Atlas","title":"Current status"},{"location":"release-notes/roadmap/#history","text":"Through 2020, our focus shifted to the integration platform as we added connector implementations for popular third party technologies and standards (see connector catalog ) and built out the ecosystem user interface (UI) that enables an organization to: configure OMAG Servers on OMAG Server Platforms visualize the open metadata types through the type explorer (TEX) visualize open metadata instances in a single repository or across the open metadata repository cohorts that a server is connected to. visualize to cohort and query the operational status of the OMAG Servers and services operating in the open metadata ecosystem configure OMAG Servers and deploy them to OMAG Server Platforms The ecosystem UI makes calls to specialized REST services supported by a type of OMAG Server called the view server . The view server is new for 2020 and enables the REST APIs to the UIs to be deployed in a DMZ and the metadata servers to be behind an additional firewall. It also takes much of the load for supporting end users off of the metadata servers. In 2020 support for a new type of OMAG Server called the integration daemon was also added. This server supports integration services that can host integration connectors dedicated to exchanging metadata with specific third party technologies.","title":"History"},{"location":"release-notes/roadmap/#plans","text":"2021 has a focus on governing metadata. There is a new OMAG Server called the engine host that runs metadata discovery engines and governance engines. These are supported by new access services for governance. Support for the governance solutions naturally follows along, building on the two lower levels. The governance solutions themselves complement specific metadata and governance solutions available in the market today. Egeria is focused on filling in the gaps to support individuals that are setting up and running an open metadata ecosystem and wish to take advantage of the enterprise perspective it brings. The first solution is Historical Lineage Exploration . This was made available as a tech preview in late 2020. This provides a user interface for finding assets and viewing their lineage along with a dedicated governance server called the open lineage server . Next will be the Subject Area Management solution closely followed by the others in 2021 and beyond.","title":"Plans"},{"location":"scenarios/data-manager-integration/overview/","text":"Data manager integration \u00b6 A data manager is a technology that manages collections of data. Examples include database management systems, document/content managers, event brokers, API gateways and file systems. The data manager typically maintains a catalog of the data it is managing and the purpose of the data manager integration is to bring this metadata into the open metadata ecosystem. Once it is in the open metadata ecosystem, the metadata can be distributed and enhanced with classifications and relationships to glossary terms, tags and reference data sets to help people find these assets and to enable governance engines to manage them. In this solution we are going to cover: automatic cataloguing of data assets and their properties automatic distribution of information about data assets to interested parties automatic configuration of data managers based on the data assets in other data managers Figure 1 shows the set up to extract metadata from one or more data managers and store it in a metadata server. It takes an integration connector to interface with a specific data manager. This is running in an appropriate Open Metadata Integration Service ( OMIS ) hosted in an Integration Daemon . The OMIS to use for different types of technology is shown in the table below. Technology Examples OMIS Database PostgreSQL Database Integrator OMIS Filesystems local disk storage Files Integrator OMIS Document/Content Managers Photo Library Files Integrator OMIS Event Brokers Apache Kafka Topic Integrator OMIS API Managers Swagger Site API Integrator OMIS In Figure 1, integration connector Database Extractor is monitoring for schema changes in the Database Server and cataloguing them in open metadata through the Database Integrator OMIS . The Database Integrator OMIS calls the Data Manager OMAS which stores the open metadata in its local repository. Similarly, * Integration connector File System Extractor is monitoring for changes to files on the file system and cataloguing them in open metadata through the Files Integrator OMIS and the Data Manager OMAS . * Integration connector Document Extractor is monitoring for changes to documents in a content manager and cataloguing them in open metadata through the Files Integrator OMIS and the Data Manager OMAS . * Integration connector Topic Extractor is monitoring for changes to files on the file system and cataloguing them in open metadata through the Topic Integrator OMIS and the Data Manager OMAS . * Integration connector API Extractor is monitoring for changes to deployed APIs in a platform or API gateway and cataloguing them in open metadata through the API Integrator OMIS and the Data Manager OMAS . Figure 1: Set up for metadata extraction from data managers and stored in a local repository Figure 2 shows a similar set up except that the resulting metadata is being stored in a remote metadata repository connected via a cohort . Figure 2: Set up for metadata extraction from data managers and stored in a remote repository Figure 3 adds a new integration connector (called Data Asset Distributor ) that listens for events from the Data Manager OMAS about new or updated data assets being catalogued in any repository in the cohort. This Data Asset Distributor can distribute this information to other processes. Note, Data Asset Distributor could be deployed in the same integration daemon as Database Extractor and File System Extractor . It is show in a different integration daemon for the sake of clarity in the diagram. Figure 3: Set up for distribution of metadata from data managers Figure 4 shows two integration connectors that are maintaining database views in a Data Virtualization Engine. Database View Maker is listening for new databases and schema changes and automatically configuring views over these data sources and the second copy of Database Extractor is detecting the schema changes in the Data Data Virtualization Engine and is cataloguing them in open metadata. It is possible for Database View Maker to create the metadata for the views that it is creating. However the approach shown in Figure 4 has the advantage that all views created in the Data Virtualization Engine are catalogued rather than just the ones created by Database View Maker . Figure 4: Set up for distribution of metadata from data managers Link to the Connector Catalog to understand the integration connectors supplied by Egeria Return to the Egeria solutions descriptions","title":"Data Manager Integration"},{"location":"scenarios/data-manager-integration/overview/#data-manager-integration","text":"A data manager is a technology that manages collections of data. Examples include database management systems, document/content managers, event brokers, API gateways and file systems. The data manager typically maintains a catalog of the data it is managing and the purpose of the data manager integration is to bring this metadata into the open metadata ecosystem. Once it is in the open metadata ecosystem, the metadata can be distributed and enhanced with classifications and relationships to glossary terms, tags and reference data sets to help people find these assets and to enable governance engines to manage them. In this solution we are going to cover: automatic cataloguing of data assets and their properties automatic distribution of information about data assets to interested parties automatic configuration of data managers based on the data assets in other data managers Figure 1 shows the set up to extract metadata from one or more data managers and store it in a metadata server. It takes an integration connector to interface with a specific data manager. This is running in an appropriate Open Metadata Integration Service ( OMIS ) hosted in an Integration Daemon . The OMIS to use for different types of technology is shown in the table below. Technology Examples OMIS Database PostgreSQL Database Integrator OMIS Filesystems local disk storage Files Integrator OMIS Document/Content Managers Photo Library Files Integrator OMIS Event Brokers Apache Kafka Topic Integrator OMIS API Managers Swagger Site API Integrator OMIS In Figure 1, integration connector Database Extractor is monitoring for schema changes in the Database Server and cataloguing them in open metadata through the Database Integrator OMIS . The Database Integrator OMIS calls the Data Manager OMAS which stores the open metadata in its local repository. Similarly, * Integration connector File System Extractor is monitoring for changes to files on the file system and cataloguing them in open metadata through the Files Integrator OMIS and the Data Manager OMAS . * Integration connector Document Extractor is monitoring for changes to documents in a content manager and cataloguing them in open metadata through the Files Integrator OMIS and the Data Manager OMAS . * Integration connector Topic Extractor is monitoring for changes to files on the file system and cataloguing them in open metadata through the Topic Integrator OMIS and the Data Manager OMAS . * Integration connector API Extractor is monitoring for changes to deployed APIs in a platform or API gateway and cataloguing them in open metadata through the API Integrator OMIS and the Data Manager OMAS . Figure 1: Set up for metadata extraction from data managers and stored in a local repository Figure 2 shows a similar set up except that the resulting metadata is being stored in a remote metadata repository connected via a cohort . Figure 2: Set up for metadata extraction from data managers and stored in a remote repository Figure 3 adds a new integration connector (called Data Asset Distributor ) that listens for events from the Data Manager OMAS about new or updated data assets being catalogued in any repository in the cohort. This Data Asset Distributor can distribute this information to other processes. Note, Data Asset Distributor could be deployed in the same integration daemon as Database Extractor and File System Extractor . It is show in a different integration daemon for the sake of clarity in the diagram. Figure 3: Set up for distribution of metadata from data managers Figure 4 shows two integration connectors that are maintaining database views in a Data Virtualization Engine. Database View Maker is listening for new databases and schema changes and automatically configuring views over these data sources and the second copy of Database Extractor is detecting the schema changes in the Data Data Virtualization Engine and is cataloguing them in open metadata. It is possible for Database View Maker to create the metadata for the views that it is creating. However the approach shown in Figure 4 has the advantage that all views created in the Data Virtualization Engine are catalogued rather than just the ones created by Database View Maker . Figure 4: Set up for distribution of metadata from data managers Link to the Connector Catalog to understand the integration connectors supplied by Egeria Return to the Egeria solutions descriptions","title":"Data manager integration"},{"location":"scenarios/file-lineage/overview/","text":"File Lineage Solutions \u00b6 Lineage shows how data flows from its origins to its various destinations. Files are often managed through a variety of ad hoc processes. They are often copied multiple times or moved from one location to another. This means that organizations need a variety of approaches to properly record lineage for files. The scenario \u00b6 Consider this example. Figure 1 shows the week4.csv file in the landing folder. It was transferred from an external party and has been automatically catalogued so it can be part of the lineage flow that identifies the source of the file. Figure 1: Receipt of file in a landing folder Then in figure 2, an onboarding process removes the file from the landing area and puts one copy in a folder in the data lake and another copy in an archive file. Figure 2: Movement of file from the landing folder to the data lake and an archive Once the onboarding process completes, the landing folder is empty as shown in figure 3. What happens to the asset that catalogued the file in the landing area? Figure 3: Ready for the next file from the hospital What follows are two possible solutions for managing lineage for files being ingested in to a data lake. Metadata capture for an onboarding process that publishes lineage \u00b6 Figure 1 shows an example of using the integration daemon to automatically capture lineage from a spark job onboarding the files in to a data lake. The spark job operates independently of Egeria but is publishing lineage through the Open Lineage API. There is a Lineage Integrator OMIS integration connector capturing this lineage from the spark job, correlating this information with the Assets being created by the integration connectors running in the Files Integrator OMIS . Figure 4: Automatic lineage capture from an external process A new file is added to the landing folder New file detected by Data File Monitor Integration Connector Asset catalogued for the new file asset Spark job detects the file in the landing folder and runs, moving the file to the data lake (and archive folder) The new file in the data lake folder is detected by the Data Folder Monitor Integration Connector The Data Folder asset is updated to reflect the new data Meanwhile the spark job is publishing lineage metadata which is picked up by the Spark Lineage Capture Integration Connector The Spark Lineage Capture Integration Connector correlates the lineage metadata from spark with the assets in the metadata catalog and records the lineage. Metadata capture through a provisioning governance action service \u00b6 Figure 5 is an alternative design where the onboarding process is implemented in a Provisioning Governance Action Service . running in an Engine Host server. The provisioning governance action service records lineage directly in the metadata server as part of its processing. This means the Lineage Capture Integration Connector is not needed. Figure 5: Automatic lineage capture from a provisioning governance action service New file detected by Data File Monitor Integration Connector File asset created in metadata server New Asset event passed to Watchdog Governance Service New Governance Action created that results in notification to Engine Host Engine Host claims Governance Action and activates Provisioning Governance Service Provisioning Governance Service moves file and writes lineage Deleted file is detected and Asset archived Resulting Lineage graphs \u00b6 Figure 6 shows the resulting lineage graph for the onboarding process. It represents the lineage status as the point shown in figure 1. Figure 6: Lineage at the point shown in figure 1 An organization may choose to the show the archive folder in lineage or it may not. It depends if it is useful to the catalog users. This is therefore shown as optional. The files: * Week 1 Landed DataFile * Week 2 Landed DataFile * Week 3 Landed DataFile are show in a slightly different color. Ths is to indicate that they have been classified with the Memento Classification to indicate that the described real world resource no longer exists and the asset is being kept to maintain the lineage graph. Figure 7 shows how the memento classification is stored in open metadata. Figure 7: Memento representation","title":"File Lineage"},{"location":"scenarios/file-lineage/overview/#file-lineage-solutions","text":"Lineage shows how data flows from its origins to its various destinations. Files are often managed through a variety of ad hoc processes. They are often copied multiple times or moved from one location to another. This means that organizations need a variety of approaches to properly record lineage for files.","title":"File Lineage Solutions"},{"location":"scenarios/file-lineage/overview/#the-scenario","text":"Consider this example. Figure 1 shows the week4.csv file in the landing folder. It was transferred from an external party and has been automatically catalogued so it can be part of the lineage flow that identifies the source of the file. Figure 1: Receipt of file in a landing folder Then in figure 2, an onboarding process removes the file from the landing area and puts one copy in a folder in the data lake and another copy in an archive file. Figure 2: Movement of file from the landing folder to the data lake and an archive Once the onboarding process completes, the landing folder is empty as shown in figure 3. What happens to the asset that catalogued the file in the landing area? Figure 3: Ready for the next file from the hospital What follows are two possible solutions for managing lineage for files being ingested in to a data lake.","title":"The scenario"},{"location":"scenarios/file-lineage/overview/#metadata-capture-for-an-onboarding-process-that-publishes-lineage","text":"Figure 1 shows an example of using the integration daemon to automatically capture lineage from a spark job onboarding the files in to a data lake. The spark job operates independently of Egeria but is publishing lineage through the Open Lineage API. There is a Lineage Integrator OMIS integration connector capturing this lineage from the spark job, correlating this information with the Assets being created by the integration connectors running in the Files Integrator OMIS . Figure 4: Automatic lineage capture from an external process A new file is added to the landing folder New file detected by Data File Monitor Integration Connector Asset catalogued for the new file asset Spark job detects the file in the landing folder and runs, moving the file to the data lake (and archive folder) The new file in the data lake folder is detected by the Data Folder Monitor Integration Connector The Data Folder asset is updated to reflect the new data Meanwhile the spark job is publishing lineage metadata which is picked up by the Spark Lineage Capture Integration Connector The Spark Lineage Capture Integration Connector correlates the lineage metadata from spark with the assets in the metadata catalog and records the lineage.","title":"Metadata capture for an onboarding process that publishes lineage"},{"location":"scenarios/file-lineage/overview/#metadata-capture-through-a-provisioning-governance-action-service","text":"Figure 5 is an alternative design where the onboarding process is implemented in a Provisioning Governance Action Service . running in an Engine Host server. The provisioning governance action service records lineage directly in the metadata server as part of its processing. This means the Lineage Capture Integration Connector is not needed. Figure 5: Automatic lineage capture from a provisioning governance action service New file detected by Data File Monitor Integration Connector File asset created in metadata server New Asset event passed to Watchdog Governance Service New Governance Action created that results in notification to Engine Host Engine Host claims Governance Action and activates Provisioning Governance Service Provisioning Governance Service moves file and writes lineage Deleted file is detected and Asset archived","title":"Metadata capture through a provisioning governance action service"},{"location":"scenarios/file-lineage/overview/#resulting-lineage-graphs","text":"Figure 6 shows the resulting lineage graph for the onboarding process. It represents the lineage status as the point shown in figure 1. Figure 6: Lineage at the point shown in figure 1 An organization may choose to the show the archive folder in lineage or it may not. It depends if it is useful to the catalog users. This is therefore shown as optional. The files: * Week 1 Landed DataFile * Week 2 Landed DataFile * Week 3 Landed DataFile are show in a slightly different color. Ths is to indicate that they have been classified with the Memento Classification to indicate that the described real world resource no longer exists and the asset is being kept to maintain the lineage graph. Figure 7 shows how the memento classification is stored in open metadata. Figure 7: Memento representation","title":"Resulting Lineage graphs"},{"location":"services/admin-services/","text":"Administration services \u00b6 The administration services support the command to both configure and operate an OMAG server .","title":"Admin services"},{"location":"services/admin-services/#administration-services","text":"The administration services support the command to both configure and operate an OMAG server .","title":"Administration services"},{"location":"services/data-engine-proxy-services/","text":"Data engine proxy services \u00b6 The data engine proxy services support the behavior of the data engine proxy .","title":"Data Engine Proxy Services"},{"location":"services/data-engine-proxy-services/#data-engine-proxy-services","text":"The data engine proxy services support the behavior of the data engine proxy .","title":"Data engine proxy services"},{"location":"services/engine-host-services/","text":"Engine host services \u00b6 The engine host services support the behavior of the engine host .","title":"Engine Host Services"},{"location":"services/engine-host-services/#engine-host-services","text":"The engine host services support the behavior of the engine host .","title":"Engine host services"},{"location":"services/ffdc-services/","text":"First failure data capture (FFDC) services \u00b6 The FFDC services supports common functions that many other services use in their REST API support: Logging the start and return to debug logging for each REST call made Capture exceptions before they are returned and set up appropriate information in response objects.","title":"FFDC"},{"location":"services/ffdc-services/#first-failure-data-capture-ffdc-services","text":"The FFDC services supports common functions that many other services use in their REST API support: Logging the start and return to debug logging for each REST call made Capture exceptions before they are returned and set up appropriate information in response objects.","title":"First failure data capture (FFDC) services"},{"location":"services/generic-handlers/","text":"Generic handlers module \u00b6 The generic handlers module supports the following features: Anchor management .","title":"Generic Handlers"},{"location":"services/generic-handlers/#generic-handlers-module","text":"The generic handlers module supports the following features: Anchor management .","title":"Generic handlers module"},{"location":"services/integration-daemon-services/","text":"Integration daemon services \u00b6 The integration daemon services support the behavior of the integration daemon .","title":"Integration Daemon Services"},{"location":"services/integration-daemon-services/#integration-daemon-services","text":"The integration daemon services support the behavior of the integration daemon .","title":"Integration daemon services"},{"location":"services/metadata-security-services/","text":"Metadata security services \u00b6 The metadata security services supports the connector interfaces and the mechanisms to invoke any configured security connectors .","title":"Metadata security services"},{"location":"services/metadata-security-services/#metadata-security-services","text":"The metadata security services supports the connector interfaces and the mechanisms to invoke any configured security connectors .","title":"Metadata security services"},{"location":"services/open-lineage-services/","text":"Open lineage services \u00b6 The open lineage services support the behavior of the open lineage server .","title":"Open Lineage Services (OLS)"},{"location":"services/open-lineage-services/#open-lineage-services","text":"The open lineage services support the behavior of the open lineage server .","title":"Open lineage services"},{"location":"services/platform/","text":"Released This function is complete and can be used. The interfaces will be supported until the function is removed from the project via the deprecation process. There will be ongoing extensions to this function, but it will be done to ensure backward compatibility as far as possible. If there is a need to break backward compatibility, this will be discussed and reviewed in the community, with a documented timeline. Platform Services \u00b6 The platform services provide the APIs for querying the Open Metadata and Governance ( OMAG ) Server Platform and discovering information about the OMAG Servers that it is hosting. There are two parts to the platform services: The OMAG Server Platform Origin Service returns a platform identifier that indicates which version of the platform is running. The OMAG Server Platform Active Service returns information about the known and active servers running on the platform along with definitions of each type of Open Metadata and Governance ( OMAG ) services.","title":"Platform Services"},{"location":"services/platform/#platform-services","text":"The platform services provide the APIs for querying the Open Metadata and Governance ( OMAG ) Server Platform and discovering information about the OMAG Servers that it is hosting. There are two parts to the platform services: The OMAG Server Platform Origin Service returns a platform identifier that indicates which version of the platform is running. The OMAG Server Platform Active Service returns information about the known and active servers running on the platform along with definitions of each type of Open Metadata and Governance ( OMAG ) services.","title":"Platform Services"},{"location":"services/repository-handler/","text":"Repository handler \u00b6 The repository handler supports the following features: Selection of elements to return based on their effectivity dates . Deduplication . Metadata provenance validation.","title":"Repository handler"},{"location":"services/repository-handler/#repository-handler","text":"The repository handler supports the following features: Selection of elements to return based on their effectivity dates . Deduplication . Metadata provenance validation.","title":"Repository handler"},{"location":"services/omas/","text":"Open Metadata Access Services ( OMAS ) \u00b6 The Open Metadata Access Services ( OMAS ) provide domain-specific services for data tools, engines and platforms to integrate with open metadata. The access services are as follows: OMAS Description analytics-modeling The Analytics Modeling OMAS configures and manages metadata for modeling analytics and reporting services. asset-catalog The Asset Catalog OMAS provides search and query capabilities for tools and applications to support an asset catalog function. It supports search requests for assets with specific characteristics and returns summaries of the matching assets, plus methods to allow drill-down into the details of a specific asset to related metadata. asset-consumer The Asset Consumer OMAS is designed for applications that are using OCF connectors to access data stores, APIs and functions such as analytics. The Asset Consumer OMAS provides a factory function for the connectors, the ability to retrieve all of the metadata about the asset and the ability to add feedback on the asset. asset-lineage The Asset Lineage OMAS listens to relevant lineage related events on the enterprise topic level and publishes these on the Asset Lineage OutTopic, combined with relevant context information on the described entities. These events are listened to by the open lineage services governance server. asset-manager The Asset Manager OMAS manages the exchange of metadata with third party metadata catalogs and asset managers. It is typically called by the Catalog Integrator OMIS to send and receive asset information, including schemas, profiles, policies and lineage information with a third party asset manager. Typical examples of asset managers include data catalogs that are managing metadata for a collection of data assets for a data-serving solution. asset-owner The Asset Owner OMAS provides services for an asset owner to curate metadata about their asset(s) and understand how these assets are being used and governed. community-profile The Community Profile OMAS supports the administration for a community and related user profiles. These communities are involved in reviewing and crowd-sourcing knowledge about the data assets and their use. data-engine The Data Engine OMAS provides APIs and events for a data movement/processing engine to record the changes it is making the the data landscape. This information forms a key part of asset lineage. data-manager The Data Manager OMAS provides an integration point to enable technologies that manage collections of data such as database servers, file systems, file managers and content managers to publish metadata to the metadata repositories about the changing structures and content stored in the data platform. It is typically called from the Database Integrator OMIS and Files Integrator OMIS integration services. data-privacy The Data Privacy OMAS supports a privacy officer as they manage data privacy in their organization. This includes managing privacy impact assessments and reviews of software services that use personal data as they move through their development, deployment and use. data-science The Data Science OMAS provides access to metadata for data assets, connections and projects, plus the ability to maintain metadata about data science notebooks and models and log activity during the analytics development process. It is designed for data science and analytics management tools. design-model The Design Model OMAS provides the ability to manage information from all types of design models. These models may come from tools or be part of a packaged standard. This content is useful for governance, system integration and software development. dev-ops The DevOps OMAS provides services for a DevOps pipeline to query and maintain metadata about systems, processes and software components that are being deployed into the information landscape. digital-architecture The Digital Architecture OMAS provides the ability to define information standards, definitions, solution blueprints and models for an organization. It is designed for architecture tools. It is able to support the definition and management of a digital service through concept to deployment. digital-service The Digital Service OMAS provides services for a managing the lifecycle of an Egeria Digital Service. discovery-engine The Discovery Engine OMAS provides an API for a discovery engine to access and store metadata from an open metadata repository (or open metadata repository cohort). governance-engine The Governance Engine OMAS provides APIs and events that retrieve and manage metadata for governance engines. Governance engines ensure that the infrastructure supporting the data landscape is operating according to the governance program. For example, the governance engine may be ensuring that individuals and servers only have access to the data they have been authorized to see. governance-program The Governance Program OMAS provides the ability to maintain a governance program in the open metadata repositories. It is designed for governance and CDO tools. it-infrastructure The IT Infrastructure OMAS provides support for the design and planning of the information infrastructure that supports the data assets. This includes the development of system blueprints that link down to the metadata about real infrastructure components. This metadata helps in the linkage between information governance metadata and IT infrastructure management (ITIL) metadata typically stored in a Configuration Management Database (CMDB). project-management The Project Management OMAS supports the metadata associated with projects and campaigns. These projects and campaigns may be for governance projects, or generic data use projects. security-manager The Security Manager OMAS provides the services to exchange security tags with access control and data protection technology services. It is called by the Security Integrator OMIS . security-officer The Security Officer OMAS provides the services to support the definition of roles and rules for managing the protection of metadata and assets, plus work with the audit logs captured by the open metadata and governance tools. It is typically used by the security, compliance and auditing teams. software-developer The Software Development OMAS provides access to metadata needed to build compliant APIs, data stores and related software components. stewardship-action The Stewardship Action OMAS provides services for managing exceptions discovered in the information landscape that need correcting. These exceptions may be quality errors, missing or outdated information, invalid licensing, job failures, and many more. The Stewardship Action OMAS also enables the review and triage of the exceptions, simple remediation and status reporting. subject-area The Subject Area OMAS is for tools that support subject matter experts who are defining glossaries, reference data and rules around data for a specific subject area, such as \"customer data\". It supports the development of a comprehensive definition of the subject area and the standards that support it. These definitions can then be folded into the Governance Program, and used by Asset Owner's to improve the findability and understandability of their assets by linking their asset's structure to relevant parts of the subject area definition. Using the OMAS 's \u00b6 The OMAS 's run in either a metadata access point or a metadata server . They can be configured and activated individually or as a complete set. The administration services provide the ability to configure, start and stop the access services. Each OMAS typically supports a REST API, a topic where it publishes notifications of interest to its users, and a topic where new metadata requests can be posted to the OMAS . It also has a Java client that provides access to its API and topics. This java client is embedded in the governance servers and view servers . They can also be downloaded and used independently with the Egeria Client Package .","title":"Open Metadata Access Services"},{"location":"services/omas/#open-metadata-access-services-omas","text":"The Open Metadata Access Services ( OMAS ) provide domain-specific services for data tools, engines and platforms to integrate with open metadata. The access services are as follows: OMAS Description analytics-modeling The Analytics Modeling OMAS configures and manages metadata for modeling analytics and reporting services. asset-catalog The Asset Catalog OMAS provides search and query capabilities for tools and applications to support an asset catalog function. It supports search requests for assets with specific characteristics and returns summaries of the matching assets, plus methods to allow drill-down into the details of a specific asset to related metadata. asset-consumer The Asset Consumer OMAS is designed for applications that are using OCF connectors to access data stores, APIs and functions such as analytics. The Asset Consumer OMAS provides a factory function for the connectors, the ability to retrieve all of the metadata about the asset and the ability to add feedback on the asset. asset-lineage The Asset Lineage OMAS listens to relevant lineage related events on the enterprise topic level and publishes these on the Asset Lineage OutTopic, combined with relevant context information on the described entities. These events are listened to by the open lineage services governance server. asset-manager The Asset Manager OMAS manages the exchange of metadata with third party metadata catalogs and asset managers. It is typically called by the Catalog Integrator OMIS to send and receive asset information, including schemas, profiles, policies and lineage information with a third party asset manager. Typical examples of asset managers include data catalogs that are managing metadata for a collection of data assets for a data-serving solution. asset-owner The Asset Owner OMAS provides services for an asset owner to curate metadata about their asset(s) and understand how these assets are being used and governed. community-profile The Community Profile OMAS supports the administration for a community and related user profiles. These communities are involved in reviewing and crowd-sourcing knowledge about the data assets and their use. data-engine The Data Engine OMAS provides APIs and events for a data movement/processing engine to record the changes it is making the the data landscape. This information forms a key part of asset lineage. data-manager The Data Manager OMAS provides an integration point to enable technologies that manage collections of data such as database servers, file systems, file managers and content managers to publish metadata to the metadata repositories about the changing structures and content stored in the data platform. It is typically called from the Database Integrator OMIS and Files Integrator OMIS integration services. data-privacy The Data Privacy OMAS supports a privacy officer as they manage data privacy in their organization. This includes managing privacy impact assessments and reviews of software services that use personal data as they move through their development, deployment and use. data-science The Data Science OMAS provides access to metadata for data assets, connections and projects, plus the ability to maintain metadata about data science notebooks and models and log activity during the analytics development process. It is designed for data science and analytics management tools. design-model The Design Model OMAS provides the ability to manage information from all types of design models. These models may come from tools or be part of a packaged standard. This content is useful for governance, system integration and software development. dev-ops The DevOps OMAS provides services for a DevOps pipeline to query and maintain metadata about systems, processes and software components that are being deployed into the information landscape. digital-architecture The Digital Architecture OMAS provides the ability to define information standards, definitions, solution blueprints and models for an organization. It is designed for architecture tools. It is able to support the definition and management of a digital service through concept to deployment. digital-service The Digital Service OMAS provides services for a managing the lifecycle of an Egeria Digital Service. discovery-engine The Discovery Engine OMAS provides an API for a discovery engine to access and store metadata from an open metadata repository (or open metadata repository cohort). governance-engine The Governance Engine OMAS provides APIs and events that retrieve and manage metadata for governance engines. Governance engines ensure that the infrastructure supporting the data landscape is operating according to the governance program. For example, the governance engine may be ensuring that individuals and servers only have access to the data they have been authorized to see. governance-program The Governance Program OMAS provides the ability to maintain a governance program in the open metadata repositories. It is designed for governance and CDO tools. it-infrastructure The IT Infrastructure OMAS provides support for the design and planning of the information infrastructure that supports the data assets. This includes the development of system blueprints that link down to the metadata about real infrastructure components. This metadata helps in the linkage between information governance metadata and IT infrastructure management (ITIL) metadata typically stored in a Configuration Management Database (CMDB). project-management The Project Management OMAS supports the metadata associated with projects and campaigns. These projects and campaigns may be for governance projects, or generic data use projects. security-manager The Security Manager OMAS provides the services to exchange security tags with access control and data protection technology services. It is called by the Security Integrator OMIS . security-officer The Security Officer OMAS provides the services to support the definition of roles and rules for managing the protection of metadata and assets, plus work with the audit logs captured by the open metadata and governance tools. It is typically used by the security, compliance and auditing teams. software-developer The Software Development OMAS provides access to metadata needed to build compliant APIs, data stores and related software components. stewardship-action The Stewardship Action OMAS provides services for managing exceptions discovered in the information landscape that need correcting. These exceptions may be quality errors, missing or outdated information, invalid licensing, job failures, and many more. The Stewardship Action OMAS also enables the review and triage of the exceptions, simple remediation and status reporting. subject-area The Subject Area OMAS is for tools that support subject matter experts who are defining glossaries, reference data and rules around data for a specific subject area, such as \"customer data\". It supports the development of a comprehensive definition of the subject area and the standards that support it. These definitions can then be folded into the Governance Program, and used by Asset Owner's to improve the findability and understandability of their assets by linking their asset's structure to relevant parts of the subject area definition.","title":"Open Metadata Access Services (OMAS)"},{"location":"services/omas/#using-the-omass","text":"The OMAS 's run in either a metadata access point or a metadata server . They can be configured and activated individually or as a complete set. The administration services provide the ability to configure, start and stop the access services. Each OMAS typically supports a REST API, a topic where it publishes notifications of interest to its users, and a topic where new metadata requests can be posted to the OMAS . It also has a Java client that provides access to its API and topics. This java client is embedded in the governance servers and view servers . They can also be downloaded and used independently with the Egeria Client Package .","title":"Using the OMAS's"},{"location":"services/omas/analytics-modeling/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Analytics Modeling Open Metadata Access Service ( OMAS ) \u00b6 The Analytics Modeling OMAS configures and manages metadata for modeling analytics and reporting services.","title":"Analytics Modeling OMAS"},{"location":"services/omas/analytics-modeling/#analytics-modeling-open-metadata-access-service-omas","text":"The Analytics Modeling OMAS configures and manages metadata for modeling analytics and reporting services.","title":"Analytics Modeling Open Metadata Access Service (OMAS)"},{"location":"services/omas/asset-catalog/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Asset Catalog Open Metadata Access Service ( OMAS ) \u00b6 The Asset Catalog OMAS provides services to search for data assets including: data stores event feeds APIs data sets The search locates assets based on the content of the Asset metadata itself and the metadata that links to it. This includes: glossary terms schema elements assets The Asset Catalog REST API supports: the retrieval of assets based on unique identifiers the retrieval of asset's relationships and classifications the retrieval of assets based on known classification or relationship to query for related assets and to retrieve an asset neighborhood The module structure for the Asset Catalog OMAS is as follows: asset-catalog-client supports the client library. asset-catalog-api supports the common Java classes that are used both by the client and the server. asset-catalog-server supports the server side implementation of the access service. This includes the interaction with the administration services for registration, configuration, initialization and termination of the access service. interaction with the repository services to work with open metadata from the cohort . support for the access service's API and its related event management. asset-catalog-spring supports the REST API using the Spring libraries. Search solution \u00b6 The search will return Assets, Glossary Terms and Schema Elements that match the search criteria. As the asset search is to be performed against on one or more repositories a search engine will be used. The search will be performed using the existing properties of the asset, glossary terms and/or schema elements. Indexing will be performed by the Asset Catalog OMAS according to supported zones. The search result will contain: guid, name (name or displayName), description, qualifiedName, classifications, zoneMembership (the basic properties of the element). In order to get the full context of the element, a second call is performed. At this step, the specific relationships are traverse for getting the connection to the asset and to get the schema type that is behind the given asset. This call is using the asset global identifier and the asset type. Figure 1:Integration of search engine Other Services \u00b6 Asset Catalog OMAS provides services to fetch the asset * classifications * relationships * specific entities that connects two assets * relationships between two known entities * related assets","title":"Asset Catalog OMAS"},{"location":"services/omas/asset-catalog/#asset-catalog-open-metadata-access-service-omas","text":"The Asset Catalog OMAS provides services to search for data assets including: data stores event feeds APIs data sets The search locates assets based on the content of the Asset metadata itself and the metadata that links to it. This includes: glossary terms schema elements assets The Asset Catalog REST API supports: the retrieval of assets based on unique identifiers the retrieval of asset's relationships and classifications the retrieval of assets based on known classification or relationship to query for related assets and to retrieve an asset neighborhood The module structure for the Asset Catalog OMAS is as follows: asset-catalog-client supports the client library. asset-catalog-api supports the common Java classes that are used both by the client and the server. asset-catalog-server supports the server side implementation of the access service. This includes the interaction with the administration services for registration, configuration, initialization and termination of the access service. interaction with the repository services to work with open metadata from the cohort . support for the access service's API and its related event management. asset-catalog-spring supports the REST API using the Spring libraries.","title":"Asset Catalog Open Metadata Access Service (OMAS)"},{"location":"services/omas/asset-catalog/#search-solution","text":"The search will return Assets, Glossary Terms and Schema Elements that match the search criteria. As the asset search is to be performed against on one or more repositories a search engine will be used. The search will be performed using the existing properties of the asset, glossary terms and/or schema elements. Indexing will be performed by the Asset Catalog OMAS according to supported zones. The search result will contain: guid, name (name or displayName), description, qualifiedName, classifications, zoneMembership (the basic properties of the element). In order to get the full context of the element, a second call is performed. At this step, the specific relationships are traverse for getting the connection to the asset and to get the schema type that is behind the given asset. This call is using the asset global identifier and the asset type. Figure 1:Integration of search engine","title":"Search solution"},{"location":"services/omas/asset-catalog/#other-services","text":"Asset Catalog OMAS provides services to fetch the asset * classifications * relationships * specific entities that connects two assets * relationships between two known entities * related assets","title":"Other Services"},{"location":"services/omas/asset-consumer/","text":"Released This function is complete and can be used. The interfaces will be supported until the function is removed from the project via the deprecation process. There will be ongoing extensions to this function, but it will be done to ensure backward compatibility as far as possible. If there is a need to break backward compatibility, this will be discussed and reviewed in the community, with a documented timeline. Asset Consumer Open Metadata Access Service ( OMAS ) \u00b6 Overrview \u00b6 The Asset Consumer OMAS provides services to an individual who wants to work with assets such as: data stores, data sets and data feeds reports APIs functions such as analytical services It supports: the retrieval of connection objects from the open metadata repositories. A connection object is used to create a connector to an asset. the creation of a connector based on the properties in a connection object. the retrieval of properties about an asset. These properties are called the connected asset properties . the adding of feedback (comments, ratings and likes) to an asset. the attachment of informal tags to an asset. the adding of an audit log record for an asset. the publishing of notifications about assets on Asset Consumer OMAS 's out topic . Adding feedback through the Asset Consumer OMAS results in Karma Points being awarded to the individual. These are maintained in the individual's profile. A karma point is awarded for each contribution of feedback through the API. (The awarding of Karma points is managed by the Community Profile OMAS .) The connectors returned by the Asset Consumer OMAS are Open Connector Framework ( OCF ) connectors. The caller can use the connector to access the contents of the asset itself and the properties about the asset it is accessing. This service is provided by the OCF Metadata Management Common Service . User Guide \u00b6 The Asset Consumer OMAS is designed for use by an application that is accessing data sources and services through connectors . These data sources and services are called Assets , hence the name of this OMAS is Asset Consumer . Typically the first action to take is to create the connector to get access to the asset content and its properties . Connectors are created from Connection objects. Connection objects can be created by the calling application, or stored in one of the open metadata repositories that are accessible to the Asset Consumer OMAS . Alternatively, if the consumer only needs access to the asset's properties, they can use the Asset Consumer OMAS to locate the identifier of the asset and then retrieve the asset properties . Within the asset properties are links to glossary terms. It is possible to look up the full description of a term to further understand the asset. There are also capabilities to log messages about the asset , add feedback to the asset in terms of likes, star ratings, reviews and comments, and add tags to the asset . Interface choices \u00b6 The Asset Consumer OMAS offers the following types of interface: Java client , REST API and Out Topic Events for receiving events about assets. Connectors are only available through the Java client. Configuration \u00b6 Details of how to configure the Asset Consumer OMAS can be found here Scenarios \u00b6 This is the list of documented scenarios: Working with Connectors (overview) Creating a connector Locating the connected asset Retrieving asset properties Logging audit messages about an event Adding Feedback to an Asset Looking up the meanings of terms assigned to an asset Adding descriptive tags to an asset","title":"Asset Consumer OMAS"},{"location":"services/omas/asset-consumer/#asset-consumer-open-metadata-access-service-omas","text":"","title":"Asset Consumer Open Metadata Access Service (OMAS)"},{"location":"services/omas/asset-consumer/#overrview","text":"The Asset Consumer OMAS provides services to an individual who wants to work with assets such as: data stores, data sets and data feeds reports APIs functions such as analytical services It supports: the retrieval of connection objects from the open metadata repositories. A connection object is used to create a connector to an asset. the creation of a connector based on the properties in a connection object. the retrieval of properties about an asset. These properties are called the connected asset properties . the adding of feedback (comments, ratings and likes) to an asset. the attachment of informal tags to an asset. the adding of an audit log record for an asset. the publishing of notifications about assets on Asset Consumer OMAS 's out topic . Adding feedback through the Asset Consumer OMAS results in Karma Points being awarded to the individual. These are maintained in the individual's profile. A karma point is awarded for each contribution of feedback through the API. (The awarding of Karma points is managed by the Community Profile OMAS .) The connectors returned by the Asset Consumer OMAS are Open Connector Framework ( OCF ) connectors. The caller can use the connector to access the contents of the asset itself and the properties about the asset it is accessing. This service is provided by the OCF Metadata Management Common Service .","title":"Overrview"},{"location":"services/omas/asset-consumer/#user-guide","text":"The Asset Consumer OMAS is designed for use by an application that is accessing data sources and services through connectors . These data sources and services are called Assets , hence the name of this OMAS is Asset Consumer . Typically the first action to take is to create the connector to get access to the asset content and its properties . Connectors are created from Connection objects. Connection objects can be created by the calling application, or stored in one of the open metadata repositories that are accessible to the Asset Consumer OMAS . Alternatively, if the consumer only needs access to the asset's properties, they can use the Asset Consumer OMAS to locate the identifier of the asset and then retrieve the asset properties . Within the asset properties are links to glossary terms. It is possible to look up the full description of a term to further understand the asset. There are also capabilities to log messages about the asset , add feedback to the asset in terms of likes, star ratings, reviews and comments, and add tags to the asset .","title":"User Guide"},{"location":"services/omas/asset-consumer/#interface-choices","text":"The Asset Consumer OMAS offers the following types of interface: Java client , REST API and Out Topic Events for receiving events about assets. Connectors are only available through the Java client.","title":"Interface choices"},{"location":"services/omas/asset-consumer/#configuration","text":"Details of how to configure the Asset Consumer OMAS can be found here","title":"Configuration"},{"location":"services/omas/asset-consumer/#scenarios","text":"This is the list of documented scenarios: Working with Connectors (overview) Creating a connector Locating the connected asset Retrieving asset properties Logging audit messages about an event Adding Feedback to an Asset Looking up the meanings of terms assigned to an asset Adding descriptive tags to an asset","title":"Scenarios"},{"location":"services/omas/asset-consumer/adding-feedback-to-an-asset/","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding feedback to an asset"},{"location":"services/omas/asset-consumer/creating-a-connector/","text":"Creating a connector for application use \u00b6 The Asset Consumer OMAS supports a REST API to extract metadata from the open metadata repositories linked to the same open metadata cohort as the Asset Consumer OMAS. It also has a Java client that provides an equivalent interface to the REST API plus connector factory methods supported by an embedded Connector Broker. The Connector Broker is an Open Connector Framework (OCF) component that is able to create and configure instances of compliant connectors. It is passed a Connection object which has all of the properties needed to create the connector. The Asset Consumer OMAS java client extracts the Connection object from the open metadata repositories and then calls the Connector Broker. The code sample below creates the Asset Consumer OMAS Client. It is passed the server name and platform root URL for the metadata server that will supply the connection object. AssetConsumer client = new AssetConsumer(serverName, serverURLRoot); The next code samples show how to create the connector. There are three approaches: Supplying a hard-coded Connection object. Supplying the unique identifier (guid) of the Connection object in the metadata repositories that Asset Consumer OMAS has access to. Supplying the unique identifier (guid) of an Asset. The connector is created using the Connection linked to the asset. In this first example, the connector is created from the hard-coded connection. /** * This method creates a connector using a hard coded connection object. This connector will be able * to retrieve the data from the file, but it will not be able to retrieve the metadata about * the file. * * @return connector to requested file */ private CSVFileStoreConnector getConnectorUsingHardCodedConnection() { CSVFileStoreConnector connector = null; try { AssetConsumer client = new AssetConsumer(serverName, serverURLRoot); connector = (CSVFileStoreConnector)client.getConnectorByConnection(clientUserId, getHardCodedConnection(fileName)); } catch (Exception error) { System.out.println(\"The connector can not be created with Asset Consumer OMAS.\"); } return connector; } /** * This method creates a connection. The connection object provides the OCF with the properties to create the * connector and the properties needed by the connector to access the asset. * * The Connection object includes a Connector Type object. This defines the type of connector to create. * The Connection object also includes an Endpoint object. This is used by the connector to locate and connect * to the Asset. * * @param fileName name of the file to connect to * @return connection object */ private Connection getHardCodedConnection(String fileName) { final String endpointGUID = \"8bf8f5fa-b5d8-40e1-a00e-e4a0c59fd6c0\"; final String connectorTypeGUID = \"2e1556a3-908f-4303-812d-d81b48b19bab\"; final String connectionGUID = \"b9af734f-f005-4085-9975-bf46c67a099a\"; final String endpointDescription = \"File name.\"; String endpointName = \"CSVFileStore.Endpoint.\" + fileName; Endpoint endpoint = new Endpoint(); endpoint.setType(Endpoint.getEndpointType()); endpoint.setGUID(endpointGUID); endpoint.setQualifiedName(endpointName); endpoint.setDisplayName(endpointName); endpoint.setDescription(endpointDescription); endpoint.setAddress(fileName); final String connectorTypeDescription = \"CSVFileStore connector type.\"; final String connectorTypeJavaClassName = CSVFileStoreProvider.class.getName(); String connectorTypeName = \"CSVFileStore.ConnectorType.Test\"; ConnectorType connectorType = new ConnectorType(); connectorType.setType(ConnectorType.getConnectorTypeType()); connectorType.setGUID(connectorTypeGUID); connectorType.setQualifiedName(connectorTypeName); connectorType.setDisplayName(connectorTypeName); connectorType.setDescription(connectorTypeDescription); connectorType.setConnectorProviderClassName(connectorTypeJavaClassName); final String connectionDescription = \"CSVFileStore connection.\"; String connectionName = \"CSVFileStore.Connection.Test\"; Connection connection = new Connection(); connection.setType(Connection.getConnectionType()); connection.setGUID(connectionGUID); connection.setQualifiedName(connectionName); connection.setDisplayName(connectionName); connection.setDescription(connectionDescription); connection.setEndpoint(endpoint); connection.setConnectorType(connectorType); return connection; } The next example, uses the Connection guid: try { /* * Return a connector for the connection. */ return (CSVFileStoreConnector) client.getConnectorByGUID(clientUserId, connectionGUID); } catch (Exception error) { System.out.println(\"Unable to create connector for connection: \" + connectionGUID); } The final example uses the Asset guid: try { /* * Return a connector for the asset. */ return (CSVFileStoreConnector) client.getConnectorForAsset(clientUserId, assetGUID); } catch (Exception error) { System.out.println(\"Unable to create connector for asset: \" + assetGUID); } Why use the Asset Consumer OMAS java client rather than the ConnectorBroker? \u00b6 Each connector has a method call called getConnectedAssetProperties . This returns the metadata known about the asset that the connector is accessing. When you create a connector using the Asset Consumer OMAS java client, and the Connection used is linked to an asset then getConnectedAssetProperties returns all of the metadata known about the asset. ConnectedAssetProperties assetProperties = connector.getConnectedAssetProperties(clientUserId); if (assetProperties != null) { AssetUniverse assetUniverse = assetProperties.getAssetUniverse(); if (assetUniverse != null) { System.out.println(\"Type Name: \" + assetUniverse.getAssetTypeName()); System.out.println(\"Qualified Name: \" + assetUniverse.getQualifiedName()); } else { System.out.println(assetProperties.toString()); } } else { System.out.println(\"No asset properties ...\"); } Return to Asset Consumer OMAS User Guide License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Creating a connector"},{"location":"services/omas/asset-consumer/creating-a-connector/#creating-a-connector-for-application-use","text":"The Asset Consumer OMAS supports a REST API to extract metadata from the open metadata repositories linked to the same open metadata cohort as the Asset Consumer OMAS. It also has a Java client that provides an equivalent interface to the REST API plus connector factory methods supported by an embedded Connector Broker. The Connector Broker is an Open Connector Framework (OCF) component that is able to create and configure instances of compliant connectors. It is passed a Connection object which has all of the properties needed to create the connector. The Asset Consumer OMAS java client extracts the Connection object from the open metadata repositories and then calls the Connector Broker. The code sample below creates the Asset Consumer OMAS Client. It is passed the server name and platform root URL for the metadata server that will supply the connection object. AssetConsumer client = new AssetConsumer(serverName, serverURLRoot); The next code samples show how to create the connector. There are three approaches: Supplying a hard-coded Connection object. Supplying the unique identifier (guid) of the Connection object in the metadata repositories that Asset Consumer OMAS has access to. Supplying the unique identifier (guid) of an Asset. The connector is created using the Connection linked to the asset. In this first example, the connector is created from the hard-coded connection. /** * This method creates a connector using a hard coded connection object. This connector will be able * to retrieve the data from the file, but it will not be able to retrieve the metadata about * the file. * * @return connector to requested file */ private CSVFileStoreConnector getConnectorUsingHardCodedConnection() { CSVFileStoreConnector connector = null; try { AssetConsumer client = new AssetConsumer(serverName, serverURLRoot); connector = (CSVFileStoreConnector)client.getConnectorByConnection(clientUserId, getHardCodedConnection(fileName)); } catch (Exception error) { System.out.println(\"The connector can not be created with Asset Consumer OMAS.\"); } return connector; } /** * This method creates a connection. The connection object provides the OCF with the properties to create the * connector and the properties needed by the connector to access the asset. * * The Connection object includes a Connector Type object. This defines the type of connector to create. * The Connection object also includes an Endpoint object. This is used by the connector to locate and connect * to the Asset. * * @param fileName name of the file to connect to * @return connection object */ private Connection getHardCodedConnection(String fileName) { final String endpointGUID = \"8bf8f5fa-b5d8-40e1-a00e-e4a0c59fd6c0\"; final String connectorTypeGUID = \"2e1556a3-908f-4303-812d-d81b48b19bab\"; final String connectionGUID = \"b9af734f-f005-4085-9975-bf46c67a099a\"; final String endpointDescription = \"File name.\"; String endpointName = \"CSVFileStore.Endpoint.\" + fileName; Endpoint endpoint = new Endpoint(); endpoint.setType(Endpoint.getEndpointType()); endpoint.setGUID(endpointGUID); endpoint.setQualifiedName(endpointName); endpoint.setDisplayName(endpointName); endpoint.setDescription(endpointDescription); endpoint.setAddress(fileName); final String connectorTypeDescription = \"CSVFileStore connector type.\"; final String connectorTypeJavaClassName = CSVFileStoreProvider.class.getName(); String connectorTypeName = \"CSVFileStore.ConnectorType.Test\"; ConnectorType connectorType = new ConnectorType(); connectorType.setType(ConnectorType.getConnectorTypeType()); connectorType.setGUID(connectorTypeGUID); connectorType.setQualifiedName(connectorTypeName); connectorType.setDisplayName(connectorTypeName); connectorType.setDescription(connectorTypeDescription); connectorType.setConnectorProviderClassName(connectorTypeJavaClassName); final String connectionDescription = \"CSVFileStore connection.\"; String connectionName = \"CSVFileStore.Connection.Test\"; Connection connection = new Connection(); connection.setType(Connection.getConnectionType()); connection.setGUID(connectionGUID); connection.setQualifiedName(connectionName); connection.setDisplayName(connectionName); connection.setDescription(connectionDescription); connection.setEndpoint(endpoint); connection.setConnectorType(connectorType); return connection; } The next example, uses the Connection guid: try { /* * Return a connector for the connection. */ return (CSVFileStoreConnector) client.getConnectorByGUID(clientUserId, connectionGUID); } catch (Exception error) { System.out.println(\"Unable to create connector for connection: \" + connectionGUID); } The final example uses the Asset guid: try { /* * Return a connector for the asset. */ return (CSVFileStoreConnector) client.getConnectorForAsset(clientUserId, assetGUID); } catch (Exception error) { System.out.println(\"Unable to create connector for asset: \" + assetGUID); }","title":"Creating a connector for application use"},{"location":"services/omas/asset-consumer/creating-a-connector/#why-use-the-asset-consumer-omas-java-client-rather-than-the-connectorbroker","text":"Each connector has a method call called getConnectedAssetProperties . This returns the metadata known about the asset that the connector is accessing. When you create a connector using the Asset Consumer OMAS java client, and the Connection used is linked to an asset then getConnectedAssetProperties returns all of the metadata known about the asset. ConnectedAssetProperties assetProperties = connector.getConnectedAssetProperties(clientUserId); if (assetProperties != null) { AssetUniverse assetUniverse = assetProperties.getAssetUniverse(); if (assetUniverse != null) { System.out.println(\"Type Name: \" + assetUniverse.getAssetTypeName()); System.out.println(\"Qualified Name: \" + assetUniverse.getQualifiedName()); } else { System.out.println(assetProperties.toString()); } } else { System.out.println(\"No asset properties ...\"); } Return to Asset Consumer OMAS User Guide License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Why use the Asset Consumer OMAS java client rather than the ConnectorBroker?"},{"location":"services/omas/asset-consumer/locating-the-connected-asset/","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Locating the connected asset"},{"location":"services/omas/asset-consumer/logging-messages-about-an-asset/","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Logging messages about an asset"},{"location":"services/omas/asset-consumer/looking-up-meanings-of-terms/","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Looking up meanings of terms"},{"location":"services/omas/asset-consumer/retrieving-asset-properties/","text":"Retrieving asset properties \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Retrieving asset properties"},{"location":"services/omas/asset-consumer/retrieving-asset-properties/#retrieving-asset-properties","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Retrieving asset properties"},{"location":"services/omas/asset-consumer/tagging-an-asset/","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Tagging an asset"},{"location":"services/omas/asset-consumer/working-with-connectors/","text":"Working with connectors \u00b6 An open connector is a Java client to an Asset that implements the Connector interface defined in the Open Connector Framework (OCF) . It has 2 parts to its interface: The specialized interface to work with the specific contents of the asset. For example, if the connector was for data stored in a relational database, this interface would probably follow the Java Database Connectivity (JDBC) specification. The documentation for this interface is found with the specific connector. These are the connectors supported by ODPi Egeria with links to the documentation: basic-file-connector provides connector to read a file. It has no special knowledge of the format. avro-file-connector provides connector to read files that have an Apache Avro format. csv-file-connector provides connector to read files that have a CSV tabular format. data-folder-connector provides connector to read a data set that is made up of many files stored within a data folder. A generalized interface to extract all of the open metadata known about the asset. This is referred to as the connected asset properties . This interface is documented here . An application creates a connector using the Asset Consumer OMAS client . When an Asset is cataloged in the open metadata repository, there is a Connection object linked to it. This defines all of the properties required to create the connector. See Creating a connector for step by step instructions on creating connectors. Asset Consumer OMAS looks up the Connection object and calls the Connector Broker to create the connector. Once the connector is created, an application may use it to retrieve the content of the asset and the connected asset properties. When the application has finished with the connector, it should call disconnect() to release any resources that the connector may be holding. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Working with connectors"},{"location":"services/omas/asset-consumer/working-with-connectors/#working-with-connectors","text":"An open connector is a Java client to an Asset that implements the Connector interface defined in the Open Connector Framework (OCF) . It has 2 parts to its interface: The specialized interface to work with the specific contents of the asset. For example, if the connector was for data stored in a relational database, this interface would probably follow the Java Database Connectivity (JDBC) specification. The documentation for this interface is found with the specific connector. These are the connectors supported by ODPi Egeria with links to the documentation: basic-file-connector provides connector to read a file. It has no special knowledge of the format. avro-file-connector provides connector to read files that have an Apache Avro format. csv-file-connector provides connector to read files that have a CSV tabular format. data-folder-connector provides connector to read a data set that is made up of many files stored within a data folder. A generalized interface to extract all of the open metadata known about the asset. This is referred to as the connected asset properties . This interface is documented here . An application creates a connector using the Asset Consumer OMAS client . When an Asset is cataloged in the open metadata repository, there is a Connection object linked to it. This defines all of the properties required to create the connector. See Creating a connector for step by step instructions on creating connectors. Asset Consumer OMAS looks up the Connection object and calls the Connector Broker to create the connector. Once the connector is created, an application may use it to retrieve the content of the asset and the connected asset properties. When the application has finished with the connector, it should call disconnect() to release any resources that the connector may be holding. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Working with connectors"},{"location":"services/omas/asset-lineage/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Asset Lineage Open Metadata Access Service ( OMAS ) \u00b6 The Asset Lineage OMAS provides services to query the lineage of business terms and data assets. This access service is used to build Vertical Lineage and Horizontal Lineage functionality. On the output topic, it publishes out events that contains full context of data assets and glossary terms involved in lineage. These events are consumed by the external tools that build the lineage graph in a specific format. Also, the Asset Lineage OMAS provides an endpoint that publishes the lineage events associated with the entities involved in lineage. User Documentation \u00b6 The Asset Lineage OMAS is designed to publish the events that can be used by external tools and engines to build lineage graphs. These complex events are constructed using the Enterprise Connector in oredr to fetch the full context of the data assets. The link between Glossary Terms and Schema Elements/Glossary Categories is named vertical lineage . The horizontal lineage traces the path which data flows starting system of records to the point of usage. Most of the interaction with the Asset Lineage OMAS will be driven by the external tools used to build lineage. To understand how to configure: Configuring the Asset Lineage OMAS","title":"Asset Lineage OMAS"},{"location":"services/omas/asset-lineage/#asset-lineage-open-metadata-access-service-omas","text":"The Asset Lineage OMAS provides services to query the lineage of business terms and data assets. This access service is used to build Vertical Lineage and Horizontal Lineage functionality. On the output topic, it publishes out events that contains full context of data assets and glossary terms involved in lineage. These events are consumed by the external tools that build the lineage graph in a specific format. Also, the Asset Lineage OMAS provides an endpoint that publishes the lineage events associated with the entities involved in lineage.","title":"Asset Lineage Open Metadata Access Service (OMAS)"},{"location":"services/omas/asset-lineage/#user-documentation","text":"The Asset Lineage OMAS is designed to publish the events that can be used by external tools and engines to build lineage graphs. These complex events are constructed using the Enterprise Connector in oredr to fetch the full context of the data assets. The link between Glossary Terms and Schema Elements/Glossary Categories is named vertical lineage . The horizontal lineage traces the path which data flows starting system of records to the point of usage. Most of the interaction with the Asset Lineage OMAS will be driven by the external tools used to build lineage. To understand how to configure: Configuring the Asset Lineage OMAS","title":"User Documentation"},{"location":"services/omas/asset-lineage/user/","text":"Asset Lineage OMAS User Documentation \u00b6 The Asset Lineage OMAS is designed to publish the events that can be used by external tools and engines to build lineage graphs. These complex events are constructed using the Enterprise Connector in oredr to fetch the full context of the data assets. The link between Glossary Terms and Schema Elements/Glossary Categories is named vertical lineage . The horizontal lineage traces the path which data flows starting system of records to the point of usage. Most of the interaction with the Asset Lineage OMAS will be driven by the external tools used to build lineage. To understand how to configure: * Configuring the Asset Lineage OMAS \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/asset-lineage/user/#asset-lineage-omas-user-documentation","text":"The Asset Lineage OMAS is designed to publish the events that can be used by external tools and engines to build lineage graphs. These complex events are constructed using the Enterprise Connector in oredr to fetch the full context of the data assets. The link between Glossary Terms and Schema Elements/Glossary Categories is named vertical lineage . The horizontal lineage traces the path which data flows starting system of records to the point of usage. Most of the interaction with the Asset Lineage OMAS will be driven by the external tools used to build lineage. To understand how to configure:","title":"Asset Lineage OMAS User Documentation"},{"location":"services/omas/asset-lineage/user/#configuring-the-asset-lineage-omas","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"* Configuring the Asset Lineage OMAS"},{"location":"services/omas/asset-manager/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Asset Manager Open Metadata Access Service ( OMAS ) \u00b6 The Asset Manager OMAS provides APIs for supporting the exchange of metadata with a third party asset manager. An asset manager is typically a catalog of assets . It is responsible for maintaining details of the assets including their characteristics, ownership, assessments and governance requirements. The Asset Manager OMAS (in conjunction with the Catalog Integrator OMIS ) provides a new integration path for metadata catalogs the goes via an integration service hosted in an integration daemon . Catalogs will be able to have a two-way integration through this path without needing to conform to the repository service rules for managing home and reference copies. This is possible for two reasons: Since the metadata from the catalog passes through an OMAS , Egeria will be able to have a better control of the metadata from the catalog. Since the catalog is not part of a federated query, any inconsistent updates to metadata that occurs in its repository, only impacts the users of that catalog and not the whole cohort. External Identifiers \u00b6 A major challenge when exchanging metadata with third party asset managers is that there is often a mismatch between the structure of the metadata in a third party asset manager and the structure of the open metadata types used by the Asset Manager OMAS . For this reason, the Asset Manager OMAS supports the ability to associate multiple external identifiers with an open metadata instance. These external identifiers are scoped to a particular third party asset manager so that there is no confusion if two third party asset managers happen to use the same unique identifier within their repositories. Each of these external identifiers can be mapped to the appropriate open metadata instances without confusion. There are also API calls for querying open metadata instances using external identifiers and the identifier of the third party asset manager. More information on the use of external identifiers to map between metadata elements in third party asset managers and open metadata instances can be found here . Supplementary Properties \u00b6 It is common for external asset managers to include extensive descriptive properties for assets that include both a technical name and description as well as a business name and description. The Asset Manager OMAS supports this distinction and stores the technical name and description in an Asset metadata instance and the business name and description in a glossary term metadata instance that is linked to the asset using a MoreInformation relationship . The properties that are stored in the glossary term are referred to as supplementary properties.","title":"Index"},{"location":"services/omas/asset-manager/#asset-manager-open-metadata-access-service-omas","text":"The Asset Manager OMAS provides APIs for supporting the exchange of metadata with a third party asset manager. An asset manager is typically a catalog of assets . It is responsible for maintaining details of the assets including their characteristics, ownership, assessments and governance requirements. The Asset Manager OMAS (in conjunction with the Catalog Integrator OMIS ) provides a new integration path for metadata catalogs the goes via an integration service hosted in an integration daemon . Catalogs will be able to have a two-way integration through this path without needing to conform to the repository service rules for managing home and reference copies. This is possible for two reasons: Since the metadata from the catalog passes through an OMAS , Egeria will be able to have a better control of the metadata from the catalog. Since the catalog is not part of a federated query, any inconsistent updates to metadata that occurs in its repository, only impacts the users of that catalog and not the whole cohort.","title":"Asset Manager Open Metadata Access Service (OMAS)"},{"location":"services/omas/asset-manager/#external-identifiers","text":"A major challenge when exchanging metadata with third party asset managers is that there is often a mismatch between the structure of the metadata in a third party asset manager and the structure of the open metadata types used by the Asset Manager OMAS . For this reason, the Asset Manager OMAS supports the ability to associate multiple external identifiers with an open metadata instance. These external identifiers are scoped to a particular third party asset manager so that there is no confusion if two third party asset managers happen to use the same unique identifier within their repositories. Each of these external identifiers can be mapped to the appropriate open metadata instances without confusion. There are also API calls for querying open metadata instances using external identifiers and the identifier of the third party asset manager. More information on the use of external identifiers to map between metadata elements in third party asset managers and open metadata instances can be found here .","title":"External Identifiers"},{"location":"services/omas/asset-manager/#supplementary-properties","text":"It is common for external asset managers to include extensive descriptive properties for assets that include both a technical name and description as well as a business name and description. The Asset Manager OMAS supports this distinction and stores the technical name and description in an Asset metadata instance and the business name and description in a glossary term metadata instance that is linked to the asset using a MoreInformation relationship . The properties that are stored in the glossary term are referred to as supplementary properties.","title":"Supplementary Properties"},{"location":"services/omas/asset-owner/","text":"Released This function is complete and can be used. The interfaces will be supported until the function is removed from the project via the deprecation process. There will be ongoing extensions to this function, but it will be done to ensure backward compatibility as far as possible. If there is a need to break backward compatibility, this will be discussed and reviewed in the community, with a documented timeline. Asset Owner Open Metadata Access Service ( OMAS ) \u00b6 The Asset Owner OMAS provides APIs and notifications for tools and applications supporting the work of Asset Owners in protecting and enhancing their assets. Every asset has an owner property. This is the userId of the owner. The owner is responsible for the correct classification of assets and the assignment of connection(s) to the asset. The owner typically links the asset (or more likely the asset's schema elements) to glossary terms and declares the asset's associated licenses and certifications. Asset owners can maintain a note log for each of their assets. They can view the feedback and respond to it. The Asset Owner OMAS generates notifications about new feedback linked to an asset.","title":"Asset Owner OMAS"},{"location":"services/omas/asset-owner/#asset-owner-open-metadata-access-service-omas","text":"The Asset Owner OMAS provides APIs and notifications for tools and applications supporting the work of Asset Owners in protecting and enhancing their assets. Every asset has an owner property. This is the userId of the owner. The owner is responsible for the correct classification of assets and the assignment of connection(s) to the asset. The owner typically links the asset (or more likely the asset's schema elements) to glossary terms and declares the asset's associated licenses and certifications. Asset owners can maintain a note log for each of their assets. They can view the feedback and respond to it. The Asset Owner OMAS generates notifications about new feedback linked to an asset.","title":"Asset Owner Open Metadata Access Service (OMAS)"},{"location":"services/omas/asset-owner/design/","text":"Asset Owner OMAS design \u00b6 The module structure for the Asset Owner OMAS follows the standard pattern as follows: asset-owner-client supports the client library. asset-owner-api supports the common Java classes that are used both by the client and the server. asset-owner-server supports in implementation of the access service and its related event management. asset-owner-spring supports the REST API using the Spring libraries. It makes use of the ocf-metadata-management for its server side interaction with the metadata repository and so the primary function of the Asset Owner OMAS is to manage the APIs for the Asset Owner and translate between them and the Open Connector Framework (OCF) oriented interfaces of ocf-metadata-management. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/asset-owner/design/#asset-owner-omas-design","text":"The module structure for the Asset Owner OMAS follows the standard pattern as follows: asset-owner-client supports the client library. asset-owner-api supports the common Java classes that are used both by the client and the server. asset-owner-server supports in implementation of the access service and its related event management. asset-owner-spring supports the REST API using the Spring libraries. It makes use of the ocf-metadata-management for its server side interaction with the metadata repository and so the primary function of the Asset Owner OMAS is to manage the APIs for the Asset Owner and translate between them and the Open Connector Framework (OCF) oriented interfaces of ocf-metadata-management. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Asset Owner OMAS design"},{"location":"services/omas/asset-owner/user/","text":"\u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/asset-owner/user/#_1","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":""},{"location":"services/omas/community-profile/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Community Profile Open Metadata Access Service ( OMAS ) \u00b6 The Community Profile OMAS provides APIs and events for tools and applications that are managing information about people and the way they work together. In particular the Community Profile OMAS supports personal profiles , organizations and teams along with communities of people collaborating around data. With this information, open metadata reduces the friction between people from different silos of an organization that can prevent the effective use of data. For example, an Asset Owner can monitor who is using their asset and for what purposes. At the same time a data scientist or business analyst can find out which assets their colleagues are using, and any feedback that they gave, which helps to guide them to the most appropriate assets for their work. Is this metadata ? \u00b6 Data about people and organizations is not strictly metadata. It is master data. This means it is a type of data that is widely duplicated across an organization's systems but mercifully slowly changing. Open metadata is therefore only one of many systems making use of this data. Many organizations use a centralized user directory, such as LDAP, for their employees. In addition large organizations with thousands of systems may also have a master data management (MDM) program to keep their data about people and organization's synchronized amongst their systems. With or without MDM, it is important that the Community Profile OMAS can operate as a downstream consumer of this data, rather than operating as an independent island. This way it adds value to the organization by enabling the recording of asset ownership, use and feedback, without an excessive amount of additional administration. Digging Deeper \u00b6 User Documentation Design Documentation","title":"Community Profile OMAS"},{"location":"services/omas/community-profile/#community-profile-open-metadata-access-service-omas","text":"The Community Profile OMAS provides APIs and events for tools and applications that are managing information about people and the way they work together. In particular the Community Profile OMAS supports personal profiles , organizations and teams along with communities of people collaborating around data. With this information, open metadata reduces the friction between people from different silos of an organization that can prevent the effective use of data. For example, an Asset Owner can monitor who is using their asset and for what purposes. At the same time a data scientist or business analyst can find out which assets their colleagues are using, and any feedback that they gave, which helps to guide them to the most appropriate assets for their work.","title":"Community Profile Open Metadata Access Service (OMAS)"},{"location":"services/omas/community-profile/#is-this-metadata","text":"Data about people and organizations is not strictly metadata. It is master data. This means it is a type of data that is widely duplicated across an organization's systems but mercifully slowly changing. Open metadata is therefore only one of many systems making use of this data. Many organizations use a centralized user directory, such as LDAP, for their employees. In addition large organizations with thousands of systems may also have a master data management (MDM) program to keep their data about people and organization's synchronized amongst their systems. With or without MDM, it is important that the Community Profile OMAS can operate as a downstream consumer of this data, rather than operating as an independent island. This way it adds value to the organization by enabling the recording of asset ownership, use and feedback, without an excessive amount of additional administration.","title":"Is this metadata ?"},{"location":"services/omas/community-profile/#digging-deeper","text":"User Documentation Design Documentation","title":"Digging Deeper"},{"location":"services/omas/community-profile/concepts/","text":"Community Profile OMAS Concepts and Vocabulary \u00b6 Below are the list of concepts that are core to the Community Profile OMAS. The link for each concept takes you to more detail about the concept itself, how it is implemented and the function supported for this concept. The list is in alphabetical order. Action Anchor Collection (of favorite things) Comments Communities Community Forums and Contributions Community Member Community Roles Community Administrator Community Contributor Community Leader Community Observer Contact Method and Contact Details Departmental Structure External References and External Reference List Favorite Things Collections Head count limit (for Roles) Karma Points Karma Point Plateau Like Master Data Manager Organization Peer Network Personal Messages Personal Note Log and Notes Personal Profiles Personal Roles Review Role Tag Team Team Leader Team Member To Do Useful Resources and Useful Resources List License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/community-profile/concepts/#community-profile-omas-concepts-and-vocabulary","text":"Below are the list of concepts that are core to the Community Profile OMAS. The link for each concept takes you to more detail about the concept itself, how it is implemented and the function supported for this concept. The list is in alphabetical order. Action Anchor Collection (of favorite things) Comments Communities Community Forums and Contributions Community Member Community Roles Community Administrator Community Contributor Community Leader Community Observer Contact Method and Contact Details Departmental Structure External References and External Reference List Favorite Things Collections Head count limit (for Roles) Karma Points Karma Point Plateau Like Master Data Manager Organization Peer Network Personal Messages Personal Note Log and Notes Personal Profiles Personal Roles Review Role Tag Team Team Leader Team Member To Do Useful Resources and Useful Resources List License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community Profile OMAS Concepts and Vocabulary"},{"location":"services/omas/community-profile/concepts/collection/","text":"Collections \u00b6 A collection is a reusable resource list . Assets and other resources can be linked to a collection. The collection itself can then be added to a resource list, say for a community or a personal profile . License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Collection"},{"location":"services/omas/community-profile/concepts/collection/#collections","text":"A collection is a reusable resource list . Assets and other resources can be linked to a collection. The collection itself can then be added to a resource list, say for a community or a personal profile . License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Collections"},{"location":"services/omas/community-profile/concepts/comment/","text":"Comments \u00b6 [Comments] are informal messages or feedback. They can be attached to many places, for example a personal note , a community , a community forum or community forum contribution , a review , an external reference , or another comment. Sometimes specific names are used for comments depending on what they are attached to. For example: * a personal note comment is a comment attached to a personal note. * a forum comment is a comment attached to a community forum either directly or via a community forum contribution. * a comment reply is a comment attached to another comment. The ability to reply to a comment (or a comment reply) means that comments can be chained together to show a detailed conversation on a topic. The owner of a personal profile or the administrator of a community are able to remove inappropriate or out-of-date comments attached to their personal profile or community respectively. See: * [Removing] License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Comment"},{"location":"services/omas/community-profile/concepts/comment/#comments","text":"[Comments] are informal messages or feedback. They can be attached to many places, for example a personal note , a community , a community forum or community forum contribution , a review , an external reference , or another comment. Sometimes specific names are used for comments depending on what they are attached to. For example: * a personal note comment is a comment attached to a personal note. * a forum comment is a comment attached to a community forum either directly or via a community forum contribution. * a comment reply is a comment attached to another comment. The ability to reply to a comment (or a comment reply) means that comments can be chained together to show a detailed conversation on a topic. The owner of a personal profile or the administrator of a community are able to remove inappropriate or out-of-date comments attached to their personal profile or community respectively. See: * [Removing] License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Comments"},{"location":"services/omas/community-profile/concepts/community-administrator/","text":"Community Administrator \u00b6 A community administrator is someone who is responsible for managing the membership list of a community . When a community is created, the administrator defaults to the person who created it. This can be changed. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community administrator"},{"location":"services/omas/community-profile/concepts/community-administrator/#community-administrator","text":"A community administrator is someone who is responsible for managing the membership list of a community . When a community is created, the administrator defaults to the person who created it. This can be changed. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community Administrator"},{"location":"services/omas/community-profile/concepts/community-contributor/","text":"Community Contributor \u00b6 A community contributor is a role for a community member who is able to create content for the community . This could be a new forum and contributions to any forum, comments, likes, tags and review. See community roles for more information on the other roles.","title":"Community contributor"},{"location":"services/omas/community-profile/concepts/community-contributor/#community-contributor","text":"A community contributor is a role for a community member who is able to create content for the community . This could be a new forum and contributions to any forum, comments, likes, tags and review. See community roles for more information on the other roles.","title":"Community Contributor"},{"location":"services/omas/community-profile/concepts/community-forum/","text":"Community Forum \u00b6 A community forum provides a place for a community to store notes and comments about a specific topic. Forums can be created by community contributors, administrators and leaders . Each forum has a name, description and a list of forum contributions . Forum contributions can be created by community members, leaders and administrators. Each contribution can be updated/deleted by the community administrators. Anyone can add comments to a forum contribution. Thus it is possible for a forum contribution to simply pose a question to the membership and the membership creates the discussion and possible answers using comments.","title":"Community forum"},{"location":"services/omas/community-profile/concepts/community-forum/#community-forum","text":"A community forum provides a place for a community to store notes and comments about a specific topic. Forums can be created by community contributors, administrators and leaders . Each forum has a name, description and a list of forum contributions . Forum contributions can be created by community members, leaders and administrators. Each contribution can be updated/deleted by the community administrators. Anyone can add comments to a forum contribution. Thus it is possible for a forum contribution to simply pose a question to the membership and the membership creates the discussion and possible answers using comments.","title":"Community Forum"},{"location":"services/omas/community-profile/concepts/community-leader/","text":"Community Leader \u00b6 A community leader is a person who gives direction to a community . See community roles . License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community leader"},{"location":"services/omas/community-profile/concepts/community-leader/#community-leader","text":"A community leader is a person who gives direction to a community . See community roles . License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community Leader"},{"location":"services/omas/community-profile/concepts/community-member/","text":"Community Member \u00b6 A community member is a person whose profile is linked to a community . There are different roles a community member can be assigned to. Each has different privileges. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community member"},{"location":"services/omas/community-profile/concepts/community-member/#community-member","text":"A community member is a person whose profile is linked to a community . There are different roles a community member can be assigned to. Each has different privileges. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community Member"},{"location":"services/omas/community-profile/concepts/community-observer/","text":"Community Observer \u00b6 A community observer is someone who is interested in a community but is not contributing. See community roles for more information. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community observer"},{"location":"services/omas/community-profile/concepts/community-observer/#community-observer","text":"A community observer is someone who is interested in a community but is not contributing. See community roles for more information. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community Observer"},{"location":"services/omas/community-profile/concepts/community-roles/","text":"Community roles \u00b6 Members of a community are assigned a role. The roles are additive. At a minimum, a members is a Community Observer . This means they receive notifications from the community. This can be upgraded to Community Contributor to add the right to post content to the community. Next is a Community Administrator who is given the additional ability to add members and delete inappropriate content. Finally the Community Leader has all of the powers of the administrator but really focuses on the health and content of the community - typically creating forums, keeping the exchange of information flowing, ensuring the lists of useful resources and external references are up to date, and more. The person creating a community is the first community leader. This can be changed. Typically the community leader assigns administrators to manage the membership lists to free them up to manage the content. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community roles"},{"location":"services/omas/community-profile/concepts/community-roles/#community-roles","text":"Members of a community are assigned a role. The roles are additive. At a minimum, a members is a Community Observer . This means they receive notifications from the community. This can be upgraded to Community Contributor to add the right to post content to the community. Next is a Community Administrator who is given the additional ability to add members and delete inappropriate content. Finally the Community Leader has all of the powers of the administrator but really focuses on the health and content of the community - typically creating forums, keeping the exchange of information flowing, ensuring the lists of useful resources and external references are up to date, and more. The person creating a community is the first community leader. This can be changed. Typically the community leader assigns administrators to manage the membership lists to free them up to manage the content. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community roles"},{"location":"services/omas/community-profile/concepts/community/","text":"Community \u00b6 A community is a anchor point for grouping people and resources together around a common interest. Communities are typically long running endeavours. Communities have members . These are the people working together in the community. The community can gather together a list of useful resources and a list of external references . The members can create forums on different topics to share information. The members can attach comments to the community itself and to forum contributions, and add replies to them. Members can also provide reviews to forum contributions. This includes a star rating and review comment. Members can add tags to the community and any of its contents. Members can also add a like to the community and any of its contents. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community"},{"location":"services/omas/community-profile/concepts/community/#community","text":"A community is a anchor point for grouping people and resources together around a common interest. Communities are typically long running endeavours. Communities have members . These are the people working together in the community. The community can gather together a list of useful resources and a list of external references . The members can create forums on different topics to share information. The members can attach comments to the community itself and to forum contributions, and add replies to them. Members can also provide reviews to forum contributions. This includes a star rating and review comment. Members can add tags to the community and any of its contents. Members can also add a like to the community and any of its contents. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community"},{"location":"services/omas/community-profile/concepts/contact-method/","text":"Contact method \u00b6 A contact method provides a means to send a person or a team a message. This includes email, phone, or through their personal profile . License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Contact method"},{"location":"services/omas/community-profile/concepts/contact-method/#contact-method","text":"A contact method provides a means to send a person or a team a message. This includes email, phone, or through their personal profile . License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Contact method"},{"location":"services/omas/community-profile/concepts/external-reference/","text":"External references \u00b6 External references describe and contain a URL to a document or online resource outside of open metadata. A list of external references can be attached to a personal profile , a community or a team License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"External reference"},{"location":"services/omas/community-profile/concepts/external-reference/#external-references","text":"External references describe and contain a URL to a document or online resource outside of open metadata. A list of external references can be attached to a personal profile , a community or a team License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"External references"},{"location":"services/omas/community-profile/concepts/favorite-things-collection/","text":"Collections \u00b6 Collections are sharable lists of things. A collection may, for example, be a member of a useful resource list that is attached to multiple anchors such as communities and personal profiles. There are three special types of collections managed by Community Profile OMAS that are only attached to a single personal profile . They are to manage collections of assets , projects and communities for the individual owner of the License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Favorite things collection"},{"location":"services/omas/community-profile/concepts/favorite-things-collection/#collections","text":"Collections are sharable lists of things. A collection may, for example, be a member of a useful resource list that is attached to multiple anchors such as communities and personal profiles. There are three special types of collections managed by Community Profile OMAS that are only attached to a single personal profile . They are to manage collections of assets , projects and communities for the individual owner of the License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Collections"},{"location":"services/omas/community-profile/concepts/head-count-limit-for-role/","text":"Head count limit \u00b6 The head count limit is an optional value that can be set in a personal role . This determines how many people are funded for the role. Open metadata does not prevent more people than this limit being appointed to the role, but it does send a notification to indicate that the limit has been breached. The organization can choose to increase the head count limit or remove one of the appointed people. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Head count limit for role"},{"location":"services/omas/community-profile/concepts/head-count-limit-for-role/#head-count-limit","text":"The head count limit is an optional value that can be set in a personal role . This determines how many people are funded for the role. Open metadata does not prevent more people than this limit being appointed to the role, but it does send a notification to indicate that the limit has been breached. The organization can choose to increase the head count limit or remove one of the appointed people. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Head count limit"},{"location":"services/omas/community-profile/concepts/karma-point-plateau/","text":"Karma Point Plateau \u00b6 A karma point plateau identifies a significant contribution to open metadata. By default, a karma point plateau is achieved for every 500 karma points awarded. However the threshold for the karma point plateau can be changed at server start up . The Community Profile OMAS generates a Karma Point Plateau Event each time a person achieves a karma point plateau. This is sent on the Community Profile OMAS's OutTopic License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Karma point plateau"},{"location":"services/omas/community-profile/concepts/karma-point-plateau/#karma-point-plateau","text":"A karma point plateau identifies a significant contribution to open metadata. By default, a karma point plateau is achieved for every 500 karma points awarded. However the threshold for the karma point plateau can be changed at server start up . The Community Profile OMAS generates a Karma Point Plateau Event each time a person achieves a karma point plateau. This is sent on the Community Profile OMAS's OutTopic License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Karma Point Plateau"},{"location":"services/omas/community-profile/concepts/karma-point/","text":"Karma Point \u00b6 A karma point is a reward given to an individual for making a contribution to open metadata. This may be for: Creating some information Correcting or enhancing some information Linking information together Removing obsolete information Karma points are awarded automatically. They are stored in an individual's personal profile . When an individual's karma point total reaches a multiple of the karma point notification threshold, the Community Profile OMAS sends a notification on its OutTopic . Related information \u00b6 [Configuring the notification threshold for karma points] License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Karma point"},{"location":"services/omas/community-profile/concepts/karma-point/#karma-point","text":"A karma point is a reward given to an individual for making a contribution to open metadata. This may be for: Creating some information Correcting or enhancing some information Linking information together Removing obsolete information Karma points are awarded automatically. They are stored in an individual's personal profile . When an individual's karma point total reaches a multiple of the karma point notification threshold, the Community Profile OMAS sends a notification on its OutTopic .","title":"Karma Point"},{"location":"services/omas/community-profile/concepts/karma-point/#related-information","text":"[Configuring the notification threshold for karma points] License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Related information"},{"location":"services/omas/community-profile/concepts/like/","text":"Like \u00b6 A \"like\" is an attachment that can be made to a personal message, personal note, forums and forum contributions, comments, teams and communities. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Like"},{"location":"services/omas/community-profile/concepts/like/#like","text":"A \"like\" is an attachment that can be made to a personal message, personal note, forums and forum contributions, comments, teams and communities. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Like"},{"location":"services/omas/community-profile/concepts/peer-network/","text":"Peer Network \u00b6 An individual can maintain a list of their close/important colleagues. This is called their peer network and it is chained off of their personal profile . It is important to note that the perspective on who is a close/important colleague is a personal perspective. Therefore Community Profile OMAS separates the concept of who has linked to them from who they have linked to. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Peer network"},{"location":"services/omas/community-profile/concepts/peer-network/#peer-network","text":"An individual can maintain a list of their close/important colleagues. This is called their peer network and it is chained off of their personal profile . It is important to note that the perspective on who is a close/important colleague is a personal perspective. Therefore Community Profile OMAS separates the concept of who has linked to them from who they have linked to. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Peer Network"},{"location":"services/omas/community-profile/concepts/personal-message/","text":"Personal Message \u00b6 A personal message is a message that is attached to a personal profile, or as a reply to another personal message. If is possible to add tags and likes to a personal message. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Personal message"},{"location":"services/omas/community-profile/concepts/personal-message/#personal-message","text":"A personal message is a message that is attached to a personal profile, or as a reply to another personal message. If is possible to add tags and likes to a personal message. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Personal Message"},{"location":"services/omas/community-profile/concepts/personal-notes/","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Personal notes"},{"location":"services/omas/community-profile/concepts/personal-profile/","text":"Personal Profile \u00b6 A personal profile provides a place for an individual to share information about themselves with the other people they are collaborating with. It is associated with one or more of the person's userIds. Each userId is linked to the profile as a UserIdentity object. There can be more than one userId for a profile (for example if a user has an administrator userId and a normal userId) However, the same userId can not be linked to two profiles. This means we can retrieve a profile from the UserId. Each profile has a qualified name that should uniquely identify the individual. For example, an employee identifier. There is space to provide the name the individual wants to be known as, and their full name, along with a job title. An individual can also maintain collections of their favourite Assets, Projects and Communities and control notifications about changes to the member of these lists. Working with personal profiles \u00b6 Retrieving my personal profile Creating my personal profile Updating my personal profile Removing my personal profile Retrieving a personal profile for another user Loading personal profiles of existing members of an organization Synchronizing updates to personal profiles from another system","title":"Personal profile"},{"location":"services/omas/community-profile/concepts/personal-profile/#personal-profile","text":"A personal profile provides a place for an individual to share information about themselves with the other people they are collaborating with. It is associated with one or more of the person's userIds. Each userId is linked to the profile as a UserIdentity object. There can be more than one userId for a profile (for example if a user has an administrator userId and a normal userId) However, the same userId can not be linked to two profiles. This means we can retrieve a profile from the UserId. Each profile has a qualified name that should uniquely identify the individual. For example, an employee identifier. There is space to provide the name the individual wants to be known as, and their full name, along with a job title. An individual can also maintain collections of their favourite Assets, Projects and Communities and control notifications about changes to the member of these lists.","title":"Personal Profile"},{"location":"services/omas/community-profile/concepts/personal-profile/#working-with-personal-profiles","text":"Retrieving my personal profile Creating my personal profile Updating my personal profile Removing my personal profile Retrieving a personal profile for another user Loading personal profiles of existing members of an organization Synchronizing updates to personal profiles from another system","title":"Working with personal profiles"},{"location":"services/omas/community-profile/concepts/personal-roles/","text":"Personal roles \u00b6 Personal roles are the list of person roles that an individual is currently appointed to. Community Member , Team Leader and Team Member are examples of personal roles. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Personal roles"},{"location":"services/omas/community-profile/concepts/personal-roles/#personal-roles","text":"Personal roles are the list of person roles that an individual is currently appointed to. Community Member , Team Leader and Team Member are examples of personal roles. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Personal roles"},{"location":"services/omas/community-profile/concepts/review/","text":"Reviews \u00b6 A review is an attachment that can be made to a personal note or forum contribution. It includes a star rating and an optional review comment. Reviews are used to provide feedback on ideas that are proposed in personal notes and forums. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Review"},{"location":"services/omas/community-profile/concepts/review/#reviews","text":"A review is an attachment that can be made to a personal note or forum contribution. It includes a star rating and an optional review comment. Reviews are used to provide feedback on ideas that are proposed in personal notes and forums. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Reviews"},{"location":"services/omas/community-profile/concepts/tag/","text":"Tag \u00b6 A tag is a descriptive name with optional description that can be attached to resources such as personal profiles, personal messages, personal notes, community forums and forum contributions, comments and communities. The process of adding a tag to an object is called tagging . A tag can be public (visible to all users) or private (visible only to the user that created it). Working with tags \u00b6 Finding existing tags Accessing resources attached to a tag Accessing my tags Creating a tag Attaching a tag Detaching my tag Detaching a tag from a resource Deleting my private tag Deleting public tags License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Tag"},{"location":"services/omas/community-profile/concepts/tag/#tag","text":"A tag is a descriptive name with optional description that can be attached to resources such as personal profiles, personal messages, personal notes, community forums and forum contributions, comments and communities. The process of adding a tag to an object is called tagging . A tag can be public (visible to all users) or private (visible only to the user that created it).","title":"Tag"},{"location":"services/omas/community-profile/concepts/tag/#working-with-tags","text":"Finding existing tags Accessing resources attached to a tag Accessing my tags Creating a tag Attaching a tag Detaching my tag Detaching a tag from a resource Deleting my private tag Deleting public tags License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Working with tags"},{"location":"services/omas/community-profile/concepts/to-do/","text":"To Dos \u00b6 A to do is a record of an action. It includes details of the action to perform and the time frame it needs to be completed for. To dos are normally created as a result of a meeting, or a process, such as a discovery process . The requested action may be ad hoc in nature, or part of a stewardship process that identified a specific action for an individual, or group of individuals. The creator of a to do is called the originator . The person, or people assigned to complete the task are called the assigned resources . Assigned to dos are attached to one of their roles rather than directly to their personal profile . Each to do has a priority and a status: * Open - no work has started. * In Progress - work is ongoing. * Waiting - work is on hold, typically blocked. * Complete - Work is completed. * Abandoned - No work will happen. Working with to dos \u00b6 Below are the descriptions of how to use the Community Profile OMAS to work with to dos. Accessing my to dos Creating a to do Managing a to do Design information \u00b6 ToDo Bean Open Metadata Type License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"To do"},{"location":"services/omas/community-profile/concepts/to-do/#to-dos","text":"A to do is a record of an action. It includes details of the action to perform and the time frame it needs to be completed for. To dos are normally created as a result of a meeting, or a process, such as a discovery process . The requested action may be ad hoc in nature, or part of a stewardship process that identified a specific action for an individual, or group of individuals. The creator of a to do is called the originator . The person, or people assigned to complete the task are called the assigned resources . Assigned to dos are attached to one of their roles rather than directly to their personal profile . Each to do has a priority and a status: * Open - no work has started. * In Progress - work is ongoing. * Waiting - work is on hold, typically blocked. * Complete - Work is completed. * Abandoned - No work will happen.","title":"To Dos"},{"location":"services/omas/community-profile/concepts/to-do/#working-with-to-dos","text":"Below are the descriptions of how to use the Community Profile OMAS to work with to dos. Accessing my to dos Creating a to do Managing a to do","title":"Working with to dos"},{"location":"services/omas/community-profile/concepts/to-do/#design-information","text":"ToDo Bean Open Metadata Type License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Design information"},{"location":"services/omas/community-profile/concepts/useful-resource/","text":"Useful Resources \u00b6 A resource is definition that is used frequently and so it is helpful to have a link to it. Examples of resources include glossaries, or categories and terms from a glossary, governance definitions, models, system definitions or process definitions. It is possible to maintain a list of useful resources for a personal profile , a team or a community . Working with resources and resource lists \u00b6 Finding a resource License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Useful resource"},{"location":"services/omas/community-profile/concepts/useful-resource/#useful-resources","text":"A resource is definition that is used frequently and so it is helpful to have a link to it. Examples of resources include glossaries, or categories and terms from a glossary, governance definitions, models, system definitions or process definitions. It is possible to maintain a list of useful resources for a personal profile , a team or a community .","title":"Useful Resources"},{"location":"services/omas/community-profile/concepts/useful-resource/#working-with-resources-and-resource-lists","text":"Finding a resource License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Working with resources and resource lists"},{"location":"services/omas/community-profile/concepts/user-identity/","text":"User identity \u00b6 The user identity is the unique name of a user's logon account. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"User identity"},{"location":"services/omas/community-profile/concepts/user-identity/#user-identity","text":"The user identity is the unique name of a user's logon account. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"User identity"},{"location":"services/omas/community-profile/design/","text":"Community Profile Open Metadata Access Service (OMAS) Design Documentation \u00b6 The Community Profile OMAS is implemented in four modules: community-profile-api supports the common Java classes that are used both by the client and the server. This includes the Java API, events, beans, events and REST API structures. community-profile-client supports the Java client library that allows applications and tools to call the remote REST APIs. community-profile-server supports the server side implementation of the access service. This includes the interaction with the administration services for registration, configuration, initialization and termination of the access service. interaction with the repository services to work with open metadata from the cohort . support for the access service's API and its related event management. community-profile-spring supports the REST API using the Spring libraries. Further documentation can be found: Java API Beans Exceptions Event Payloads REST API Operations Client-side design Server-side design License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/community-profile/design/#community-profile-open-metadata-access-service-omas-design-documentation","text":"The Community Profile OMAS is implemented in four modules: community-profile-api supports the common Java classes that are used both by the client and the server. This includes the Java API, events, beans, events and REST API structures. community-profile-client supports the Java client library that allows applications and tools to call the remote REST APIs. community-profile-server supports the server side implementation of the access service. This includes the interaction with the administration services for registration, configuration, initialization and termination of the access service. interaction with the repository services to work with open metadata from the cohort . support for the access service's API and its related event management. community-profile-spring supports the REST API using the Spring libraries. Further documentation can be found: Java API Beans Exceptions Event Payloads REST API Operations Client-side design Server-side design License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community Profile Open Metadata Access Service (OMAS) Design Documentation"},{"location":"services/omas/community-profile/scenarios/","text":"Using the Community Profile OMAS \u00b6 Below are the list of tasks supported by the Community Profile OMAS . One time set up by the administrator \u00b6 Many organizations already have a system that maintains information about their employees and/or customers and/or business partners . The Community Profile OMAS therefore supports an event exchange with such a system to keep the profiles synchronized. The following tasks cover the work of the IT team to integrate the Community Profile OMAS with other systems. Loading personal profiles of existing members of an organization into an open metadata repository. Synchronizing updates to personal profiles from another system Loading the organization's departmental structure into an open metadata repository. Synchronizing the organization's departmental structure with another system Capturing karma point plateaus emitted from the Community Profile OMAS OutTopic . Synchronizing collaboration activity with another system Individuals working with their personal profile \u00b6 A personal profile provides a place for an individual to share information about themselves with the other people they are collaborating with. Each personal profile is associated with one or more of the person's userIds. It is retrieved using one of these userIds. Retrieving my personal profile For organizations where the personal profile is not loaded from another system (see above) an individual can maintain their own profile. Creating my personal profile Updating my personal profile Removing my personal profile Once an individual has a personal profile, they will be awarded karma points when they contribute content to open metadata. An individual can query their karma points. Retrieving my karma points The individual can also maintain collections of their favourite Assets , Projects and Communities and control notifications about changes to the contents of these lists. Accessing my favorite assets Managing my favorite assets Accessing my favorite projects Managing my favorite projects Accessing my favorite communities Managing my favorite communities An individual can link other resources such as glossaries, and external references to their profile. Finding resources Accessing my resource list Managing my resource list Accessing my external reference list Managing my external reference list An individual can create a series of personal notes. These are like a personal blog. They are visible to other users who can comment on and review the content. Setting up my personal notes Accessing my personal notes Removing my personal notes Adding a personal note Updating a personal note Removing a personal note An individual can query the teams and communities they belong to. Accessing my communities Accessing my teams An individual can access an manage a list of close colleagues called their peer network . Accessing my peer network Managing my peer network An individual can query their roles in the organization and any actions (to dos) that have been assigned to them as part of one of these roles. Accessing my roles Accessing my to dos for each role Managing to dos An individual can add feedback to their profile and others (see below). Providing feedback and content to personal profiles \u00b6 An individual can send a personal message to themselves, or another user. This message is attached to the recipient's profile. Sending a personal message Replying to a personal message Updating a personal message Removing a personal message It is possible to add comments, likes and reviews to a personal note. Adding a comment to a personal note Updating a comment to a personal note Removing my comment from a personal note Adding a review to a personal note Updating my review to a personal note Removing my review from a personal note Adding a like to a personal note Removing a like from a personal note It is possible to create and attach tags to personal profiles, personal notes, and comments either for your personal profile or someone else's. Finding existing tags Accessing resources attached to a tag Accessing my tags Creating a tag Attaching a tag Detaching my tag Detaching a tag from a resource Deleting my private tag Deleting public tags Individuals searching for other people and teams \u00b6 Below are different ways to locate people in the organization. Finding a Person Querying another's personal profile Navigating the Departmental Structure Finding a Team Accessing my teams Viewing Leaders of a Team Viewing Members of a Team Communities \u00b6 Communities collect together resources, best practices and ideas for a group of people who are collaborating on a specific topic or skill. Anyone can create a community. Creating a community The person creating the community is the community leader . They can then add other people as community members with different community roles . Adding a new community member Changing a community member's role Removing a community member Community leaders and administrators can remove inappropriate content from a community and close it. Removing a comment from a community Removing a note from a community Removing a review from a community Removing a resource from a community Closing a community Individuals can locate and connect with a community. Finding the communities I am a member of Finding a community Querying a community Watching a community Joining a community Leaving a community Once someone is a member of a community they can add content to it. Adding a comment to a community Replying to a community comment Removing my comment from a community Adding a resource to a community Creating a community forum Adding a contribution to a community forum Removing my contribution from a community forum Community content can have feedback attached in the form of tags, reviews and likes. Attaching feedback to a community Attaching feedback to a community comment Attaching feedback to a community forum Attaching feedback to a community forum contribution Related information \u00b6 Community Profile OMAS Concepts Community Profile OMAS Design","title":"Index"},{"location":"services/omas/community-profile/scenarios/#using-the-community-profile-omas","text":"Below are the list of tasks supported by the Community Profile OMAS .","title":"Using the Community Profile OMAS"},{"location":"services/omas/community-profile/scenarios/#one-time-set-up-by-the-administrator","text":"Many organizations already have a system that maintains information about their employees and/or customers and/or business partners . The Community Profile OMAS therefore supports an event exchange with such a system to keep the profiles synchronized. The following tasks cover the work of the IT team to integrate the Community Profile OMAS with other systems. Loading personal profiles of existing members of an organization into an open metadata repository. Synchronizing updates to personal profiles from another system Loading the organization's departmental structure into an open metadata repository. Synchronizing the organization's departmental structure with another system Capturing karma point plateaus emitted from the Community Profile OMAS OutTopic . Synchronizing collaboration activity with another system","title":"One time set up by the administrator"},{"location":"services/omas/community-profile/scenarios/#individuals-working-with-their-personal-profile","text":"A personal profile provides a place for an individual to share information about themselves with the other people they are collaborating with. Each personal profile is associated with one or more of the person's userIds. It is retrieved using one of these userIds. Retrieving my personal profile For organizations where the personal profile is not loaded from another system (see above) an individual can maintain their own profile. Creating my personal profile Updating my personal profile Removing my personal profile Once an individual has a personal profile, they will be awarded karma points when they contribute content to open metadata. An individual can query their karma points. Retrieving my karma points The individual can also maintain collections of their favourite Assets , Projects and Communities and control notifications about changes to the contents of these lists. Accessing my favorite assets Managing my favorite assets Accessing my favorite projects Managing my favorite projects Accessing my favorite communities Managing my favorite communities An individual can link other resources such as glossaries, and external references to their profile. Finding resources Accessing my resource list Managing my resource list Accessing my external reference list Managing my external reference list An individual can create a series of personal notes. These are like a personal blog. They are visible to other users who can comment on and review the content. Setting up my personal notes Accessing my personal notes Removing my personal notes Adding a personal note Updating a personal note Removing a personal note An individual can query the teams and communities they belong to. Accessing my communities Accessing my teams An individual can access an manage a list of close colleagues called their peer network . Accessing my peer network Managing my peer network An individual can query their roles in the organization and any actions (to dos) that have been assigned to them as part of one of these roles. Accessing my roles Accessing my to dos for each role Managing to dos An individual can add feedback to their profile and others (see below).","title":"Individuals working with their personal profile"},{"location":"services/omas/community-profile/scenarios/#providing-feedback-and-content-to-personal-profiles","text":"An individual can send a personal message to themselves, or another user. This message is attached to the recipient's profile. Sending a personal message Replying to a personal message Updating a personal message Removing a personal message It is possible to add comments, likes and reviews to a personal note. Adding a comment to a personal note Updating a comment to a personal note Removing my comment from a personal note Adding a review to a personal note Updating my review to a personal note Removing my review from a personal note Adding a like to a personal note Removing a like from a personal note It is possible to create and attach tags to personal profiles, personal notes, and comments either for your personal profile or someone else's. Finding existing tags Accessing resources attached to a tag Accessing my tags Creating a tag Attaching a tag Detaching my tag Detaching a tag from a resource Deleting my private tag Deleting public tags","title":"Providing feedback and content to personal profiles"},{"location":"services/omas/community-profile/scenarios/#individuals-searching-for-other-people-and-teams","text":"Below are different ways to locate people in the organization. Finding a Person Querying another's personal profile Navigating the Departmental Structure Finding a Team Accessing my teams Viewing Leaders of a Team Viewing Members of a Team","title":"Individuals searching for other people and teams"},{"location":"services/omas/community-profile/scenarios/#communities","text":"Communities collect together resources, best practices and ideas for a group of people who are collaborating on a specific topic or skill. Anyone can create a community. Creating a community The person creating the community is the community leader . They can then add other people as community members with different community roles . Adding a new community member Changing a community member's role Removing a community member Community leaders and administrators can remove inappropriate content from a community and close it. Removing a comment from a community Removing a note from a community Removing a review from a community Removing a resource from a community Closing a community Individuals can locate and connect with a community. Finding the communities I am a member of Finding a community Querying a community Watching a community Joining a community Leaving a community Once someone is a member of a community they can add content to it. Adding a comment to a community Replying to a community comment Removing my comment from a community Adding a resource to a community Creating a community forum Adding a contribution to a community forum Removing my contribution from a community forum Community content can have feedback attached in the form of tags, reviews and likes. Attaching feedback to a community Attaching feedback to a community comment Attaching feedback to a community forum Attaching feedback to a community forum contribution","title":"Communities"},{"location":"services/omas/community-profile/scenarios/#related-information","text":"Community Profile OMAS Concepts Community Profile OMAS Design","title":"Related information"},{"location":"services/omas/community-profile/scenarios/accessing-a-useful-resource-list/","text":"Accessing a Useful Resource List \u00b6 It is possible to maintain a list of useful resources with a personal profile , a team or a community . First locate the unique identifier (guid) of the element acting as an anchor ofr","title":"Accessing a useful resource list"},{"location":"services/omas/community-profile/scenarios/accessing-a-useful-resource-list/#accessing-a-useful-resource-list","text":"It is possible to maintain a list of useful resources with a personal profile , a team or a community . First locate the unique identifier (guid) of the element acting as an anchor ofr","title":"Accessing a Useful Resource List"},{"location":"services/omas/community-profile/scenarios/accessing-an-external-references-list/","text":"Accessing an External References List \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Accessing an external references list"},{"location":"services/omas/community-profile/scenarios/accessing-an-external-references-list/#accessing-an-external-references-list","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Accessing an External References List"},{"location":"services/omas/community-profile/scenarios/accessing-my-communities/","text":"Accessing my communities \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Accessing my communities"},{"location":"services/omas/community-profile/scenarios/accessing-my-communities/#accessing-my-communities","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Accessing my communities"},{"location":"services/omas/community-profile/scenarios/accessing-my-external-references/","text":"Accessing My External References \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Accessing my external references"},{"location":"services/omas/community-profile/scenarios/accessing-my-external-references/#accessing-my-external-references","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Accessing My External References"},{"location":"services/omas/community-profile/scenarios/accessing-my-favorite-assets/","text":"Accessing my favorite assets \u00b6","title":"Accessing my favorite assets"},{"location":"services/omas/community-profile/scenarios/accessing-my-favorite-assets/#accessing-my-favorite-assets","text":"","title":"Accessing my favorite assets"},{"location":"services/omas/community-profile/scenarios/accessing-my-favorite-communities/","text":"Accessing my favorite communities \u00b6","title":"Accessing my favorite communities"},{"location":"services/omas/community-profile/scenarios/accessing-my-favorite-communities/#accessing-my-favorite-communities","text":"","title":"Accessing my favorite communities"},{"location":"services/omas/community-profile/scenarios/accessing-my-favorite-projects/","text":"Accessing my favorite projects \u00b6","title":"Accessing my favorite projects"},{"location":"services/omas/community-profile/scenarios/accessing-my-favorite-projects/#accessing-my-favorite-projects","text":"","title":"Accessing my favorite projects"},{"location":"services/omas/community-profile/scenarios/accessing-my-peer-network/","text":"Accessing my peer network \u00b6","title":"Accessing my peer network"},{"location":"services/omas/community-profile/scenarios/accessing-my-peer-network/#accessing-my-peer-network","text":"","title":"Accessing my peer network"},{"location":"services/omas/community-profile/scenarios/accessing-my-personal-notes/","text":"Accessing my roles \u00b6","title":"Accessing my personal notes"},{"location":"services/omas/community-profile/scenarios/accessing-my-personal-notes/#accessing-my-roles","text":"","title":"Accessing my roles"},{"location":"services/omas/community-profile/scenarios/accessing-my-resource-list/","text":"Accessing my Resource List \u00b6","title":"Accessing my resource list"},{"location":"services/omas/community-profile/scenarios/accessing-my-resource-list/#accessing-my-resource-list","text":"","title":"Accessing my Resource List"},{"location":"services/omas/community-profile/scenarios/accessing-my-roles/","text":"Accessing my roles \u00b6","title":"Accessing my roles"},{"location":"services/omas/community-profile/scenarios/accessing-my-roles/#accessing-my-roles","text":"","title":"Accessing my roles"},{"location":"services/omas/community-profile/scenarios/accessing-my-tags/","text":"Accessing my tags \u00b6 Tags provide an informal way of identifying particular types of resources.","title":"Accessing my tags"},{"location":"services/omas/community-profile/scenarios/accessing-my-tags/#accessing-my-tags","text":"Tags provide an informal way of identifying particular types of resources.","title":"Accessing my tags"},{"location":"services/omas/community-profile/scenarios/accessing-my-teams/","text":"Accessing the team I am a member of \u00b6","title":"Accessing my teams"},{"location":"services/omas/community-profile/scenarios/accessing-my-teams/#accessing-the-team-i-am-a-member-of","text":"","title":"Accessing the team I am a member of"},{"location":"services/omas/community-profile/scenarios/accessing-my-to-dos/","text":"Accessing my to dos \u00b6","title":"Accessing my to dos"},{"location":"services/omas/community-profile/scenarios/accessing-my-to-dos/#accessing-my-to-dos","text":"","title":"Accessing my to dos"},{"location":"services/omas/community-profile/scenarios/accessing-tagged-resources/","text":"Accessing tagged resources \u00b6","title":"Accessing tagged resources"},{"location":"services/omas/community-profile/scenarios/accessing-tagged-resources/#accessing-tagged-resources","text":"","title":"Accessing tagged resources"},{"location":"services/omas/community-profile/scenarios/adding-a-comment-to-a-community/","text":"Adding a comment to a community \u00b6 Can be added to the community, or to a a forum contribution.","title":"Adding a comment to a community"},{"location":"services/omas/community-profile/scenarios/adding-a-comment-to-a-community/#adding-a-comment-to-a-community","text":"Can be added to the community, or to a a forum contribution.","title":"Adding a comment to a community"},{"location":"services/omas/community-profile/scenarios/adding-a-comment-to-a-personal-note/","text":"Adding a comment to a personal note \u00b6 Can add to personal note linked to your profile or someone else's.","title":"Adding a comment to a personal note"},{"location":"services/omas/community-profile/scenarios/adding-a-comment-to-a-personal-note/#adding-a-comment-to-a-personal-note","text":"Can add to personal note linked to your profile or someone else's.","title":"Adding a comment to a personal note"},{"location":"services/omas/community-profile/scenarios/adding-a-comment/","text":"Adding a comment \u00b6 Maybe to a community, community forum contribution License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding a comment"},{"location":"services/omas/community-profile/scenarios/adding-a-comment/#adding-a-comment","text":"Maybe to a community, community forum contribution License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding a comment"},{"location":"services/omas/community-profile/scenarios/adding-a-contribution-to-a-forum/","text":"Adding a Contribution to a Community Forum \u00b6","title":"Adding a contribution to a forum"},{"location":"services/omas/community-profile/scenarios/adding-a-contribution-to-a-forum/#adding-a-contribution-to-a-community-forum","text":"","title":"Adding a Contribution to a Community Forum"},{"location":"services/omas/community-profile/scenarios/adding-a-like-to-a-personal-note/","text":"Adding a like to a personal note \u00b6 Can add like to personal note linked to your profile or someone else's.","title":"Adding a like to a personal note"},{"location":"services/omas/community-profile/scenarios/adding-a-like-to-a-personal-note/#adding-a-like-to-a-personal-note","text":"Can add like to personal note linked to your profile or someone else's.","title":"Adding a like to a personal note"},{"location":"services/omas/community-profile/scenarios/adding-a-new-community-member/","text":"Adding a new community member \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding a new community member"},{"location":"services/omas/community-profile/scenarios/adding-a-new-community-member/#adding-a-new-community-member","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding a new community member"},{"location":"services/omas/community-profile/scenarios/adding-a-personal-note/","text":"Adding a personal note \u00b6","title":"Adding a personal note"},{"location":"services/omas/community-profile/scenarios/adding-a-personal-note/#adding-a-personal-note","text":"","title":"Adding a personal note"},{"location":"services/omas/community-profile/scenarios/adding-a-resource-to-a-resource-list/","text":"Adding a Resource to a Resource List \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding a resource to a resource list"},{"location":"services/omas/community-profile/scenarios/adding-a-resource-to-a-resource-list/#adding-a-resource-to-a-resource-list","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding a Resource to a Resource List"},{"location":"services/omas/community-profile/scenarios/adding-a-review-to-a-personal-note/","text":"Adding a review to a personal note \u00b6 Can add to personal note linked to your profile or someone else's. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding a review to a personal note"},{"location":"services/omas/community-profile/scenarios/adding-a-review-to-a-personal-note/#adding-a-review-to-a-personal-note","text":"Can add to personal note linked to your profile or someone else's. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Adding a review to a personal note"},{"location":"services/omas/community-profile/scenarios/attaching-a-tag/","text":"Attaching a tag to a resource \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Attaching a tag"},{"location":"services/omas/community-profile/scenarios/attaching-a-tag/#attaching-a-tag-to-a-resource","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Attaching a tag to a resource"},{"location":"services/omas/community-profile/scenarios/attaching-feedback-to-a-community-comment/","text":"Attaching feedback to a community comment \u00b6","title":"Attaching feedback to a community comment"},{"location":"services/omas/community-profile/scenarios/attaching-feedback-to-a-community-comment/#attaching-feedback-to-a-community-comment","text":"","title":"Attaching feedback to a community comment"},{"location":"services/omas/community-profile/scenarios/attaching-feedback-to-a-community-forum-contribution/","text":"Attaching feedback to a community forum contribution \u00b6","title":"Attaching feedback to a community forum contribution"},{"location":"services/omas/community-profile/scenarios/attaching-feedback-to-a-community-forum-contribution/#attaching-feedback-to-a-community-forum-contribution","text":"","title":"Attaching feedback to a community forum contribution"},{"location":"services/omas/community-profile/scenarios/attaching-feedback-to-a-community-forum/","text":"Attaching feedback to a community forum \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Attaching feedback to a community forum"},{"location":"services/omas/community-profile/scenarios/attaching-feedback-to-a-community-forum/#attaching-feedback-to-a-community-forum","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Attaching feedback to a community forum"},{"location":"services/omas/community-profile/scenarios/attaching-feedback-to-a-community/","text":"Attaching feedback to a community \u00b6","title":"Attaching feedback to a community"},{"location":"services/omas/community-profile/scenarios/attaching-feedback-to-a-community/#attaching-feedback-to-a-community","text":"","title":"Attaching feedback to a community"},{"location":"services/omas/community-profile/scenarios/capturing-karma-point-plateaus/","text":"Capturing karma point plateaus \u00b6","title":"Capturing karma point plateaus"},{"location":"services/omas/community-profile/scenarios/capturing-karma-point-plateaus/#capturing-karma-point-plateaus","text":"","title":"Capturing karma point plateaus"},{"location":"services/omas/community-profile/scenarios/changing-community-member-role/","text":"Changing a community member's role \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Changing community member role"},{"location":"services/omas/community-profile/scenarios/changing-community-member-role/#changing-a-community-members-role","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Changing a community member's role"},{"location":"services/omas/community-profile/scenarios/closing-a-community/","text":"Closing a community \u00b6","title":"Closing a community"},{"location":"services/omas/community-profile/scenarios/closing-a-community/#closing-a-community","text":"","title":"Closing a community"},{"location":"services/omas/community-profile/scenarios/creating-a-community-forum/","text":"Creating a community forum \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Creating a community forum"},{"location":"services/omas/community-profile/scenarios/creating-a-community-forum/#creating-a-community-forum","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Creating a community forum"},{"location":"services/omas/community-profile/scenarios/creating-a-community/","text":"Creating a community \u00b6","title":"Creating a community"},{"location":"services/omas/community-profile/scenarios/creating-a-community/#creating-a-community","text":"","title":"Creating a community"},{"location":"services/omas/community-profile/scenarios/creating-a-tag/","text":"Creating a tag \u00b6","title":"Creating a tag"},{"location":"services/omas/community-profile/scenarios/creating-a-tag/#creating-a-tag","text":"","title":"Creating a tag"},{"location":"services/omas/community-profile/scenarios/creating-a-to-do/","text":"Creating a to do \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Creating a to do"},{"location":"services/omas/community-profile/scenarios/creating-a-to-do/#creating-a-to-do","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Creating a to do"},{"location":"services/omas/community-profile/scenarios/creating-my-personal-profile/","text":"Creating my personal profile \u00b6 If your organization has not already created a personal profile for you then it is possible to create the profile yourself. The information that you will need is as follows. Many of the fields are optional but the more information that you supply, the easier it will be for people to locate you. qualified name - this is a unique identifier for you - for example if you are an employee of the organization then use your employee number. name - this is the name that you want to be known by. full name - this is your full legal name. This is optional. job title - this is also optional. job description - this is a short paragraph describing what your role is. It is optional. contact details such as email address, phone number social media account. See also \u00b6 Managing my contact details Design note \u00b6 The Community Profile OMAS will emit an [event] whenever a new profile is created using this approach","title":"Creating my personal profile"},{"location":"services/omas/community-profile/scenarios/creating-my-personal-profile/#creating-my-personal-profile","text":"If your organization has not already created a personal profile for you then it is possible to create the profile yourself. The information that you will need is as follows. Many of the fields are optional but the more information that you supply, the easier it will be for people to locate you. qualified name - this is a unique identifier for you - for example if you are an employee of the organization then use your employee number. name - this is the name that you want to be known by. full name - this is your full legal name. This is optional. job title - this is also optional. job description - this is a short paragraph describing what your role is. It is optional. contact details such as email address, phone number social media account.","title":"Creating my personal profile"},{"location":"services/omas/community-profile/scenarios/creating-my-personal-profile/#see-also","text":"Managing my contact details","title":"See also"},{"location":"services/omas/community-profile/scenarios/creating-my-personal-profile/#design-note","text":"The Community Profile OMAS will emit an [event] whenever a new profile is created using this approach","title":"Design note"},{"location":"services/omas/community-profile/scenarios/detaching-a-tag/","text":"Detaching a tag from a resource \u00b6 Find the resource and detach the tag.","title":"Detaching a tag"},{"location":"services/omas/community-profile/scenarios/detaching-a-tag/#detaching-a-tag-from-a-resource","text":"Find the resource and detach the tag.","title":"Detaching a tag from a resource"},{"location":"services/omas/community-profile/scenarios/detaching-my-tag/","text":"Detaching my tag from a resource \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Detaching my tag"},{"location":"services/omas/community-profile/scenarios/detaching-my-tag/#detaching-my-tag-from-a-resource","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Detaching my tag from a resource"},{"location":"services/omas/community-profile/scenarios/finding-a-community/","text":"Finding a community \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Finding a community"},{"location":"services/omas/community-profile/scenarios/finding-a-community/#finding-a-community","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Finding a community"},{"location":"services/omas/community-profile/scenarios/finding-a-person/","text":"Finding a person \u00b6","title":"Finding a person"},{"location":"services/omas/community-profile/scenarios/finding-a-person/#finding-a-person","text":"","title":"Finding a person"},{"location":"services/omas/community-profile/scenarios/finding-a-resource/","text":"Finding a resource \u00b6 See also \u00b6 Finding resources by tags","title":"Finding a resource"},{"location":"services/omas/community-profile/scenarios/finding-a-resource/#finding-a-resource","text":"","title":"Finding a resource"},{"location":"services/omas/community-profile/scenarios/finding-a-resource/#see-also","text":"Finding resources by tags","title":"See also"},{"location":"services/omas/community-profile/scenarios/finding-a-tag/","text":"Finding a tag \u00b6 Find request, then browse results. Then query?","title":"Finding a tag"},{"location":"services/omas/community-profile/scenarios/finding-a-tag/#finding-a-tag","text":"Find request, then browse results. Then query?","title":"Finding a tag"},{"location":"services/omas/community-profile/scenarios/finding-a-team/","text":"Finding a team \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Finding a team"},{"location":"services/omas/community-profile/scenarios/finding-a-team/#finding-a-team","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Finding a team"},{"location":"services/omas/community-profile/scenarios/joining-a-community/","text":"Joining a community \u00b6 Add a to do on community administrators License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Joining a community"},{"location":"services/omas/community-profile/scenarios/joining-a-community/#joining-a-community","text":"Add a to do on community administrators License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Joining a community"},{"location":"services/omas/community-profile/scenarios/leaving-a-community/","text":"Leaving a community \u00b6 Add a to-do on a community administrator","title":"Leaving a community"},{"location":"services/omas/community-profile/scenarios/leaving-a-community/#leaving-a-community","text":"Add a to-do on a community administrator","title":"Leaving a community"},{"location":"services/omas/community-profile/scenarios/loading-departmental-structure/","text":"Loading an organization's departmental structure \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Loading departmental structure"},{"location":"services/omas/community-profile/scenarios/loading-departmental-structure/#loading-an-organizations-departmental-structure","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Loading an organization's departmental structure"},{"location":"services/omas/community-profile/scenarios/loading-personal-profiles/","text":"Loading the personal profiles of existing members of an organization \u00b6","title":"Loading personal profiles"},{"location":"services/omas/community-profile/scenarios/loading-personal-profiles/#loading-the-personal-profiles-of-existing-members-of-an-organization","text":"","title":"Loading the personal profiles of existing members of an organization"},{"location":"services/omas/community-profile/scenarios/managing-a-to-do/","text":"Managing an action (to do) \u00b6","title":"Managing a to do"},{"location":"services/omas/community-profile/scenarios/managing-a-to-do/#managing-an-action-to-do","text":"","title":"Managing an action (to do)"},{"location":"services/omas/community-profile/scenarios/managing-my-contact-details/","text":"Managing my contact details \u00b6","title":"Managing my contact details"},{"location":"services/omas/community-profile/scenarios/managing-my-contact-details/#managing-my-contact-details","text":"","title":"Managing my contact details"},{"location":"services/omas/community-profile/scenarios/managing-my-external-references/","text":"Managing My External References \u00b6","title":"Managing my external references"},{"location":"services/omas/community-profile/scenarios/managing-my-external-references/#managing-my-external-references","text":"","title":"Managing My External References"},{"location":"services/omas/community-profile/scenarios/managing-my-favorite-assets/","text":"Managing my favorite assets \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Managing my favorite assets"},{"location":"services/omas/community-profile/scenarios/managing-my-favorite-assets/#managing-my-favorite-assets","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Managing my favorite assets"},{"location":"services/omas/community-profile/scenarios/managing-my-favorite-communities/","text":"Managing my favorite communities \u00b6","title":"Managing my favorite communities"},{"location":"services/omas/community-profile/scenarios/managing-my-favorite-communities/#managing-my-favorite-communities","text":"","title":"Managing my favorite communities"},{"location":"services/omas/community-profile/scenarios/managing-my-favorite-projects/","text":"Managing my favorite projects \u00b6","title":"Managing my favorite projects"},{"location":"services/omas/community-profile/scenarios/managing-my-favorite-projects/#managing-my-favorite-projects","text":"","title":"Managing my favorite projects"},{"location":"services/omas/community-profile/scenarios/managing-my-peer-network/","text":"Managing my peer network \u00b6","title":"Managing my peer network"},{"location":"services/omas/community-profile/scenarios/managing-my-peer-network/#managing-my-peer-network","text":"","title":"Managing my peer network"},{"location":"services/omas/community-profile/scenarios/managing-my-resource-list/","text":"Managing My Resource List \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Managing my resource list"},{"location":"services/omas/community-profile/scenarios/managing-my-resource-list/#managing-my-resource-list","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Managing My Resource List"},{"location":"services/omas/community-profile/scenarios/navigating-the-departmental-structure/","text":"Navigating the departmental structure of an organization \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Navigating the departmental structure"},{"location":"services/omas/community-profile/scenarios/navigating-the-departmental-structure/#navigating-the-departmental-structure-of-an-organization","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Navigating the departmental structure of an organization"},{"location":"services/omas/community-profile/scenarios/querying-a-community/","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Querying a community"},{"location":"services/omas/community-profile/scenarios/querying-anothers-personal-profile/","text":"Querying another person's personal profile \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Querying anothers personal profile"},{"location":"services/omas/community-profile/scenarios/querying-anothers-personal-profile/#querying-another-persons-personal-profile","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Querying another person's personal profile"},{"location":"services/omas/community-profile/scenarios/removing-a-community-comment/","text":"Removing a comment from a community \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a community comment"},{"location":"services/omas/community-profile/scenarios/removing-a-community-comment/#removing-a-comment-from-a-community","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a comment from a community"},{"location":"services/omas/community-profile/scenarios/removing-a-community-member/","text":"Removing a community member \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a community member"},{"location":"services/omas/community-profile/scenarios/removing-a-community-member/#removing-a-community-member","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a community member"},{"location":"services/omas/community-profile/scenarios/removing-a-community-note/","text":"Removing a community note \u00b6","title":"Removing a community note"},{"location":"services/omas/community-profile/scenarios/removing-a-community-note/#removing-a-community-note","text":"","title":"Removing a community note"},{"location":"services/omas/community-profile/scenarios/removing-a-community-resource/","text":"Removing a resource from a community \u00b6","title":"Removing a community resource"},{"location":"services/omas/community-profile/scenarios/removing-a-community-resource/#removing-a-resource-from-a-community","text":"","title":"Removing a resource from a community"},{"location":"services/omas/community-profile/scenarios/removing-a-contribution-from-a-forum/","text":"Removing a Contribution from a Community Forum \u00b6","title":"Removing a contribution from a forum"},{"location":"services/omas/community-profile/scenarios/removing-a-contribution-from-a-forum/#removing-a-contribution-from-a-community-forum","text":"","title":"Removing a Contribution from a Community Forum"},{"location":"services/omas/community-profile/scenarios/removing-a-like/","text":"Removing a like \u00b6 This is from anything","title":"Removing a like"},{"location":"services/omas/community-profile/scenarios/removing-a-like/#removing-a-like","text":"This is from anything","title":"Removing a like"},{"location":"services/omas/community-profile/scenarios/removing-a-personal-message/","text":"Removing a personal message \u00b6","title":"Removing a personal message"},{"location":"services/omas/community-profile/scenarios/removing-a-personal-message/#removing-a-personal-message","text":"","title":"Removing a personal message"},{"location":"services/omas/community-profile/scenarios/removing-a-personal-note/","text":"Removing a personal note \u00b6","title":"Removing a personal note"},{"location":"services/omas/community-profile/scenarios/removing-a-personal-note/#removing-a-personal-note","text":"","title":"Removing a personal note"},{"location":"services/omas/community-profile/scenarios/removing-a-review/","text":"Removing a review \u00b6 Can do if own the thing review is being removed from. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a review"},{"location":"services/omas/community-profile/scenarios/removing-a-review/#removing-a-review","text":"Can do if own the thing review is being removed from. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a review"},{"location":"services/omas/community-profile/scenarios/removing-a-tag/","text":"Removing a public tag \u00b6 Can do it if not attached to anything License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a tag"},{"location":"services/omas/community-profile/scenarios/removing-a-tag/#removing-a-public-tag","text":"Can do it if not attached to anything License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a public tag"},{"location":"services/omas/community-profile/scenarios/removing-my-comment-from-a-community/","text":"Removing a comment that I made on a community \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing my comment from a community"},{"location":"services/omas/community-profile/scenarios/removing-my-comment-from-a-community/#removing-a-comment-that-i-made-on-a-community","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a comment that I made on a community"},{"location":"services/omas/community-profile/scenarios/removing-my-comment-from-a-personal-note/","text":"Removing a comment that I made to a personal note \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing my comment from a personal note"},{"location":"services/omas/community-profile/scenarios/removing-my-comment-from-a-personal-note/#removing-a-comment-that-i-made-to-a-personal-note","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a comment that I made to a personal note"},{"location":"services/omas/community-profile/scenarios/removing-my-like-from-a-personal-note/","text":"Removing a like that I made to a personal note \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing my like from a personal note"},{"location":"services/omas/community-profile/scenarios/removing-my-like-from-a-personal-note/#removing-a-like-that-i-made-to-a-personal-note","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing a like that I made to a personal note"},{"location":"services/omas/community-profile/scenarios/removing-my-personal-notes/","text":"Removing my personal notes \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing my personal notes"},{"location":"services/omas/community-profile/scenarios/removing-my-personal-notes/#removing-my-personal-notes","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing my personal notes"},{"location":"services/omas/community-profile/scenarios/removing-my-personal-profile/","text":"Removing my personal profile \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing my personal profile"},{"location":"services/omas/community-profile/scenarios/removing-my-personal-profile/#removing-my-personal-profile","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Removing my personal profile"},{"location":"services/omas/community-profile/scenarios/removing-my-review/","text":"Removing my review \u00b6 Can do if own the review.","title":"Removing my review"},{"location":"services/omas/community-profile/scenarios/removing-my-review/#removing-my-review","text":"Can do if own the review.","title":"Removing my review"},{"location":"services/omas/community-profile/scenarios/removing-my-tag/","text":"Removing one of my private tags \u00b6","title":"Removing my tag"},{"location":"services/omas/community-profile/scenarios/removing-my-tag/#removing-one-of-my-private-tags","text":"","title":"Removing one of my private tags"},{"location":"services/omas/community-profile/scenarios/replying-to-a-comment/","text":"Replying to a comment \u00b6","title":"Replying to a comment"},{"location":"services/omas/community-profile/scenarios/replying-to-a-comment/#replying-to-a-comment","text":"","title":"Replying to a comment"},{"location":"services/omas/community-profile/scenarios/replying-to-a-personal-message/","text":"Replying to a personal message \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Replying to a personal message"},{"location":"services/omas/community-profile/scenarios/replying-to-a-personal-message/#replying-to-a-personal-message","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Replying to a personal message"},{"location":"services/omas/community-profile/scenarios/retrieving-my-karma-points/","text":"Retrieving my karma points \u00b6 If an individual has a Personal profile the Community Profile OMAS will reward him/her whenever they contribute to open metadata. These rewards are in the form of karma points . The Community Profile OMAS is responsible for maintaining the count of the karma points. It does this by listening to the metadata changes occurring in the metadata repositories and updates the personal profile of each user making a contribution. The Community Profile OMAS provides a method/operation to allow an individual to retrieve their current karma point total. [Using Java to query my karma points] [Using the REST API to query my karma points] The access service option property \"KarmaPointPlateau\" indicates the multiple of karma points for an individual that results in an external event being published - the default is 500. This means that when an individual gets to 500 karma points, and event is sent, and other event is sent when they get to 1000 karma points and so on. These events can be used to trigger additional recognition activities for the individuals concerned. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Retrieving my karma points"},{"location":"services/omas/community-profile/scenarios/retrieving-my-karma-points/#retrieving-my-karma-points","text":"If an individual has a Personal profile the Community Profile OMAS will reward him/her whenever they contribute to open metadata. These rewards are in the form of karma points . The Community Profile OMAS is responsible for maintaining the count of the karma points. It does this by listening to the metadata changes occurring in the metadata repositories and updates the personal profile of each user making a contribution. The Community Profile OMAS provides a method/operation to allow an individual to retrieve their current karma point total. [Using Java to query my karma points] [Using the REST API to query my karma points] The access service option property \"KarmaPointPlateau\" indicates the multiple of karma points for an individual that results in an external event being published - the default is 500. This means that when an individual gets to 500 karma points, and event is sent, and other event is sent when they get to 1000 karma points and so on. These events can be used to trigger additional recognition activities for the individuals concerned. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Retrieving my karma points"},{"location":"services/omas/community-profile/scenarios/retrieving-my-personal-profile/","text":"Retrieving my personal profile \u00b6 Every user accessing the open metadata ecosystem has a unique user identity (userId). This identity is used for authentication, authorization and auditing of activity related to open metadata and governance. Optionally a user identity can be associated with a personal profile . This provides information about the user behind the userId and aims to improve collaboration across the organization. There are two mechanisms for retrieving your personal profile: Retrieving your personal profile using Java Retrieving your personal profile using the REST API If you do not have a personal profile \u00b6 An organization can choose to load personal profiles automatically Alternatively, it can be left to the individual to create their own personal profile .","title":"Retrieving my personal profile"},{"location":"services/omas/community-profile/scenarios/retrieving-my-personal-profile/#retrieving-my-personal-profile","text":"Every user accessing the open metadata ecosystem has a unique user identity (userId). This identity is used for authentication, authorization and auditing of activity related to open metadata and governance. Optionally a user identity can be associated with a personal profile . This provides information about the user behind the userId and aims to improve collaboration across the organization. There are two mechanisms for retrieving your personal profile: Retrieving your personal profile using Java Retrieving your personal profile using the REST API","title":"Retrieving my personal profile"},{"location":"services/omas/community-profile/scenarios/retrieving-my-personal-profile/#if-you-do-not-have-a-personal-profile","text":"An organization can choose to load personal profiles automatically Alternatively, it can be left to the individual to create their own personal profile .","title":"If you do not have a personal profile"},{"location":"services/omas/community-profile/scenarios/sending-a-personal-message/","text":"Sending a personal message \u00b6 Link through to adding a comment or separate method?","title":"Sending a personal message"},{"location":"services/omas/community-profile/scenarios/sending-a-personal-message/#sending-a-personal-message","text":"Link through to adding a comment or separate method?","title":"Sending a personal message"},{"location":"services/omas/community-profile/scenarios/setting-up-my-personal-notes/","text":"Setting up my personal notes \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Setting up my personal notes"},{"location":"services/omas/community-profile/scenarios/setting-up-my-personal-notes/#setting-up-my-personal-notes","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Setting up my personal notes"},{"location":"services/omas/community-profile/scenarios/synchronizing-collaboration-activity/","text":"Synchronizing collaboration activity with another system \u00b6","title":"Synchronizing collaboration activity"},{"location":"services/omas/community-profile/scenarios/synchronizing-collaboration-activity/#synchronizing-collaboration-activity-with-another-system","text":"","title":"Synchronizing collaboration activity with another system"},{"location":"services/omas/community-profile/scenarios/synchronizing-departmental-structure/","text":"Synchronizing Departmental Structure \u00b6","title":"Synchronizing departmental structure"},{"location":"services/omas/community-profile/scenarios/synchronizing-departmental-structure/#synchronizing-departmental-structure","text":"","title":"Synchronizing Departmental Structure"},{"location":"services/omas/community-profile/scenarios/synchronizing-personal-profiles/","text":"Synchronizing updates to personal profiles from another system \u00b6","title":"Synchronizing personal profiles"},{"location":"services/omas/community-profile/scenarios/synchronizing-personal-profiles/#synchronizing-updates-to-personal-profiles-from-another-system","text":"","title":"Synchronizing updates to personal profiles from another system"},{"location":"services/omas/community-profile/scenarios/updating-a-comment/","text":"Updating a comment \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Updating a comment"},{"location":"services/omas/community-profile/scenarios/updating-a-comment/#updating-a-comment","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Updating a comment"},{"location":"services/omas/community-profile/scenarios/updating-a-personal-message/","text":"Updating a personal message \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Updating a personal message"},{"location":"services/omas/community-profile/scenarios/updating-a-personal-message/#updating-a-personal-message","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Updating a personal message"},{"location":"services/omas/community-profile/scenarios/updating-a-personal-note/","text":"Updating a personal note \u00b6","title":"Updating a personal note"},{"location":"services/omas/community-profile/scenarios/updating-a-personal-note/#updating-a-personal-note","text":"","title":"Updating a personal note"},{"location":"services/omas/community-profile/scenarios/updating-my-personal-profile/","text":"Updating my personal profile \u00b6 Include adding another userId to the profile See also \u00b6 Managing my contact details","title":"Updating my personal profile"},{"location":"services/omas/community-profile/scenarios/updating-my-personal-profile/#updating-my-personal-profile","text":"Include adding another userId to the profile","title":"Updating my personal profile"},{"location":"services/omas/community-profile/scenarios/updating-my-personal-profile/#see-also","text":"Managing my contact details","title":"See also"},{"location":"services/omas/community-profile/scenarios/updating-my-review/","text":"Updating my review \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Updating my review"},{"location":"services/omas/community-profile/scenarios/updating-my-review/#updating-my-review","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Updating my review"},{"location":"services/omas/community-profile/scenarios/viewing-leaders-of-a-team/","text":"Viewing leaders of a team \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Viewing leaders of a team"},{"location":"services/omas/community-profile/scenarios/viewing-leaders-of-a-team/#viewing-leaders-of-a-team","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Viewing leaders of a team"},{"location":"services/omas/community-profile/scenarios/viewing-members-of-a-team/","text":"Viewing members of a team \u00b6","title":"Viewing members of a team"},{"location":"services/omas/community-profile/scenarios/viewing-members-of-a-team/#viewing-members-of-a-team","text":"","title":"Viewing members of a team"},{"location":"services/omas/community-profile/scenarios/watching-a-community/","text":"Watching a community \u00b6 Add yourself as an observer. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Watching a community"},{"location":"services/omas/community-profile/scenarios/watching-a-community/#watching-a-community","text":"Add yourself as an observer. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Watching a community"},{"location":"services/omas/community-profile/user/","text":"Community Profile OMAS User Documentation \u00b6 The Community Profile OMAS is designed to cover many of the administrative tasks relating to managing information about people, teams and communities. Most of the interaction with the Community Profile OMAS will be driven by individuals. All users will be able to manage their personal profile and lists of favourite assets, projects and communities . All users will be able to manage any to dos that have been assigned to them. All users will be able to create a community and administer it. This includes managing members, the communities resources and the notifications sent to the members. All users can also query the communities and teams they are a member of. All users will be able to search for people, teams and communities. There is also support for an administrator to create and delete personal profiles as individuals join and leave the organization and also manage the organization's departmental structure. The assumption is that the organization already has at least one system that manages this information, and so Community Profile OMAS is designed to be integrated with existing systems in order to keep the profiles and departmental structure up-to-date. To understand more see: Configuring the Community Profile OMAS Using the Community Profile OMAS License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/community-profile/user/#community-profile-omas-user-documentation","text":"The Community Profile OMAS is designed to cover many of the administrative tasks relating to managing information about people, teams and communities. Most of the interaction with the Community Profile OMAS will be driven by individuals. All users will be able to manage their personal profile and lists of favourite assets, projects and communities . All users will be able to manage any to dos that have been assigned to them. All users will be able to create a community and administer it. This includes managing members, the communities resources and the notifications sent to the members. All users can also query the communities and teams they are a member of. All users will be able to search for people, teams and communities. There is also support for an administrator to create and delete personal profiles as individuals join and leave the organization and also manage the organization's departmental structure. The assumption is that the organization already has at least one system that manages this information, and so Community Profile OMAS is designed to be integrated with existing systems in order to keep the profiles and departmental structure up-to-date. To understand more see: Configuring the Community Profile OMAS Using the Community Profile OMAS License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Community Profile OMAS User Documentation"},{"location":"services/omas/data-engine/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Data Engine Open Metadata Access Service ( OMAS ) \u00b6 The Data Engine OMAS provides APIs and events for data movement/processing engines to record the changes made to the data landscape. It provides the ability to register the data engine itself along with the lineage details of the ETL transformations. Data Engine OMAS APIs offer support for creating the corresponding open metadata types for assets and jobs. The module structure for the Data Engine OMAS is as follows: data-engine-api supports the common Java classes that are used both by the client and the server. This includes the Java API, beans and REST API structures. data-engine-client supports the Java client library that allows applications and tools to call the remote REST APIs. data-engine-server supports the server side implementation of the access service. This includes the interaction with the administration services for registration, configuration, initialization and termination of the access service. interaction with the repository services to work with open metadata from the cohort . support for the access service's API and its related event management. data-engine-spring supports the REST API using the Spring libraries. Digging Deeper \u00b6 User Documentation Design Documentation","title":"Data Engine OMAS"},{"location":"services/omas/data-engine/#data-engine-open-metadata-access-service-omas","text":"The Data Engine OMAS provides APIs and events for data movement/processing engines to record the changes made to the data landscape. It provides the ability to register the data engine itself along with the lineage details of the ETL transformations. Data Engine OMAS APIs offer support for creating the corresponding open metadata types for assets and jobs. The module structure for the Data Engine OMAS is as follows: data-engine-api supports the common Java classes that are used both by the client and the server. This includes the Java API, beans and REST API structures. data-engine-client supports the Java client library that allows applications and tools to call the remote REST APIs. data-engine-server supports the server side implementation of the access service. This includes the interaction with the administration services for registration, configuration, initialization and termination of the access service. interaction with the repository services to work with open metadata from the cohort . support for the access service's API and its related event management. data-engine-spring supports the REST API using the Spring libraries.","title":"Data Engine Open Metadata Access Service (OMAS)"},{"location":"services/omas/data-engine/#digging-deeper","text":"User Documentation Design Documentation","title":"Digging Deeper"},{"location":"services/omas/data-engine/design/","text":"Data Engine OMAS Design \u00b6 The module structure for the Data Engine OMAS is as follows: data-engine-api supports the common Java classes that are used both by the client and the server. This includes the Java API, beans and REST API structures. data-engine-client supports the Java client library that allows applications and tools to call the remote REST APIs. data-engine-server supports the server side implementation of the access service.This includes the interaction with the administration services for registration, configuration, initialization and termination of the access service. interaction with the repository services to work with open metadata from the cohort . support for the access service's API and its related event management. data-engine-spring supports the REST API using the Spring libraries. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/data-engine/design/#data-engine-omas-design","text":"The module structure for the Data Engine OMAS is as follows: data-engine-api supports the common Java classes that are used both by the client and the server. This includes the Java API, beans and REST API structures. data-engine-client supports the Java client library that allows applications and tools to call the remote REST APIs. data-engine-server supports the server side implementation of the access service.This includes the interaction with the administration services for registration, configuration, initialization and termination of the access service. interaction with the repository services to work with open metadata from the cohort . support for the access service's API and its related event management. data-engine-spring supports the REST API using the Spring libraries. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Data Engine OMAS Design"},{"location":"services/omas/data-engine/samples/collections/","text":"Samples \u00b6 DataEngine-asset-endpoints.postman_collection.json \u00b6 This sample Postman collection illustrates DataEngine OMAS endpoints for creating/updating/deleting assets DataEngine-process-endpoints.postman_collection.json \u00b6 This sample Postman collection illustrates DataEngine OMAS endpoints for creating/updating/deleting processes DataEngineOMAS-local-graph-integration.postman_collection.json \u00b6 This sample Postman collection illustrate configuring and using the DataEngine OMAS with the Egeria graph repository. This script can be used to configure Egeria with Data Engine OMAS and the local graph repository. It can be used to run through a number of different tests of the REST endpoints that Data Engine OMAS exposes. Prerequisites: local-integration-tests.postman_environment.json - the environment used for running the tests locally Egeria by default uses https:// requests with a self-signed certificate. Any PostMan users therefore will need to go into settings->general and turn off 'SSL certificate verification' or requests will fail. Each step is sequentially numbered so that they can be executed in-order as part of a Postman \"Runner\", if desired. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/data-engine/samples/collections/#samples","text":"","title":"Samples"},{"location":"services/omas/data-engine/samples/collections/#dataengine-asset-endpointspostman_collectionjson","text":"This sample Postman collection illustrates DataEngine OMAS endpoints for creating/updating/deleting assets","title":"DataEngine-asset-endpoints.postman_collection.json"},{"location":"services/omas/data-engine/samples/collections/#dataengine-process-endpointspostman_collectionjson","text":"This sample Postman collection illustrates DataEngine OMAS endpoints for creating/updating/deleting processes","title":"DataEngine-process-endpoints.postman_collection.json"},{"location":"services/omas/data-engine/samples/collections/#dataengineomas-local-graph-integrationpostman_collectionjson","text":"This sample Postman collection illustrate configuring and using the DataEngine OMAS with the Egeria graph repository. This script can be used to configure Egeria with Data Engine OMAS and the local graph repository. It can be used to run through a number of different tests of the REST endpoints that Data Engine OMAS exposes. Prerequisites: local-integration-tests.postman_environment.json - the environment used for running the tests locally Egeria by default uses https:// requests with a self-signed certificate. Any PostMan users therefore will need to go into settings->general and turn off 'SSL certificate verification' or requests will fail. Each step is sequentially numbered so that they can be executed in-order as part of a Postman \"Runner\", if desired. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"DataEngineOMAS-local-graph-integration.postman_collection.json"},{"location":"services/omas/data-engine/samples/events/","text":"Samples \u00b6 DataEngine_upsert_events.txt - file with sample event types for upserting entities in Data Engine OMAS \u00b6 DataEngine_delete_events.txt - file with sample event types for deleting entities in Data Engine OMAS \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/data-engine/samples/events/#samples","text":"","title":"Samples"},{"location":"services/omas/data-engine/samples/events/#dataengine_upsert_eventstxt-file-with-sample-event-types-for-upserting-entities-in-data-engine-omas","text":"","title":"DataEngine_upsert_events.txt - file with sample event types for upserting entities in Data Engine OMAS"},{"location":"services/omas/data-engine/samples/events/#dataengine_delete_eventstxt-file-with-sample-event-types-for-deleting-entities-in-data-engine-omas","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"DataEngine_delete_events.txt - file with sample event types for deleting entities in Data Engine OMAS"},{"location":"services/omas/data-engine/scenarios/","text":"Using the Data Engine OMAS \u00b6 Below is the list of tasks supported by Data Engine OMAS. External Tool registration \u00b6 Typically the first action to take for an external tool is to register as a software-server-capability . External Tool lookup \u00b6 An external tool can lookup for the registered external tool. Create Schema Type \u00b6 Create Port Implementation with schema type \u00b6 Create Port Alias with delegation to a Port Implementation \u00b6 Create Process, with corresponding Port Aliases, Port Implementations and Schema Types \u00b6 Add lineage mappings to processes \u00b6 Create Database \u00b6 Create Relational Tables \u00b6 Create Data Files \u00b6 Delete Database \u00b6 Delete Relational Tables \u00b6 Delete Data Files \u00b6 Delete Connections \u00b6 Delete Endpoint \u00b6 Sample use case \u00b6 Initial load use case illustrates the integration between Data Engine OMAS and IBM's DataStage ETL tool. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/data-engine/scenarios/#using-the-data-engine-omas","text":"Below is the list of tasks supported by Data Engine OMAS.","title":"Using the Data Engine OMAS"},{"location":"services/omas/data-engine/scenarios/#external-tool-registration","text":"Typically the first action to take for an external tool is to register as a software-server-capability .","title":"External Tool registration"},{"location":"services/omas/data-engine/scenarios/#external-tool-lookup","text":"An external tool can lookup for the registered external tool.","title":"External Tool lookup"},{"location":"services/omas/data-engine/scenarios/#create-schema-type","text":"","title":"Create Schema Type"},{"location":"services/omas/data-engine/scenarios/#create-port-implementation-with-schema-type","text":"","title":"Create Port Implementation with schema type"},{"location":"services/omas/data-engine/scenarios/#create-port-alias-with-delegation-to-a-port-implementation","text":"","title":"Create Port Alias with delegation to a Port Implementation"},{"location":"services/omas/data-engine/scenarios/#create-process-with-corresponding-port-aliases-port-implementations-and-schema-types","text":"","title":"Create Process, with corresponding Port Aliases, Port Implementations and Schema Types"},{"location":"services/omas/data-engine/scenarios/#add-lineage-mappings-to-processes","text":"","title":"Add lineage mappings to processes"},{"location":"services/omas/data-engine/scenarios/#create-database","text":"","title":"Create Database"},{"location":"services/omas/data-engine/scenarios/#create-relational-tables","text":"","title":"Create Relational Tables"},{"location":"services/omas/data-engine/scenarios/#create-data-files","text":"","title":"Create Data Files"},{"location":"services/omas/data-engine/scenarios/#delete-database","text":"","title":"Delete Database"},{"location":"services/omas/data-engine/scenarios/#delete-relational-tables","text":"","title":"Delete Relational Tables"},{"location":"services/omas/data-engine/scenarios/#delete-data-files","text":"","title":"Delete Data Files"},{"location":"services/omas/data-engine/scenarios/#delete-connections","text":"","title":"Delete Connections"},{"location":"services/omas/data-engine/scenarios/#delete-endpoint","text":"","title":"Delete Endpoint"},{"location":"services/omas/data-engine/scenarios/#sample-use-case","text":"Initial load use case illustrates the integration between Data Engine OMAS and IBM's DataStage ETL tool. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Sample use case"},{"location":"services/omas/data-engine/scenarios/add-lineage-mappings/","text":"Add lineage mappings \u00b6 Add lineage mappings between schema types involved in a ETL transformation. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Add lineage mappings"},{"location":"services/omas/data-engine/scenarios/add-lineage-mappings/#add-lineage-mappings","text":"Add lineage mappings between schema types involved in a ETL transformation. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Add lineage mappings"},{"location":"services/omas/data-engine/scenarios/create-data-files/","text":"Create data files \u00b6 Create a data file with the associated schema, columns and folder hierarchy. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create data files"},{"location":"services/omas/data-engine/scenarios/create-data-files/#create-data-files","text":"Create a data file with the associated schema, columns and folder hierarchy. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create data files"},{"location":"services/omas/data-engine/scenarios/create-databases/","text":"Create processes \u00b6 Create a database with the associated schema type. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create databases"},{"location":"services/omas/data-engine/scenarios/create-databases/#create-processes","text":"Create a database with the associated schema type. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create processes"},{"location":"services/omas/data-engine/scenarios/create-port-aliases/","text":"Create port aliases \u00b6 Create a port alias with the delegated port implementation and the corresponding port delegation relationship. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create port aliases"},{"location":"services/omas/data-engine/scenarios/create-port-aliases/#create-port-aliases","text":"Create a port alias with the delegated port implementation and the corresponding port delegation relationship. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create port aliases"},{"location":"services/omas/data-engine/scenarios/create-port-implementations/","text":"Create port implementations \u00b6 Create a port implementation with the associated schema type and port schema relationship. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create port implementations"},{"location":"services/omas/data-engine/scenarios/create-port-implementations/#create-port-implementations","text":"Create a port implementation with the associated schema type and port schema relationship. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create port implementations"},{"location":"services/omas/data-engine/scenarios/create-processes/","text":"Create processes \u00b6 Create a process with the associated ports and process port relationships. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create processes"},{"location":"services/omas/data-engine/scenarios/create-processes/#create-processes","text":"Create a process with the associated ports and process port relationships. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create processes"},{"location":"services/omas/data-engine/scenarios/create-relational-tables/","text":"Create relational tables \u00b6 Create a relational table with the associated ports and process port relationships. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create relational tables"},{"location":"services/omas/data-engine/scenarios/create-relational-tables/#create-relational-tables","text":"Create a relational table with the associated ports and process port relationships. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create relational tables"},{"location":"services/omas/data-engine/scenarios/create-schema-types/","text":"Create schema types \u00b6 Create a schema type with all the schema attributes and relationships describing the columns involved in a transformation. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create schema types"},{"location":"services/omas/data-engine/scenarios/create-schema-types/#create-schema-types","text":"Create a schema type with all the schema attributes and relationships describing the columns involved in a transformation. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Create schema types"},{"location":"services/omas/data-engine/scenarios/delete-connections/","text":"Delete connections \u00b6 Delete a connection License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete connections"},{"location":"services/omas/data-engine/scenarios/delete-connections/#delete-connections","text":"Delete a connection License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete connections"},{"location":"services/omas/data-engine/scenarios/delete-data-files/","text":"Delete data files \u00b6 Delete a data file with all the schema attributes and relationships describing the columns. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete data files"},{"location":"services/omas/data-engine/scenarios/delete-data-files/#delete-data-files","text":"Delete a data file with all the schema attributes and relationships describing the columns. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete data files"},{"location":"services/omas/data-engine/scenarios/delete-databases/","text":"Delete databases \u00b6 Delete a database with all the tables attached License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete databases"},{"location":"services/omas/data-engine/scenarios/delete-databases/#delete-databases","text":"Delete a database with all the tables attached License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete databases"},{"location":"services/omas/data-engine/scenarios/delete-endpoints/","text":"Delete endpoints \u00b6 Delete an endpoint License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete endpoints"},{"location":"services/omas/data-engine/scenarios/delete-endpoints/#delete-endpoints","text":"Delete an endpoint License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete endpoints"},{"location":"services/omas/data-engine/scenarios/delete-port-aliases/","text":"Delete port aliases \u00b6 Delete a port alias with the corresponding port delegation relationship. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete port aliases"},{"location":"services/omas/data-engine/scenarios/delete-port-aliases/#delete-port-aliases","text":"Delete a port alias with the corresponding port delegation relationship. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete port aliases"},{"location":"services/omas/data-engine/scenarios/delete-port-implementations/","text":"Delete port implementations \u00b6 Delete a port implementation with the associated schema type and port schema relationship. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete port implementations"},{"location":"services/omas/data-engine/scenarios/delete-port-implementations/#delete-port-implementations","text":"Delete a port implementation with the associated schema type and port schema relationship. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete port implementations"},{"location":"services/omas/data-engine/scenarios/delete-processes/","text":"Delete processes \u00b6 Delete a process with the associated ports and process port relationships. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete processes"},{"location":"services/omas/data-engine/scenarios/delete-processes/#delete-processes","text":"Delete a process with the associated ports and process port relationships. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete processes"},{"location":"services/omas/data-engine/scenarios/delete-relational-tables/","text":"Delete relational tables \u00b6 Delete a relational table with all the schema attributes and relationships describing the columns. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete relational tables"},{"location":"services/omas/data-engine/scenarios/delete-relational-tables/#delete-relational-tables","text":"Delete a relational table with all the schema attributes and relationships describing the columns. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete relational tables"},{"location":"services/omas/data-engine/scenarios/delete-schema-types/","text":"Delete schema types \u00b6 Delete a schema type with all the schema attributes and relationships describing the columns. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete schema types"},{"location":"services/omas/data-engine/scenarios/delete-schema-types/#delete-schema-types","text":"Delete a schema type with all the schema attributes and relationships describing the columns. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Delete schema types"},{"location":"services/omas/data-engine/scenarios/initial-load-igc-data-stage/","text":"Initial load use case \u00b6 Initial load use case shows the integration between Data Engine OMAS and IBM Data Stage. The calls from assets sample collection describe the operations needed for creating the open metadata entities corresponding to the Data Stage ETL job. Note: Data Engine OMAS must have access to the IGC entities. Check egeria-connector-ibm-information-server for more details. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Initial load igc data stage"},{"location":"services/omas/data-engine/scenarios/initial-load-igc-data-stage/#initial-load-use-case","text":"Initial load use case shows the integration between Data Engine OMAS and IBM Data Stage. The calls from assets sample collection describe the operations needed for creating the open metadata entities corresponding to the Data Stage ETL job. Note: Data Engine OMAS must have access to the IGC entities. Check egeria-connector-ibm-information-server for more details. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Initial load use case"},{"location":"services/omas/data-engine/scenarios/lookup-registration-tool/","text":"Lookup an external tool \u00b6 An external tool can lookup for the software server capability entity created at registration step. Request to use is: lookup-external-tool License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Lookup registration tool"},{"location":"services/omas/data-engine/scenarios/lookup-registration-tool/#lookup-an-external-tool","text":"An external tool can lookup for the software server capability entity created at registration step. Request to use is: lookup-external-tool License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Lookup an external tool"},{"location":"services/omas/data-engine/scenarios/register-external-tool/","text":"Registering an external tool \u00b6 For an external tool to submit metadata to Data Engine OMAS it needs to first register. This implies creating a SoftwareServerCapability entity with the properties defining the external tool. Request to use is: register-external-tool License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Register external tool"},{"location":"services/omas/data-engine/scenarios/register-external-tool/#registering-an-external-tool","text":"For an external tool to submit metadata to Data Engine OMAS it needs to first register. This implies creating a SoftwareServerCapability entity with the properties defining the external tool. Request to use is: register-external-tool License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Registering an external tool"},{"location":"services/omas/data-engine/user/","text":"Data Engine OMAS User Documentation \u00b6 The Data Engine OMAS manages the creation of open metadata types for all the assets and jobs that are involved in ETL transformation. Data Engine OMAS offers a Java client and REST API for creating the job metadata. To understand more see: Configuring the Data Engine OMAS Using the Data Engine OMAS License: CC BY 4.0 ,ky Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/data-engine/user/#data-engine-omas-user-documentation","text":"The Data Engine OMAS manages the creation of open metadata types for all the assets and jobs that are involved in ETL transformation. Data Engine OMAS offers a Java client and REST API for creating the job metadata. To understand more see: Configuring the Data Engine OMAS Using the Data Engine OMAS License: CC BY 4.0 ,ky Copyright Contributors to the ODPi Egeria project.","title":"Data Engine OMAS User Documentation"},{"location":"services/omas/data-manager/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Data Manager Open Metadata Access Service ( OMAS ) \u00b6 The Data Manager OMAS provides APIs for technologies wishing to register new data assets, connections and related schema from data resources located in database servers, file systems, event brokers, API gateways and file managers and content managers. The caller of this interface may be the data manager itself, or an integration daemon if the data manager does not support open metadata directly. The integration daemon calls the Data Manager OMAS client through the following integration services . API Integrator OMIS for API Gateways Database Integrator OMIS for database managers Display Integrator OMIS for reports and forms Files Integrator OMIS for file systems and file managers Topic Integrator OMIS for event-based brokers and managers There are specific APIs for different types of data managers and assets. These reflect the terminology typically associated with the specific type of data manager to make it easier for people to map the Data Manager OMAS APIs and events to the actual technology. However, the specific implementation objects supported by these APIs all inherit from common open metadata types so it is possible to work with the resulting metadata in a technology agnostic manner using services such as the Asset Consumer OMAS . Basic metadata model \u00b6 Figure 1 shows the types of metadata captured by the Data Manager OMAS . Figure 1: Basic metadata capture by the Data Manager OMAS These are: Asset - Asset describes the data asset such as the data set, database schema, topic, API etc. Connection , Connector Type and Endpoint are used to create a connector to access the data in the data asset. Schema Element(s) describe the structure of the data managed by the data asset. To make it possible to search for particular types of asset, there are many specialized asset types defined in Egeria. The full list is shown here , however Data Manager OMAS supports the following subtypes of Asset (and any additional subtypes of these types that you wish to define yourself). DeployedAPI for API descriptions. Topic for topics supported by an event manager. DataFile for a file with sub types of: CSVFile for CSV files. AvroFile for files using the Avro format. JSONFile for files using the JSON format. Database for databases. DeployedDatabaseSchema for schemas within a database. DeployedReport for reports. Form for interactive forms. The Data Manager OMAS APIs needs to accommodate slight variations between different vendor implementations of data managers, along with information relating to local deployment standards. As such there is provision in these interfaces to support: VendorProperties for properties unique to a specific vendor implementation, and AdditionalProperties for properties that the metadata team wish to add to the metadata. Data Managers \u00b6 The Data Manager OMAS Supports the following types of data managers: Icon Name Provenance Description File System Local Cohort Create metadata elements for files and folders along with their data connections and any known schema information. Catalogued files and folders are members of the local cohort because many different types of processes may work with them. File Manager External Create metadata elements for files and folders along with their data connections and any known schema information. Catalogued files and folders are members of the data manager's metadata collection because it is responsible for their maintenance. Database Manager External Create metadata elements for databases, database schemas, tables, views, columns, primary keys and foreign keys. Catalogued elements are members of the data manager's metadata collection because it is responsible for their maintenance. Event Broker Local Cohort or External Create metadata elements for topics and the event payloads they support. Catalogued elements are members of the data manager's metadata collection (ie External provenance) if it is responsible for their maintenance. API Manager Local Cohort or External Create metadata elements for APIs and their supported headers and payloads. Catalogued elements are members of the data manager's metadata collection (ie External provenance) if it is responsible for their maintenance. More information \u00b6 What is an Asset? Building an asset catalog Modeling schema structures Design information \u00b6 The module structure for the Data Manager OMAS is as follows: data-manager-client supports the client library. data-manager-api supports the common Java classes that are used both by the client and the server. data-manager-server supports in implementation of the access service and its related event management. data-manager-spring supports the REST API using the Spring libraries. data-manager-topic-connectors supports the connectors used to access the OutTopic events from the Data Manager OMAS .","title":"Data Manager OMAS"},{"location":"services/omas/data-manager/#data-manager-open-metadata-access-service-omas","text":"The Data Manager OMAS provides APIs for technologies wishing to register new data assets, connections and related schema from data resources located in database servers, file systems, event brokers, API gateways and file managers and content managers. The caller of this interface may be the data manager itself, or an integration daemon if the data manager does not support open metadata directly. The integration daemon calls the Data Manager OMAS client through the following integration services . API Integrator OMIS for API Gateways Database Integrator OMIS for database managers Display Integrator OMIS for reports and forms Files Integrator OMIS for file systems and file managers Topic Integrator OMIS for event-based brokers and managers There are specific APIs for different types of data managers and assets. These reflect the terminology typically associated with the specific type of data manager to make it easier for people to map the Data Manager OMAS APIs and events to the actual technology. However, the specific implementation objects supported by these APIs all inherit from common open metadata types so it is possible to work with the resulting metadata in a technology agnostic manner using services such as the Asset Consumer OMAS .","title":"Data Manager Open Metadata Access Service (OMAS)"},{"location":"services/omas/data-manager/#basic-metadata-model","text":"Figure 1 shows the types of metadata captured by the Data Manager OMAS . Figure 1: Basic metadata capture by the Data Manager OMAS These are: Asset - Asset describes the data asset such as the data set, database schema, topic, API etc. Connection , Connector Type and Endpoint are used to create a connector to access the data in the data asset. Schema Element(s) describe the structure of the data managed by the data asset. To make it possible to search for particular types of asset, there are many specialized asset types defined in Egeria. The full list is shown here , however Data Manager OMAS supports the following subtypes of Asset (and any additional subtypes of these types that you wish to define yourself). DeployedAPI for API descriptions. Topic for topics supported by an event manager. DataFile for a file with sub types of: CSVFile for CSV files. AvroFile for files using the Avro format. JSONFile for files using the JSON format. Database for databases. DeployedDatabaseSchema for schemas within a database. DeployedReport for reports. Form for interactive forms. The Data Manager OMAS APIs needs to accommodate slight variations between different vendor implementations of data managers, along with information relating to local deployment standards. As such there is provision in these interfaces to support: VendorProperties for properties unique to a specific vendor implementation, and AdditionalProperties for properties that the metadata team wish to add to the metadata.","title":"Basic metadata model"},{"location":"services/omas/data-manager/#data-managers","text":"The Data Manager OMAS Supports the following types of data managers: Icon Name Provenance Description File System Local Cohort Create metadata elements for files and folders along with their data connections and any known schema information. Catalogued files and folders are members of the local cohort because many different types of processes may work with them. File Manager External Create metadata elements for files and folders along with their data connections and any known schema information. Catalogued files and folders are members of the data manager's metadata collection because it is responsible for their maintenance. Database Manager External Create metadata elements for databases, database schemas, tables, views, columns, primary keys and foreign keys. Catalogued elements are members of the data manager's metadata collection because it is responsible for their maintenance. Event Broker Local Cohort or External Create metadata elements for topics and the event payloads they support. Catalogued elements are members of the data manager's metadata collection (ie External provenance) if it is responsible for their maintenance. API Manager Local Cohort or External Create metadata elements for APIs and their supported headers and payloads. Catalogued elements are members of the data manager's metadata collection (ie External provenance) if it is responsible for their maintenance.","title":"Data Managers"},{"location":"services/omas/data-manager/#more-information","text":"What is an Asset? Building an asset catalog Modeling schema structures","title":"More information"},{"location":"services/omas/data-manager/#design-information","text":"The module structure for the Data Manager OMAS is as follows: data-manager-client supports the client library. data-manager-api supports the common Java classes that are used both by the client and the server. data-manager-server supports in implementation of the access service and its related event management. data-manager-spring supports the REST API using the Spring libraries. data-manager-topic-connectors supports the connectors used to access the OutTopic events from the Data Manager OMAS .","title":"Design information"},{"location":"services/omas/data-privacy/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Data Privacy Open Metadata Access Service (OMAS) \u00b6 The Data Privacy OMAS provides APIs and events for tools that supports the operational side of a data privacy program. This includes: Reviewing the regulations and governance requirements defined in the governance program that related to privacy. Maintaining the definitions for personal data. Retrieving information about the location and protection of personal data. Retrieving information about the digital services in order to assess their compliance to the data privacy program. Recording data processing impact assessments. Managing incidents relating to data privacy. The module structure for the Data Privacy OMAS is as follows: data-privacy-client supports the client libraries for different languages. data-privacy-api supports the common Java classes that are used both by the client and the server. data-privacy-server supports in implementation of the access service and its related event management. data-privacy-spring supports the REST API using the Spring libraries. Return to the access-services module. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Data Privacy OMAS"},{"location":"services/omas/data-privacy/#data-privacy-open-metadata-access-service-omas","text":"The Data Privacy OMAS provides APIs and events for tools that supports the operational side of a data privacy program. This includes: Reviewing the regulations and governance requirements defined in the governance program that related to privacy. Maintaining the definitions for personal data. Retrieving information about the location and protection of personal data. Retrieving information about the digital services in order to assess their compliance to the data privacy program. Recording data processing impact assessments. Managing incidents relating to data privacy. The module structure for the Data Privacy OMAS is as follows: data-privacy-client supports the client libraries for different languages. data-privacy-api supports the common Java classes that are used both by the client and the server. data-privacy-server supports in implementation of the access service and its related event management. data-privacy-spring supports the REST API using the Spring libraries. Return to the access-services module. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Data Privacy Open Metadata Access Service (OMAS)"},{"location":"services/omas/data-science/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Data Science Open Metadata Access Service ( OMAS ) \u00b6 The Data Science OMAS provides APIs and events for tools and applications focused on building all types of analytics models such as predictive models and machine learning models. It provides the ability to define the purpose and requirements for a model, along with lineage and audit information relating to the development and validation process associated with the model. It also supports the packaging of the model into software components for consumption by the Software Developer OMAS , Digital Architecture OMAS and DevOps OMAS since the models ultimately provide the implementation of software components that form part of the implementation of a digital service . Design \u00b6 The module structure for the Data Science OMAS is as follows: data-science-client supports the client library. data-science-api supports the common Java classes that are used both by the client and the server. data-science-server supports in implementation of the access service and its related event management. data-science-spring supports the REST API using the Spring libraries.","title":"Data Science OMAS"},{"location":"services/omas/data-science/#data-science-open-metadata-access-service-omas","text":"The Data Science OMAS provides APIs and events for tools and applications focused on building all types of analytics models such as predictive models and machine learning models. It provides the ability to define the purpose and requirements for a model, along with lineage and audit information relating to the development and validation process associated with the model. It also supports the packaging of the model into software components for consumption by the Software Developer OMAS , Digital Architecture OMAS and DevOps OMAS since the models ultimately provide the implementation of software components that form part of the implementation of a digital service .","title":"Data Science Open Metadata Access Service (OMAS)"},{"location":"services/omas/data-science/#design","text":"The module structure for the Data Science OMAS is as follows: data-science-client supports the client library. data-science-api supports the common Java classes that are used both by the client and the server. data-science-server supports in implementation of the access service and its related event management. data-science-spring supports the REST API using the Spring libraries.","title":"Design"},{"location":"services/omas/design-model/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Design Model Open Metadata Access Service ( OMAS ) \u00b6 The Design Model OMAS supports the management of design model intellectual property that has either been provided as standard or created in a software architecture and design modeling tool. The module structure for the Design Model OMAS is as follows: design-model-client supports the client library. design-model-api supports the common Java classes that are used both by the client and the server. design-model-server supports in implementation of the access service and its related event management. design-model-spring supports the REST API using the Spring libraries.","title":"Design Model OMAS"},{"location":"services/omas/design-model/#design-model-open-metadata-access-service-omas","text":"The Design Model OMAS supports the management of design model intellectual property that has either been provided as standard or created in a software architecture and design modeling tool. The module structure for the Design Model OMAS is as follows: design-model-client supports the client library. design-model-api supports the common Java classes that are used both by the client and the server. design-model-server supports in implementation of the access service and its related event management. design-model-spring supports the REST API using the Spring libraries.","title":"Design Model Open Metadata Access Service (OMAS)"},{"location":"services/omas/dev-ops/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. DevOps Open Metadata Access Service ( OMAS ) \u00b6 The DevOps OMAS provides APIs and events for tools that play a role in a DevOps pipeline. It enables these tools to query information about the assets it is deploying, the infrastructure options and any governance actions that need to be performed. The module structure for the DevOps OMAS is as follows: dev-ops-client supports the client library. dev-ops-api supports the common Java classes that are used both by the client and the server. dev-ops-server supports in implementation of the access service and its related event management. dev-ops-spring supports the REST API using the Spring libraries.","title":"DevOps OMAS"},{"location":"services/omas/dev-ops/#devops-open-metadata-access-service-omas","text":"The DevOps OMAS provides APIs and events for tools that play a role in a DevOps pipeline. It enables these tools to query information about the assets it is deploying, the infrastructure options and any governance actions that need to be performed. The module structure for the DevOps OMAS is as follows: dev-ops-client supports the client library. dev-ops-api supports the common Java classes that are used both by the client and the server. dev-ops-server supports in implementation of the access service and its related event management. dev-ops-spring supports the REST API using the Spring libraries.","title":"DevOps Open Metadata Access Service (OMAS)"},{"location":"services/omas/digital-architecture/","text":"Technical preview Technical preview function is in a state that it can be tried. The development is complete, there is documentation and there are samples, tutorials and hands-on labs as appropriate. The community is looking for feedback on the function before releasing it. This feedback may result in changes to the external interfaces. Digital Architecture Open Metadata Access Service ( OMAS ) \u00b6 The Digital Architecture OMAS provides APIs for tools and applications managing the design of data structures, software and the IT infrastructure that supports the operations of the organization. It is primarily supporting architects and their tools as they are setting up common definitions and standards that help to increase the consistency of the IT landscape. Further information is available below: User Documentation Design Documentation","title":"Digital Architecture OMAS"},{"location":"services/omas/digital-architecture/#digital-architecture-open-metadata-access-service-omas","text":"The Digital Architecture OMAS provides APIs for tools and applications managing the design of data structures, software and the IT infrastructure that supports the operations of the organization. It is primarily supporting architects and their tools as they are setting up common definitions and standards that help to increase the consistency of the IT landscape. Further information is available below: User Documentation Design Documentation","title":"Digital Architecture Open Metadata Access Service (OMAS)"},{"location":"services/omas/digital-architecture/design/","text":"Digital Architecture OMAS Design \u00b6 The module structure for the Digital Architecture OMAS follows the standard pattern as follows: digital-architecture-client supports the client library. digital-architecture-api supports the common Java classes that are used both by the client and the server. digital-architecture-server supports in implementation of the access service and its related event management. digital-architecture-spring supports the REST API using the Spring libraries. It makes use of the ocf-metadata-management for its server side interaction with the metadata repository and so the primary function of the Digital Architecture OMAS is to manage the APIs for the architects and translate between them and the Open Connector Framework (OCF) oriented interfaces of ocf-metadata-management. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/digital-architecture/design/#digital-architecture-omas-design","text":"The module structure for the Digital Architecture OMAS follows the standard pattern as follows: digital-architecture-client supports the client library. digital-architecture-api supports the common Java classes that are used both by the client and the server. digital-architecture-server supports in implementation of the access service and its related event management. digital-architecture-spring supports the REST API using the Spring libraries. It makes use of the ocf-metadata-management for its server side interaction with the metadata repository and so the primary function of the Digital Architecture OMAS is to manage the APIs for the architects and translate between them and the Open Connector Framework (OCF) oriented interfaces of ocf-metadata-management. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Digital Architecture OMAS Design"},{"location":"services/omas/digital-architecture/user/","text":"Digital Architecture OMAS User Documentation \u00b6 License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Index"},{"location":"services/omas/digital-architecture/user/#digital-architecture-omas-user-documentation","text":"License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Digital Architecture OMAS User Documentation"},{"location":"services/omas/digital-service/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Digital Service Open Metadata Access Service ( OMAS ) \u00b6 The Digital Service OMAS supports the business capability owners as they track the development and use of digital services that support the operation of the organization. Digital services are business services that are implemented in software. An example of a digital service is one that allows a customer to buy a product from the organization. Digital services are implemented using a variety of software components. These components are defined and deployed using the Software Developer OMAS and DevOps OMAS respectively. The Digital Service OMAS is responsible for: Recording the key business capabilities of the organization - with particular focus on those business capabilities involved in the business transformation. Assigning the owner of each business capability. Linking the business capability to the governance definitions defined by the governance program . For each business capability, defining the digital services that support it. Assigning ownership to each digital service. Supporting the owner of a digital service throughout the digital service's lifecycle. Supporting the business capability owners with the ability to review the status of the digital services within their business capability. Design \u00b6 The module structure for the Digital Service OMAS is as follows: digital-service-api supports the common Java classes that are used both by the client and the server. digital-service-client supports the client library. digital-service-server supports in implementation of the access service and its related event management. digital-service-spring supports the REST API using the Spring libraries.","title":"Digital Service OMAS"},{"location":"services/omas/digital-service/#digital-service-open-metadata-access-service-omas","text":"The Digital Service OMAS supports the business capability owners as they track the development and use of digital services that support the operation of the organization. Digital services are business services that are implemented in software. An example of a digital service is one that allows a customer to buy a product from the organization. Digital services are implemented using a variety of software components. These components are defined and deployed using the Software Developer OMAS and DevOps OMAS respectively. The Digital Service OMAS is responsible for: Recording the key business capabilities of the organization - with particular focus on those business capabilities involved in the business transformation. Assigning the owner of each business capability. Linking the business capability to the governance definitions defined by the governance program . For each business capability, defining the digital services that support it. Assigning ownership to each digital service. Supporting the owner of a digital service throughout the digital service's lifecycle. Supporting the business capability owners with the ability to review the status of the digital services within their business capability.","title":"Digital Service Open Metadata Access Service (OMAS)"},{"location":"services/omas/digital-service/#design","text":"The module structure for the Digital Service OMAS is as follows: digital-service-api supports the common Java classes that are used both by the client and the server. digital-service-client supports the client library. digital-service-server supports in implementation of the access service and its related event management. digital-service-spring supports the REST API using the Spring libraries.","title":"Design"},{"location":"services/omas/discovery-engine/","text":"Technical preview Technical preview function is in a state that it can be tried. The development is complete, there is documentation and there are samples, tutorials and hands-on labs as appropriate. The community is looking for feedback on the function before releasing it. This feedback may result in changes to the external interfaces. Discovery Engine Open Metadata Access Service ( OMAS ) \u00b6 The Discovery Engine OMAS provides APIs and events for metadata discovery tools that are surveying the data landscape and recording information in metadata repositories. These types of tools are called Discovery Engines in the Open Discovery Framework ( ODF ) , which is why this access service is called the Discovery Engine OMAS . The Open Discovery Framework ( ODF ) provides a comprehensive set of open APIs that describe the interaction between metadata discovery tools and a metadata server. The aim is to make it easy for metadata discovery tools to work with open metadata repositories. The capabilities defined in the ODF fall into 4 broad categories. The metadata server APIs - these are implemented by the Discovery Engine OMAS and include: Discovery configuration API - for configuring discovery engines and services - and also retrieving this configuration. Asset catalog API - for finding assets in the metadata repository. Asset store API - for retrieving a specific asset's metadata and connector. Annotation store API - for storing new metadata about the asset. The discovery services - these are the specialist plugin services that each perform a particular type of analysis. These are implemented by the metadata discovery tool (or interface with the discovery tool's APIs to drive specific types of analysis). The discovery engines - these manage the work of a collection of related discovery services. The discovery server - this hosts one or more discovery engines. It provides a REST API to request specific analysis on particular assets, monitor progress of the discovery services and review the results. In Egeria, the discovery server is implemented by the Asset Analysis OMES running in an engine host . Figure 1 shows how these capabilities work together. Figure 1: Interfaces of the Discovery Engine OMAS The engine host server retrieves configuration from the Governance Engine OMAS . When a discovery engine receives a request to analyse an asset, it retrieves the annotations from previous analysis of this asset. While the discovery service is running, it is writing new annotations about the asset through the Discovery Engine OMAS . More details of this processing follows. Discovery Engine Configuration \u00b6 The configuration of the discovery engines and the discovery services that they support are managed in the metadata server through the Governance Engine OMAS . The Engine Host OMAG Server is typically located close to the data assets to minimize the network traffic resulting from the analysis. Where the data assets are distributed in multiple locations, it is possible to deploy an Engine Host server in each location so the discovery workload is kept close to the data. A single Discovery Engine OMAS can support multiple engine hosts deployed in this way. The Asset Analysis OMES on the engine host server is configured with the location of the metadata server where the Discovery Engine OMAS is running along with the names of the discovery engines it will host. The same discovery engine can simultaneously run on multiple engine host servers. This means the Asset Analysis OMES can host all of the discovery engines it needs to analyse the assets at its location. When the Asset Analysis OMES starts in the engine host, it calls the Governance Engine OMAS to retrieve the configuration for each of its discovery engines (see Figure 1, number 1). It also connects to the Governance Engine OMAS 's out topic to receive any updates on this configuration while it is running. Within the discovery engine's configuration are the list of discovery request types it supports that are in turn each linked to the discovery service that should run when one of these discovery types is requested to be run against a specific asset. This is shown in figure 2. Figure 2: Discovery Engine Configuration Processing Discovery Requests \u00b6 When a discovery request is made, the discovery engine creates an instance of the discovery service and gives it access to a discovery context . The discovery context provides access to existing metadata known about the Asset, a connector to access the data stored in the asset and a store to record the new metadata it has discovered about the asset. Behind the scenes, the discovery context is calling the Discovery Engine OMAS to both retrieve metadata about the Asset and its connector (see Figure 1, number 2), and to store the new metadata (Figure 1, number 3). Further Information \u00b6 The Open Discovery Framework ( ODF ) provides more information about the discovery engines and discovery services along with the metadata APIs. In Egeria, both the metadata server where the Discovery Engine OMAS runs and the engine host whether the Asset Analysis OMES runs are types of OMAG Servers . More information on the operation of the engine host can be found under the Engine Services . An overview of automated metadata discovery approaches is available here . Design information \u00b6 The module structure for the Discovery Engine OMAS is as follows: discovery-engine-client supports the client library that is used by the discovery server (and the discovery engines and discovery services it hosts) to access the Discovery Engine OMAS 's REST API and out topic. discovery-engine-api supports the common Java classes that are used both by the client and the server. Since the Open Discovery Framework ( ODF ) defines most of the interfaces for the Discovery Engine OMAS , this module only needs to provide the interfaces associated with the out topic. discovery-engine-server supports in implementation of the metadata interfaces defined by the Open Discovery Framework ( ODF ) and its related event management. discovery-engine-spring supports the REST API using the Spring libraries. This module has no business logic associated with it. Each REST API endpoint delegates immediately to an equivalent function in the server module. It is, however, a useful place to look to get a view of the REST API supported by this OMAS .","title":"Discovery Engine OMAS"},{"location":"services/omas/discovery-engine/#discovery-engine-open-metadata-access-service-omas","text":"The Discovery Engine OMAS provides APIs and events for metadata discovery tools that are surveying the data landscape and recording information in metadata repositories. These types of tools are called Discovery Engines in the Open Discovery Framework ( ODF ) , which is why this access service is called the Discovery Engine OMAS . The Open Discovery Framework ( ODF ) provides a comprehensive set of open APIs that describe the interaction between metadata discovery tools and a metadata server. The aim is to make it easy for metadata discovery tools to work with open metadata repositories. The capabilities defined in the ODF fall into 4 broad categories. The metadata server APIs - these are implemented by the Discovery Engine OMAS and include: Discovery configuration API - for configuring discovery engines and services - and also retrieving this configuration. Asset catalog API - for finding assets in the metadata repository. Asset store API - for retrieving a specific asset's metadata and connector. Annotation store API - for storing new metadata about the asset. The discovery services - these are the specialist plugin services that each perform a particular type of analysis. These are implemented by the metadata discovery tool (or interface with the discovery tool's APIs to drive specific types of analysis). The discovery engines - these manage the work of a collection of related discovery services. The discovery server - this hosts one or more discovery engines. It provides a REST API to request specific analysis on particular assets, monitor progress of the discovery services and review the results. In Egeria, the discovery server is implemented by the Asset Analysis OMES running in an engine host . Figure 1 shows how these capabilities work together. Figure 1: Interfaces of the Discovery Engine OMAS The engine host server retrieves configuration from the Governance Engine OMAS . When a discovery engine receives a request to analyse an asset, it retrieves the annotations from previous analysis of this asset. While the discovery service is running, it is writing new annotations about the asset through the Discovery Engine OMAS . More details of this processing follows.","title":"Discovery Engine Open Metadata Access Service (OMAS)"},{"location":"services/omas/discovery-engine/#discovery-engine-configuration","text":"The configuration of the discovery engines and the discovery services that they support are managed in the metadata server through the Governance Engine OMAS . The Engine Host OMAG Server is typically located close to the data assets to minimize the network traffic resulting from the analysis. Where the data assets are distributed in multiple locations, it is possible to deploy an Engine Host server in each location so the discovery workload is kept close to the data. A single Discovery Engine OMAS can support multiple engine hosts deployed in this way. The Asset Analysis OMES on the engine host server is configured with the location of the metadata server where the Discovery Engine OMAS is running along with the names of the discovery engines it will host. The same discovery engine can simultaneously run on multiple engine host servers. This means the Asset Analysis OMES can host all of the discovery engines it needs to analyse the assets at its location. When the Asset Analysis OMES starts in the engine host, it calls the Governance Engine OMAS to retrieve the configuration for each of its discovery engines (see Figure 1, number 1). It also connects to the Governance Engine OMAS 's out topic to receive any updates on this configuration while it is running. Within the discovery engine's configuration are the list of discovery request types it supports that are in turn each linked to the discovery service that should run when one of these discovery types is requested to be run against a specific asset. This is shown in figure 2. Figure 2: Discovery Engine Configuration","title":"Discovery Engine Configuration"},{"location":"services/omas/discovery-engine/#processing-discovery-requests","text":"When a discovery request is made, the discovery engine creates an instance of the discovery service and gives it access to a discovery context . The discovery context provides access to existing metadata known about the Asset, a connector to access the data stored in the asset and a store to record the new metadata it has discovered about the asset. Behind the scenes, the discovery context is calling the Discovery Engine OMAS to both retrieve metadata about the Asset and its connector (see Figure 1, number 2), and to store the new metadata (Figure 1, number 3).","title":"Processing Discovery Requests"},{"location":"services/omas/discovery-engine/#further-information","text":"The Open Discovery Framework ( ODF ) provides more information about the discovery engines and discovery services along with the metadata APIs. In Egeria, both the metadata server where the Discovery Engine OMAS runs and the engine host whether the Asset Analysis OMES runs are types of OMAG Servers . More information on the operation of the engine host can be found under the Engine Services . An overview of automated metadata discovery approaches is available here .","title":"Further Information"},{"location":"services/omas/discovery-engine/#design-information","text":"The module structure for the Discovery Engine OMAS is as follows: discovery-engine-client supports the client library that is used by the discovery server (and the discovery engines and discovery services it hosts) to access the Discovery Engine OMAS 's REST API and out topic. discovery-engine-api supports the common Java classes that are used both by the client and the server. Since the Open Discovery Framework ( ODF ) defines most of the interfaces for the Discovery Engine OMAS , this module only needs to provide the interfaces associated with the out topic. discovery-engine-server supports in implementation of the metadata interfaces defined by the Open Discovery Framework ( ODF ) and its related event management. discovery-engine-spring supports the REST API using the Spring libraries. This module has no business logic associated with it. Each REST API endpoint delegates immediately to an equivalent function in the server module. It is, however, a useful place to look to get a view of the REST API supported by this OMAS .","title":"Design information"},{"location":"services/omas/governance-engine/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Governance Engine Open Metadata Access Service ( OMAS ) \u00b6 The Governance Engine OMAS supports the implementation of a governance program by providing the metadata services for running governance engines . A governance engine is a collection of related governance services that provide pluggable governance functions. The governance services are implemented as specialist connectors that are defined by: Open Discovery Framework ( ODF ) for Open Discovery Services that analyse the content of resources in the digital landscape. Governance Action Framework ( GAF ) of Governance Action Services that monitor, assess and maintain metadata. The governance services run in the Engine Host OMAG Server supported by the Open Metadata Engine Services ( OMES ) . The Governance Engine OMAS has the following capabilities: Creating the definitions for governance engines and their governance services . Providing the APIs and events that enable the Engine Host OMAG Server to retrieve the definitions of the governance engines and services and be notified of any changes to them. Creating the definitions for governance action processes that control the sequencing of governance actions . Providing APIs to create governance actions explicitly and incident reports . Initiation and choreography of governance actions based on the template provided by a governance actions process . Notification of new governance actions to the Engine Host OMAG Servers that then invoke the appropriate governance services to action them. Supporting the metadata requirements for many of the engine services . Linking the governance actions, governance action processes and governance services to the governance definitions supported by the Governance Program OMAS . Providing APIs to query the status of the governance capabilities implemented through the governance engines. Documentation \u00b6 Governance Engine OMAS has a User Guide that covers the Governance Engine OMAS 's APIs and events. The documentation for writing governance services is located: Open Discovery Framework ( ODF ) for Open Discovery Services. Governance Action Framework ( GAF ) for the Governance Action Services: Watchdog Governance Services, Triage Governance Services, Verification Governance Services, Remediation Governance Services and Provisioning Governance Services. Internals \u00b6 The module structure for the Governance Engine OMAS is as follows: governance-engine-client supports the client library. governance-engine-api supports the common Java classes that are used both by the client and the server. governance-engine-topic-connectors provides access to this modules In and Out Topics. governance-engine-server supports in implementation of the access service and its related event management. governance-engine-spring supports the REST API using the Spring libraries.","title":"Governance Engine OMAS"},{"location":"services/omas/governance-engine/#governance-engine-open-metadata-access-service-omas","text":"The Governance Engine OMAS supports the implementation of a governance program by providing the metadata services for running governance engines . A governance engine is a collection of related governance services that provide pluggable governance functions. The governance services are implemented as specialist connectors that are defined by: Open Discovery Framework ( ODF ) for Open Discovery Services that analyse the content of resources in the digital landscape. Governance Action Framework ( GAF ) of Governance Action Services that monitor, assess and maintain metadata. The governance services run in the Engine Host OMAG Server supported by the Open Metadata Engine Services ( OMES ) . The Governance Engine OMAS has the following capabilities: Creating the definitions for governance engines and their governance services . Providing the APIs and events that enable the Engine Host OMAG Server to retrieve the definitions of the governance engines and services and be notified of any changes to them. Creating the definitions for governance action processes that control the sequencing of governance actions . Providing APIs to create governance actions explicitly and incident reports . Initiation and choreography of governance actions based on the template provided by a governance actions process . Notification of new governance actions to the Engine Host OMAG Servers that then invoke the appropriate governance services to action them. Supporting the metadata requirements for many of the engine services . Linking the governance actions, governance action processes and governance services to the governance definitions supported by the Governance Program OMAS . Providing APIs to query the status of the governance capabilities implemented through the governance engines.","title":"Governance Engine Open Metadata Access Service (OMAS)"},{"location":"services/omas/governance-engine/#documentation","text":"Governance Engine OMAS has a User Guide that covers the Governance Engine OMAS 's APIs and events. The documentation for writing governance services is located: Open Discovery Framework ( ODF ) for Open Discovery Services. Governance Action Framework ( GAF ) for the Governance Action Services: Watchdog Governance Services, Triage Governance Services, Verification Governance Services, Remediation Governance Services and Provisioning Governance Services.","title":"Documentation"},{"location":"services/omas/governance-engine/#internals","text":"The module structure for the Governance Engine OMAS is as follows: governance-engine-client supports the client library. governance-engine-api supports the common Java classes that are used both by the client and the server. governance-engine-topic-connectors provides access to this modules In and Out Topics. governance-engine-server supports in implementation of the access service and its related event management. governance-engine-spring supports the REST API using the Spring libraries.","title":"Internals"},{"location":"services/omas/governance-engine/concepts/","text":"Governance Engine Open Metadata Access Service ( OMAS ) Concepts \u00b6 The concepts introduced by the Governance Engine OMAS are (in alphabetical order): Governance Action Governance Action Process Governance Action Type Governance Engine Governance Request Type Governance Service Incident Report","title":"Index"},{"location":"services/omas/governance-engine/concepts/#governance-engine-open-metadata-access-service-omas-concepts","text":"The concepts introduced by the Governance Engine OMAS are (in alphabetical order): Governance Action Governance Action Process Governance Action Type Governance Engine Governance Request Type Governance Service Incident Report","title":"Governance Engine Open Metadata Access Service (OMAS) Concepts"},{"location":"services/omas/governance-engine/concepts/governance-action-process/","text":"Governance Action Process \u00b6 A governance action process is a predefined sequence of governance actions that are coordinated by the Governance Engine OMAS . The steps in a governance action process are defined by linked governance action types . Each governance action type provides the specification of the governance action to run. The links between then show which guards cause the governance action to run. Details of how to set up governance action process is described in the Governance Engine OMAS User Guide . Open metadata types \u00b6 0462 Governance Action Types shows the structure of the incident report. It is a Referenceable so it can support comments and have governance actions linked to it. Further information \u00b6 The Open Metadata Engine Services ( OMES ) provide the mechanisms that support the different types of governance engines . These engines run the governance services that execute the governance actions defined by the governance action process.","title":"Governance action process"},{"location":"services/omas/governance-engine/concepts/governance-action-process/#governance-action-process","text":"A governance action process is a predefined sequence of governance actions that are coordinated by the Governance Engine OMAS . The steps in a governance action process are defined by linked governance action types . Each governance action type provides the specification of the governance action to run. The links between then show which guards cause the governance action to run. Details of how to set up governance action process is described in the Governance Engine OMAS User Guide .","title":"Governance Action Process"},{"location":"services/omas/governance-engine/concepts/governance-action-process/#open-metadata-types","text":"0462 Governance Action Types shows the structure of the incident report. It is a Referenceable so it can support comments and have governance actions linked to it.","title":"Open metadata types"},{"location":"services/omas/governance-engine/concepts/governance-action-process/#further-information","text":"The Open Metadata Engine Services ( OMES ) provide the mechanisms that support the different types of governance engines . These engines run the governance services that execute the governance actions defined by the governance action process.","title":"Further information"},{"location":"services/omas/governance-engine/concepts/governance-action-type/","text":"Governance Action Type \u00b6 A governance action type is a template for a governance action . A set of linked governance action types form the definition of a governance action process . Governance action types are defined through the Governance Engine OMAS and this OMAS also coordinates the create of a governance action from the governance action type as part of its execution of the governance action process. Open metadata type definition \u00b6 The governance action type is defined in the 0462 Governance Action Type model of the Open Metadata Types.","title":"Governance action type"},{"location":"services/omas/governance-engine/concepts/governance-action-type/#governance-action-type","text":"A governance action type is a template for a governance action . A set of linked governance action types form the definition of a governance action process . Governance action types are defined through the Governance Engine OMAS and this OMAS also coordinates the create of a governance action from the governance action type as part of its execution of the governance action process.","title":"Governance Action Type"},{"location":"services/omas/governance-engine/concepts/governance-action-type/#open-metadata-type-definition","text":"The governance action type is defined in the 0462 Governance Action Type model of the Open Metadata Types.","title":"Open metadata type definition"},{"location":"services/omas/governance-engine/concepts/governance-action/","text":"Governance Action \u00b6 A governance action describes a specific governance activity that needs to be performed on one or more metadata elements, or their counterparts in the digital landscape. A governance action is represented as a metadata entity in the open metadata repositories and linked to: The source (cause) of the governance action. The target elements that need to be acted upon. The governance engine that will run the governance service that implements the desired behavior. The governance action metadata entity is used to coordinate the desired activity in the governance engine, record its current state and act as a record of the activity for future audits. Governance actions can be created through the Governance Engine OMAS API . Some governance services (for example, the Watchdog Governance Action Service ) can create governance actions when they run. Governance services produce output strings called guards that indicate specific conditions or outcomes. These guards can be used to trigger new governance actions. Triggered governance actions are linked to their predecessor so it possible to trace through the governance actions that ran. The governance action process defines the flow of governance actions. It uses governance action types to build up a template of possible governance actions linked via the guards. When the process runs, its linked governance action types control the triggering of new governance actions. If the start date of the governance action is in the future, the Engine Host Services running in the same Engine Host OMAG Server as the nominated governance engine will schedule the governance service to run soon after the requested start date. If the start date is left blank, the requested governance service is run as soon as possible.","title":"Governance action"},{"location":"services/omas/governance-engine/concepts/governance-action/#governance-action","text":"A governance action describes a specific governance activity that needs to be performed on one or more metadata elements, or their counterparts in the digital landscape. A governance action is represented as a metadata entity in the open metadata repositories and linked to: The source (cause) of the governance action. The target elements that need to be acted upon. The governance engine that will run the governance service that implements the desired behavior. The governance action metadata entity is used to coordinate the desired activity in the governance engine, record its current state and act as a record of the activity for future audits. Governance actions can be created through the Governance Engine OMAS API . Some governance services (for example, the Watchdog Governance Action Service ) can create governance actions when they run. Governance services produce output strings called guards that indicate specific conditions or outcomes. These guards can be used to trigger new governance actions. Triggered governance actions are linked to their predecessor so it possible to trace through the governance actions that ran. The governance action process defines the flow of governance actions. It uses governance action types to build up a template of possible governance actions linked via the guards. When the process runs, its linked governance action types control the triggering of new governance actions. If the start date of the governance action is in the future, the Engine Host Services running in the same Engine Host OMAG Server as the nominated governance engine will schedule the governance service to run soon after the requested start date. If the start date is left blank, the requested governance service is run as soon as possible.","title":"Governance Action"},{"location":"services/omas/governance-engine/concepts/governance-engine/","text":"Governance Engine \u00b6 A governance engine is responsible for executing requests to a collection of related governance services . The implementation of a governance engine is handled by an Open Metadata Engine Service ( OMES ) running in an Engine Host OMAG Server. There is a specific engine service for each type of governance engine/service pair. Governance Engines \u00b6 Governance engines define a collection of related governance services. Governance services are specialized connectors that implement a single specialized governance activity. There are six types of governance service: Open Discovery Service for analysing the content of an Asset's real-world counterpart in the digital landscape. (For example, if the asset describes a file, the discovery service analyses the data stored in the file). Open Watchdog Service for monitoring changes to open metadata elements and when certain changes occur (such as the creation of a new Asset ) the watchdog service requests action from other governance services by creating either a Governance Action , a Governance Action Process or an Incident Report . Open Verification Service for testing the properties of specific open metadata elements to ensure they are set up correctly or do not indicate a situation where governance activity is required. The results returned from the verification service can be used to trigger other governance services as part of a Governance Action Process . Open Triage Service for making decisions on how to handle a specific situation or incident. Often this involves a human decision maker. Open Remediation Service for correcting errors in open metadata or the digital landscape it represents. Open Provisioning Service for configuring, enabling, provisioning resources in the digital landscape. Often these provisioning services manage the cataloguing of new assets and the lineage between them. There is a different Open Metadata Engine Service ( OMES ) depending on the type of governance service. The engine services support the specialist REST APIs and event handling needed for the specific type of governance service. Governance Service Engine Service Open Discovery Service Asset Analysis OMES Watchdog Governance Service Governance Action OMES Verification Governance Service Governance Action OMES Triage Governance Service Governance Action OMES Remediation Governance Service Governance Action OMES Provisioning Governance Service Governance Action OMES Each governance engine has a unique name. A governance engine definition for this unique name is created using the Governance Engine OMAS API . Figure 1 shows the structure of a governance engine definition. The open metadata types for this definition are in model 0461 - Governance Engines (see Governance Engine , GovernanceService linked by the SupportedGovernanceService relationship. Figure 1: The structure of a governance engine definition When a governance engine is called, it is passed a request type and request parameters. This is mapped to a call to a governance service . Return to Governance Engine OMAS Concepts Return to Governance Engine OMAS Overview","title":"Governance engine"},{"location":"services/omas/governance-engine/concepts/governance-engine/#governance-engine","text":"A governance engine is responsible for executing requests to a collection of related governance services . The implementation of a governance engine is handled by an Open Metadata Engine Service ( OMES ) running in an Engine Host OMAG Server. There is a specific engine service for each type of governance engine/service pair.","title":"Governance Engine"},{"location":"services/omas/governance-engine/concepts/governance-engine/#governance-engines","text":"Governance engines define a collection of related governance services. Governance services are specialized connectors that implement a single specialized governance activity. There are six types of governance service: Open Discovery Service for analysing the content of an Asset's real-world counterpart in the digital landscape. (For example, if the asset describes a file, the discovery service analyses the data stored in the file). Open Watchdog Service for monitoring changes to open metadata elements and when certain changes occur (such as the creation of a new Asset ) the watchdog service requests action from other governance services by creating either a Governance Action , a Governance Action Process or an Incident Report . Open Verification Service for testing the properties of specific open metadata elements to ensure they are set up correctly or do not indicate a situation where governance activity is required. The results returned from the verification service can be used to trigger other governance services as part of a Governance Action Process . Open Triage Service for making decisions on how to handle a specific situation or incident. Often this involves a human decision maker. Open Remediation Service for correcting errors in open metadata or the digital landscape it represents. Open Provisioning Service for configuring, enabling, provisioning resources in the digital landscape. Often these provisioning services manage the cataloguing of new assets and the lineage between them. There is a different Open Metadata Engine Service ( OMES ) depending on the type of governance service. The engine services support the specialist REST APIs and event handling needed for the specific type of governance service. Governance Service Engine Service Open Discovery Service Asset Analysis OMES Watchdog Governance Service Governance Action OMES Verification Governance Service Governance Action OMES Triage Governance Service Governance Action OMES Remediation Governance Service Governance Action OMES Provisioning Governance Service Governance Action OMES Each governance engine has a unique name. A governance engine definition for this unique name is created using the Governance Engine OMAS API . Figure 1 shows the structure of a governance engine definition. The open metadata types for this definition are in model 0461 - Governance Engines (see Governance Engine , GovernanceService linked by the SupportedGovernanceService relationship. Figure 1: The structure of a governance engine definition When a governance engine is called, it is passed a request type and request parameters. This is mapped to a call to a governance service . Return to Governance Engine OMAS Concepts Return to Governance Engine OMAS Overview","title":"Governance Engines"},{"location":"services/omas/governance-engine/concepts/governance-request-type/","text":"Governance Request Type \u00b6 The governance request type defines the descriptive name of a specific governance activity that the organization wishes to run. The request type is mapped to a governance service implementation along with request parameters to configure the behaviour of the service in a governance engine definition as shown in Figure 1. Figure 1: Governance request types as part of a governance engine definition Governance services are run by the Open Metadata Engine Services ( OMES ) in an Engine Host OMAG Server. The Engine Host Services called the Governance Engine OMAS They are used by the Governance Engines to determine which Governance Service to run. Related Information \u00b6 The Open Metadata Types model 0461 Governance Action Engines shows how the request type links the governance engine to the governance service via the SupportedGovernanceService relationship.","title":"Governance request type"},{"location":"services/omas/governance-engine/concepts/governance-request-type/#governance-request-type","text":"The governance request type defines the descriptive name of a specific governance activity that the organization wishes to run. The request type is mapped to a governance service implementation along with request parameters to configure the behaviour of the service in a governance engine definition as shown in Figure 1. Figure 1: Governance request types as part of a governance engine definition Governance services are run by the Open Metadata Engine Services ( OMES ) in an Engine Host OMAG Server. The Engine Host Services called the Governance Engine OMAS They are used by the Governance Engines to determine which Governance Service to run.","title":"Governance Request Type"},{"location":"services/omas/governance-engine/concepts/governance-request-type/#related-information","text":"The Open Metadata Types model 0461 Governance Action Engines shows how the request type links the governance engine to the governance service via the SupportedGovernanceService relationship.","title":"Related Information"},{"location":"services/omas/governance-engine/concepts/governance-service/","text":"Governance Service \u00b6 A governance service is a specialized connector that implements a specific governance activity. There are six types of governance services: Open Discovery Service for analysing the content of an Asset's real-world counterpart in the digital landscape. (For example, if the asset describes a file, the discovery service analyses the data stored in the file). Watchdog Governance Service for monitoring changes to open metadata elements and when certain changes occur (such as the creation of a new Asset ) the watchdog service requests action from other governance services by creating either a Governance Action , a Governance Action Process or an Incident Report . Verification Governance Service for testing the properties of specific open metadata elements to ensure they are set up correctly or do not indicate a situation where governance activity is required. The results returned from the verification service can be used to trigger other governance services as part of a Governance Action Process . Triage Governance Service for making decisions on how to handle a specific situation or incident. Often this involves a human decision maker. Remediation Governance Service for correcting errors in open metadata or the digital landscape it represents. Provisioning Governance Service for configuring, enabling, provisioning resources in the digital landscape. Often these provisioning services manage the cataloguing of new assets and the lineage between them. The Governance Action Open Metadata Engine Service ( OMES ) supports the execution of the governance action service. It supports the specialist REST APIs and event handling needed for the specific type of governance action service. Governance Service Engine Service Open Discovery Service Asset Analysis OMES Watchdog Governance Service Governance Action OMES Verification Governance Service Governance Action OMES Triage Governance Service Governance Action OMES Remediation Governance Service Governance Action OMES Provisioning Governance Service Governance Action OMES Support for implementing governance services \u00b6 The interface for the Open Discovery Service is defined by the Open Discovery Framework ( ODF ) and the rest are defined by the Governance Action Framework ( GAF ) . These frameworks provide the guidance to developers of new governance services. Support for running governance services \u00b6 Related governance services are configured together as a governance engine and they run in the appropriate Open Metadata Engine Service ( OMES ) . The Governance Engine OMAS provides: * The API to create governance engine definitions for the governance services. * The API to link governance services together into governance action processes . * The metadata support for the Engine Host Services to drive the governance services in an Engine Host OMAG Server.","title":"Governance service"},{"location":"services/omas/governance-engine/concepts/governance-service/#governance-service","text":"A governance service is a specialized connector that implements a specific governance activity. There are six types of governance services: Open Discovery Service for analysing the content of an Asset's real-world counterpart in the digital landscape. (For example, if the asset describes a file, the discovery service analyses the data stored in the file). Watchdog Governance Service for monitoring changes to open metadata elements and when certain changes occur (such as the creation of a new Asset ) the watchdog service requests action from other governance services by creating either a Governance Action , a Governance Action Process or an Incident Report . Verification Governance Service for testing the properties of specific open metadata elements to ensure they are set up correctly or do not indicate a situation where governance activity is required. The results returned from the verification service can be used to trigger other governance services as part of a Governance Action Process . Triage Governance Service for making decisions on how to handle a specific situation or incident. Often this involves a human decision maker. Remediation Governance Service for correcting errors in open metadata or the digital landscape it represents. Provisioning Governance Service for configuring, enabling, provisioning resources in the digital landscape. Often these provisioning services manage the cataloguing of new assets and the lineage between them. The Governance Action Open Metadata Engine Service ( OMES ) supports the execution of the governance action service. It supports the specialist REST APIs and event handling needed for the specific type of governance action service. Governance Service Engine Service Open Discovery Service Asset Analysis OMES Watchdog Governance Service Governance Action OMES Verification Governance Service Governance Action OMES Triage Governance Service Governance Action OMES Remediation Governance Service Governance Action OMES Provisioning Governance Service Governance Action OMES","title":"Governance Service"},{"location":"services/omas/governance-engine/concepts/governance-service/#support-for-implementing-governance-services","text":"The interface for the Open Discovery Service is defined by the Open Discovery Framework ( ODF ) and the rest are defined by the Governance Action Framework ( GAF ) . These frameworks provide the guidance to developers of new governance services.","title":"Support for implementing governance services"},{"location":"services/omas/governance-engine/concepts/governance-service/#support-for-running-governance-services","text":"Related governance services are configured together as a governance engine and they run in the appropriate Open Metadata Engine Service ( OMES ) . The Governance Engine OMAS provides: * The API to create governance engine definitions for the governance services. * The API to link governance services together into governance action processes . * The metadata support for the Engine Host Services to drive the governance services in an Engine Host OMAG Server.","title":"Support for running governance services"},{"location":"services/omas/governance-engine/concepts/incident-report/","text":"Incident Report \u00b6 An incident report provides a record of an error or situation that needs some governance action.","title":"Incident report"},{"location":"services/omas/governance-engine/concepts/incident-report/#incident-report","text":"An incident report provides a record of an error or situation that needs some governance action.","title":"Incident Report"},{"location":"services/omas/governance-engine/user/","text":"Governance Engine Open Metadata Access Service ( OMAS ) User Guide \u00b6 Defining Governance Engines and Governance Services \u00b6 Figure 1: Governance request types as part of a governance engine definition Defining Governance Action Processes \u00b6","title":"Index"},{"location":"services/omas/governance-engine/user/#governance-engine-open-metadata-access-service-omas-user-guide","text":"","title":"Governance Engine Open Metadata Access Service (OMAS) User Guide"},{"location":"services/omas/governance-engine/user/#defining-governance-engines-and-governance-services","text":"Figure 1: Governance request types as part of a governance engine definition","title":"Defining Governance Engines and Governance Services"},{"location":"services/omas/governance-engine/user/#defining-governance-action-processes","text":"","title":"Defining Governance Action Processes"},{"location":"services/omas/governance-program/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Governance Program Open Metadata Access Service ( OMAS ) \u00b6 The Governance Program OMAS provides APIs and events for tools and applications focused on defining a data strategy, planning support for a regulation and/or developing a governance program for the data landscape. It assumes an organization is operating an active governance program that is iteratively reviewed and developed. It covers: Understanding the business drivers and regulations that provide the motivation and direction to the governance program. Laying down the governance policies (principles, obligations and approaches) that frame the governance program. Planning and defining the governance controls that detail how these governance policies will be implemented in the organization, and enumerating the implications of these decisions and the expected outcomes. Defining the organization's roles and responsibilities that will support the governance program. Defining the classifications and governance zones that will organize the assets being governed. Defining the subject areas that will organize the data-oriented definitions such as glossary terms, valid values and quality rules. Reviewing the impact of the governance program. adjusting governance definitions and metrics as necessary. Reviewing the strategy, business and regulatory landscape. adjusting the governance definitions and metrics as necessary. Related OMASs \u00b6 The Community Profile OMAS supports the definition of the profiles for people and teams that will support the governance program. These are linked to the governance roles defined by the governance program. The Project Management OMAS supports the rollout of the governance program by commissioning campaigns and projects to implement the governance controls and the collection of measurements to assess the success of the program. The Digital Architecture OMAS provides the set up of the digital landscape that supports the governance program. This includes the definitions of the information supply chains and solution components that support the organization's activities. The Digital Service OMAS documents the business capabilities along with their digital services that are supported by the governance program. The Governance Engine OMAS supports the implementation of technical controls and the choreography of their execution. The Stewardship Action OMAS supports the stewards as they manage the exceptions detected to the governance program. The Data Privacy OMAS supports the operational aspects of managing privacy as part of the organization's activities. The Subject Area OMAS supports the definitions of the vocabularies associated with a subject area. The Data Manager OMAS support the automated cataloging of assets and configuration of technology that is managing them. The Security Manager OMAS support the configuration of technology that is managing the security of assets. The Security Officer OMAS support the definitions of users and groups and related definitions that make up the user directory. The Asset Manager OMAS supports the automated exchange of governance definitions between catalogs and asset managers to create a consistent rollout of governance requirements. The Asset Owner OMAS supports the linking of governance definitions and classifications to assets to define how they should be governed. The Asset Consumer OMAS supports the visibility of the governance definitions and classification by consumers of the assets. Design Information \u00b6 The Governance Program OMAS provides both a Java and a REST API for managing the definitions for a governance program. It has the following modules: governance-program-api defines the Java API and the common Java classes that are used both by the client and the server. governance-program-client supports the client library. This is used by tools that help organizations to plan and manage their governance program. governance-program-server supports in implementation of the access service and its related event management. governance-program-spring supports the REST API using the Spring libraries.","title":"Governance Program OMAS"},{"location":"services/omas/governance-program/#governance-program-open-metadata-access-service-omas","text":"The Governance Program OMAS provides APIs and events for tools and applications focused on defining a data strategy, planning support for a regulation and/or developing a governance program for the data landscape. It assumes an organization is operating an active governance program that is iteratively reviewed and developed. It covers: Understanding the business drivers and regulations that provide the motivation and direction to the governance program. Laying down the governance policies (principles, obligations and approaches) that frame the governance program. Planning and defining the governance controls that detail how these governance policies will be implemented in the organization, and enumerating the implications of these decisions and the expected outcomes. Defining the organization's roles and responsibilities that will support the governance program. Defining the classifications and governance zones that will organize the assets being governed. Defining the subject areas that will organize the data-oriented definitions such as glossary terms, valid values and quality rules. Reviewing the impact of the governance program. adjusting governance definitions and metrics as necessary. Reviewing the strategy, business and regulatory landscape. adjusting the governance definitions and metrics as necessary.","title":"Governance Program Open Metadata Access Service (OMAS)"},{"location":"services/omas/governance-program/#related-omass","text":"The Community Profile OMAS supports the definition of the profiles for people and teams that will support the governance program. These are linked to the governance roles defined by the governance program. The Project Management OMAS supports the rollout of the governance program by commissioning campaigns and projects to implement the governance controls and the collection of measurements to assess the success of the program. The Digital Architecture OMAS provides the set up of the digital landscape that supports the governance program. This includes the definitions of the information supply chains and solution components that support the organization's activities. The Digital Service OMAS documents the business capabilities along with their digital services that are supported by the governance program. The Governance Engine OMAS supports the implementation of technical controls and the choreography of their execution. The Stewardship Action OMAS supports the stewards as they manage the exceptions detected to the governance program. The Data Privacy OMAS supports the operational aspects of managing privacy as part of the organization's activities. The Subject Area OMAS supports the definitions of the vocabularies associated with a subject area. The Data Manager OMAS support the automated cataloging of assets and configuration of technology that is managing them. The Security Manager OMAS support the configuration of technology that is managing the security of assets. The Security Officer OMAS support the definitions of users and groups and related definitions that make up the user directory. The Asset Manager OMAS supports the automated exchange of governance definitions between catalogs and asset managers to create a consistent rollout of governance requirements. The Asset Owner OMAS supports the linking of governance definitions and classifications to assets to define how they should be governed. The Asset Consumer OMAS supports the visibility of the governance definitions and classification by consumers of the assets.","title":"Related OMASs"},{"location":"services/omas/governance-program/#design-information","text":"The Governance Program OMAS provides both a Java and a REST API for managing the definitions for a governance program. It has the following modules: governance-program-api defines the Java API and the common Java classes that are used both by the client and the server. governance-program-client supports the client library. This is used by tools that help organizations to plan and manage their governance program. governance-program-server supports in implementation of the access service and its related event management. governance-program-spring supports the REST API using the Spring libraries.","title":"Design Information"},{"location":"services/omas/it-infrastructure/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. IT Infrastructure Open Metadata Access Service ( OMAS ) \u00b6 The IT Infrastructure OMAS provides APIs for tools and applications managing the IT infrastructure that supports the data assets and software. It is typically used by the Infrastructure Integrator OMIS to capture metadata from deployment artifacts, or to generate deployment artifacts from open metadata. The other major use of IT Infrastructure OMAS is to manually catalog the key pieces of IT Infrastructure used by an organization. Often the creation of this metadata is used to kick of the automated cataloging of the capabilities and assets associated with the infrastructure. Basic Concepts \u00b6 At the base is the notion of a Host . This could be: * BareMetalComputer - traditional computer hardware or * VirtualMachine - a virtualized machine (such as VMWare or VirtualBox) that uses a hypervisor to virtualize machine hardware or * VirtualContainer - a software system using a container library to virtualize the operating system it uses or * HostCluster - a cluster of Hosts that are operating as a single operational environment (such as a Hadoop cluster or kubernetes cluster). Hosts are composable and reusable. For example, figure 1 shows a Virtual Container that is deployed to two Bare Metal Computers. The relationship between them is called HostedHost . Figure 1: A virtual container deployed to two bare metal computers Figure 2 shows an example of Host Cluster, such as a Hadoop Cluster, that manages multiple Hosts (Bare Metal Computers in this example). The relationship between the Host Cluster and each subordinate Host is HostClusterMember . The host cluster may not have all of its members active. The membership denotes the pool of resources that the cluster has to work with. Figure 2: A cluster of bare metal computers operating as single host A Host typically runs an operating system and may have various hardware characteristics of interest (such as byte ordering). Collectively this information is called the OperatingPlatform . The Operating Platform can be linked to many hosts through the HostOperatingPlatform relationship. This is shown in figure 2 and figure 3. It documents that these hosts are running the software identified by the operating platform. This is particularly useful if you using standard software stack builds that are deployed to multiple hosts since it is easy to see which hosts are at which levels of the software and to manage the rollout of upgrades to the stack. Figure 3: A collection of hosts using the same operating platform The SoftwarePackageManifest shown in figure 4 details the software stack for the operating platform. It is represented as a Collection linked to the operating platform using the OperatingPlatformManifest relationship. Figure 4: The software stack definition for an operating platform Linked to a Host via the SoftwareServerPlatformDeployment are the SoftwareServerPlatform s. They describe the running processes running on the Host that use software described in the Operating Platform. This is shown in figure 5. Figure 5: The software server platforms running on the host The SoftwareServerPlatform itself may run one or many SoftwareServers where a Software Server is a collection of SoftwareServerCapabilities that access the operating system through the software server platform. The Software Server Capabilities deliver the function of the server. They typically host/manage assets such as DataSets , DataStores and Processes that are linked to the Software Server Capability using the ServerAssetUse relationship. Some technologies are written as a single stack. This means there is a single Software Server for the Software Server Platform. Figure 6 shows the structure of the metadata elements for a technology - such as Apache Kafka or a Database Server - that is a single stack. Figure 6: The metadata elements to represent a single stack technology Figure 7 shows the representation of the stack of a platform that allows multiple servers to be configured. Egeria's OMAG Server Platform is an example of this type of technology. The Software Servers are OMAG Servers and the registered services: Open Metadata Access Services (OMASs), Open Metadata Engine Services (OMESs), Open Metadata Integration Services (OMISs) and Open Metadata View Services (OMVSs) are Software Server Capabilities of types: MetadataAccessService , EngineHostingService , MetadataIntegrationService and UserViewService respectively. Figure 7: The metadata elements to represent a configurable software server platform Software Server Capabilities \u00b6 There are many types of software server capability. The list below contains the Software Server Capabilities defined in the open metadata types. These are the software server capabilities defined in the open types: APIManager - A capability that manages callable APIs that typically delegate onto Software Services. Application - A capability supporting a specific business function. Catalog - A capability that manages collections of descriptions about people, places, digital assets, things, ... DataManager - A capability that manages collections of data. Engine - A programmable engine for running automated processes. Workflow Engine - An engine capable of running a mixture of human and automated tasks as part of a workflow process. Reporting Engine - An engine capable of creating reports by combining information from multiple data sets. Analytics Engine - An engine capable of running analytics models using data from one or more data sets. Data Movement Engine - An engine capable of copying data from one data store to another. Data Virtualization Engine - An engine capable of creating new data sets by dynamically combining data from one or more data stores or data sets. EventBroker - A capability that supports event-based services, typically around topics. Software Services - A capability that provides externally callable functions to other services. Application Service - A software service that supports a reusable business function. Metadata Integration Service - A software service that exchanges metadata between servers. Metadata Access Service - A software service that provides access to stored metadata. Engine Hosting Service - A software service that provides services that delegate to a hosted engine. User View Service - A software service that provides user interfaces access to digital resources. Network Gateway - A connection point enabling network traffic to pass between two networks. Database Manager - A capability that manages data organized as relational schemas. Enterprise Access Layer - Repository services for the Open Metadata Access Services ( OMAS ) supporting federated queries and aggregated events from the connected cohorts. Cohort Member - A capability enabling a server to access an open metadata repository cohort. Governance Engine - A collection of related governance services of the same type. Governance Action Engine - A collection of related governance services supporting the Governance Action Framework ( GAF ). Open Discovery Engine - A collection of related governance services supporting the Open Discovery Framework ( ODF ). In addition it is possible to augment software server capabilities with classifications. The following classifications are typically associated with the DataManager : Content Collection Manager - A manager of controlled documents and related media. File System - A capability that supports a store of files organized into a hierarchy of file folders for general use. File Manager - A manager of a collection of files and folders. The following are more generally applied. * Notification Manager - A server capability that is distributing events from a topic to its subscriber list. * Cloud Service - A capability enabled for a tenant on a cloud platform. Technology Examples \u00b6 Using the basic concepts described above, here are some examples of metadata for different types of technologies. Figure 8 shows the example of the software stack for Apache Kafka. Figure 8: The metadata elements to represent a Kafka Server Attachments and Classifications \u00b6 Locations Zones Ownership External References Infrastructure Managers \u00b6 When the IT Infrastructure OMAS is capturing metadata from deployment artifacts that are managed wholly by a specific technology or automated process, this technology should be catalogued as a SoftwareServerCapability and its guid and qualifiedName passed as the infrastructureManagerGUID and infrastructureManagerName parameters on the API. This will mark the metadata elements as managed by an external source which makes the metadata read-only to all but the caller responsible for cataloguing the artifact. Where Egeria is the primary catalog of the infrastructure metadata, or deployment artifacts that the metadata is derived from are either manually created or maintained by multiple process, the infrastructure manager identifiers are left blank so the resulting metadata elements are editable by any authorized caller. See Metadata Provenance for more information about the use of external source identifiers. Module Design \u00b6 The module structure for the IT Infrastructure OMAS is as follows: it-infrastructure-client supports the client library. it-infrastructure-api supports the common Java classes that are used both by the client and the server. it-infrastructure-server supports in implementation of the access service and its related event management. it-infrastructure-spring supports the REST API using the Spring libraries.","title":"IT Infrastructure OMAS"},{"location":"services/omas/it-infrastructure/#it-infrastructure-open-metadata-access-service-omas","text":"The IT Infrastructure OMAS provides APIs for tools and applications managing the IT infrastructure that supports the data assets and software. It is typically used by the Infrastructure Integrator OMIS to capture metadata from deployment artifacts, or to generate deployment artifacts from open metadata. The other major use of IT Infrastructure OMAS is to manually catalog the key pieces of IT Infrastructure used by an organization. Often the creation of this metadata is used to kick of the automated cataloging of the capabilities and assets associated with the infrastructure.","title":"IT Infrastructure Open Metadata Access Service (OMAS)"},{"location":"services/omas/it-infrastructure/#basic-concepts","text":"At the base is the notion of a Host . This could be: * BareMetalComputer - traditional computer hardware or * VirtualMachine - a virtualized machine (such as VMWare or VirtualBox) that uses a hypervisor to virtualize machine hardware or * VirtualContainer - a software system using a container library to virtualize the operating system it uses or * HostCluster - a cluster of Hosts that are operating as a single operational environment (such as a Hadoop cluster or kubernetes cluster). Hosts are composable and reusable. For example, figure 1 shows a Virtual Container that is deployed to two Bare Metal Computers. The relationship between them is called HostedHost . Figure 1: A virtual container deployed to two bare metal computers Figure 2 shows an example of Host Cluster, such as a Hadoop Cluster, that manages multiple Hosts (Bare Metal Computers in this example). The relationship between the Host Cluster and each subordinate Host is HostClusterMember . The host cluster may not have all of its members active. The membership denotes the pool of resources that the cluster has to work with. Figure 2: A cluster of bare metal computers operating as single host A Host typically runs an operating system and may have various hardware characteristics of interest (such as byte ordering). Collectively this information is called the OperatingPlatform . The Operating Platform can be linked to many hosts through the HostOperatingPlatform relationship. This is shown in figure 2 and figure 3. It documents that these hosts are running the software identified by the operating platform. This is particularly useful if you using standard software stack builds that are deployed to multiple hosts since it is easy to see which hosts are at which levels of the software and to manage the rollout of upgrades to the stack. Figure 3: A collection of hosts using the same operating platform The SoftwarePackageManifest shown in figure 4 details the software stack for the operating platform. It is represented as a Collection linked to the operating platform using the OperatingPlatformManifest relationship. Figure 4: The software stack definition for an operating platform Linked to a Host via the SoftwareServerPlatformDeployment are the SoftwareServerPlatform s. They describe the running processes running on the Host that use software described in the Operating Platform. This is shown in figure 5. Figure 5: The software server platforms running on the host The SoftwareServerPlatform itself may run one or many SoftwareServers where a Software Server is a collection of SoftwareServerCapabilities that access the operating system through the software server platform. The Software Server Capabilities deliver the function of the server. They typically host/manage assets such as DataSets , DataStores and Processes that are linked to the Software Server Capability using the ServerAssetUse relationship. Some technologies are written as a single stack. This means there is a single Software Server for the Software Server Platform. Figure 6 shows the structure of the metadata elements for a technology - such as Apache Kafka or a Database Server - that is a single stack. Figure 6: The metadata elements to represent a single stack technology Figure 7 shows the representation of the stack of a platform that allows multiple servers to be configured. Egeria's OMAG Server Platform is an example of this type of technology. The Software Servers are OMAG Servers and the registered services: Open Metadata Access Services (OMASs), Open Metadata Engine Services (OMESs), Open Metadata Integration Services (OMISs) and Open Metadata View Services (OMVSs) are Software Server Capabilities of types: MetadataAccessService , EngineHostingService , MetadataIntegrationService and UserViewService respectively. Figure 7: The metadata elements to represent a configurable software server platform","title":"Basic Concepts"},{"location":"services/omas/it-infrastructure/#software-server-capabilities","text":"There are many types of software server capability. The list below contains the Software Server Capabilities defined in the open metadata types. These are the software server capabilities defined in the open types: APIManager - A capability that manages callable APIs that typically delegate onto Software Services. Application - A capability supporting a specific business function. Catalog - A capability that manages collections of descriptions about people, places, digital assets, things, ... DataManager - A capability that manages collections of data. Engine - A programmable engine for running automated processes. Workflow Engine - An engine capable of running a mixture of human and automated tasks as part of a workflow process. Reporting Engine - An engine capable of creating reports by combining information from multiple data sets. Analytics Engine - An engine capable of running analytics models using data from one or more data sets. Data Movement Engine - An engine capable of copying data from one data store to another. Data Virtualization Engine - An engine capable of creating new data sets by dynamically combining data from one or more data stores or data sets. EventBroker - A capability that supports event-based services, typically around topics. Software Services - A capability that provides externally callable functions to other services. Application Service - A software service that supports a reusable business function. Metadata Integration Service - A software service that exchanges metadata between servers. Metadata Access Service - A software service that provides access to stored metadata. Engine Hosting Service - A software service that provides services that delegate to a hosted engine. User View Service - A software service that provides user interfaces access to digital resources. Network Gateway - A connection point enabling network traffic to pass between two networks. Database Manager - A capability that manages data organized as relational schemas. Enterprise Access Layer - Repository services for the Open Metadata Access Services ( OMAS ) supporting federated queries and aggregated events from the connected cohorts. Cohort Member - A capability enabling a server to access an open metadata repository cohort. Governance Engine - A collection of related governance services of the same type. Governance Action Engine - A collection of related governance services supporting the Governance Action Framework ( GAF ). Open Discovery Engine - A collection of related governance services supporting the Open Discovery Framework ( ODF ). In addition it is possible to augment software server capabilities with classifications. The following classifications are typically associated with the DataManager : Content Collection Manager - A manager of controlled documents and related media. File System - A capability that supports a store of files organized into a hierarchy of file folders for general use. File Manager - A manager of a collection of files and folders. The following are more generally applied. * Notification Manager - A server capability that is distributing events from a topic to its subscriber list. * Cloud Service - A capability enabled for a tenant on a cloud platform.","title":"Software Server Capabilities"},{"location":"services/omas/it-infrastructure/#technology-examples","text":"Using the basic concepts described above, here are some examples of metadata for different types of technologies. Figure 8 shows the example of the software stack for Apache Kafka. Figure 8: The metadata elements to represent a Kafka Server","title":"Technology Examples"},{"location":"services/omas/it-infrastructure/#attachments-and-classifications","text":"Locations Zones Ownership External References","title":"Attachments and Classifications"},{"location":"services/omas/it-infrastructure/#infrastructure-managers","text":"When the IT Infrastructure OMAS is capturing metadata from deployment artifacts that are managed wholly by a specific technology or automated process, this technology should be catalogued as a SoftwareServerCapability and its guid and qualifiedName passed as the infrastructureManagerGUID and infrastructureManagerName parameters on the API. This will mark the metadata elements as managed by an external source which makes the metadata read-only to all but the caller responsible for cataloguing the artifact. Where Egeria is the primary catalog of the infrastructure metadata, or deployment artifacts that the metadata is derived from are either manually created or maintained by multiple process, the infrastructure manager identifiers are left blank so the resulting metadata elements are editable by any authorized caller. See Metadata Provenance for more information about the use of external source identifiers.","title":"Infrastructure Managers"},{"location":"services/omas/it-infrastructure/#module-design","text":"The module structure for the IT Infrastructure OMAS is as follows: it-infrastructure-client supports the client library. it-infrastructure-api supports the common Java classes that are used both by the client and the server. it-infrastructure-server supports in implementation of the access service and its related event management. it-infrastructure-spring supports the REST API using the Spring libraries.","title":"Module Design"},{"location":"services/omas/project-management/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Project Management Open Metadata Access Service ( OMAS ) \u00b6 The Project Management OMAS provides APIs and events for tools and applications that support project leaders - particularly those who are leading governance projects. The interface support the setting up, management and completion of projects along with the teams that are working on them. It is aimed at linking the projects and tasks associated with the rollout and management of capability used to govern the organization's digital landscape and the people who use it. The module structure for the Project Management OMAS is as follows: project-management-client supports the client library. project-management-api supports the common Java classes that are used both by the client and the server. project-management-server supports in implementation of the access service and its related event management. project-management-spring supports the REST API using the Spring libraries.","title":"Project Management OMAS"},{"location":"services/omas/project-management/#project-management-open-metadata-access-service-omas","text":"The Project Management OMAS provides APIs and events for tools and applications that support project leaders - particularly those who are leading governance projects. The interface support the setting up, management and completion of projects along with the teams that are working on them. It is aimed at linking the projects and tasks associated with the rollout and management of capability used to govern the organization's digital landscape and the people who use it. The module structure for the Project Management OMAS is as follows: project-management-client supports the client library. project-management-api supports the common Java classes that are used both by the client and the server. project-management-server supports in implementation of the access service and its related event management. project-management-spring supports the REST API using the Spring libraries.","title":"Project Management Open Metadata Access Service (OMAS)"},{"location":"services/omas/security-manager/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Security Manager Open Metadata Access Service ( OMAS ) \u00b6 The Security Manager OMAS provides APIs for technologies wishing to register new data assets, connections and related schema from data resources located in database servers, file systems, file managers and content managers. The caller of this interface may be the security manager itself, or an integration daemon if the security manager does not support open metadata directly. There are specific APIs for different types of security managers and assets. These reflect the terminology typically associated with the specific type of security manager to make it easier for people to map the Security Manager OMAS APIs and events to the actual technology. However, the specific implementation objects supported by these APIs all inherit from common open metadata types so it is possible to work with the resulting metadata in a technology agnostic manner using services such as the Asset Consumer OMAS . The Security Manager OMAS APIs needs to accommodate slight variations between different vendor implementations of security managers, along with information relating to local deployment standards. As such there is provision in these interfaces to support: VendorProperties for properties unique to a specific vendor implementation, and AdditionalProperties for properties that the metadata team wish to add to the metadata. The module structure for the Security Manager OMAS is as follows: security-manager-client supports the client library. security-manager-api supports the common Java classes that are used both by the client and the server. security-manager-server supports in implementation of the access service and its related event management. security-manager-spring supports the REST API using the Spring libraries. security-manager-topic-connectors supports the connectors used to access the InTopic and OutTopic events from the Security Manager OMAS .","title":"Security Manager OMAS"},{"location":"services/omas/security-manager/#security-manager-open-metadata-access-service-omas","text":"The Security Manager OMAS provides APIs for technologies wishing to register new data assets, connections and related schema from data resources located in database servers, file systems, file managers and content managers. The caller of this interface may be the security manager itself, or an integration daemon if the security manager does not support open metadata directly. There are specific APIs for different types of security managers and assets. These reflect the terminology typically associated with the specific type of security manager to make it easier for people to map the Security Manager OMAS APIs and events to the actual technology. However, the specific implementation objects supported by these APIs all inherit from common open metadata types so it is possible to work with the resulting metadata in a technology agnostic manner using services such as the Asset Consumer OMAS . The Security Manager OMAS APIs needs to accommodate slight variations between different vendor implementations of security managers, along with information relating to local deployment standards. As such there is provision in these interfaces to support: VendorProperties for properties unique to a specific vendor implementation, and AdditionalProperties for properties that the metadata team wish to add to the metadata. The module structure for the Security Manager OMAS is as follows: security-manager-client supports the client library. security-manager-api supports the common Java classes that are used both by the client and the server. security-manager-server supports in implementation of the access service and its related event management. security-manager-spring supports the REST API using the Spring libraries. security-manager-topic-connectors supports the connectors used to access the InTopic and OutTopic events from the Security Manager OMAS .","title":"Security Manager Open Metadata Access Service (OMAS)"},{"location":"services/omas/security-officer/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Security Officer Open Metadata Access Service ( OMAS ) \u00b6 The Security Officer Open Metadata Access Service ( OMAS ) provides access to metadata for policy enforcement frameworks such as Apache Ranger. This API simplifies the internal models and structures of the open metadata type model and related structure for the consumers. As an example, Apache Ranger needs to know how a particular entity is classified so that the classification can be used within a policy (rule). The Open Metadata Types define a complex graph-oriented model, within which classifications can be multi level - for example a column may be classified as employee_salary whilst employee_salary itself may be classified as SPI . Ranger however just needs to know that the column is SPI, not how we got there. So we convert this complex model into something much more operationally-focused in the form of SecurityTags and deliver that over the API. The implementation will follow this graph, and build up a list of all tags that are appropriate to use. Note that in the case of Ranger it is actually the tagsync process that will call the Governance Engine OMAS for this classification information Ranger can do this today, but via a large number of individual requests to retrieve types and entities. Rather than these lower level queries to the metadata repository services, the Security Officer OMAS offers result sets to make queries more efficient, and more appropriate notifications. More details on Apache Ranger's Tag Propagation Process is found in the docs directory by following the link. Internals \u00b6 The module structure for the Security Officer OMAS is as follows: security-officer-api supports the common Java classes that are used both by the client and the server. security-officer-topic-connectors supports the common Java classes that are used both by the client and the server. security-officer-client supports the client library. security-officer-server supports in implementation of the access service and its related event management. security-officer-spring supports the REST API using the Spring libraries.","title":"Security Officer OMAS"},{"location":"services/omas/security-officer/#security-officer-open-metadata-access-service-omas","text":"The Security Officer Open Metadata Access Service ( OMAS ) provides access to metadata for policy enforcement frameworks such as Apache Ranger. This API simplifies the internal models and structures of the open metadata type model and related structure for the consumers. As an example, Apache Ranger needs to know how a particular entity is classified so that the classification can be used within a policy (rule). The Open Metadata Types define a complex graph-oriented model, within which classifications can be multi level - for example a column may be classified as employee_salary whilst employee_salary itself may be classified as SPI . Ranger however just needs to know that the column is SPI, not how we got there. So we convert this complex model into something much more operationally-focused in the form of SecurityTags and deliver that over the API. The implementation will follow this graph, and build up a list of all tags that are appropriate to use. Note that in the case of Ranger it is actually the tagsync process that will call the Governance Engine OMAS for this classification information Ranger can do this today, but via a large number of individual requests to retrieve types and entities. Rather than these lower level queries to the metadata repository services, the Security Officer OMAS offers result sets to make queries more efficient, and more appropriate notifications. More details on Apache Ranger's Tag Propagation Process is found in the docs directory by following the link.","title":"Security Officer Open Metadata Access Service (OMAS)"},{"location":"services/omas/security-officer/#internals","text":"The module structure for the Security Officer OMAS is as follows: security-officer-api supports the common Java classes that are used both by the client and the server. security-officer-topic-connectors supports the common Java classes that are used both by the client and the server. security-officer-client supports the client library. security-officer-server supports in implementation of the access service and its related event management. security-officer-spring supports the REST API using the Spring libraries.","title":"Internals"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/","text":"Tag Propagation \u00b6 Introduction \u00b6 This document aims to explain how tag propagation will be handled within Governance Engine OMAS. The terms tag and classification should be treated interchangeably.... Tag propagation is the process by which we figure out which classifications should apply to a particular asset. For example a classification may be associated directly with an asset, or instead an asset may be associated with a business term that itself is classified. We also have to resolve conflicts. A series of scenarios will be presented. Scenarios \u00b6 Direct Classification \u00b6 The Asset (EmpSal) is classified as Sensitive This is a direct classification, exactly once, - there is nothing to resolve This classification will be exposed via GE-omas against the EmpSal resource Direct Multiple Classification \u00b6 The Asset (EmpSal) is classified as Sensitive and TopSecret. This is invalid - there should only be a single governance classification applied. No attempt will be made to reconcile these multiple classifications - ie to determine which should take precedence, which is most restrictive, are they the same etc. instead as this is an error, the asset will not be exposed at GE-omas at all. An Audit log entry will be created reporting the error. Classification via Business Term \u00b6 The EmpSal asset is assigned the business term 'EmployeeSalary' which gives it meaning. This business term is classified as Sensitive, so the resultant classification for EmpSal is Sensitive Classification via Business Term and Directly \u00b6 The EmpSal asset is assigned the business term 'EmployeeSalary' which gives it meaning. This business term is classified as Sensitive However the asset is also classified as Top Secret Since this has narrower scope, and as long as it is the only direct classification, this will be used So the resultant classification here is TopSecret. Classification via multiple business terms \u00b6 The Asset (EmpSal) is assigned the two business terms EmployeeBonus & EmployeeSalary This is invalid - there should only be a single business term applied. No attempt will be made to reconcile these multiple terms, or their classifications - ie to determine which should take precedence, which is most restrictive, are they the same etc. instead as this is an error, the asset will not be exposed at GE-omas at all. An Audit log entry will be created reporting the error. Reference material \u00b6 Cary Workshop \u00b6 In November 2018 design meetings in Cary came up with the following diagrams, which hopefully have been explained and the points addressed in this document. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"TagPropogation"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#tag-propagation","text":"","title":"Tag Propagation"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#introduction","text":"This document aims to explain how tag propagation will be handled within Governance Engine OMAS. The terms tag and classification should be treated interchangeably.... Tag propagation is the process by which we figure out which classifications should apply to a particular asset. For example a classification may be associated directly with an asset, or instead an asset may be associated with a business term that itself is classified. We also have to resolve conflicts. A series of scenarios will be presented.","title":"Introduction"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#scenarios","text":"","title":"Scenarios"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#direct-classification","text":"The Asset (EmpSal) is classified as Sensitive This is a direct classification, exactly once, - there is nothing to resolve This classification will be exposed via GE-omas against the EmpSal resource","title":"Direct Classification"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#direct-multiple-classification","text":"The Asset (EmpSal) is classified as Sensitive and TopSecret. This is invalid - there should only be a single governance classification applied. No attempt will be made to reconcile these multiple classifications - ie to determine which should take precedence, which is most restrictive, are they the same etc. instead as this is an error, the asset will not be exposed at GE-omas at all. An Audit log entry will be created reporting the error.","title":"Direct Multiple Classification"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#classification-via-business-term","text":"The EmpSal asset is assigned the business term 'EmployeeSalary' which gives it meaning. This business term is classified as Sensitive, so the resultant classification for EmpSal is Sensitive","title":"Classification via Business Term"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#classification-via-business-term-and-directly","text":"The EmpSal asset is assigned the business term 'EmployeeSalary' which gives it meaning. This business term is classified as Sensitive However the asset is also classified as Top Secret Since this has narrower scope, and as long as it is the only direct classification, this will be used So the resultant classification here is TopSecret.","title":"Classification via Business Term and Directly"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#classification-via-multiple-business-terms","text":"The Asset (EmpSal) is assigned the two business terms EmployeeBonus & EmployeeSalary This is invalid - there should only be a single business term applied. No attempt will be made to reconcile these multiple terms, or their classifications - ie to determine which should take precedence, which is most restrictive, are they the same etc. instead as this is an error, the asset will not be exposed at GE-omas at all. An Audit log entry will be created reporting the error.","title":"Classification via multiple business terms"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#reference-material","text":"","title":"Reference material"},{"location":"services/omas/security-officer/TagPropogation/TagPropogation/#cary-workshop","text":"In November 2018 design meetings in Cary came up with the following diagrams, which hopefully have been explained and the points addressed in this document. License: CC BY 4.0 , Copyright Contributors to the ODPi Egeria project.","title":"Cary Workshop"},{"location":"services/omas/software-developer/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Software Developer Open Metadata Access Service ( OMAS ) \u00b6 The Software Developer OMAS provides APIs and events for software developer tools and applications that help developers make good use of the standards and best practices defined for the data landscape. It supports the documentation of the component structure of a software capability and the ability to link it to the digital services it supports for the business. As the software developer works on the implementation, the Software Developer OMAS supports APIs to search for data structure implementation snippets based on search criteria such as glossary terms and/or language. It also provides information about the most appropriate data sources to use for particular situations along with details of reference data values and sets. Using these services augments the software component model for the software capability. Finally it enables the documentation of the packaging as the components are moved into the DevOps Pipeline . Design \u00b6 The module structure for the Software Developer OMAS is as follows: software-developer-client supports the client library. software-developer-api supports the common Java classes that are used both by the client and the server. software-developer-server supports in implementation of the access service and its related event management. software-developer-spring supports the REST API using the Spring libraries.","title":"Software Developer OMAS"},{"location":"services/omas/software-developer/#software-developer-open-metadata-access-service-omas","text":"The Software Developer OMAS provides APIs and events for software developer tools and applications that help developers make good use of the standards and best practices defined for the data landscape. It supports the documentation of the component structure of a software capability and the ability to link it to the digital services it supports for the business. As the software developer works on the implementation, the Software Developer OMAS supports APIs to search for data structure implementation snippets based on search criteria such as glossary terms and/or language. It also provides information about the most appropriate data sources to use for particular situations along with details of reference data values and sets. Using these services augments the software component model for the software capability. Finally it enables the documentation of the packaging as the components are moved into the DevOps Pipeline .","title":"Software Developer Open Metadata Access Service (OMAS)"},{"location":"services/omas/software-developer/#design","text":"The module structure for the Software Developer OMAS is as follows: software-developer-client supports the client library. software-developer-api supports the common Java classes that are used both by the client and the server. software-developer-server supports in implementation of the access service and its related event management. software-developer-spring supports the REST API using the Spring libraries.","title":"Design"},{"location":"services/omas/stewardship-action/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Stewardship Action Open Metadata Access Service ( OMAS ) \u00b6 The Stewardship Action OMAS provides APIs and events for tools and applications focused on resolving issues detected in the data landscape. It works in partnership with the stewardship server to execute functions that detect, report on and implement the resolution of issues. These functions are called stewardship actions . For example, when a change is detected in an Asset metadata entity, the Stewardship Action OMAS runs the stewardship actions associated with that asset. These could be: * detect and emit an event if a new asset is created without an owner. * create an entry in a maintenance NoteLog to record each change to the Asset. Where a stewardship action creates an event, this is published to the stewardship action OMASs OutTopic where it is picked up by the Stewardship server to process. The stewardship server is configured with the stewardship actions to process ite incoming events. For example, there could be a stewardship action to assign an owner to an Asset without one based on values in a reference table or if there was no default owner defined for the asset type, to initiate a workflow to enable a human steward to assign it. Implementing Stewardship Actions \u00b6 The implementation of stewardship actions is through the Governance Action Framework ( GAF ) . The GAF defines plug-in components that can be configured and executed by the stewardship action OMAS and in the stewardship server. The the stewardship actions are open connectors (see Open Connector Framework ( OCF ) ) that implement the interfaces defined by the governance action framework. Configuring the Stewardship Action OMAS \u00b6 The stewardship action OMAS is controlled by the definition of StewardshipAction and RequestForAction entities in the metadata repositories. StewardshipAction entities relate to conditions found in the metadata and include details of how to detect the condition and the action to take. RequestForAction entities refer to issues found in the data landscape itself. They do not contain information about how to fix the problem. This is decided in the stewardship server. These entities are linked to the assets that need the automated stewardship actions. They can be created through the stewardship action OMAS API, or by other OMASs. For example, the Asset Owner OMAS may set up stewardship actions on behalf of the owner of the asset. A discovery service may use the Discovery Engine OMAS to attach RequestForAction entities to an asset as a result of issues it has found in the data access through the asset. The stewardship action OMAS is triggered by listening for metadata changes through its OMRS topic listener. It detects new RequestForAction entities being created and it listens for changes to the assets. All new RequestForAction entities are actioned by sending an event on the stewardship action OMAS OutTopic. Asset changes are assessed using information in any attached StewardshipAction entities. If the assessment determines action is required then an event is sent through the stewardship action OMAS OutTopic. The stewardship server is listening for these events and running the GAF stewardship actions specified in the request for action. These actions may call back to the open metadata access services. Module structure \u00b6 The module structure for the Stewardship Action OMAS is as follows: stewardship-action-client supports the client library. stewardship-action-api supports the common Java classes that are used both by the client and the server. stewardship-action-server supports in implementation of the access service and its related event management. stewardship-action-spring supports the REST API using the Spring libraries.","title":"Stewardship Action OMAS"},{"location":"services/omas/stewardship-action/#stewardship-action-open-metadata-access-service-omas","text":"The Stewardship Action OMAS provides APIs and events for tools and applications focused on resolving issues detected in the data landscape. It works in partnership with the stewardship server to execute functions that detect, report on and implement the resolution of issues. These functions are called stewardship actions . For example, when a change is detected in an Asset metadata entity, the Stewardship Action OMAS runs the stewardship actions associated with that asset. These could be: * detect and emit an event if a new asset is created without an owner. * create an entry in a maintenance NoteLog to record each change to the Asset. Where a stewardship action creates an event, this is published to the stewardship action OMASs OutTopic where it is picked up by the Stewardship server to process. The stewardship server is configured with the stewardship actions to process ite incoming events. For example, there could be a stewardship action to assign an owner to an Asset without one based on values in a reference table or if there was no default owner defined for the asset type, to initiate a workflow to enable a human steward to assign it.","title":"Stewardship Action Open Metadata Access Service (OMAS)"},{"location":"services/omas/stewardship-action/#implementing-stewardship-actions","text":"The implementation of stewardship actions is through the Governance Action Framework ( GAF ) . The GAF defines plug-in components that can be configured and executed by the stewardship action OMAS and in the stewardship server. The the stewardship actions are open connectors (see Open Connector Framework ( OCF ) ) that implement the interfaces defined by the governance action framework.","title":"Implementing Stewardship Actions"},{"location":"services/omas/stewardship-action/#configuring-the-stewardship-action-omas","text":"The stewardship action OMAS is controlled by the definition of StewardshipAction and RequestForAction entities in the metadata repositories. StewardshipAction entities relate to conditions found in the metadata and include details of how to detect the condition and the action to take. RequestForAction entities refer to issues found in the data landscape itself. They do not contain information about how to fix the problem. This is decided in the stewardship server. These entities are linked to the assets that need the automated stewardship actions. They can be created through the stewardship action OMAS API, or by other OMASs. For example, the Asset Owner OMAS may set up stewardship actions on behalf of the owner of the asset. A discovery service may use the Discovery Engine OMAS to attach RequestForAction entities to an asset as a result of issues it has found in the data access through the asset. The stewardship action OMAS is triggered by listening for metadata changes through its OMRS topic listener. It detects new RequestForAction entities being created and it listens for changes to the assets. All new RequestForAction entities are actioned by sending an event on the stewardship action OMAS OutTopic. Asset changes are assessed using information in any attached StewardshipAction entities. If the assessment determines action is required then an event is sent through the stewardship action OMAS OutTopic. The stewardship server is listening for these events and running the GAF stewardship actions specified in the request for action. These actions may call back to the open metadata access services.","title":"Configuring the Stewardship Action OMAS"},{"location":"services/omas/stewardship-action/#module-structure","text":"The module structure for the Stewardship Action OMAS is as follows: stewardship-action-client supports the client library. stewardship-action-api supports the common Java classes that are used both by the client and the server. stewardship-action-server supports in implementation of the access service and its related event management. stewardship-action-spring supports the REST API using the Spring libraries.","title":"Module structure"},{"location":"services/omas/subject-area/","text":"Technical preview Technical preview function is in a state that it can be tried. The development is complete, there is documentation and there are samples, tutorials and hands-on labs as appropriate. The community is looking for feedback on the function before releasing it. This feedback may result in changes to the external interfaces. Subject Area Open Metadata Access Service ( OMAS ) \u00b6 The Subject Area OMAS supports subject matter experts who are documenting their knowledge about a particular subject. This includes: glossary terms reference data validation rules The Subject Area API enables subject matter experts to author glossary content. The operations include Find, Create, Read, Update and Delete (CRUD) operations on Glossary, Term and Category objects. These structures are defined as POJO property objects (aka beans). The module structure for the Subject Area OMAS is as follows: subject-area-client supports the client library. subject-area-api supports the common Java classes that are used both by the client and the server. subject-area-server supports an implementation of the access service and its related event management. subject-area-spring supports the REST API using the Spring libraries. The implementation is not complete. The following has been implemented : Java and REST API for create, get and update for Glossary, Category, Term , SubjectAreaDefinition. Java and REST API for the Term to Term relationships HAS-A, RelatedTerm, Synonym, Antonym, Translations, used in context, preferred terms, valid values, replacement terms, typed by, is a, is a type of. Java and REST API for the Term to Category relationships TermCategorization. TermAnchor and CategoryAnchor relationships can be created , deleted, purged and restored. As there are no properties, there are no update or replace operations. getTermRelationships, get GlossaryRelationships and getCategoryRelationships findTerm, findCategory and findGlossary This has been verified by running the Subject Area samples and Subject Area FVT against an in-memory repository Example REST calls: \u00b6 Create Glossary instance \u00b6 POST url: localhost:9443/servers/{serverName}/open-metadata/access-services/subject-area/users/{user}/glossaries JSON body: { \"name\" : \"Test glossary 1\" , \"description\" : \"This is a Glossary for testing.\" , \"usage\" : \"for test\" } Get Glossary instance \u00b6 Get Glossary instance (where {serverName} is the name of the server, {guid} is the guid in the Glossary create response and {user} is the userid ) GET url: localhost:9443/servers/{serverName}/open-metadata/access-services/subject-area/users/{user}/glossaries/{guid} (where {guid} is the GUID in the Glossary create response) Delete Glossary instance \u00b6 Delete Glossary instance (where {guid} is the guid in the Glossary create response and {user} is the userid ) DELETE url : localhost:9443/open-metadata/access-services/subject-area/users/{user}/glossaries/{guid} The Subject Area OMAS philosophy \u00b6 The Subject area OMAS is the access service that subject area experts should use. The intent is that the APIs that are exposed are natural for the tasks that a subject area expert is performing. At this time the Subject area OMAS exposes APIs around the task of Glossary authoring, focusing on Glossary, Category and Term objects. The Subject Area OMAS architecture \u00b6 The Subject Area main objects are the Glossary, Category and Terms. There map onto the OMRS types Glossary, GlossaryCategory and GlossaryTerm. The mapping is not one to one, because the OMAS API is looking to emphasise certain content and hide some of the OMRS details that the subject area expert is not concerned with. Subject Area OMAS mapping to OMRS entities considerations: * Glossary, Category and Term objects have associated icons, these are embedded objects rather than relationships. In this way icon content is shown as important to the subject area expert as they are like to be working with the glossary content visually * The icon embedded object is an IconSummary object. This is an example of other object in the OMAS API whose names end with \"Summary\". These objects represent a summary of the entity at the end of a certain type of OMRS relationships. Note the icon function has not been implemented in the OMAS yet. * Categories and Terms have a GlossarySummary , this is there associated Glossary. Good practice is to have Terms and Categories within a Glossary, so the Subject area API Term and Category create and update APIs expect a glossary to be supplied. See effective date considerations. * OMRS relationships can be managed via the Subject Area relationships API. Some of these relationships may appear as summary objects. The Subject Area OMAS API overview. \u00b6 There are a number of types of APIs associated with the Subject Area OMAS . * Create, update, replace, get, delete (hard and soft) and restore for Glossary, Category, Term and relationships. * get relationships associated with a Term - implemented * Find APIs allow content to be found - findTerm, findCategory and findGlossary implemented * Collaboration APIs allow comments and TODO and the like to be associate with glossary content * A report API, allows glossary content to be analysed, the API response highlights areas that the subject Area Expert might want to amend. - not implemented yet * Node orientated APIs How the Subject Area OMAS deals with effective dates \u00b6 The OMRS entities, relationships and classifications have optional effective From and To dates. These dates are exposed in the Term, Category and Glossary objects as attributes. * create, update and replace calls to the subject Area for Term, Category, glossary and relationships omas can specify an effective date range in the request, allowing the subject area OMAS to manage effective dates. The null value or when it is not specified To date means there is no limit in the future for the objects effectivity. A null or unspecified from date means that this no starting restriction for effectivity. The date must not be in the past. The From date should be prior to the To Date. * create, update, replace, restore, soft delete responses may return Summary objects that are not in the effective date range of the associated Term, Category or Glossary object. This is to allow glossaries content to be 'messy' and allow the subject area expert to fix it up. * A get of a Term, Glossary or Category that has potentially associated Summary objects. Because the Subject Area OMAS is an authoring interface, the user needs to see all content irrespective of the effectivity date. So associated summary objects are exposed even if they are not effective. The summary objects contain the effectivity dates of the relationship and the connected object. The Subject Area user can see these dates and maker a decision as to whether they want to amend them. * create, update, delete restore and replace operations are exposed for relationships that appear as summary objects - so that their effectivity ranges can be managed by the subject area expert. How the Subject Area OMAS deals with finds \u00b6 The find APIs in the Subject Area do not accept input from the user that will be interpreted as a regex. Instead 2 flags are supplied, with the searchCriteria: exactValue and mixedCase. The search criteria from API is a literal and is then extended appropriately to form a regex expression - implementing the requested exactValue and mixedCase.","title":"Subject Area OMAS"},{"location":"services/omas/subject-area/#subject-area-open-metadata-access-service-omas","text":"The Subject Area OMAS supports subject matter experts who are documenting their knowledge about a particular subject. This includes: glossary terms reference data validation rules The Subject Area API enables subject matter experts to author glossary content. The operations include Find, Create, Read, Update and Delete (CRUD) operations on Glossary, Term and Category objects. These structures are defined as POJO property objects (aka beans). The module structure for the Subject Area OMAS is as follows: subject-area-client supports the client library. subject-area-api supports the common Java classes that are used both by the client and the server. subject-area-server supports an implementation of the access service and its related event management. subject-area-spring supports the REST API using the Spring libraries. The implementation is not complete. The following has been implemented : Java and REST API for create, get and update for Glossary, Category, Term , SubjectAreaDefinition. Java and REST API for the Term to Term relationships HAS-A, RelatedTerm, Synonym, Antonym, Translations, used in context, preferred terms, valid values, replacement terms, typed by, is a, is a type of. Java and REST API for the Term to Category relationships TermCategorization. TermAnchor and CategoryAnchor relationships can be created , deleted, purged and restored. As there are no properties, there are no update or replace operations. getTermRelationships, get GlossaryRelationships and getCategoryRelationships findTerm, findCategory and findGlossary This has been verified by running the Subject Area samples and Subject Area FVT against an in-memory repository","title":"Subject Area Open Metadata Access Service (OMAS)"},{"location":"services/omas/subject-area/#example-rest-calls","text":"","title":"Example REST calls:"},{"location":"services/omas/subject-area/#create-glossary-instance","text":"POST url: localhost:9443/servers/{serverName}/open-metadata/access-services/subject-area/users/{user}/glossaries JSON body: { \"name\" : \"Test glossary 1\" , \"description\" : \"This is a Glossary for testing.\" , \"usage\" : \"for test\" }","title":"Create Glossary instance"},{"location":"services/omas/subject-area/#get-glossary-instance","text":"Get Glossary instance (where {serverName} is the name of the server, {guid} is the guid in the Glossary create response and {user} is the userid ) GET url: localhost:9443/servers/{serverName}/open-metadata/access-services/subject-area/users/{user}/glossaries/{guid} (where {guid} is the GUID in the Glossary create response)","title":"Get Glossary instance"},{"location":"services/omas/subject-area/#delete-glossary-instance","text":"Delete Glossary instance (where {guid} is the guid in the Glossary create response and {user} is the userid ) DELETE url : localhost:9443/open-metadata/access-services/subject-area/users/{user}/glossaries/{guid}","title":"Delete Glossary instance"},{"location":"services/omas/subject-area/#the-subject-area-omas-philosophy","text":"The Subject area OMAS is the access service that subject area experts should use. The intent is that the APIs that are exposed are natural for the tasks that a subject area expert is performing. At this time the Subject area OMAS exposes APIs around the task of Glossary authoring, focusing on Glossary, Category and Term objects.","title":"The Subject Area OMAS philosophy"},{"location":"services/omas/subject-area/#the-subject-area-omas-architecture","text":"The Subject Area main objects are the Glossary, Category and Terms. There map onto the OMRS types Glossary, GlossaryCategory and GlossaryTerm. The mapping is not one to one, because the OMAS API is looking to emphasise certain content and hide some of the OMRS details that the subject area expert is not concerned with. Subject Area OMAS mapping to OMRS entities considerations: * Glossary, Category and Term objects have associated icons, these are embedded objects rather than relationships. In this way icon content is shown as important to the subject area expert as they are like to be working with the glossary content visually * The icon embedded object is an IconSummary object. This is an example of other object in the OMAS API whose names end with \"Summary\". These objects represent a summary of the entity at the end of a certain type of OMRS relationships. Note the icon function has not been implemented in the OMAS yet. * Categories and Terms have a GlossarySummary , this is there associated Glossary. Good practice is to have Terms and Categories within a Glossary, so the Subject area API Term and Category create and update APIs expect a glossary to be supplied. See effective date considerations. * OMRS relationships can be managed via the Subject Area relationships API. Some of these relationships may appear as summary objects.","title":"The Subject Area OMAS architecture"},{"location":"services/omas/subject-area/#the-subject-area-omas-api-overview","text":"There are a number of types of APIs associated with the Subject Area OMAS . * Create, update, replace, get, delete (hard and soft) and restore for Glossary, Category, Term and relationships. * get relationships associated with a Term - implemented * Find APIs allow content to be found - findTerm, findCategory and findGlossary implemented * Collaboration APIs allow comments and TODO and the like to be associate with glossary content * A report API, allows glossary content to be analysed, the API response highlights areas that the subject Area Expert might want to amend. - not implemented yet * Node orientated APIs","title":"The Subject Area OMAS API overview."},{"location":"services/omas/subject-area/#how-the-subject-area-omas-deals-with-effective-dates","text":"The OMRS entities, relationships and classifications have optional effective From and To dates. These dates are exposed in the Term, Category and Glossary objects as attributes. * create, update and replace calls to the subject Area for Term, Category, glossary and relationships omas can specify an effective date range in the request, allowing the subject area OMAS to manage effective dates. The null value or when it is not specified To date means there is no limit in the future for the objects effectivity. A null or unspecified from date means that this no starting restriction for effectivity. The date must not be in the past. The From date should be prior to the To Date. * create, update, replace, restore, soft delete responses may return Summary objects that are not in the effective date range of the associated Term, Category or Glossary object. This is to allow glossaries content to be 'messy' and allow the subject area expert to fix it up. * A get of a Term, Glossary or Category that has potentially associated Summary objects. Because the Subject Area OMAS is an authoring interface, the user needs to see all content irrespective of the effectivity date. So associated summary objects are exposed even if they are not effective. The summary objects contain the effectivity dates of the relationship and the connected object. The Subject Area user can see these dates and maker a decision as to whether they want to amend them. * create, update, delete restore and replace operations are exposed for relationships that appear as summary objects - so that their effectivity ranges can be managed by the subject area expert.","title":"How the Subject Area OMAS deals with effective dates"},{"location":"services/omas/subject-area/#how-the-subject-area-omas-deals-with-finds","text":"The find APIs in the Subject Area do not accept input from the user that will be interpreted as a regex. Instead 2 flags are supplied, with the searchCriteria: exactValue and mixedCase. The search criteria from API is a literal and is then extended appropriately to form a regex expression - implementing the requested exactValue and mixedCase.","title":"How the Subject Area OMAS deals with finds"},{"location":"services/omes/","text":"Open Metadata Engine Services ( OMES ) \u00b6 The engine services are each able to host a specific type of governance engine. Broadly there are two types of governance engines: Open discovery engines that run automatic metadata discovery requests to analyze the content of an asset's real-world counterpart. Governance action engines that manage the processing supporting governance processing such as the resolution of issues reported in the open metadata ecosystem or the assets it supports. These engines are supported by the Asset Analysis OMES and Governance Action OMES respectively.","title":"Governance Action"},{"location":"services/omes/#open-metadata-engine-services-omes","text":"The engine services are each able to host a specific type of governance engine. Broadly there are two types of governance engines: Open discovery engines that run automatic metadata discovery requests to analyze the content of an asset's real-world counterpart. Governance action engines that manage the processing supporting governance processing such as the resolution of issues reported in the open metadata ecosystem or the assets it supports. These engines are supported by the Asset Analysis OMES and Governance Action OMES respectively.","title":"Open Metadata Engine Services (OMES)"},{"location":"services/omes/asset-analysis/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Asset Analysis Open Metadata Engine Service ( OMES ) \u00b6 The Asset Analysis OMES provides support for open discovery engines that are part of the Open Discovery Service ( ODF ) . Open discovery engines \u00b6 A discovery engine hosts automated metadata discovery . The Asset Analysis OMES is capable of hosting one or more discovery engines and supports a REST API to request that a discovery engine runs an discovery service to analyse an asset and to access the results. The results of each of these calls is a discovery analysis report . The REST API also supports a request to a discovery engine to run a specific open discovery service against each asset it has access to. The discovery engine services call the Discovery Engine Open Metadata Access Service ( OMAS ) running in an open metadata server to retrieve information about assets and to store the results of the discovery services.","title":"Index"},{"location":"services/omes/asset-analysis/#asset-analysis-open-metadata-engine-service-omes","text":"The Asset Analysis OMES provides support for open discovery engines that are part of the Open Discovery Service ( ODF ) .","title":"Asset Analysis Open Metadata Engine Service (OMES)"},{"location":"services/omes/asset-analysis/#open-discovery-engines","text":"A discovery engine hosts automated metadata discovery . The Asset Analysis OMES is capable of hosting one or more discovery engines and supports a REST API to request that a discovery engine runs an discovery service to analyse an asset and to access the results. The results of each of these calls is a discovery analysis report . The REST API also supports a request to a discovery engine to run a specific open discovery service against each asset it has access to. The discovery engine services call the Discovery Engine Open Metadata Access Service ( OMAS ) running in an open metadata server to retrieve information about assets and to store the results of the discovery services.","title":"Open discovery engines"},{"location":"services/omes/governance-action/","text":"In development A subsystem that is in development means that the Egeria community is still building the function. The code is added continuously in small pieces to help the review and socialization process. It may not run, or do something useful - it only promises not to break other function. There will be git issues describing the end state. Governance Action Open Metadata Engine Services ( OMES ) \u00b6 The Governance Action Open Metadata Engine Service ( OMES ) runs in an Engine Host OMAG Server . It provides access to the open metadata ecosystem for governance action services . These are pluggable connectors that manage governance of open metadata. Their interfaces are defined by the Governance Action Framework ( GAF ) and supported by the Governance Action OMES . The governance Action OMES also provides an API to allow a third party tool to validate that a specific governance action service will load in the engine host server, and it returns the usage information encoded in the service's implementation. Using the Governance Action OMES \u00b6 Governance action services are defined and linked to one or more governance action engines using the Governance Engine OMAS . The definitions for both the governance action engines and their linked services are stored in a metadata server . When the Governance Action OMES is configured in the engine host, a list of governance action engines is supplied. This determines which governance action engines and hence governance action services that it supports. The Governance Action OMES is responsible for initializing the governance action engines and providing the context and runtime environment for governance action services when they are requested by third party technologies or through the governance action processing of the Governance Engine OMAS .","title":"Index"},{"location":"services/omes/governance-action/#governance-action-open-metadata-engine-services-omes","text":"The Governance Action Open Metadata Engine Service ( OMES ) runs in an Engine Host OMAG Server . It provides access to the open metadata ecosystem for governance action services . These are pluggable connectors that manage governance of open metadata. Their interfaces are defined by the Governance Action Framework ( GAF ) and supported by the Governance Action OMES . The governance Action OMES also provides an API to allow a third party tool to validate that a specific governance action service will load in the engine host server, and it returns the usage information encoded in the service's implementation.","title":"Governance Action Open Metadata Engine Services (OMES)"},{"location":"services/omes/governance-action/#using-the-governance-action-omes","text":"Governance action services are defined and linked to one or more governance action engines using the Governance Engine OMAS . The definitions for both the governance action engines and their linked services are stored in a metadata server . When the Governance Action OMES is configured in the engine host, a list of governance action engines is supplied. This determines which governance action engines and hence governance action services that it supports. The Governance Action OMES is responsible for initializing the governance action engines and providing the context and runtime environment for governance action services when they are requested by third party technologies or through the governance action processing of the Governance Engine OMAS .","title":"Using the Governance Action OMES"},{"location":"services/omis/","text":"Open Metadata Integration Services (OMISs) \u00b6 The integration services run in an Integration Daemon OMAG server. Each type of integration service focuses on metadata exchange with a particular type of third party technology. Figure 1: The integration daemon manages the automatic exchange of open metadata between third party technologies and Metadata Access Points or Metadata Servers that are sharing this metadata across the Open Metadata Repository Cohorts that they are connected to Each integration service provides a specialist API for the integration connectors that it manages along with a context manager implementation that is used to set up the integration connectors inside the integration daemon. Figure 2: The integration services running in the integration daemon manage the integration connectors and supply them with a context that gives them access to the Egeria services they need. The integration services available today are: API Integrator - provides cataloguing for APIs. Analytics Integrator - provides cataloguing for Analytics tools. Archive Integrator - provides dynamic maintenance for open metadata archives such as content packs and metadata exports. Catalog Integrator - provides a two-way synchronization for data catalogs. Database Integrator - provides metadata extraction from relational databases. Display Integrator - provides metadata extraction from systems that provide user displays and forms to capture new data values. Files Integrator - collects metadata about files stored in a filesystem or file manager. Infrastructure Integrator - supports the extraction of metadata from IT infrastructure artifacts as well as the use of metadata to maintain IT infrastructure artifacts. Lineage Integrator - collects metadata about processes, their internal logic and the data assets they work with. Organization Integrator - imports details of an organization's structure - such as teams and departments. Security Integrator - distributes security properties to access control enforcement points. Stewardship Integrator - exchanges requests for stewardship action (and results) with a human task manager. Topic Integrator - provides cataloguing of topics and event schema for event brokers. More information about the operation of the integration daemon and the integration services within, along with details of how to set up these integration services are located in the Administration Guide .","title":"Open Metadata Integration Services"},{"location":"services/omis/#open-metadata-integration-services-omiss","text":"The integration services run in an Integration Daemon OMAG server. Each type of integration service focuses on metadata exchange with a particular type of third party technology. Figure 1: The integration daemon manages the automatic exchange of open metadata between third party technologies and Metadata Access Points or Metadata Servers that are sharing this metadata across the Open Metadata Repository Cohorts that they are connected to Each integration service provides a specialist API for the integration connectors that it manages along with a context manager implementation that is used to set up the integration connectors inside the integration daemon. Figure 2: The integration services running in the integration daemon manage the integration connectors and supply them with a context that gives them access to the Egeria services they need. The integration services available today are: API Integrator - provides cataloguing for APIs. Analytics Integrator - provides cataloguing for Analytics tools. Archive Integrator - provides dynamic maintenance for open metadata archives such as content packs and metadata exports. Catalog Integrator - provides a two-way synchronization for data catalogs. Database Integrator - provides metadata extraction from relational databases. Display Integrator - provides metadata extraction from systems that provide user displays and forms to capture new data values. Files Integrator - collects metadata about files stored in a filesystem or file manager. Infrastructure Integrator - supports the extraction of metadata from IT infrastructure artifacts as well as the use of metadata to maintain IT infrastructure artifacts. Lineage Integrator - collects metadata about processes, their internal logic and the data assets they work with. Organization Integrator - imports details of an organization's structure - such as teams and departments. Security Integrator - distributes security properties to access control enforcement points. Stewardship Integrator - exchanges requests for stewardship action (and results) with a human task manager. Topic Integrator - provides cataloguing of topics and event schema for event brokers. More information about the operation of the integration daemon and the integration services within, along with details of how to set up these integration services are located in the Administration Guide .","title":"Open Metadata Integration Services (OMISs)"},{"location":"services/omrs/archive-manager/","text":"Archive manager \u00b6 An open metadata archive provides pre-built definitions for types and metadata instances. OMRSArchiveManager manages the loading and unloading of open metadata archives for the local OMRS repository. It is invoked at server start up for a cohort member and whenever a new open metadata archive is loaded via a REST API. During server start up, it first calls the repository content manager to load the types into the local repository (if any) and to maintain the cache of know and active types in the server. It then calls the local repository instance event processor to load the instances. Related information \u00b6 A description of the utilities for building archives can be found in the open-metadata-archives modules. Details for configuring a metadata server to load archives can be found in the administration guide .","title":"Archive manager"},{"location":"services/omrs/archive-manager/#archive-manager","text":"An open metadata archive provides pre-built definitions for types and metadata instances. OMRSArchiveManager manages the loading and unloading of open metadata archives for the local OMRS repository. It is invoked at server start up for a cohort member and whenever a new open metadata archive is loaded via a REST API. During server start up, it first calls the repository content manager to load the types into the local repository (if any) and to maintain the cache of know and active types in the server. It then calls the local repository instance event processor to load the instances.","title":"Archive manager"},{"location":"services/omrs/archive-manager/#related-information","text":"A description of the utilities for building archives can be found in the open-metadata-archives modules. Details for configuring a metadata server to load archives can be found in the administration guide .","title":"Related information"},{"location":"services/omrs/cohort/","text":"Cohorts \u00b6 An Open Metadata Repository Cohort (or more simply, just a cohort ) is a collection of servers sharing metadata using the Open Metadata Repository Services ( OMRS ) . This sharing is peer-to-peer. Once a server becomes a member of the cohort, it can share metadata with, and receive metadata from, any other member. The cohort itself is self-configuring. At the heart of it is between one and four shared topics. OMRS needs to be flexible to support different performance and availability requirements. For example, where metadata is changing rapidly (such as in a data lake), this metadata should be dynamically queried from the repository where it was created and is being maintained because the rate of updates mean it would cost a lot of network traffic to keep a copy of this metadata up to date. The repository where a piece of metadata (metadata instance) was created and where it is maintained is called its home metadata repository . On the other hand, governance definitions (such as policies) and glossary terms rarely change. They are often administered centrally by the governance team and then linked to all metadata that describes the organization's data resources. Thus, it makes sense for this metadata to be replicated across the repositories within the cohort. These copies are called reference copies of the metadata, and they are read-only. The role of the OMRS is to optimize access to metadata across the cohort by using a combination of replication and federated queries, driven by the metadata workload from the connected tools. Formation of a cohort \u00b6 Cohort membership is established dynamically. This is through the cohort topic(s) . First server \u00b6 To join an open metadata repository cohort, a server must integrate with the OMRS module. OMRS then manages the metadata exchange. When OMRS running inside the server is configured to join a cohort it first adds a registration event to the cohort topic(s). This event identifies the server, its metadata repository (if any) and its capabilities. Subsequent servers \u00b6 When another server joins the cohort, it also adds its registration event to the cohort topic(s) and begins to receive the registration events from other members. The other members respond with re-registration events to ensure the new member has the latest information about the originator's capabilities. The exchange of registration information causes all members to verify that they have the latest information about their peers. This is maintained in their own cohort registry store so that they can reconfigure themselves on restart without needing the other members to resend their registration information. Peer-to-peer operation \u00b6 Once the registration information is exchanged and stored in each member's cohort registry store, it is ready to issue federated queries across the cohort, and respond to requests for metadata from other members. These requests can both retrieve metadata and maintain metadata in the home metadata repository . The management of federated queries and the routing of maintenance requests is managed by OMRS 's enterprise repository services . The enterprise repository services are configured with the registration information from across the cohort at the same time as the cohort registry store is updated. This process is managed by the cohort registry . The registration information includes the URL Root and server name of the member. The federation capability in each member allows it to issue metadata create, update, delete and search requests to each and every member of the cohort. Primary mechanism for accessing metadata This peer-to-peer operation and federated queries are the primary mechanism for accessing metadata, because the access services use federated queries for every request they make for metadata. Metadata exchange \u00b6 Once the cohort membership is established, the server begins publishing information using instance events about changes to the home metadata instances in their repository. These events can be used by other members to maintain a cache of reference copies of this metadata to improve availability of the metadata and retrieval performance. Updates to this metadata will, however, be automatically routed to the home repository by the enterprise repository services: Metadata refresh A member may also request that metadata is \"refreshed\" across the cohort. The originator of the requested metadata then sends the latest version of this metadata to the rest of the cohort through the cohort topic. This mechanism is useful to seed the cache in a new member of the cohort and is invoked as a result of a federated query issued from the new member. Dynamic changes to types \u00b6 Finally, as type definitions (TypeDefs) are added and updated, the cohort members send out events to allow the other members to verify that this type does not conflict with any of their types. Any conflicts in the types causes audit log messages to be logged in all members, prompting action to resolve the conflicts. Leaving the cohort \u00b6 When an OMAG Server permanently leaves the cohort, it sends an unregistration request. This enables the other members to remove the parting member from their registries. Enabling cohort membership \u00b6 Egeria provides a number of pre-built cohort members . One of them, the repository proxy provides a simple way to integrate a third party server into a cohort by creating an OMRS Repository Connector and optional Event Mapper Connector to map between the third party APIs/events and the repository service's equivalents A more bespoke integration involves: Creating an OMRS repository connector and optional event mapper connector Designing how to configure the OMRS Services for your metadata repository. Typically, this is done by extending the existing administration services of the metadata repository, but Egeria also offers some pre-built administration services that can be used or modified. Plugging the OMRS and any administration services into the metadata repository's security module so that requests to the server can be secured against unauthorized access. Integrating the OMRS , administration and security capability into your product. There are different integration patterns available to help you choose the best approach for your product. Each method is optimized for specific use cases and so the metadata repository can only play a full role in the open metadata use cases if it supports all integration methods. These are: Support for an OMRS repository connector to allow open metadata API calls to the repository to create, query, update and delete metadata stored in the repository. The OMRS connectors support the Open Connector Framework ( OCF ) to provide a call interface to the metadata repositories. The OMRS Repository Connector API is a standard interface for all metadata repositories. This enables services such as the Enterprise OMRS Repository Connector to interact with 1 or many metadata repositories through the same interface. The connection configuration it passes to the OCF determines which type of OMRS connector is returned by the OCF . Support for the OMRS event notifications that are used to synchronize selective metadata between the metadata repositories. Cohort members \u00b6 A cohort member is an OMAG Server that is registered with at least one open metadata repository cohort. Management of a server's membership is handled by the cohort services . The exchange of metadata uses the Open Metadata Repository Services ( OMRS ) interfaces which gives fine-grained 1 metadata notifications and updates. During server start up, the repository services detect the configuration of at least one cohort and starts the metadata highway manager . The metadata highway manager creates a cohort manager for each cohort configuration. The cohort manager manages the initialization and shutdown of the server's connectivity to a cohort, including the management of the cohort registry . The server's metadata security connector provides fine-grained control on which metadata is sent, received and/or stored by the server. This level of control is necessary for metadata repositories that are managing specific collections of valuable objects such as Assets . The types of cohort members include: Metadata server Metadata access point Repository proxy Conformance test server Explore hands-on The administration hands-on lab called \"Understanding Cohort Configuration Lab\" provides an opportunity to query the cohort registries of cohort members as they exchange metadata for Coco Pharmaceuticals. Cohort registration \u00b6 Each repository in the cohort has a cohort registry that supports the registration of the metadata repositories across the cohort. Through the registration process, each cohort registry assembles a list of all members of the cohort. This is saved in the cohort registry store . The list of connections to the remote members of the cohort are passed to the OMRS Enterprise Connector Manager that in turn manages the configuration of the Enterprise OMRS Repository Connectors. The Enterprise OMRS Connector provides federated query support across the metadata cohort for the Open Metadata Access Services ( OMAS ) . When a metadata repository registers with the cohort registry , the administrator may either supply a unique server identifier, or ask the OMRS to generate one. This server identifier (the metadata collection ID ) is used in the OMRS event notifications, and on OMRS repository connector calls to identify the location of the home copy of the metadata entities and to identify which repository is requesting a service or supports a particular function. Once the metadata repository has registered with the cohort registry , it is a member of the metadata repository cohort and can synchronize and share metadata with other repositories in the cohort through the OMRS topic(s) . Registering with multiple cohorts A single metadata repository can register with multiple metadata cohorts as long as its server identifier is unique across all cohorts that it joins and it manages the posting of events to the appropriate OMRS topic for each cohort it registers with. This capability is useful for a metadata repository that is aggregating reference copies of metadata from multiple open metadata repository cohorts. Cohort registry \u00b6 The cohort registry resides in each cohort member . It is responsible for registering a member with a specific open metadata repository cohort and maintaining a list of the other members of this cohort. The registration process is managed by exchanging registry events over the cohort topic(s) . The cohort registry maintains its record of the membership of the cohort in a cohort registry store . You may want to see the OMRS metamodel for more details on the granularity of metadata exchange. \u21a9","title":"Cohorts"},{"location":"services/omrs/cohort/#cohorts","text":"An Open Metadata Repository Cohort (or more simply, just a cohort ) is a collection of servers sharing metadata using the Open Metadata Repository Services ( OMRS ) . This sharing is peer-to-peer. Once a server becomes a member of the cohort, it can share metadata with, and receive metadata from, any other member. The cohort itself is self-configuring. At the heart of it is between one and four shared topics. OMRS needs to be flexible to support different performance and availability requirements. For example, where metadata is changing rapidly (such as in a data lake), this metadata should be dynamically queried from the repository where it was created and is being maintained because the rate of updates mean it would cost a lot of network traffic to keep a copy of this metadata up to date. The repository where a piece of metadata (metadata instance) was created and where it is maintained is called its home metadata repository . On the other hand, governance definitions (such as policies) and glossary terms rarely change. They are often administered centrally by the governance team and then linked to all metadata that describes the organization's data resources. Thus, it makes sense for this metadata to be replicated across the repositories within the cohort. These copies are called reference copies of the metadata, and they are read-only. The role of the OMRS is to optimize access to metadata across the cohort by using a combination of replication and federated queries, driven by the metadata workload from the connected tools.","title":"Cohorts"},{"location":"services/omrs/cohort/#formation-of-a-cohort","text":"Cohort membership is established dynamically. This is through the cohort topic(s) .","title":"Formation of a cohort"},{"location":"services/omrs/cohort/#first-server","text":"To join an open metadata repository cohort, a server must integrate with the OMRS module. OMRS then manages the metadata exchange. When OMRS running inside the server is configured to join a cohort it first adds a registration event to the cohort topic(s). This event identifies the server, its metadata repository (if any) and its capabilities.","title":"First server"},{"location":"services/omrs/cohort/#subsequent-servers","text":"When another server joins the cohort, it also adds its registration event to the cohort topic(s) and begins to receive the registration events from other members. The other members respond with re-registration events to ensure the new member has the latest information about the originator's capabilities. The exchange of registration information causes all members to verify that they have the latest information about their peers. This is maintained in their own cohort registry store so that they can reconfigure themselves on restart without needing the other members to resend their registration information.","title":"Subsequent servers"},{"location":"services/omrs/cohort/#peer-to-peer-operation","text":"Once the registration information is exchanged and stored in each member's cohort registry store, it is ready to issue federated queries across the cohort, and respond to requests for metadata from other members. These requests can both retrieve metadata and maintain metadata in the home metadata repository . The management of federated queries and the routing of maintenance requests is managed by OMRS 's enterprise repository services . The enterprise repository services are configured with the registration information from across the cohort at the same time as the cohort registry store is updated. This process is managed by the cohort registry . The registration information includes the URL Root and server name of the member. The federation capability in each member allows it to issue metadata create, update, delete and search requests to each and every member of the cohort. Primary mechanism for accessing metadata This peer-to-peer operation and federated queries are the primary mechanism for accessing metadata, because the access services use federated queries for every request they make for metadata.","title":"Peer-to-peer operation"},{"location":"services/omrs/cohort/#metadata-exchange","text":"Once the cohort membership is established, the server begins publishing information using instance events about changes to the home metadata instances in their repository. These events can be used by other members to maintain a cache of reference copies of this metadata to improve availability of the metadata and retrieval performance. Updates to this metadata will, however, be automatically routed to the home repository by the enterprise repository services: Metadata refresh A member may also request that metadata is \"refreshed\" across the cohort. The originator of the requested metadata then sends the latest version of this metadata to the rest of the cohort through the cohort topic. This mechanism is useful to seed the cache in a new member of the cohort and is invoked as a result of a federated query issued from the new member.","title":"Metadata exchange"},{"location":"services/omrs/cohort/#dynamic-changes-to-types","text":"Finally, as type definitions (TypeDefs) are added and updated, the cohort members send out events to allow the other members to verify that this type does not conflict with any of their types. Any conflicts in the types causes audit log messages to be logged in all members, prompting action to resolve the conflicts.","title":"Dynamic changes to types"},{"location":"services/omrs/cohort/#leaving-the-cohort","text":"When an OMAG Server permanently leaves the cohort, it sends an unregistration request. This enables the other members to remove the parting member from their registries.","title":"Leaving the cohort"},{"location":"services/omrs/cohort/#enabling-cohort-membership","text":"Egeria provides a number of pre-built cohort members . One of them, the repository proxy provides a simple way to integrate a third party server into a cohort by creating an OMRS Repository Connector and optional Event Mapper Connector to map between the third party APIs/events and the repository service's equivalents A more bespoke integration involves: Creating an OMRS repository connector and optional event mapper connector Designing how to configure the OMRS Services for your metadata repository. Typically, this is done by extending the existing administration services of the metadata repository, but Egeria also offers some pre-built administration services that can be used or modified. Plugging the OMRS and any administration services into the metadata repository's security module so that requests to the server can be secured against unauthorized access. Integrating the OMRS , administration and security capability into your product. There are different integration patterns available to help you choose the best approach for your product. Each method is optimized for specific use cases and so the metadata repository can only play a full role in the open metadata use cases if it supports all integration methods. These are: Support for an OMRS repository connector to allow open metadata API calls to the repository to create, query, update and delete metadata stored in the repository. The OMRS connectors support the Open Connector Framework ( OCF ) to provide a call interface to the metadata repositories. The OMRS Repository Connector API is a standard interface for all metadata repositories. This enables services such as the Enterprise OMRS Repository Connector to interact with 1 or many metadata repositories through the same interface. The connection configuration it passes to the OCF determines which type of OMRS connector is returned by the OCF . Support for the OMRS event notifications that are used to synchronize selective metadata between the metadata repositories.","title":"Enabling cohort membership"},{"location":"services/omrs/cohort/#cohort-members","text":"A cohort member is an OMAG Server that is registered with at least one open metadata repository cohort. Management of a server's membership is handled by the cohort services . The exchange of metadata uses the Open Metadata Repository Services ( OMRS ) interfaces which gives fine-grained 1 metadata notifications and updates. During server start up, the repository services detect the configuration of at least one cohort and starts the metadata highway manager . The metadata highway manager creates a cohort manager for each cohort configuration. The cohort manager manages the initialization and shutdown of the server's connectivity to a cohort, including the management of the cohort registry . The server's metadata security connector provides fine-grained control on which metadata is sent, received and/or stored by the server. This level of control is necessary for metadata repositories that are managing specific collections of valuable objects such as Assets . The types of cohort members include: Metadata server Metadata access point Repository proxy Conformance test server Explore hands-on The administration hands-on lab called \"Understanding Cohort Configuration Lab\" provides an opportunity to query the cohort registries of cohort members as they exchange metadata for Coco Pharmaceuticals.","title":"Cohort members"},{"location":"services/omrs/cohort/#cohort-registration","text":"Each repository in the cohort has a cohort registry that supports the registration of the metadata repositories across the cohort. Through the registration process, each cohort registry assembles a list of all members of the cohort. This is saved in the cohort registry store . The list of connections to the remote members of the cohort are passed to the OMRS Enterprise Connector Manager that in turn manages the configuration of the Enterprise OMRS Repository Connectors. The Enterprise OMRS Connector provides federated query support across the metadata cohort for the Open Metadata Access Services ( OMAS ) . When a metadata repository registers with the cohort registry , the administrator may either supply a unique server identifier, or ask the OMRS to generate one. This server identifier (the metadata collection ID ) is used in the OMRS event notifications, and on OMRS repository connector calls to identify the location of the home copy of the metadata entities and to identify which repository is requesting a service or supports a particular function. Once the metadata repository has registered with the cohort registry , it is a member of the metadata repository cohort and can synchronize and share metadata with other repositories in the cohort through the OMRS topic(s) . Registering with multiple cohorts A single metadata repository can register with multiple metadata cohorts as long as its server identifier is unique across all cohorts that it joins and it manages the posting of events to the appropriate OMRS topic for each cohort it registers with. This capability is useful for a metadata repository that is aggregating reference copies of metadata from multiple open metadata repository cohorts.","title":"Cohort registration"},{"location":"services/omrs/cohort/#cohort-registry","text":"The cohort registry resides in each cohort member . It is responsible for registering a member with a specific open metadata repository cohort and maintaining a list of the other members of this cohort. The registration process is managed by exchanging registry events over the cohort topic(s) . The cohort registry maintains its record of the membership of the cohort in a cohort registry store . You may want to see the OMRS metamodel for more details on the granularity of metadata exchange. \u21a9","title":"Cohort registry"},{"location":"services/omrs/metadata-repositories/","text":"Metadata repositories \u00b6 A metadata repository that supports the open metadata repository standards defined by the Open Metadata Repository Services ( OMRS ) is called an \"open metadata repository\". Home metadata repositories \u00b6 The metadata repository where a metadata entity or relationship is created is called its home repository . Metadata can only be updated and deleted in its home repository The Open Metadata Repository Services ( OMRS ) is responsible for sharing this metadata with other metadata repositories who are members of the same cohort . Reference copies \u00b6 These shared copies are called reference copies . Reference copies are read-only Update requests to a reference copy are automatically redirected to the home repository by the OMRS , without the caller being aware. Every metadata repository in a cohort has a unique identifier called the local metadata collection id . This identifier is set up in the server configuration and shared when this server connects to a cohort . When metadata is shared by OMRS , each element is tagged with the metadata collection id of its home repository. OMRS is able to route update requests to the right server by comparing the metadata collection id in the metadata instance with the cohort registration information passed between members of the cohort when they connect. Metadata collections \u00b6 A metadata collection refers to a set of metadata instances that are being maintained and accessed as a coherent set of information. These instances are explicitly typed using open metadata type definitions (TypeDefs) . Typically, metadata collections are stored in a single metadata repository. However, the Open Metadata Access Services (OMASs) provide access to a federated metadata collection called the enterprise metadata collection . Enterprise metadata collection \u00b6 The enterprise metadata collection is the metadata collection that is the combination of metadata from all metadata collections held by the open metadata repositories that are members of the same open metadata repository cohorts as the server where the enterprise repository services are enabled. Metadata collection ID \u00b6 Every metadata repository has a unique identifier called the local-metadata-collection-id . This identifier is assigned automatically during the configuration of the local repository but can be overridden through administrative commands. A new local metadata collection id is assigned when the local repository is set up In the following server configuration, the local metadata collection id is 1b96495f-82d3-4224-9fdd-31bcb84c224c . It also appears in an audit log message written at start up. OMRS-AUDIT-0001 The Open Metadata Repository Services (OMRS) is initializing : : : OMRS-AUDIT-0003 The local repository is initializing with metadata collection id 1b96495f-82d3-4224-9fdd-31bcb84c224c If the server is connected to a cohort, the local cohort registry sends the local metadata collection id and a registration event like the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 { \"localRegistration\" : { \"metadataCollectionId\" : \"1b96495f-82d3-4224-9fdd-31bcb84c224c\" , \"serverName\" : \"cocoMDS1\" , \"serverType\" : \"Open Metadata and Governance Server\" , \"registrationTime\" : 1531820378765 , \"repositoryConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"64e67923-8190-45ea-8f96-39320d638c02\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.ConnectorType.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.ConnectorType.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connector type.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/openmetadata/repositoryservices/\" } } } }","title":"Metadata Repositories"},{"location":"services/omrs/metadata-repositories/#metadata-repositories","text":"A metadata repository that supports the open metadata repository standards defined by the Open Metadata Repository Services ( OMRS ) is called an \"open metadata repository\".","title":"Metadata repositories"},{"location":"services/omrs/metadata-repositories/#home-metadata-repositories","text":"The metadata repository where a metadata entity or relationship is created is called its home repository . Metadata can only be updated and deleted in its home repository The Open Metadata Repository Services ( OMRS ) is responsible for sharing this metadata with other metadata repositories who are members of the same cohort .","title":"Home metadata repositories"},{"location":"services/omrs/metadata-repositories/#reference-copies","text":"These shared copies are called reference copies . Reference copies are read-only Update requests to a reference copy are automatically redirected to the home repository by the OMRS , without the caller being aware. Every metadata repository in a cohort has a unique identifier called the local metadata collection id . This identifier is set up in the server configuration and shared when this server connects to a cohort . When metadata is shared by OMRS , each element is tagged with the metadata collection id of its home repository. OMRS is able to route update requests to the right server by comparing the metadata collection id in the metadata instance with the cohort registration information passed between members of the cohort when they connect.","title":"Reference copies"},{"location":"services/omrs/metadata-repositories/#metadata-collections","text":"A metadata collection refers to a set of metadata instances that are being maintained and accessed as a coherent set of information. These instances are explicitly typed using open metadata type definitions (TypeDefs) . Typically, metadata collections are stored in a single metadata repository. However, the Open Metadata Access Services (OMASs) provide access to a federated metadata collection called the enterprise metadata collection .","title":"Metadata collections"},{"location":"services/omrs/metadata-repositories/#enterprise-metadata-collection","text":"The enterprise metadata collection is the metadata collection that is the combination of metadata from all metadata collections held by the open metadata repositories that are members of the same open metadata repository cohorts as the server where the enterprise repository services are enabled.","title":"Enterprise metadata collection"},{"location":"services/omrs/metadata-repositories/#metadata-collection-id","text":"Every metadata repository has a unique identifier called the local-metadata-collection-id . This identifier is assigned automatically during the configuration of the local repository but can be overridden through administrative commands. A new local metadata collection id is assigned when the local repository is set up In the following server configuration, the local metadata collection id is 1b96495f-82d3-4224-9fdd-31bcb84c224c . It also appears in an audit log message written at start up. OMRS-AUDIT-0001 The Open Metadata Repository Services (OMRS) is initializing : : : OMRS-AUDIT-0003 The local repository is initializing with metadata collection id 1b96495f-82d3-4224-9fdd-31bcb84c224c If the server is connected to a cohort, the local cohort registry sends the local metadata collection id and a registration event like the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 { \"localRegistration\" : { \"metadataCollectionId\" : \"1b96495f-82d3-4224-9fdd-31bcb84c224c\" , \"serverName\" : \"cocoMDS1\" , \"serverType\" : \"Open Metadata and Governance Server\" , \"registrationTime\" : 1531820378765 , \"repositoryConnection\" : { \"class\" : \"Connection\" , \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"114e9f8f-5ff3-4c32-bd37-a7eb42712253\" , \"elementTypeName\" : \"Connection\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties to identify and configure a connector instance.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"858be98b-49d2-4ccf-9b23-01085a5f473f\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.Connection.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connection.\" , \"connectorType\" : { \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"954421eb-33a6-462d-a8ca-b5709a1bd0d4\" , \"elementTypeName\" : \"ConnectorType\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"A set of properties describing a type of connector.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"64e67923-8190-45ea-8f96-39320d638c02\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.ConnectorType.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.ConnectorType.cocoMDS1\" , \"description\" : \"OMRS default repository REST API connector type.\" , \"connectorProviderClassName\" : \"org.odpi.openmetadata.adapters.repositoryservices.rest.repositoryconnector.OMRSRESTRepositoryConnectorProvider\" }, \"endpoint\" : { \"type\" : { \"type\" : \"ElementType\" , \"elementTypeId\" : \"dbc20663-d705-4ff0-8424-80c262c6b8e7\" , \"elementTypeName\" : \"Endpoint\" , \"elementTypeVersion\" : 1 , \"elementTypeDescription\" : \"Description of the network address and related information needed to call a software service.\" , \"elementOrigin\" : \"CONFIGURATION\" }, \"guid\" : \"cee85898-43aa-4af5-9bbd-2bed809d1acb\" , \"qualifiedName\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"name\" : \"DefaultRepositoryRESTAPI.Endpoint.cocoMDS1\" , \"description\" : \"OMRS default repository REST API endpoint.\" , \"address\" : \"https://localhost:9443/openmetadata/repositoryservices/\" } } } }","title":"Metadata collection ID"},{"location":"services/omrs/omrs-topic-connector/","text":"OMRS Topic Connector \u00b6 The OMRS topic connector provides a common interface to interact with an instance of the OMRS event topic(s) .","title":"Omrs topic connector"},{"location":"services/omrs/omrs-topic-connector/#omrs-topic-connector","text":"The OMRS topic connector provides a common interface to interact with an instance of the OMRS event topic(s) .","title":"OMRS Topic Connector"},{"location":"services/omrs/overview/","text":"Repository Services ( OMRS ) Design \u00b6 On the left-hand side is the administration interface supported by the OMAG Server. This is where configuration is passed to the OMRS , and status and other relevant information is made available to the OMAG Administration Services. Along the top is the interface with the Open Metadata Access Services ( OMAS ) . The OMRS provides access to the open metadata repositories through both APIs (see Enterprise OMRS Repository Connector ) and events (see Enterprise OMRS Topic ). Along the bottom are the six types of connectors that provide the OMRS with access to the stores and system resources it needs to support the OMAS . These connectors enable the OMRS to be deployed into different types of server environments and connect with different types of infrastructure and services. Repository connectors provide a common interface for metadata repositories. The OMRS store connectors can range from simple file stores to enterprise / cloud provider admin repositories and the event topic can support different types of messaging infrastructure. OMRS subsystems \u00b6 Inside the OMRS are 4 major subsystems (groups of components). Enterprise repository services \u00b6 The enterprise repository services provide a virtual metadata repository by combining the content of multiple open metadata repositories and delivering this metadata through a single API and event topic. The Enterprise Repository Services provide the enterprise access metadata support for the OMASs, supporting the federation of metadata across all of the repositories that are members of the cohort. The services include the following components: Enterprise Connector Manager - Manages the list of open metadata repositories that the Enterprise OMRS Repository Connector should call to retrieve an enterprise view of the metadata collections supported by these repositories. Enterprise Repository Connector - Supports federated queries. Enterprise OMRS Connector Provider - The OCF Connector Provider factory for the Enterprise OMRS Repository Connector. Enterprise OMRS Repository Connector - Implements the OMRS Repository Connector interface that supports enterprise access to the list of open metadata repositories registered with the OMRS Enterprise Connector Manager. Enterprise OMRS Metadata Collection - Manages calls to the list of open metadata repositories registered with the OMRS Enterprise Connector Manager on behalf of the Enterprise OMRS Repository Connector. Enterprise OMRS Connector Properties - Provides the connected asset properties for the Enterprise OMRS Repository Connector. The enterprise repository services are enabled automatically in a metadata server when one or more Open Metadata Access Services ( OMAS ) are configured. Administration services \u00b6 The administration services drive the initialization of the OMRS at server startup, provide access to the OMRS 's internal status and coordinate the orderly termination of OMRS when the open metadata services are deactivated. OMRS 's administration services are called by the server's administration services. It is supplied with configuration information including: Connections for the connectors it should use. Information about the local repository (if any). Whether the enterprise repository services should be initialized. Details of any cohorts it should join. The administration services include the following components: OMRS Operational Services - supports the admin interface for the OMRS . OMRS Configuration Factory - manages default values and creation of connectors. OMRS Audit Log - manages the storage and retrieval of audit log records. OMRS Archive Manager - manages the loading of open metadata archives. Cohort services \u00b6 The cohort services manage the exchange of metadata between a repository and other members of an open metadata repository cohort . It includes the following components: OMRS Metadata Highway Manager - manages the OMRS Cohort Manager for each open metadata repository cohort that the local server belongs to. OMRS Cohort Manager - manages the components needed in the local server for it to act as a member of an open metadata repository cohort. OMRS Cohort Registry - manages registration exchanges with other members of a cohort on behalf of the local server. Local repository services \u00b6 The local repository services manage the interaction with the local server's metadata collection (stored in the local repository). They include the following components: Local OMRS Repository Connector - Implements the OMRS Repository Connector interface that supports access to the local metadata repository. Local OMRS Connector Provider - The OCF Connector Provider factory for the Local OMRS Repository Connector. Local OMRS Metadata Collection - Manages metadata requests for the local repository. Local OMRS Repository Content Manager - Provides an in-memory cache of open metadata type definitions (TypeDefs) that are used for validating of TypeDefs from other open metadata repositories and creation of new open metadata instances (entities and relationships). Local OMRS Instance Event Processor - Processes inbound Instance Events on behalf of the local repository. These events may come from one of the connected open metadata repository cohorts or the OMRS Archive Manager. OMRS REST Repository Services - Implements the server-side of the In-memory OMRS Repository Connector. OMRS REST Repository Connector - Implements the OMRS Repository Connector interface that supports metadata access to a remote open metadata repository service via the OMRS Repository REST API. OMRS REST Connector Provider - The OCF Connector Provider factory for the OMRS REST Repository Connector. OMRS REST Metadata Collection - Manages calls to the OMRS REST Repository Services in a remote open metadata repository. Event management services \u00b6 Isn't this a fifth subsystem? The event management services are not illustrated in the overview of OMRS subsystems as we do not consider them to be one of the major subsystems that can be used on its own. It is nonetheless a subsystem of the OMRS , and hence is described here for completeness -- you will also see it illustrated further below in the component-level diagram in the purple box. The event management services provide event passing: Inbound event passing from the cohort services to the optional local repository services and enterprise repository services. Outbound event passing from the local repository services to the optional cohort services and enterprise repository services. The event management services ensure that the other subsystems do not need to be aware of whether the other subsystems are active or not. The event management services include the following components: OMRS Repository Event Manager - Manages the distribution of repository events (TypeDef and Instance Events) within the local server's OMRS components. OMRS Event Listener - Receives Registry and Repository (TypeDef and Instance) events from the OMRS Topic for a cohort. OMRS Event Publisher - Sends Registry and Repository (TypeDef and Instance) events to the OMRS Topic. This may be the OMRS Topic for a cohort, or the OMRS Topic used by the Open Metadata Access Services ( OMAS ). Patterns \u00b6 The OMRS is highly configurable and runs in every type of OMAG Server . The figures below show the different combinations. Local repository (only) \u00b6 The OMRS can support the OMAS 's with access to a single, local-only repository - with no connectivity to other open metadata repositories. This is what runs in a metadata server that is not connected to an open metadata repository cohort . Access services (only) \u00b6 The OMRS can also support a server without any local repository - so that all metadata for the OMAS 's is coming through the cohort services from remote metadata repositories. This is the caller integration pattern supported by the metadata access point OMAG Server . Repository proxy \u00b6 The OMRS can support a server where the OMAS 's are not deployed and the local repository is configured to connect as an adapter for a non-native open metadata repository. The cohort services connect this metadata repository with other members in one or more cohorts. This is called the adapter integration pattern and is used in a repository proxy OMAG Server . Connected metadata server \u00b6 Of course, it is also possible to run all the OMRS components together as well, supporting the OMAS 's with a local repository and connectivity to other repositories through the cohort servers. This is what runs in a metadata server that is connected to an open metadata repository cohort . Administration subsystem (alone) \u00b6 Finally, the administration subsystem alone is active in the servers that are not cohort members , that is the Governance Servers and the view servers . OMRS components \u00b6 The different combinations of operation required means that the OMRS components need to be flexible and communicate with one another through well-defined interfaces so that component implementations can be swapped in and out to support different configurations.","title":"Open Metadata Repository Services"},{"location":"services/omrs/overview/#repository-services-omrs-design","text":"On the left-hand side is the administration interface supported by the OMAG Server. This is where configuration is passed to the OMRS , and status and other relevant information is made available to the OMAG Administration Services. Along the top is the interface with the Open Metadata Access Services ( OMAS ) . The OMRS provides access to the open metadata repositories through both APIs (see Enterprise OMRS Repository Connector ) and events (see Enterprise OMRS Topic ). Along the bottom are the six types of connectors that provide the OMRS with access to the stores and system resources it needs to support the OMAS . These connectors enable the OMRS to be deployed into different types of server environments and connect with different types of infrastructure and services. Repository connectors provide a common interface for metadata repositories. The OMRS store connectors can range from simple file stores to enterprise / cloud provider admin repositories and the event topic can support different types of messaging infrastructure.","title":"Repository Services (OMRS) Design"},{"location":"services/omrs/overview/#omrs-subsystems","text":"Inside the OMRS are 4 major subsystems (groups of components).","title":"OMRS subsystems"},{"location":"services/omrs/overview/#enterprise-repository-services","text":"The enterprise repository services provide a virtual metadata repository by combining the content of multiple open metadata repositories and delivering this metadata through a single API and event topic. The Enterprise Repository Services provide the enterprise access metadata support for the OMASs, supporting the federation of metadata across all of the repositories that are members of the cohort. The services include the following components: Enterprise Connector Manager - Manages the list of open metadata repositories that the Enterprise OMRS Repository Connector should call to retrieve an enterprise view of the metadata collections supported by these repositories. Enterprise Repository Connector - Supports federated queries. Enterprise OMRS Connector Provider - The OCF Connector Provider factory for the Enterprise OMRS Repository Connector. Enterprise OMRS Repository Connector - Implements the OMRS Repository Connector interface that supports enterprise access to the list of open metadata repositories registered with the OMRS Enterprise Connector Manager. Enterprise OMRS Metadata Collection - Manages calls to the list of open metadata repositories registered with the OMRS Enterprise Connector Manager on behalf of the Enterprise OMRS Repository Connector. Enterprise OMRS Connector Properties - Provides the connected asset properties for the Enterprise OMRS Repository Connector. The enterprise repository services are enabled automatically in a metadata server when one or more Open Metadata Access Services ( OMAS ) are configured.","title":"Enterprise repository services"},{"location":"services/omrs/overview/#administration-services","text":"The administration services drive the initialization of the OMRS at server startup, provide access to the OMRS 's internal status and coordinate the orderly termination of OMRS when the open metadata services are deactivated. OMRS 's administration services are called by the server's administration services. It is supplied with configuration information including: Connections for the connectors it should use. Information about the local repository (if any). Whether the enterprise repository services should be initialized. Details of any cohorts it should join. The administration services include the following components: OMRS Operational Services - supports the admin interface for the OMRS . OMRS Configuration Factory - manages default values and creation of connectors. OMRS Audit Log - manages the storage and retrieval of audit log records. OMRS Archive Manager - manages the loading of open metadata archives.","title":"Administration services"},{"location":"services/omrs/overview/#cohort-services","text":"The cohort services manage the exchange of metadata between a repository and other members of an open metadata repository cohort . It includes the following components: OMRS Metadata Highway Manager - manages the OMRS Cohort Manager for each open metadata repository cohort that the local server belongs to. OMRS Cohort Manager - manages the components needed in the local server for it to act as a member of an open metadata repository cohort. OMRS Cohort Registry - manages registration exchanges with other members of a cohort on behalf of the local server.","title":"Cohort services"},{"location":"services/omrs/overview/#local-repository-services","text":"The local repository services manage the interaction with the local server's metadata collection (stored in the local repository). They include the following components: Local OMRS Repository Connector - Implements the OMRS Repository Connector interface that supports access to the local metadata repository. Local OMRS Connector Provider - The OCF Connector Provider factory for the Local OMRS Repository Connector. Local OMRS Metadata Collection - Manages metadata requests for the local repository. Local OMRS Repository Content Manager - Provides an in-memory cache of open metadata type definitions (TypeDefs) that are used for validating of TypeDefs from other open metadata repositories and creation of new open metadata instances (entities and relationships). Local OMRS Instance Event Processor - Processes inbound Instance Events on behalf of the local repository. These events may come from one of the connected open metadata repository cohorts or the OMRS Archive Manager. OMRS REST Repository Services - Implements the server-side of the In-memory OMRS Repository Connector. OMRS REST Repository Connector - Implements the OMRS Repository Connector interface that supports metadata access to a remote open metadata repository service via the OMRS Repository REST API. OMRS REST Connector Provider - The OCF Connector Provider factory for the OMRS REST Repository Connector. OMRS REST Metadata Collection - Manages calls to the OMRS REST Repository Services in a remote open metadata repository.","title":"Local repository services"},{"location":"services/omrs/overview/#event-management-services","text":"Isn't this a fifth subsystem? The event management services are not illustrated in the overview of OMRS subsystems as we do not consider them to be one of the major subsystems that can be used on its own. It is nonetheless a subsystem of the OMRS , and hence is described here for completeness -- you will also see it illustrated further below in the component-level diagram in the purple box. The event management services provide event passing: Inbound event passing from the cohort services to the optional local repository services and enterprise repository services. Outbound event passing from the local repository services to the optional cohort services and enterprise repository services. The event management services ensure that the other subsystems do not need to be aware of whether the other subsystems are active or not. The event management services include the following components: OMRS Repository Event Manager - Manages the distribution of repository events (TypeDef and Instance Events) within the local server's OMRS components. OMRS Event Listener - Receives Registry and Repository (TypeDef and Instance) events from the OMRS Topic for a cohort. OMRS Event Publisher - Sends Registry and Repository (TypeDef and Instance) events to the OMRS Topic. This may be the OMRS Topic for a cohort, or the OMRS Topic used by the Open Metadata Access Services ( OMAS ).","title":"Event management services"},{"location":"services/omrs/overview/#patterns","text":"The OMRS is highly configurable and runs in every type of OMAG Server . The figures below show the different combinations.","title":"Patterns"},{"location":"services/omrs/overview/#local-repository-only","text":"The OMRS can support the OMAS 's with access to a single, local-only repository - with no connectivity to other open metadata repositories. This is what runs in a metadata server that is not connected to an open metadata repository cohort .","title":"Local repository (only)"},{"location":"services/omrs/overview/#access-services-only","text":"The OMRS can also support a server without any local repository - so that all metadata for the OMAS 's is coming through the cohort services from remote metadata repositories. This is the caller integration pattern supported by the metadata access point OMAG Server .","title":"Access services (only)"},{"location":"services/omrs/overview/#repository-proxy","text":"The OMRS can support a server where the OMAS 's are not deployed and the local repository is configured to connect as an adapter for a non-native open metadata repository. The cohort services connect this metadata repository with other members in one or more cohorts. This is called the adapter integration pattern and is used in a repository proxy OMAG Server .","title":"Repository proxy"},{"location":"services/omrs/overview/#connected-metadata-server","text":"Of course, it is also possible to run all the OMRS components together as well, supporting the OMAS 's with a local repository and connectivity to other repositories through the cohort servers. This is what runs in a metadata server that is connected to an open metadata repository cohort .","title":"Connected metadata server"},{"location":"services/omrs/overview/#administration-subsystem-alone","text":"Finally, the administration subsystem alone is active in the servers that are not cohort members , that is the Governance Servers and the view servers .","title":"Administration subsystem (alone)"},{"location":"services/omrs/overview/#omrs-components","text":"The different combinations of operation required means that the OMRS components need to be flexible and communicate with one another through well-defined interfaces so that component implementations can be swapped in and out to support different configurations.","title":"OMRS components"},{"location":"services/omrs/repository-connector/","text":"OMRS Repository Connector \u00b6 Repository Connectors make use of the Egeria meta-model to represent and communicate metadata. The OMRS Repository Connector API defines a call interface to create, search, query, update and delete metadata stored in a metadata repository. The implementation of a specific OMRS connector determines which type(s) of metadata repository it is able to access. The OMRS has three repository connector implementations that form part of the core open metadata capability for a cohort member : Enterprise Repository Connector - This connector can issue calls to multiple OMRS connectors and aggregate the results as if the metadata was stored in a single repository. This is how metadata queries are federated across open metadata repositories. Since all implementations of OMRS repository connectors have the same API, the Enterprise Repository Connector is able to work with a heterogeneous collection of repositories. Local OMRS Repository Connector - This connector wraps a \"real\" repository connector (see below) and manages events and validation for this connector. OMRS REST Repository Connector - This is the connector used by the Enterprise Repository Connector to make a direct call to another open metadata repository through the OMRS REST API . These are the \"real\" OMRS Repository Connector implementations that provide open metadata access to specific types of metadata repositories. Apache Atlas Repository Connector - This is the connector that runs in an Egeria repository proxy server, pulling in the key parts of Egeria it needs to support the open metadata standards. It calls directly to Apache Atlas's REST API interface for the metadata repository. IGC OMRS Repository Connector - This is the connector for retrieving metadata from IBM's Information Governance Catalog (aka IGC ). This connector translates the calls to its OMRS Connector API to IGC 's REST API and then translates the results of these calls to appropriate responses on its API. This connector also runs in a repository proxy server. In-memory OMRS Repository Connector - This connector provides a simple in-memory repository for testing/demos or small-scale environments where metadata is being managed remotely and cached locally. It has native support for the open metadata types an instances and so runs in a metadata server . Graph OMRS Repository Connector - This connector is provides a high functioning open metadata repository implementation built on JanusGraph. It also has native support for the open metadata types an instances and so runs in a metadata server .","title":"Repository connector"},{"location":"services/omrs/repository-connector/#omrs-repository-connector","text":"Repository Connectors make use of the Egeria meta-model to represent and communicate metadata. The OMRS Repository Connector API defines a call interface to create, search, query, update and delete metadata stored in a metadata repository. The implementation of a specific OMRS connector determines which type(s) of metadata repository it is able to access. The OMRS has three repository connector implementations that form part of the core open metadata capability for a cohort member : Enterprise Repository Connector - This connector can issue calls to multiple OMRS connectors and aggregate the results as if the metadata was stored in a single repository. This is how metadata queries are federated across open metadata repositories. Since all implementations of OMRS repository connectors have the same API, the Enterprise Repository Connector is able to work with a heterogeneous collection of repositories. Local OMRS Repository Connector - This connector wraps a \"real\" repository connector (see below) and manages events and validation for this connector. OMRS REST Repository Connector - This is the connector used by the Enterprise Repository Connector to make a direct call to another open metadata repository through the OMRS REST API . These are the \"real\" OMRS Repository Connector implementations that provide open metadata access to specific types of metadata repositories. Apache Atlas Repository Connector - This is the connector that runs in an Egeria repository proxy server, pulling in the key parts of Egeria it needs to support the open metadata standards. It calls directly to Apache Atlas's REST API interface for the metadata repository. IGC OMRS Repository Connector - This is the connector for retrieving metadata from IBM's Information Governance Catalog (aka IGC ). This connector translates the calls to its OMRS Connector API to IGC 's REST API and then translates the results of these calls to appropriate responses on its API. This connector also runs in a repository proxy server. In-memory OMRS Repository Connector - This connector provides a simple in-memory repository for testing/demos or small-scale environments where metadata is being managed remotely and cached locally. It has native support for the open metadata types an instances and so runs in a metadata server . Graph OMRS Repository Connector - This connector is provides a high functioning open metadata repository implementation built on JanusGraph. It also has native support for the open metadata types an instances and so runs in a metadata server .","title":"OMRS Repository Connector"},{"location":"services/omrs/repository-content-manager/","text":"Repository content manager \u00b6 The repository content manager provides the function of the TypeDef manager plus the implementation of many repository helper and repository validator methods.","title":"Repository content manager"},{"location":"services/omrs/repository-content-manager/#repository-content-manager","text":"The repository content manager provides the function of the TypeDef manager plus the implementation of many repository helper and repository validator methods.","title":"Repository content manager"},{"location":"services/omrs/typedef-manager/","text":"TypeDef manager \u00b6 The TypeDef manager is the component that caches and manages the validation of TypeDefs. The TypeDef manager is implemented by the repository content manager","title":"Typedef manager"},{"location":"services/omrs/typedef-manager/#typedef-manager","text":"The TypeDef manager is the component that caches and manages the validation of TypeDefs. The TypeDef manager is implemented by the repository content manager","title":"TypeDef manager"},{"location":"standards/overview/","text":"Open Metadata Specifications and Standards \u00b6 Egeria is build up with layers of open components that build on many open standards relevant to metadata management and governance. Open standards further influence the implementation of the Egeria libraries. Metadata Metamodel defines how metadata is structured and organized through an open and extensible type system. Open Metadata Types shows the pre-defined types included with Egeria. These types have been built and are loaded into a metadata server . Open Metadata Repository Cohort Event Payloads define the structure of the events that flow between members of an open metadata repository cohort . Open Metadata Archive Format - describes how to package up metadata into a portable format for back up and sharing. Open Metadata Frameworks - define the Java interfaces for building connectors and other plug-in components for Egeria.","title":"Standards"},{"location":"standards/overview/#open-metadata-specifications-and-standards","text":"Egeria is build up with layers of open components that build on many open standards relevant to metadata management and governance. Open standards further influence the implementation of the Egeria libraries. Metadata Metamodel defines how metadata is structured and organized through an open and extensible type system. Open Metadata Types shows the pre-defined types included with Egeria. These types have been built and are loaded into a metadata server . Open Metadata Repository Cohort Event Payloads define the structure of the events that flow between members of an open metadata repository cohort . Open Metadata Archive Format - describes how to package up metadata into a portable format for back up and sharing. Open Metadata Frameworks - define the Java interfaces for building connectors and other plug-in components for Egeria.","title":"Open Metadata Specifications and Standards"},{"location":"tools/development/","text":"Development Tools \u00b6 Git and GitHub \u00b6 git is an open source version control system. It is what we use to: Store all of our source code, documentation and other file-based resources. Track changes to the underlying Egeria code as the project evolves. Track issues and enhancements, and link these back to the code changes that resolve them. Collaborate on and review the issues, enhancements and code changes. As a result, it gives us a definitive source for the latest and greatest source code for Egeria itself, its history, and the rationale behind various decisions that are made over time. The Egeria project's git repositories are located on GitHub . GitHub is a free, public git service for sharing code and related files. It has a web interface to make it easier for the Egeria community to monitor the activity in the project and process new content. Repositories \u00b6 Repository Purpose egeria contains the core Egeria function along with samples, tutorials and documentation. egeria-connector-xtdb contains a plugin repository connector to use XTDB as a pluggable back-end for an Egeria metadata server . egeria-connector-hadoop-ecosystem contains connectors to integrate technologies from the Hadoop ecosystem into the open metadata ecosystem. egeria-connector-ibm-information-server contains connectors to integrate IBM Information Server into the open metadata ecosystem. data-governance contains Egeria's Guidance on Governance (GoG) as well as large media files such as presentations and movies. egeria-dev-projects contains fun projects for developers to help them learn about the Egeria technology. egeria-palisade contains content from the collaboration between the Egeria project and the Palisade project. All of these repositories are publicly visible; however, if you want to contribute new content then you need to create a GitHub account. This can be done from the top of the GitHub home page . Further information Interested to learn more? GitHub provides some great introductory guides to git . Egeria provides specific tutorials for working with Egeria's git repositories . IntelliJ IDEA \u00b6 IntelliJ IDEA by JetBrains is the Interactive Development Environment (IDE) used by most of the Egeria developers. The community edition is free to use and covers all the function needed by an Egeria developer. We provide our own tutorial for IntelliJ . Lombok Plugin \u00b6 Egeria makes use of Project Lombok . If using JetBrains IntelliJ IDEA ensure it has the required plugin configured :material-dock-window . Don't detect generated sources Also, before running a Maven build please choose Don't detect from the Generated sources folders dropdown in Preferences -> Build, Execution, Deployment -> Build Tools -> Maven -> Importing . This will avoid triggering a duplicate classes build error caused by the delombok ed sources folders being added as source folders for the Maven module. If this wasn't set when your project was initially setup, you may find that delombok directories are already present in IntelliJ's source path for some modules, leading to errors with duplicate classes. To check for any modules still refering to delombok you can run this at the command line, from your top-level source tree: Find any existing delombok source entries in IntelliJ find . -name '*.iml' | xargs -n50 grep -y delombok If you find any hits such as: ./open-metadata-implementation/access-services/data-engine/data-engine-api/data-engine-api.iml: <sourceFolder url=\"file://$MODULE_DIR$/target/delombok\" isTestSource=\"false\" /> then either remove those lines without IntelliJ running, or go into File -> Project Structure -> Modules , and remove target/delombok from the Source Folders list Explanation: in addition to importing module defintions from the Maven pom.xml , IntelliJ also tries to look for any generated source. It finds the delombok directory, causing duplicates: in fact we only use this directory for generating Javadoc of lombok-enabled modules. Switching the setting / removing these source folders prevents these duplicate classes. Apache Maven \u00b6 Apache Maven is the tool that supports our project build. This includes the code compilation, running unit tests, validating dependencies and Javadoc as well as build our distribution archive. Maven 3.5 or higher is required to build Egeria. 3.6.x or above is recommended. The Maven processing organizes the modules into a hierarchy. Each module has a pom.xml file (called the pom file ) that defines the artifact, its parent / children, dependencies and any special processing that the module builds. The top-level pom file is the pom.xml file at the root of the repository's source code directory structure. When the Maven command is run, it passes through the hierarchy of modules multiple times. Each pass processes a particular lifecycle phase of the build (to ensure, for example, Java source files are compiled before the resulting object files are packaged into a jar file). Maven repositories This processing includes locating and downloading external libraries and dependencies, typically from an online open source repository called Maven Central. The directory where these external dependencies is stored locally is called .m2 . Rebuild the project with Maven mvn clean install The building Egeria tutorial covers more details on the build process. Check if Maven is installed mvn --version Install Maven using: MacOS Install Maven through HomeBrew brew install maven RedHat Install through yum yum install maven Debian Install through apt-get apt-get install maven Windows On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for that Linux distribution. Ensure you are using version 3.5.0 or higher in order to build Egeria. Gradle \u00b6 Gradle is an alternative build tool to Maven and offers: better support for parallel builds more flexibility for build tasks breaking the link between directory structure and maven artifacts extremely fast incremental builds Our direction is for a Gradle build to replace Maven; however, that work is still underway . As such, our supported build environment remains Maven As of release 3.0, most components are building with gradle, but artifacts are not being created, and verification has not been done. Contributions to this work are welcome, as are issue reports! No gradle installation is required, as we use the 'gradle wrapper' which will automatically install gradle if needed. This reduces the setup steps, and ensure everyone runs the same version of gradle (currently 7.02 in Release 3.0). Rebuild the project with Gradle ./gradlew build","title":"Development"},{"location":"tools/development/#development-tools","text":"","title":"Development Tools"},{"location":"tools/development/#git-and-github","text":"git is an open source version control system. It is what we use to: Store all of our source code, documentation and other file-based resources. Track changes to the underlying Egeria code as the project evolves. Track issues and enhancements, and link these back to the code changes that resolve them. Collaborate on and review the issues, enhancements and code changes. As a result, it gives us a definitive source for the latest and greatest source code for Egeria itself, its history, and the rationale behind various decisions that are made over time. The Egeria project's git repositories are located on GitHub . GitHub is a free, public git service for sharing code and related files. It has a web interface to make it easier for the Egeria community to monitor the activity in the project and process new content.","title":"Git and GitHub"},{"location":"tools/development/#repositories","text":"Repository Purpose egeria contains the core Egeria function along with samples, tutorials and documentation. egeria-connector-xtdb contains a plugin repository connector to use XTDB as a pluggable back-end for an Egeria metadata server . egeria-connector-hadoop-ecosystem contains connectors to integrate technologies from the Hadoop ecosystem into the open metadata ecosystem. egeria-connector-ibm-information-server contains connectors to integrate IBM Information Server into the open metadata ecosystem. data-governance contains Egeria's Guidance on Governance (GoG) as well as large media files such as presentations and movies. egeria-dev-projects contains fun projects for developers to help them learn about the Egeria technology. egeria-palisade contains content from the collaboration between the Egeria project and the Palisade project. All of these repositories are publicly visible; however, if you want to contribute new content then you need to create a GitHub account. This can be done from the top of the GitHub home page . Further information Interested to learn more? GitHub provides some great introductory guides to git . Egeria provides specific tutorials for working with Egeria's git repositories .","title":"Repositories"},{"location":"tools/development/#intellij-idea","text":"IntelliJ IDEA by JetBrains is the Interactive Development Environment (IDE) used by most of the Egeria developers. The community edition is free to use and covers all the function needed by an Egeria developer. We provide our own tutorial for IntelliJ .","title":"IntelliJ IDEA"},{"location":"tools/development/#lombok-plugin","text":"Egeria makes use of Project Lombok . If using JetBrains IntelliJ IDEA ensure it has the required plugin configured :material-dock-window . Don't detect generated sources Also, before running a Maven build please choose Don't detect from the Generated sources folders dropdown in Preferences -> Build, Execution, Deployment -> Build Tools -> Maven -> Importing . This will avoid triggering a duplicate classes build error caused by the delombok ed sources folders being added as source folders for the Maven module. If this wasn't set when your project was initially setup, you may find that delombok directories are already present in IntelliJ's source path for some modules, leading to errors with duplicate classes. To check for any modules still refering to delombok you can run this at the command line, from your top-level source tree: Find any existing delombok source entries in IntelliJ find . -name '*.iml' | xargs -n50 grep -y delombok If you find any hits such as: ./open-metadata-implementation/access-services/data-engine/data-engine-api/data-engine-api.iml: <sourceFolder url=\"file://$MODULE_DIR$/target/delombok\" isTestSource=\"false\" /> then either remove those lines without IntelliJ running, or go into File -> Project Structure -> Modules , and remove target/delombok from the Source Folders list Explanation: in addition to importing module defintions from the Maven pom.xml , IntelliJ also tries to look for any generated source. It finds the delombok directory, causing duplicates: in fact we only use this directory for generating Javadoc of lombok-enabled modules. Switching the setting / removing these source folders prevents these duplicate classes.","title":"Lombok Plugin"},{"location":"tools/development/#apache-maven","text":"Apache Maven is the tool that supports our project build. This includes the code compilation, running unit tests, validating dependencies and Javadoc as well as build our distribution archive. Maven 3.5 or higher is required to build Egeria. 3.6.x or above is recommended. The Maven processing organizes the modules into a hierarchy. Each module has a pom.xml file (called the pom file ) that defines the artifact, its parent / children, dependencies and any special processing that the module builds. The top-level pom file is the pom.xml file at the root of the repository's source code directory structure. When the Maven command is run, it passes through the hierarchy of modules multiple times. Each pass processes a particular lifecycle phase of the build (to ensure, for example, Java source files are compiled before the resulting object files are packaged into a jar file). Maven repositories This processing includes locating and downloading external libraries and dependencies, typically from an online open source repository called Maven Central. The directory where these external dependencies is stored locally is called .m2 . Rebuild the project with Maven mvn clean install The building Egeria tutorial covers more details on the build process. Check if Maven is installed mvn --version Install Maven using: MacOS Install Maven through HomeBrew brew install maven RedHat Install through yum yum install maven Debian Install through apt-get apt-get install maven Windows On Windows, you should use Windows Subsystem for Linux Version 2 or above, install an appropriate Linux distribution, and follow the instructions for that Linux distribution. Ensure you are using version 3.5.0 or higher in order to build Egeria.","title":"Apache Maven"},{"location":"tools/development/#gradle","text":"Gradle is an alternative build tool to Maven and offers: better support for parallel builds more flexibility for build tasks breaking the link between directory structure and maven artifacts extremely fast incremental builds Our direction is for a Gradle build to replace Maven; however, that work is still underway . As such, our supported build environment remains Maven As of release 3.0, most components are building with gradle, but artifacts are not being created, and verification has not been done. Contributions to this work are welcome, as are issue reports! No gradle installation is required, as we use the 'gradle wrapper' which will automatically install gradle if needed. This reduces the setup steps, and ensure everyone runs the same version of gradle (currently 7.02 in Release 3.0). Rebuild the project with Gradle ./gradlew build","title":"Gradle"},{"location":"tools/documentation/","text":"Documentation Tools \u00b6 draw.io \u00b6 We use the free draw.io tool to produce all the diagrams for our website and presentations. Following the process outlined below, the draw.io files are stored as XML, which means it is easy to manage them in git. The tool can be run from the browser, or as a desktop tool. We recommend the desktop tool if you are doing editing of the diagrams because it supports auto-save. Opening multiple diagrams Whenever you start draw.io, it offers the choice to either open a new diagram or an existing file. On the desktop, New... means new window, and you can use it to have multiple files open at once. New diagrams \u00b6 Export new diagrams as an SVG, including a copy of the diagram The following instructions must be followed to maximize diagram maintainability. To save a new diagram, choose File -> Export as -> SVG... Ensure the Include a copy of my diagram box is ticked, and tick the Transparent Background box as well: This will ensure that: the output renders nicely at all sizes in any modern web browser (no image artifacts, especially on text) the diagram is entirely self-contained, and can continue to be edited and evolved in draw.io each diagram is version-controlled in git as its own independent XML file subsequent changes to the diagram can just directly edit this SVG file (no further Export as needed) Existing diagrams \u00b6 As indicated above, to edit existing SVG diagrams, you should be able to simply: open them directly in draw.io make any changes directly to the diagram save the file (no Export as needed) Swagger \u00b6 Swagger automatically generates a website that documents the REST APIs supported by the OMAG Server Platform . It is based on the Open API Specification (V3) . The website is found at <serverURLroot>/swagger-ui.html , where <serverURLroot> is the location of the OMAG Server Platform (for example, https://localhost:9443/swagger-ui.html ). The top of the page gives a general description of the OMAG Server Platform plus a link to more documentation. The content for this header is located in the OMAGServerPlatform.java file that provides the main() method for the OMAG Server Platform. Swagger annotations in OMAGServerPlatform.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @OpenAPIDefinition ( info = @Info ( title = \"Egeria's Open Metadata and Governance (OMAG) Server Platform\" , version = \"3.1-SNAPSHOT\" , description = \"The OMAG Server Platform provides a runtime process and platform for Open Metadata and Governance (OMAG) Services.\\n\" + \"\\n\" + \"The OMAG services are configured and activated in OMAG Servers using the Administration Services.\\n\" + \"The configuration operations of the admin services create configuration documents, one for each OMAG Server. \" + \"Inside a configuration document is the definition of which OMAG services to activate in the server. \" + \"These include the repository services (any type of server), the access services (for metadata access points \" + \"and metadata servers), governance services (for governance servers) and view services (for view servers). \" + \"Once a configuration document is defined, the OMAG Server can be started and stopped multiple times by \" + \"the admin services server instance operations. \\n\" + \"\\n\" + \"The OMAG Server Platform also supports platform services to query details of the servers running on the platform.\\n\" + \"\\n\" + \"The OMAG Server Platform can host multiple OMAG servers at any one time. \" + \"Each OMAG server is isolated within the server platform and so the OMAG server platform can be used to support multi-tenant \" + \"operation for a cloud service, \" + \"or host a variety of different OMAG Servers needed at a particular location.\\n\" + \"\\n\" + \"Click on the documentation link to find out more ...\" , license = @License ( name = \"Apache 2.0\" , url = \"https://www.apache.org/licenses/LICENSE-2.0\" ), contact = @Contact ( url = \"https://egeria.odpi.org\" , name = \"Egeria Project\" , email = \"egeria-technical-discuss@lists.lfaidata.foundation\" ) ), externalDocs = @ExternalDocumentation ( description = \"OMAG Server Platform documentation\" , url = \"https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user\" ) ) Beneath the header is a list of the platform's REST APIs. This is the definition for the operational services that are part of the administration services : The REST API operations are grouped into services by the following @Tag annotation that appears in each Spring resource bean that is part of the service. If the name of the @Tag matches then the operations in the resource beans are all part of the same service. Swagger annotations in OperationalServicesResource.java 1 2 3 4 5 @Tag ( name = \"Administration Services - Operational\" , description = \"The operational administration services support the management \" + \"of OMAG Server instances. This includes starting and stopping the servers as well as querying and changing their operational state.\" , externalDocs = @ExternalDocumentation ( description = \"Further information\" , url = \"https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user/operating-omag-server.html\" )) Further information can be provided for each operation. This is one of the operational services operations: This is added to the spring resource bean using the @Operation annotation: Swagger annotations 1 2 3 4 @Operation ( summary = \"Activate server with stored configuration document\" , description = \"Activate the named OMAG server using the appropriate configuration document found in the configuration store.\" , externalDocs = @ExternalDocumentation ( description = \"Configuration Documents\" , url = \"https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/concepts/configuration-document.html\" ))","title":"Documentation"},{"location":"tools/documentation/#documentation-tools","text":"","title":"Documentation Tools"},{"location":"tools/documentation/#drawio","text":"We use the free draw.io tool to produce all the diagrams for our website and presentations. Following the process outlined below, the draw.io files are stored as XML, which means it is easy to manage them in git. The tool can be run from the browser, or as a desktop tool. We recommend the desktop tool if you are doing editing of the diagrams because it supports auto-save. Opening multiple diagrams Whenever you start draw.io, it offers the choice to either open a new diagram or an existing file. On the desktop, New... means new window, and you can use it to have multiple files open at once.","title":"draw.io"},{"location":"tools/documentation/#new-diagrams","text":"Export new diagrams as an SVG, including a copy of the diagram The following instructions must be followed to maximize diagram maintainability. To save a new diagram, choose File -> Export as -> SVG... Ensure the Include a copy of my diagram box is ticked, and tick the Transparent Background box as well: This will ensure that: the output renders nicely at all sizes in any modern web browser (no image artifacts, especially on text) the diagram is entirely self-contained, and can continue to be edited and evolved in draw.io each diagram is version-controlled in git as its own independent XML file subsequent changes to the diagram can just directly edit this SVG file (no further Export as needed)","title":"New diagrams"},{"location":"tools/documentation/#existing-diagrams","text":"As indicated above, to edit existing SVG diagrams, you should be able to simply: open them directly in draw.io make any changes directly to the diagram save the file (no Export as needed)","title":"Existing diagrams"},{"location":"tools/documentation/#swagger","text":"Swagger automatically generates a website that documents the REST APIs supported by the OMAG Server Platform . It is based on the Open API Specification (V3) . The website is found at <serverURLroot>/swagger-ui.html , where <serverURLroot> is the location of the OMAG Server Platform (for example, https://localhost:9443/swagger-ui.html ). The top of the page gives a general description of the OMAG Server Platform plus a link to more documentation. The content for this header is located in the OMAGServerPlatform.java file that provides the main() method for the OMAG Server Platform. Swagger annotations in OMAGServerPlatform.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @OpenAPIDefinition ( info = @Info ( title = \"Egeria's Open Metadata and Governance (OMAG) Server Platform\" , version = \"3.1-SNAPSHOT\" , description = \"The OMAG Server Platform provides a runtime process and platform for Open Metadata and Governance (OMAG) Services.\\n\" + \"\\n\" + \"The OMAG services are configured and activated in OMAG Servers using the Administration Services.\\n\" + \"The configuration operations of the admin services create configuration documents, one for each OMAG Server. \" + \"Inside a configuration document is the definition of which OMAG services to activate in the server. \" + \"These include the repository services (any type of server), the access services (for metadata access points \" + \"and metadata servers), governance services (for governance servers) and view services (for view servers). \" + \"Once a configuration document is defined, the OMAG Server can be started and stopped multiple times by \" + \"the admin services server instance operations. \\n\" + \"\\n\" + \"The OMAG Server Platform also supports platform services to query details of the servers running on the platform.\\n\" + \"\\n\" + \"The OMAG Server Platform can host multiple OMAG servers at any one time. \" + \"Each OMAG server is isolated within the server platform and so the OMAG server platform can be used to support multi-tenant \" + \"operation for a cloud service, \" + \"or host a variety of different OMAG Servers needed at a particular location.\\n\" + \"\\n\" + \"Click on the documentation link to find out more ...\" , license = @License ( name = \"Apache 2.0\" , url = \"https://www.apache.org/licenses/LICENSE-2.0\" ), contact = @Contact ( url = \"https://egeria.odpi.org\" , name = \"Egeria Project\" , email = \"egeria-technical-discuss@lists.lfaidata.foundation\" ) ), externalDocs = @ExternalDocumentation ( description = \"OMAG Server Platform documentation\" , url = \"https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user\" ) ) Beneath the header is a list of the platform's REST APIs. This is the definition for the operational services that are part of the administration services : The REST API operations are grouped into services by the following @Tag annotation that appears in each Spring resource bean that is part of the service. If the name of the @Tag matches then the operations in the resource beans are all part of the same service. Swagger annotations in OperationalServicesResource.java 1 2 3 4 5 @Tag ( name = \"Administration Services - Operational\" , description = \"The operational administration services support the management \" + \"of OMAG Server instances. This includes starting and stopping the servers as well as querying and changing their operational state.\" , externalDocs = @ExternalDocumentation ( description = \"Further information\" , url = \"https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/user/operating-omag-server.html\" )) Further information can be provided for each operation. This is one of the operational services operations: This is added to the spring resource bean using the @Operation annotation: Swagger annotations 1 2 3 4 @Operation ( summary = \"Activate server with stored configuration document\" , description = \"Activate the named OMAG server using the appropriate configuration document found in the configuration store.\" , externalDocs = @ExternalDocumentation ( description = \"Configuration Documents\" , url = \"https://egeria.odpi.org/open-metadata-implementation/admin-services/docs/concepts/configuration-document.html\" ))","title":"Swagger"},{"location":"tools/runtime/","text":"Runtime Tools \u00b6 Apache Kafka \u00b6 Apache Kafka is an event bus that is used to pass events between different Egeria servers. Kafka's own QuickStart Guide covers installation and basic usage. You may alternatively wish to install Kafka using a package manager such as HomeBrew on MacOS. For Egeria, the Kafka server needs to be running a PLAINTEXT listener. From the directory where Kafka is installed, check the config/server.properties file so that the listeners and advertised.listeners are setup as follows: Example: Kafka configuration listeners=PLAINTEXT://localhost:9092 advertised.listeners=PLAINTEXT://localhost:5092 The example above uses localhost:9092 for simplicity, assuming you are running Kafka locally on the same machine where you are doing your development. If running elsewhere, replace this with a name that is fully network resolveable (i.e. by both the host running Kafka and the client machines that will connect to Kafka from other hosts). Starting Kafka: MacOS When installed via HomeBrew brew services start zookeeper brew services start kafka Linux From within the bin folder of Apache Kafka ./zookeeper-server-start.sh ../config/zookeeper.properties & rm -rf /tmp/kafka-logs/* ./kafka-server-start.sh ../config/server.properties Shutting down Kafka: MacOS When installed via HomeBrew brew services stop kafka brew services stop zookeeper Linux From within the bin folder of Apache Kafka ./kafka-server-stop.sh ./zookeeper-server-stop.sh Docker \u00b6 Docker is a simple container runtime and standard . Every day, the Egeria build processing creates a Docker image of Egeria and pushes it to the public Docker catalog called Docker Hub . This docker image provides a simple way to bring a runnable version of Egeria onto your machine without any additional dependencies aside from Docker itself. It also provides the basis for a Kubernetes deployment of Egeria. The Overview tab describes the docker container. The Tags tab shows the different releases that are available. The docker image needs a runtime to execute. It can run in the cloud using various platforms or on your machine using Docker Desktop . Docker Desktop supports running a docker image as a standalone container, or as part of group of containers started with docker-compose . Follow the instructions for you operating system. For MacOS, Docker Desktop is installed like a standard application. Once it is installed, it can be launched like any other application, such as through the launchpad / start menu. Further information If you are working through the Egeria Dojo, you can return to the guide for Day 1 of the Egeria Dojo Otherwise, use the Docker tutorial to get the image up and running in Docker. It describes how to install, set up Docker and make use of Egeria's Docker image. Kubernetes \u00b6 Kubernetes orchestrates (starts / stops / connects) different containers, such as Docker containers together so that they can be managed as a complete solution. Kubernetes is an open source project managed by the Cloud Native Computing Foundation . Egeria uses Kubernetes to run all the components in the Coco Pharmaceuticals hands-on labs . Helm \u00b6 Helm is a package manager for Kubernetes . Through Helm, a chart can be used to deploy multiple containers and other related components as a single deployable unit. This makes it one simple step to deploy what may otherwise be a complex solution composed of multiple runtimes (like Egeria's OMAG Server Platform , Apache Kafka , JupyterHub , and so on) -- without needing to obtain or download all the various runtimes, know how to operate them, and so on. The Egeria team maintains an odpi-egeria-lab Helm chart that can be used to automatically deploy all the components necessary to run through the hands-on labs . Spring \u00b6 Spring is a framework and set of annotations for building REST APIs. Spring Boot provides the server chassis (or main() method) for hosting RESTful services in a server. It is used in the OMAG Server Platform to provide the server chassis that searches for all REST API definitions to start them in a server. Spring is used in our client libraries to call REST APIs. Specifically it provides the org.springframework.web.client.RestTemplate class for formatting REST calls and parsing the responses. On the server-side, Spring provides the annotations that define how a Java method is exposed as a REST API. This includes the URL of the call, and how the parameters and responses are mapped. A REST API is typically implemented as a single Java class where each method is a different operation on the REST API. At the top of the Java class is a declaration of the URI that is common for all methods in the class. Example: declaration used for the OMRS REST APIs 1 2 @RestController @RequestMapping ( \"/open-metadata/repository-services\" ) Such a URI follows the root URL of the server: so if the server was using https://localhost:9443 , the methods are called using: https://localhost:9443/open-metadata/repository-services ... For each method / operation, the rest of the URL is defined and mapped through additional annotations. Example: operation defined through annotation 1 2 3 4 5 6 7 @GetMapping ( path = \"/metadata-collection-id\" ) public MetadataCollectionIdResponse getMetadataCollectionId () { /* * ... implementation here */ } Jupyter Notebooks \u00b6 Project Jupyter provides tools for interactive computing. In particular, we use Jupyter notebooks to provide an interactive environment for running snippets of Python code, interspersed with Markdown documentation, for our hands-on labs . A free version of the latest Jupyter Notebook support (called JupyterHub ) can be installed in various ways. Installing JupyterHub on MacOS Using HomeBrew you can simply run: brew install jupyterlab","title":"Runtime"},{"location":"tools/runtime/#runtime-tools","text":"","title":"Runtime Tools"},{"location":"tools/runtime/#apache-kafka","text":"Apache Kafka is an event bus that is used to pass events between different Egeria servers. Kafka's own QuickStart Guide covers installation and basic usage. You may alternatively wish to install Kafka using a package manager such as HomeBrew on MacOS. For Egeria, the Kafka server needs to be running a PLAINTEXT listener. From the directory where Kafka is installed, check the config/server.properties file so that the listeners and advertised.listeners are setup as follows: Example: Kafka configuration listeners=PLAINTEXT://localhost:9092 advertised.listeners=PLAINTEXT://localhost:5092 The example above uses localhost:9092 for simplicity, assuming you are running Kafka locally on the same machine where you are doing your development. If running elsewhere, replace this with a name that is fully network resolveable (i.e. by both the host running Kafka and the client machines that will connect to Kafka from other hosts). Starting Kafka: MacOS When installed via HomeBrew brew services start zookeeper brew services start kafka Linux From within the bin folder of Apache Kafka ./zookeeper-server-start.sh ../config/zookeeper.properties & rm -rf /tmp/kafka-logs/* ./kafka-server-start.sh ../config/server.properties Shutting down Kafka: MacOS When installed via HomeBrew brew services stop kafka brew services stop zookeeper Linux From within the bin folder of Apache Kafka ./kafka-server-stop.sh ./zookeeper-server-stop.sh","title":"Apache Kafka"},{"location":"tools/runtime/#docker","text":"Docker is a simple container runtime and standard . Every day, the Egeria build processing creates a Docker image of Egeria and pushes it to the public Docker catalog called Docker Hub . This docker image provides a simple way to bring a runnable version of Egeria onto your machine without any additional dependencies aside from Docker itself. It also provides the basis for a Kubernetes deployment of Egeria. The Overview tab describes the docker container. The Tags tab shows the different releases that are available. The docker image needs a runtime to execute. It can run in the cloud using various platforms or on your machine using Docker Desktop . Docker Desktop supports running a docker image as a standalone container, or as part of group of containers started with docker-compose . Follow the instructions for you operating system. For MacOS, Docker Desktop is installed like a standard application. Once it is installed, it can be launched like any other application, such as through the launchpad / start menu. Further information If you are working through the Egeria Dojo, you can return to the guide for Day 1 of the Egeria Dojo Otherwise, use the Docker tutorial to get the image up and running in Docker. It describes how to install, set up Docker and make use of Egeria's Docker image.","title":"Docker"},{"location":"tools/runtime/#kubernetes","text":"Kubernetes orchestrates (starts / stops / connects) different containers, such as Docker containers together so that they can be managed as a complete solution. Kubernetes is an open source project managed by the Cloud Native Computing Foundation . Egeria uses Kubernetes to run all the components in the Coco Pharmaceuticals hands-on labs .","title":"Kubernetes"},{"location":"tools/runtime/#helm","text":"Helm is a package manager for Kubernetes . Through Helm, a chart can be used to deploy multiple containers and other related components as a single deployable unit. This makes it one simple step to deploy what may otherwise be a complex solution composed of multiple runtimes (like Egeria's OMAG Server Platform , Apache Kafka , JupyterHub , and so on) -- without needing to obtain or download all the various runtimes, know how to operate them, and so on. The Egeria team maintains an odpi-egeria-lab Helm chart that can be used to automatically deploy all the components necessary to run through the hands-on labs .","title":"Helm"},{"location":"tools/runtime/#spring","text":"Spring is a framework and set of annotations for building REST APIs. Spring Boot provides the server chassis (or main() method) for hosting RESTful services in a server. It is used in the OMAG Server Platform to provide the server chassis that searches for all REST API definitions to start them in a server. Spring is used in our client libraries to call REST APIs. Specifically it provides the org.springframework.web.client.RestTemplate class for formatting REST calls and parsing the responses. On the server-side, Spring provides the annotations that define how a Java method is exposed as a REST API. This includes the URL of the call, and how the parameters and responses are mapped. A REST API is typically implemented as a single Java class where each method is a different operation on the REST API. At the top of the Java class is a declaration of the URI that is common for all methods in the class. Example: declaration used for the OMRS REST APIs 1 2 @RestController @RequestMapping ( \"/open-metadata/repository-services\" ) Such a URI follows the root URL of the server: so if the server was using https://localhost:9443 , the methods are called using: https://localhost:9443/open-metadata/repository-services ... For each method / operation, the rest of the URL is defined and mapped through additional annotations. Example: operation defined through annotation 1 2 3 4 5 6 7 @GetMapping ( path = \"/metadata-collection-id\" ) public MetadataCollectionIdResponse getMetadataCollectionId () { /* * ... implementation here */ }","title":"Spring"},{"location":"tools/runtime/#jupyter-notebooks","text":"Project Jupyter provides tools for interactive computing. In particular, we use Jupyter notebooks to provide an interactive environment for running snippets of Python code, interspersed with Markdown documentation, for our hands-on labs . A free version of the latest Jupyter Notebook support (called JupyterHub ) can be installed in various ways. Installing JupyterHub on MacOS Using HomeBrew you can simply run: brew install jupyterlab","title":"Jupyter Notebooks"},{"location":"tools/testing/","text":"Testing Tools \u00b6 Postman \u00b6 Postman is an interactive tool for calling REST APIs. The Egeria community uses Postman for demos and education as well as testing APIs during development. Disable SSL certificate verification Egeria by default uses secure HTTP requests ( https:// ) with a self-signed certificate. By default, Postman does not allow self-signed certificates. Any Postman users will therefore need to go into Preferences -> Settings and on the General tab, turn off SSL certificate verification or requests will fail. Further information Egeria-specific Postman tutorial . Adding Postman samples Command-line request tools \u00b6 In addition to Postman there are command line tools for calling REST APIs. curl \u00b6 The command that is most commonly available is curl . Example curl command curl --insecure -X GET https://localhost:9443/open-metadata/platform-services/users/test/server-platform/origin Disable SSL certificate verification Note that Egeria is using https:// , so if you have not replaced the provided self-signed certificate, ensure you include --insecure on any requests to skip certificate validation. HTTPie \u00b6 As an alternative to curl you might like to try HTTPie , which has more advanced functions. Disable SSL certificate verification Note that Egeria is using https:// , so if you have not replaced the provided self-signed certificate, ensure you include --verify no to any requests to skip certificate validation.","title":"Testing"},{"location":"tools/testing/#testing-tools","text":"","title":"Testing Tools"},{"location":"tools/testing/#postman","text":"Postman is an interactive tool for calling REST APIs. The Egeria community uses Postman for demos and education as well as testing APIs during development. Disable SSL certificate verification Egeria by default uses secure HTTP requests ( https:// ) with a self-signed certificate. By default, Postman does not allow self-signed certificates. Any Postman users will therefore need to go into Preferences -> Settings and on the General tab, turn off SSL certificate verification or requests will fail. Further information Egeria-specific Postman tutorial . Adding Postman samples","title":"Postman"},{"location":"tools/testing/#command-line-request-tools","text":"In addition to Postman there are command line tools for calling REST APIs.","title":"Command-line request tools"},{"location":"tools/testing/#curl","text":"The command that is most commonly available is curl . Example curl command curl --insecure -X GET https://localhost:9443/open-metadata/platform-services/users/test/server-platform/origin Disable SSL certificate verification Note that Egeria is using https:// , so if you have not replaced the provided self-signed certificate, ensure you include --insecure on any requests to skip certificate validation.","title":"curl"},{"location":"tools/testing/#httpie","text":"As an alternative to curl you might like to try HTTPie , which has more advanced functions. Disable SSL certificate verification Note that Egeria is using https:// , so if you have not replaced the provided self-signed certificate, ensure you include --verify no to any requests to skip certificate validation.","title":"HTTPie"},{"location":"types/","text":"The open metadata type system \u00b6 Knowledge about data is spread amongst many people and systems. One of the roles of a metadata repository is to provide a place where this knowledge can be collected and correlated, as automated as possible. To enable different tools and processes to populate the metadata repository we need agreement on what data should be stored and in what format (structures). The different areas of metadata that we need to support for a wide range of metadata management and governance tasks include: This metadata may be spread across different metadata repositories that each specialize in particular use cases or communities of users. Area Description Area 0 describes base types and infrastructure. This includes the root type for all open metadata entities called OpenMetadataRoot and types for Asset , DataSet , Infrastructure , Process , Referenceable , SoftwareServer and Host . Area 1 collects information from people using the data assets. It includes their use of the assets and their feedback. It also manages crowd-sourced enhancements to the metadata from other areas before it is approved and incorporated into the governance program. Area 2 describes the data assets. These are the data sources, APIs, analytics models, transformation functions and rule implementations that store and manage data. The definitions in Area 2 include connectivity information that is used by the open connector framework (and other tools) to get access to the data assets. Area 3 describes the glossary. This is the definitions of terms and concepts and how they relate to one another. Linking the concepts/terms defined in the glossary to the data assets in Area 2 defines the meaning of the data that is managed by the data assets. This is a key relationship that helps people locate and understand the data assets they are working with. Area 4 defines how the data assets should be governed. This is where the classifications, policies and rules are defined. Area 5 is where standards are established. This includes data models, schema fragments and reference data that are used to assist developers and architects in using best practice data structures and valid values as they develop new capabilities around the data assets. Area 6 provides the additional information that automated metadata discovery engines have discovered about the data assets. This includes profile information, quality scores and suggested classifications. Area 7 provides the structures for recording lineage. The following diagram provides more detail of the metadata structures in each area and how they link together: Metadata is highly interconnected Bottom left is Area 0 - the foundation of the open metadata types along with the IT infrastructure that digital systems run on such as platforms, servers and network connections. Sitting on the foundation are the assets. The base definition for Asset is in Area 0 but Area 2 (middle bottom) builds out common types of assets that an organization uses. These assets are hosted and linked to the infrastructure described in Area 0. For example, a data set could be linked to the file system description to show where it is stored. Area 5 (right middle) focuses on defining the structure of data and the standard sets of values (called reference data). The structure of data is described in schemas and these are linked to the assets that use them. Many assets have technical names. Area 3 (top middle) captures business and real world terminologies and organizes them into glossaries. The individual terms described can be linked to the technical names and labels given to the assets and the data fields described in their schemas. Area 6 (bottom right) captures additional metadata captured through automated analysis of data. These analysis results are linked to the assets that hold the data so that data professionals can evaluate the suitability of the data for different purposes. Area 7 (left middle) captures the lineage of assets from a business and technical perspective. Above that in Area 4 are the definitions that control the governance of all of the assets. Finally, Area 1 (top right) captures information about users (people, automated process) their organization, such as teams and projects, and feedback. Within each area, the definitions are broken down into numbered packages to help identify groups of related elements. The numbering system relates to the area that the elements belong to. For example, area 1 has models 0100-0199, area 2 has models 0200-299, etc. Each area's sub-models are dispersed along its range, ensuring there is space to insert additional models in the future. Understanding the models \u00b6 The diagram above shows a few fragments from the models. Each of the UML classes represents an open metadata type. The stereotype on the UML class in the double angle brackets of entity , relationship and classification defines the category of type . The line between entities with the big arrow head means \"inheritance\". A type points to its supertype. The example on the left comes from model 0010 It shows that Asset inherits from Referenceable which inherits from OpenMetadataRoot . This means that Asset is a subtype of Referenceable , which is a subtype of OpenMetadataRoot . Alternatively, OpenMetadataRoot is the supertype of Referenceable , which is a supertype of Asset . This inheritance identifies which attributes (instance properties) are valid for an instance of a particular type since it is the aggregation of the attributes defined explicitly for the type and all of its supertypes. For example, Asset has two attributes defined: name and description . It also supports qualifiedName and additionalProperties because they are inherited from Referenceable . OpenMetadataRoot does not have any attributes defined so Asset gets nothing from it. The example on the right comes from model 0011 It shows the classification called Template that can be connected to a Referenceable . Since Referenceable is already defined in model 0010, it is shown without the white box where the attributes are show (called the \"attribute container\" in UML parlance). SourcedFrom is a relationship that connects two instances of Referenceable and any of its subtypes. This means SourcedFrom could connect two instances of type Asset together. The types of the instances connected do not need to be the same - SourcedFrom could connect a Referenceable instance with an Asset instance. The UML model diagrams show the currently active types. Some types and attributes have been deprecated and these have been removed from the model diagrams. However, there is a description of the deprecated types and which of the active types to use instead. Although the deprecated types can be used (for backwards compatibility) it is always preferable to use the latest types since they are typically more efficient and more consistent than their predecessors. Attribute type definitions \u00b6 The properties defined on each open metadata type will be one of the following attribute types: object boolean byte char short int long float double biginteger bigdecimal string date map<string,string> map<string,boolean> map<string,int> map<string,long> map<string,object> array<string> array<int>","title":"Open Metadata Type System"},{"location":"types/#the-open-metadata-type-system","text":"Knowledge about data is spread amongst many people and systems. One of the roles of a metadata repository is to provide a place where this knowledge can be collected and correlated, as automated as possible. To enable different tools and processes to populate the metadata repository we need agreement on what data should be stored and in what format (structures). The different areas of metadata that we need to support for a wide range of metadata management and governance tasks include: This metadata may be spread across different metadata repositories that each specialize in particular use cases or communities of users. Area Description Area 0 describes base types and infrastructure. This includes the root type for all open metadata entities called OpenMetadataRoot and types for Asset , DataSet , Infrastructure , Process , Referenceable , SoftwareServer and Host . Area 1 collects information from people using the data assets. It includes their use of the assets and their feedback. It also manages crowd-sourced enhancements to the metadata from other areas before it is approved and incorporated into the governance program. Area 2 describes the data assets. These are the data sources, APIs, analytics models, transformation functions and rule implementations that store and manage data. The definitions in Area 2 include connectivity information that is used by the open connector framework (and other tools) to get access to the data assets. Area 3 describes the glossary. This is the definitions of terms and concepts and how they relate to one another. Linking the concepts/terms defined in the glossary to the data assets in Area 2 defines the meaning of the data that is managed by the data assets. This is a key relationship that helps people locate and understand the data assets they are working with. Area 4 defines how the data assets should be governed. This is where the classifications, policies and rules are defined. Area 5 is where standards are established. This includes data models, schema fragments and reference data that are used to assist developers and architects in using best practice data structures and valid values as they develop new capabilities around the data assets. Area 6 provides the additional information that automated metadata discovery engines have discovered about the data assets. This includes profile information, quality scores and suggested classifications. Area 7 provides the structures for recording lineage. The following diagram provides more detail of the metadata structures in each area and how they link together: Metadata is highly interconnected Bottom left is Area 0 - the foundation of the open metadata types along with the IT infrastructure that digital systems run on such as platforms, servers and network connections. Sitting on the foundation are the assets. The base definition for Asset is in Area 0 but Area 2 (middle bottom) builds out common types of assets that an organization uses. These assets are hosted and linked to the infrastructure described in Area 0. For example, a data set could be linked to the file system description to show where it is stored. Area 5 (right middle) focuses on defining the structure of data and the standard sets of values (called reference data). The structure of data is described in schemas and these are linked to the assets that use them. Many assets have technical names. Area 3 (top middle) captures business and real world terminologies and organizes them into glossaries. The individual terms described can be linked to the technical names and labels given to the assets and the data fields described in their schemas. Area 6 (bottom right) captures additional metadata captured through automated analysis of data. These analysis results are linked to the assets that hold the data so that data professionals can evaluate the suitability of the data for different purposes. Area 7 (left middle) captures the lineage of assets from a business and technical perspective. Above that in Area 4 are the definitions that control the governance of all of the assets. Finally, Area 1 (top right) captures information about users (people, automated process) their organization, such as teams and projects, and feedback. Within each area, the definitions are broken down into numbered packages to help identify groups of related elements. The numbering system relates to the area that the elements belong to. For example, area 1 has models 0100-0199, area 2 has models 0200-299, etc. Each area's sub-models are dispersed along its range, ensuring there is space to insert additional models in the future.","title":"The open metadata type system"},{"location":"types/#understanding-the-models","text":"The diagram above shows a few fragments from the models. Each of the UML classes represents an open metadata type. The stereotype on the UML class in the double angle brackets of entity , relationship and classification defines the category of type . The line between entities with the big arrow head means \"inheritance\". A type points to its supertype. The example on the left comes from model 0010 It shows that Asset inherits from Referenceable which inherits from OpenMetadataRoot . This means that Asset is a subtype of Referenceable , which is a subtype of OpenMetadataRoot . Alternatively, OpenMetadataRoot is the supertype of Referenceable , which is a supertype of Asset . This inheritance identifies which attributes (instance properties) are valid for an instance of a particular type since it is the aggregation of the attributes defined explicitly for the type and all of its supertypes. For example, Asset has two attributes defined: name and description . It also supports qualifiedName and additionalProperties because they are inherited from Referenceable . OpenMetadataRoot does not have any attributes defined so Asset gets nothing from it. The example on the right comes from model 0011 It shows the classification called Template that can be connected to a Referenceable . Since Referenceable is already defined in model 0010, it is shown without the white box where the attributes are show (called the \"attribute container\" in UML parlance). SourcedFrom is a relationship that connects two instances of Referenceable and any of its subtypes. This means SourcedFrom could connect two instances of type Asset together. The types of the instances connected do not need to be the same - SourcedFrom could connect a Referenceable instance with an Asset instance. The UML model diagrams show the currently active types. Some types and attributes have been deprecated and these have been removed from the model diagrams. However, there is a description of the deprecated types and which of the active types to use instead. Although the deprecated types can be used (for backwards compatibility) it is always preferable to use the latest types since they are typically more efficient and more consistent than their predecessors.","title":"Understanding the models"},{"location":"types/#attribute-type-definitions","text":"The properties defined on each open metadata type will be one of the following attribute types: object boolean byte char short int long float double biginteger bigdecimal string date map<string,string> map<string,boolean> map<string,int> map<string,long> map<string,object> array<string> array<int>","title":"Attribute type definitions"},{"location":"types/0/","text":"Area 0 Models - Common Definitions and Infrastructure \u00b6 Area 0 describes base types and infrastructure. This includes types for Asset , DataSet , Infrastructure , Process , Referenceable , Server and Host . 0010 Base Model 0011 Managing Referenceables 0012 Search Keywords 0015 Linked Media Types 0017 External Identifiers 0019 More Information 0020 Property Facets 0021 Collections 0025 Locations 0026 Endpoints 0030 Hosts and Platforms 0035 Complex Hosts 0036 Storage 0037 Software Server Platforms 0040 Software Servers 0042 Software Server Capabilities 0045 Servers and Assets 0050 Applications and Processes 0055 Data Processing Engines 0057 Integration Capabilities 0070 Networks and Gateways 0090 Cloud Platforms and Services","title":"Area 0 Base"},{"location":"types/0/#area-0-models-common-definitions-and-infrastructure","text":"Area 0 describes base types and infrastructure. This includes types for Asset , DataSet , Infrastructure , Process , Referenceable , Server and Host . 0010 Base Model 0011 Managing Referenceables 0012 Search Keywords 0015 Linked Media Types 0017 External Identifiers 0019 More Information 0020 Property Facets 0021 Collections 0025 Locations 0026 Endpoints 0030 Hosts and Platforms 0035 Complex Hosts 0036 Storage 0037 Software Server Platforms 0040 Software Servers 0042 Software Server Capabilities 0045 Servers and Assets 0050 Applications and Processes 0055 Data Processing Engines 0057 Integration Capabilities 0070 Networks and Gateways 0090 Cloud Platforms and Services","title":"Area 0 Models - Common Definitions and Infrastructure"},{"location":"types/0/0010-base-model/","text":"0010 Base model \u00b6 OpenMetadataRoot \u00b6 OpenMetadataRoot is the root entity for all open metadata entity types. Referenceable \u00b6 Referenceable is the super type for many of the open metadata entity types. A Referenceable is something that is important enough to be assigned a unique (qualified) name within its type. This unique name is often used outside the open metadata ecosystem as its unique identifier. Referenceable also has provision for storing additional properties. This is a set of name-value pairs (i.e. a map) where the values are all strings. Further information on the use of Referenceable. Asset \u00b6 Asset represents the most significant type of Referenceable . An Asset is something (either physical or digital) that is of value and so needs to be managed and governed. Deprecated attributes The Asset entity has the following deprecated attributes. Their values have been moved to classifications as shown in the table below. Many Asset s are created by their hosting technology and locked read-only to the broader metadata ecosystem (see external metadata provenance for more detail). By moving the governance related information to a classification, it can be maintained by a different service to the Asset creator. Deprecated attribute Moved to classification owner (type string ) Ownership ownerType (type AssetOwnerType enum) Ownership zoneMembership (type array<string> ) AssetZoneMembership latestChange (type string ) LatestChange Infrastructure , Process and DataSet are examples of Asset s. Infrastructure \u00b6 Infrastructure represents both the physical and digital assets that the organization runs its business on. There is more information on Infrastructure in: 0030 Hosts and platforms 0035 Complex hosts 0037 Software server platforms 0040 Software servers 0042 Software server capabilities Process \u00b6 Process describes a well-defined set of processing steps and decisions that drive a particular aspect of the organization's business. Most Process es are automated with software (see DeployedSoftwareComponent ) but they may also be a manual procedure. An automated process can be invoked from a remote server through a DeployedAPI . DataSet \u00b6 DataSet represents a collection of related data. This data does not need to be stored together. See DataStore for the Asset that represents a physical store. More information on assets can be found in building an Asset Catalog . Anchors \u00b6 The Anchors classification is used internally by the open metadata ecosystem to optimize the lookup of the entity at the root of a cluster of elements that represents a larger object. Currently, there is support for objects uniquely \"owned\" by an asset to store the GUID of that asset. Further information on the use of Anchors. Memento \u00b6 Finally, the Memento classification identifies that the Referenceable refers to a real-world asset/artifact that has either been deleted or archived offline. The metadata element has been retained to show its role in the lineage of other assets/artifacts . The properties in this classification identifies the archive processing and any information that helps to locate the asset/artifact in the archive (if applicable).","title":"Base Model"},{"location":"types/0/0010-base-model/#0010-base-model","text":"","title":"0010 Base model"},{"location":"types/0/0010-base-model/#openmetadataroot","text":"OpenMetadataRoot is the root entity for all open metadata entity types.","title":"OpenMetadataRoot"},{"location":"types/0/0010-base-model/#referenceable","text":"Referenceable is the super type for many of the open metadata entity types. A Referenceable is something that is important enough to be assigned a unique (qualified) name within its type. This unique name is often used outside the open metadata ecosystem as its unique identifier. Referenceable also has provision for storing additional properties. This is a set of name-value pairs (i.e. a map) where the values are all strings. Further information on the use of Referenceable.","title":"Referenceable"},{"location":"types/0/0010-base-model/#asset","text":"Asset represents the most significant type of Referenceable . An Asset is something (either physical or digital) that is of value and so needs to be managed and governed. Deprecated attributes The Asset entity has the following deprecated attributes. Their values have been moved to classifications as shown in the table below. Many Asset s are created by their hosting technology and locked read-only to the broader metadata ecosystem (see external metadata provenance for more detail). By moving the governance related information to a classification, it can be maintained by a different service to the Asset creator. Deprecated attribute Moved to classification owner (type string ) Ownership ownerType (type AssetOwnerType enum) Ownership zoneMembership (type array<string> ) AssetZoneMembership latestChange (type string ) LatestChange Infrastructure , Process and DataSet are examples of Asset s.","title":"Asset"},{"location":"types/0/0010-base-model/#infrastructure","text":"Infrastructure represents both the physical and digital assets that the organization runs its business on. There is more information on Infrastructure in: 0030 Hosts and platforms 0035 Complex hosts 0037 Software server platforms 0040 Software servers 0042 Software server capabilities","title":"Infrastructure"},{"location":"types/0/0010-base-model/#process","text":"Process describes a well-defined set of processing steps and decisions that drive a particular aspect of the organization's business. Most Process es are automated with software (see DeployedSoftwareComponent ) but they may also be a manual procedure. An automated process can be invoked from a remote server through a DeployedAPI .","title":"Process"},{"location":"types/0/0010-base-model/#dataset","text":"DataSet represents a collection of related data. This data does not need to be stored together. See DataStore for the Asset that represents a physical store. More information on assets can be found in building an Asset Catalog .","title":"DataSet"},{"location":"types/0/0010-base-model/#anchors","text":"The Anchors classification is used internally by the open metadata ecosystem to optimize the lookup of the entity at the root of a cluster of elements that represents a larger object. Currently, there is support for objects uniquely \"owned\" by an asset to store the GUID of that asset. Further information on the use of Anchors.","title":"Anchors"},{"location":"types/0/0010-base-model/#memento","text":"Finally, the Memento classification identifies that the Referenceable refers to a real-world asset/artifact that has either been deleted or archived offline. The metadata element has been retained to show its role in the lineage of other assets/artifacts . The properties in this classification identifies the archive processing and any information that helps to locate the asset/artifact in the archive (if applicable).","title":"Memento"},{"location":"types/0/0011-managing-referenceables/","text":"0011 Managing Referenceables \u00b6 Referenceable s can have chains of related feedback and additional knowledge attached to them. The following types help a metadata manager to process these collections of elements more efficiently. LatestChange \u00b6 The LatestChange classification is a convenience mechanism to indicate where the last change occurred. Components that are monitoring Referenceable s can use the open metadata events related to classifications to maintain a complete picture of the asset. Template \u00b6 The Template classification indicates that a Referenceable is a good element be used as a template when creating a new element of the same type. There is no restriction on using Referenceable s without this classification as templates. The Template classification is simply a useful marker to enable templates to be found. SourcedFrom \u00b6 When one Referenceable is created by using another Referencable as a template, the qualifiedName must be changed in the new Referenceable to give it a unique name - often the displayName changes, too. This makes it hard to identify which Referenceable s have been created from a template. The SourcedFrom relationship is used to show the provenance of the information from the template. This is useful to help trace where information has come from and to help understand any potential impact cause by a change to the template if this change also needs to be made to the elements that were copied from it. Deprecated types LastAttachment - use LatestChange instead LastAttachmentLink - use LatestChange instead Further information Cataloguing assets Using templates","title":"Managing Referenceables"},{"location":"types/0/0011-managing-referenceables/#0011-managing-referenceables","text":"Referenceable s can have chains of related feedback and additional knowledge attached to them. The following types help a metadata manager to process these collections of elements more efficiently.","title":"0011 Managing Referenceables"},{"location":"types/0/0011-managing-referenceables/#latestchange","text":"The LatestChange classification is a convenience mechanism to indicate where the last change occurred. Components that are monitoring Referenceable s can use the open metadata events related to classifications to maintain a complete picture of the asset.","title":"LatestChange"},{"location":"types/0/0011-managing-referenceables/#template","text":"The Template classification indicates that a Referenceable is a good element be used as a template when creating a new element of the same type. There is no restriction on using Referenceable s without this classification as templates. The Template classification is simply a useful marker to enable templates to be found.","title":"Template"},{"location":"types/0/0011-managing-referenceables/#sourcedfrom","text":"When one Referenceable is created by using another Referencable as a template, the qualifiedName must be changed in the new Referenceable to give it a unique name - often the displayName changes, too. This makes it hard to identify which Referenceable s have been created from a template. The SourcedFrom relationship is used to show the provenance of the information from the template. This is useful to help trace where information has come from and to help understand any potential impact cause by a change to the template if this change also needs to be made to the elements that were copied from it. Deprecated types LastAttachment - use LatestChange instead LastAttachmentLink - use LatestChange instead Further information Cataloguing assets Using templates","title":"SourcedFrom"},{"location":"types/0/0012-search-keywords/","text":"0012 - Search Keywords \u00b6 Some Referenceable s such as GlossaryTerm s have a lot of text in their definitions, making them easy to find using search strings. Asset definitions, on the other hand, typically have less text. Even the schema associated with the asset might only contain technical terms, and they are often abbreviated. The result is that assets can be hard for consumers to find. It is possible to link assets and schemas to glossary terms to make them findable by association. However, this linkage is a formal semantic relationship. Consumers of the assets can add InformalTag s to the assets and schemas, but only once they have found them. The search keywords provide a mechanism to allow the asset owner to tag the asset - and linked elements such as the schema - with a variety of keywords that can be matched during a search. This helps to boost relevant assets to the top of the search results. SearchKeyword \u00b6 The SearchKeyword entity stores the definition of the search keyword. SearchKeywordLink \u00b6 The SearchKeywordLink relationship links SearchKeyword s with the asset and their associated elements. RelatedKeyword \u00b6 Related keywords can be linked together using the RelatedKeyword relationship to allow simple synonym type expansions of the search. Further information Search keywords can be added manually through the Asset Owner OMAS . Some files such as documents and photos may have keywords embedded in them. These can be automatically discovered through metadata discovery and stored in their corresponding asset properties using these same search keyword elements.","title":"Search Keywords"},{"location":"types/0/0012-search-keywords/#0012-search-keywords","text":"Some Referenceable s such as GlossaryTerm s have a lot of text in their definitions, making them easy to find using search strings. Asset definitions, on the other hand, typically have less text. Even the schema associated with the asset might only contain technical terms, and they are often abbreviated. The result is that assets can be hard for consumers to find. It is possible to link assets and schemas to glossary terms to make them findable by association. However, this linkage is a formal semantic relationship. Consumers of the assets can add InformalTag s to the assets and schemas, but only once they have found them. The search keywords provide a mechanism to allow the asset owner to tag the asset - and linked elements such as the schema - with a variety of keywords that can be matched during a search. This helps to boost relevant assets to the top of the search results.","title":"0012 - Search Keywords"},{"location":"types/0/0012-search-keywords/#searchkeyword","text":"The SearchKeyword entity stores the definition of the search keyword.","title":"SearchKeyword"},{"location":"types/0/0012-search-keywords/#searchkeywordlink","text":"The SearchKeywordLink relationship links SearchKeyword s with the asset and their associated elements.","title":"SearchKeywordLink"},{"location":"types/0/0012-search-keywords/#relatedkeyword","text":"Related keywords can be linked together using the RelatedKeyword relationship to allow simple synonym type expansions of the search. Further information Search keywords can be added manually through the Asset Owner OMAS . Some files such as documents and photos may have keywords embedded in them. These can be automatically discovered through metadata discovery and stored in their corresponding asset properties using these same search keyword elements.","title":"RelatedKeyword"},{"location":"types/0/0015-linked-media-types/","text":"0015 Linked Media Types \u00b6 Linked media types describe the simple structures that are used repeatedly in open metadata to connect it to documents and entities in other types of repositories. ExternalReference \u00b6 ExternalReference s link metadata to elements in external repositories. RelatedMedia \u00b6 RelatedMedia such as images allow an icon, thumbnail and larger images to be associated with a metadata element. They are intended to be displayed with the metadata content. These images enrich the description of the object and may include, for example, design drawings, photographs or illustrations of the component in action.","title":"Linked Media"},{"location":"types/0/0015-linked-media-types/#0015-linked-media-types","text":"Linked media types describe the simple structures that are used repeatedly in open metadata to connect it to documents and entities in other types of repositories.","title":"0015 Linked Media Types"},{"location":"types/0/0015-linked-media-types/#externalreference","text":"ExternalReference s link metadata to elements in external repositories.","title":"ExternalReference"},{"location":"types/0/0015-linked-media-types/#relatedmedia","text":"RelatedMedia such as images allow an icon, thumbnail and larger images to be associated with a metadata element. They are intended to be displayed with the metadata content. These images enrich the description of the object and may include, for example, design drawings, photographs or illustrations of the component in action.","title":"RelatedMedia"},{"location":"types/0/0017-external-identifiers/","text":"0017 External Identifiers \u00b6 External identifiers are used to correlate the identifiers used in third party metadata catalogs with open metadata elements. ExternalId \u00b6 The ExternalId entity describes an external identifier from a specific third party metadata repository. It includes: The identifier value itself in identifier . The pattern used for the identifier (how it is generated and managed) is stored in keyPattern . These are the values it can take, with the default (and most used) being LOCAL_KEY : Value Meaning LOCAL_KEY Unique key allocated and used within the scope of a single system. RECYCLED_KEY Key allocated and used within the scope of a single system that is periodically reused for different records. NATURAL_KEY Key derived from an attribute of the entity, such as email address, passport number. MIRROR_KEY Key value copied from another system. AGGREGATE_KEY Key formed by combining keys from multiple systems. CALLERS_KEY Key from another system can bey used if system name provided. STABLE_KEY Key value will remain active even if records are merged. OTHER Another key pattern. ExternalIdLink \u00b6 The mapping of identifiers can be many-to-many, which is why you see that the ExternalIdLink relationship between the OpenMetadataRoot (open metadata resources) and the ExternalId is also many-to-many. This relationship includes properties to help to map the OpenMetadataRoot to the external identifier. ExternalIdScope \u00b6 There is no guarantee that external identifiers from a third party metadata catalog are globally unique and so the ExternalIdScope relationship links the external identifier to the Referenceable that represents the third party metadata catalog. Typically, this is a type of SoftwareServerCapability , for example, AssetManager . Further information There is an article on managing external identifiers to correlate metadata elements from different types of technologies.","title":"External Identifiers"},{"location":"types/0/0017-external-identifiers/#0017-external-identifiers","text":"External identifiers are used to correlate the identifiers used in third party metadata catalogs with open metadata elements.","title":"0017 External Identifiers"},{"location":"types/0/0017-external-identifiers/#externalid","text":"The ExternalId entity describes an external identifier from a specific third party metadata repository. It includes: The identifier value itself in identifier . The pattern used for the identifier (how it is generated and managed) is stored in keyPattern . These are the values it can take, with the default (and most used) being LOCAL_KEY : Value Meaning LOCAL_KEY Unique key allocated and used within the scope of a single system. RECYCLED_KEY Key allocated and used within the scope of a single system that is periodically reused for different records. NATURAL_KEY Key derived from an attribute of the entity, such as email address, passport number. MIRROR_KEY Key value copied from another system. AGGREGATE_KEY Key formed by combining keys from multiple systems. CALLERS_KEY Key from another system can bey used if system name provided. STABLE_KEY Key value will remain active even if records are merged. OTHER Another key pattern.","title":"ExternalId"},{"location":"types/0/0017-external-identifiers/#externalidlink","text":"The mapping of identifiers can be many-to-many, which is why you see that the ExternalIdLink relationship between the OpenMetadataRoot (open metadata resources) and the ExternalId is also many-to-many. This relationship includes properties to help to map the OpenMetadataRoot to the external identifier.","title":"ExternalIdLink"},{"location":"types/0/0017-external-identifiers/#externalidscope","text":"There is no guarantee that external identifiers from a third party metadata catalog are globally unique and so the ExternalIdScope relationship links the external identifier to the Referenceable that represents the third party metadata catalog. Typically, this is a type of SoftwareServerCapability , for example, AssetManager . Further information There is an article on managing external identifiers to correlate metadata elements from different types of technologies.","title":"ExternalIdScope"},{"location":"types/0/0019-more-information/","text":"0019 More Information \u00b6 MoreInformation \u00b6 The MoreInformation relationship enables Referenceable s of different subtypes to be associated in a way that indicates that one provides more detail about another. It can be used to show linkage between a glossary and the primary top level category, between a glossary term and its implementation. It is a looser association that a relationship such as SemanticAssignment . The Asset Manager OMAS makes use of this relationship to link an asset to a glossary term that is providing supplementary properties to the asset.","title":"More Information"},{"location":"types/0/0019-more-information/#0019-more-information","text":"","title":"0019 More Information"},{"location":"types/0/0019-more-information/#moreinformation","text":"The MoreInformation relationship enables Referenceable s of different subtypes to be associated in a way that indicates that one provides more detail about another. It can be used to show linkage between a glossary and the primary top level category, between a glossary term and its implementation. It is a looser association that a relationship such as SemanticAssignment . The Asset Manager OMAS makes use of this relationship to link an asset to a glossary term that is providing supplementary properties to the asset.","title":"MoreInformation"},{"location":"types/0/0020-property-facets/","text":"0020 Property Facets \u00b6 Property facets allow any entity to be extended with additional properties. This is particularly useful for storing metadata that originated in another type of metadata repository or tool, since it allows vendor-/tool-specific values to be stored. PropertyFacet \u00b6 The PropertyFacet entity describes the additional properties. ReferenceableFacet \u00b6 The ReferenceableFacet relationship indicates the source of the additional properties.","title":"Property Facets"},{"location":"types/0/0020-property-facets/#0020-property-facets","text":"Property facets allow any entity to be extended with additional properties. This is particularly useful for storing metadata that originated in another type of metadata repository or tool, since it allows vendor-/tool-specific values to be stored.","title":"0020 Property Facets"},{"location":"types/0/0020-property-facets/#propertyfacet","text":"The PropertyFacet entity describes the additional properties.","title":"PropertyFacet"},{"location":"types/0/0020-property-facets/#referenceablefacet","text":"The ReferenceableFacet relationship indicates the source of the additional properties.","title":"ReferenceableFacet"},{"location":"types/0/0021-collections/","text":"0021 Collections \u00b6 Collection \u00b6 Collection s provide a general mechanism for grouping resources together. Classifications \u00b6 The classifications associated with Collection allow it to be specialized for particular uses.","title":"Collections"},{"location":"types/0/0021-collections/#0021-collections","text":"","title":"0021 Collections"},{"location":"types/0/0021-collections/#collection","text":"Collection s provide a general mechanism for grouping resources together.","title":"Collection"},{"location":"types/0/0021-collections/#classifications","text":"The classifications associated with Collection allow it to be specialized for particular uses.","title":"Classifications"},{"location":"types/0/0025-locations/","text":"0025 Locations \u00b6 It is important to understand where assets are located to ensure they are properly protected and comply with data sovereignty laws. The open metadata model allows location information to be captured at many levels of granularity. NestedLocation \u00b6 The NestedLocation relationship allows hierarchical groupings of locations to be represented. Notice that locations can be organized into multiple hierarchies. AdjacentLocation \u00b6 The AdjacentLocation relationship links locations that touch one another. Classifications \u00b6 The notion of a location is variable, and the classifications help to clarify the nature of the location. FixedLocation \u00b6 FixedLocation means that the location represents a physical place where, for example, Host s , servers and hence data may be located. This could be an area of a data center, the building the data center is located in, or even the country where the server/data is located. The physical location may be defined using a postal address or coordinates. The coordinates should be accompanied by the type of map projection used. For example, Goode's Homolosine Equal Area Projection, Mercator Projection, Gall-Peters Projection, Miller Cylindrical Projection, Mollweide Projection, Sinusoidal EqualArea Projection or Robinson Projection. SecureLocation \u00b6 SecureLocation indicates that there is restricted access to the location. This can include a description of the type of security. CyberLocation \u00b6 CyberLocation means that the location describes something in cyberspace. It may include the network address of this location.","title":"Locations"},{"location":"types/0/0025-locations/#0025-locations","text":"It is important to understand where assets are located to ensure they are properly protected and comply with data sovereignty laws. The open metadata model allows location information to be captured at many levels of granularity.","title":"0025 Locations"},{"location":"types/0/0025-locations/#nestedlocation","text":"The NestedLocation relationship allows hierarchical groupings of locations to be represented. Notice that locations can be organized into multiple hierarchies.","title":"NestedLocation"},{"location":"types/0/0025-locations/#adjacentlocation","text":"The AdjacentLocation relationship links locations that touch one another.","title":"AdjacentLocation"},{"location":"types/0/0025-locations/#classifications","text":"The notion of a location is variable, and the classifications help to clarify the nature of the location.","title":"Classifications"},{"location":"types/0/0025-locations/#fixedlocation","text":"FixedLocation means that the location represents a physical place where, for example, Host s , servers and hence data may be located. This could be an area of a data center, the building the data center is located in, or even the country where the server/data is located. The physical location may be defined using a postal address or coordinates. The coordinates should be accompanied by the type of map projection used. For example, Goode's Homolosine Equal Area Projection, Mercator Projection, Gall-Peters Projection, Miller Cylindrical Projection, Mollweide Projection, Sinusoidal EqualArea Projection or Robinson Projection.","title":"FixedLocation"},{"location":"types/0/0025-locations/#securelocation","text":"SecureLocation indicates that there is restricted access to the location. This can include a description of the type of security.","title":"SecureLocation"},{"location":"types/0/0025-locations/#cyberlocation","text":"CyberLocation means that the location describes something in cyberspace. It may include the network address of this location.","title":"CyberLocation"},{"location":"types/0/0026-endpoints/","text":"0026 Endpoints \u00b6 Endpoint \u00b6 Endpoint s capture the network information needed to connect to a service. There is a wide variety of approaches to identifying the endpoint and so its properties will depend on how it is being used. Endpoints are part of a Connection . The connection provides the information to create an instance of a connector that is accessing a remote asset. In this situation the networkAddress is set up to the URL needed to connect to the specific asset. ServerEndpoint \u00b6 Endpoints can also be linked to infrastructure elements using the ServerEndpoint relationship to document their network address(s). These are often the values needed in the connection objects configured for integration connectors running in an integration daemon and so the endpoint can be looked up either as the integration connector is being configured, or dynamically when the integration connector is running. Endpoint examples The following picture illustrates the different uses of Endpoint . The top of the diagram shows the endpoint as part of a connection object used to create a connector to the real resource described by the Asset s shown in green. In the middle is an Endpoint tied to a SoftwareServerPlatform that is hosting assets. This endpoint can be queried when configuring integration connectors that are to connect to the platform and catalog the resources (assets) it is hosting. Finally, the VisibleEndpoint and NetworkEndpoint relationships shown at the bottom of the diagram help to document the visibility of an endpoint to a particular network and the host behind it.","title":"Endpoints"},{"location":"types/0/0026-endpoints/#0026-endpoints","text":"","title":"0026 Endpoints"},{"location":"types/0/0026-endpoints/#endpoint","text":"Endpoint s capture the network information needed to connect to a service. There is a wide variety of approaches to identifying the endpoint and so its properties will depend on how it is being used. Endpoints are part of a Connection . The connection provides the information to create an instance of a connector that is accessing a remote asset. In this situation the networkAddress is set up to the URL needed to connect to the specific asset.","title":"Endpoint"},{"location":"types/0/0026-endpoints/#serverendpoint","text":"Endpoints can also be linked to infrastructure elements using the ServerEndpoint relationship to document their network address(s). These are often the values needed in the connection objects configured for integration connectors running in an integration daemon and so the endpoint can be looked up either as the integration connector is being configured, or dynamically when the integration connector is running. Endpoint examples The following picture illustrates the different uses of Endpoint . The top of the diagram shows the endpoint as part of a connection object used to create a connector to the real resource described by the Asset s shown in green. In the middle is an Endpoint tied to a SoftwareServerPlatform that is hosting assets. This endpoint can be queried when configuring integration connectors that are to connect to the platform and catalog the resources (assets) it is hosting. Finally, the VisibleEndpoint and NetworkEndpoint relationships shown at the bottom of the diagram help to document the visibility of an endpoint to a particular network and the host behind it.","title":"ServerEndpoint"},{"location":"types/0/0030-hosts-and-platforms/","text":"0030 Hosts and Platforms \u00b6 The host and platform metadata entities provide a simple model for the IT infrastructure (nodes, computers, etc) that data resources are hosted on. ITInfrastructure \u00b6 ITInfrastructure is a type of Asset that supports the running of software systems. Host \u00b6 In today's systems, hardware is managed to get the maximum use out of it. Therefore, the concept of a Host is abstracted to describe a deployment environment that has access to hardware and has a basic software stack, typically including the operating systems. The host can be linked to its location through the AssetLocation relationship. OperatingPlatform \u00b6 The OperatingPlatform is an informational structure to describe the hardware characteristics and software stack (operating system, etc) of the host. OperatingPlatformManifest \u00b6 Details of the software stack can be captured in a Collection linked to the operating platform using the OperatingPlatformManifest . The collection may contain different types of details such as configuration files and software packages that can be organized into nested collections. SoftwarePackageManifest \u00b6 Collections that list software packages can be classified with the SoftwarePackageManifest classification. Many hosts could have the same operating platform. This means it can be used to represent standardized software stacks and which hosts they have been deployed to. Pipelines that manage the software stacks on these machines can use these elements to manage the rollout and update of the different software packages. Further information 0035 Complex Hosts describes how hardware is virtualized. 0037 Software Server Platform describes the software process that run on a host.","title":"Hosts and Platforms"},{"location":"types/0/0030-hosts-and-platforms/#0030-hosts-and-platforms","text":"The host and platform metadata entities provide a simple model for the IT infrastructure (nodes, computers, etc) that data resources are hosted on.","title":"0030 Hosts and Platforms"},{"location":"types/0/0030-hosts-and-platforms/#itinfrastructure","text":"ITInfrastructure is a type of Asset that supports the running of software systems.","title":"ITInfrastructure"},{"location":"types/0/0030-hosts-and-platforms/#host","text":"In today's systems, hardware is managed to get the maximum use out of it. Therefore, the concept of a Host is abstracted to describe a deployment environment that has access to hardware and has a basic software stack, typically including the operating systems. The host can be linked to its location through the AssetLocation relationship.","title":"Host"},{"location":"types/0/0030-hosts-and-platforms/#operatingplatform","text":"The OperatingPlatform is an informational structure to describe the hardware characteristics and software stack (operating system, etc) of the host.","title":"OperatingPlatform"},{"location":"types/0/0030-hosts-and-platforms/#operatingplatformmanifest","text":"Details of the software stack can be captured in a Collection linked to the operating platform using the OperatingPlatformManifest . The collection may contain different types of details such as configuration files and software packages that can be organized into nested collections.","title":"OperatingPlatformManifest"},{"location":"types/0/0030-hosts-and-platforms/#softwarepackagemanifest","text":"Collections that list software packages can be classified with the SoftwarePackageManifest classification. Many hosts could have the same operating platform. This means it can be used to represent standardized software stacks and which hosts they have been deployed to. Pipelines that manage the software stacks on these machines can use these elements to manage the rollout and update of the different software packages. Further information 0035 Complex Hosts describes how hardware is virtualized. 0037 Software Server Platform describes the software process that run on a host.","title":"SoftwarePackageManifest"},{"location":"types/0/0035-complex-hosts/","text":"0035 Complex Hosts \u00b6 In today's systems, hardware is managed to get the maximum use out of it. Therefore, the concept of a host is typically virtualized to allow a single computer to be used for many hosts and for multiple computers to collectively support a single host. The complex hosts handle environments where many nodes are acting together as a cluster, and where virtualized containers (such as Docker) are being used. BareMetalComputer \u00b6 A BareMetalComputer describes a connected set of physical hardware. The open metadata types today do not attempt to model hardware in detail but this could be easily added if a contributor with the appropriate expertise was willing to work on it. VirtualMachine \u00b6 A VirtualMachine provides virtualized hardware through a hypervisor that allows a single physical bare metal computer to run multiple virtual machines. VirtualContainer \u00b6 A VirtualContainer provides the services of a host to the software servers deployed on it. When the server makes requests for storage, network access, etc, the VirtualContainer delegates the requests to the equivalent services of the actual host it is deployed on. VirtualContainer s can be hosted on other VirtualContainer s, but to actually run they need to ultimately be deployed onto a real physical Host . DockerContainer \u00b6 DockerContainer provides a specific type for the popular container type called docker . HostCluster \u00b6 A HostCluster describes a collection of hosts that together are providing a service. Clusters are often used to provide horizontal scaling of services. There are two specific types of host clusters defined: in both, the hosts that they manage are often referred to as nodes . Within the host cluster is typically a special host (node) that is controlling the execution of the other members. This host is modelled with a SoftwareServerPlatform that describes the cluster management platform, and a SoftwareServer that groups the SoftwareServerCapabilities needed to manage the cluster. These software server capabilities are linked to the ITInfrastructure assets that are being managed by the cluster using the ServerAssetUse relationship. HadoopCluster \u00b6 HadoopCluster describes a Hadoop cluster that uses multiple bare metal computers/virtual machines to manage big data workloads. KuberenetesCluster \u00b6 KubernetesCluster describes a Kubernetes cluster that manages containerized applications across multiple bare metal computers/virtual machines. The containerized applications managed by Kubernetes are represented as VirtualContainer s. HostedHost \u00b6 The hosts can actually be virtualized through many levels. The HostedHost relationship is used to represent the layers of virtualized hosts. HostClusterMember \u00b6 The host cluster is linked to the hosts it is managing using the HostClusterMember relationship. Deprecated types DeployedVirtualContainer - use HostedHost , which is more general.","title":"Complex Hosts"},{"location":"types/0/0035-complex-hosts/#0035-complex-hosts","text":"In today's systems, hardware is managed to get the maximum use out of it. Therefore, the concept of a host is typically virtualized to allow a single computer to be used for many hosts and for multiple computers to collectively support a single host. The complex hosts handle environments where many nodes are acting together as a cluster, and where virtualized containers (such as Docker) are being used.","title":"0035 Complex Hosts"},{"location":"types/0/0035-complex-hosts/#baremetalcomputer","text":"A BareMetalComputer describes a connected set of physical hardware. The open metadata types today do not attempt to model hardware in detail but this could be easily added if a contributor with the appropriate expertise was willing to work on it.","title":"BareMetalComputer"},{"location":"types/0/0035-complex-hosts/#virtualmachine","text":"A VirtualMachine provides virtualized hardware through a hypervisor that allows a single physical bare metal computer to run multiple virtual machines.","title":"VirtualMachine"},{"location":"types/0/0035-complex-hosts/#virtualcontainer","text":"A VirtualContainer provides the services of a host to the software servers deployed on it. When the server makes requests for storage, network access, etc, the VirtualContainer delegates the requests to the equivalent services of the actual host it is deployed on. VirtualContainer s can be hosted on other VirtualContainer s, but to actually run they need to ultimately be deployed onto a real physical Host .","title":"VirtualContainer"},{"location":"types/0/0035-complex-hosts/#dockercontainer","text":"DockerContainer provides a specific type for the popular container type called docker .","title":"DockerContainer"},{"location":"types/0/0035-complex-hosts/#hostcluster","text":"A HostCluster describes a collection of hosts that together are providing a service. Clusters are often used to provide horizontal scaling of services. There are two specific types of host clusters defined: in both, the hosts that they manage are often referred to as nodes . Within the host cluster is typically a special host (node) that is controlling the execution of the other members. This host is modelled with a SoftwareServerPlatform that describes the cluster management platform, and a SoftwareServer that groups the SoftwareServerCapabilities needed to manage the cluster. These software server capabilities are linked to the ITInfrastructure assets that are being managed by the cluster using the ServerAssetUse relationship.","title":"HostCluster"},{"location":"types/0/0035-complex-hosts/#hadoopcluster","text":"HadoopCluster describes a Hadoop cluster that uses multiple bare metal computers/virtual machines to manage big data workloads.","title":"HadoopCluster"},{"location":"types/0/0035-complex-hosts/#kuberenetescluster","text":"KubernetesCluster describes a Kubernetes cluster that manages containerized applications across multiple bare metal computers/virtual machines. The containerized applications managed by Kubernetes are represented as VirtualContainer s.","title":"KuberenetesCluster"},{"location":"types/0/0035-complex-hosts/#hostedhost","text":"The hosts can actually be virtualized through many levels. The HostedHost relationship is used to represent the layers of virtualized hosts.","title":"HostedHost"},{"location":"types/0/0035-complex-hosts/#hostclustermember","text":"The host cluster is linked to the hosts it is managing using the HostClusterMember relationship. Deprecated types DeployedVirtualContainer - use HostedHost , which is more general.","title":"HostClusterMember"},{"location":"types/0/0036-storage/","text":"0036 Storage \u00b6 It is common for the processing running on a Host to need to persist data to storage. StorageVolume \u00b6 StorageVolume describes a persistent storage volume. AttachedStorage \u00b6 AttachedStorage identifies the host(s) that the StorageVolume is connected to.","title":"Storage"},{"location":"types/0/0036-storage/#0036-storage","text":"It is common for the processing running on a Host to need to persist data to storage.","title":"0036 Storage"},{"location":"types/0/0036-storage/#storagevolume","text":"StorageVolume describes a persistent storage volume.","title":"StorageVolume"},{"location":"types/0/0036-storage/#attachedstorage","text":"AttachedStorage identifies the host(s) that the StorageVolume is connected to.","title":"AttachedStorage"},{"location":"types/0/0037-software-server-platforms/","text":"0037 Software Server Platforms \u00b6 Software servers often use a software server platform to provide many of the services they use. The OMAG Server Platform is an example of a software server platform.","title":"Software Server Platforms"},{"location":"types/0/0037-software-server-platforms/#0037-software-server-platforms","text":"Software servers often use a software server platform to provide many of the services they use. The OMAG Server Platform is an example of a software server platform.","title":"0037 Software Server Platforms"},{"location":"types/0/0040-software-servers/","text":"0040 Software Servers \u00b6 Software servers describe the middleware software servers (such as application servers, data movement engines and database servers) that run on the Host s . SoftwareServer \u00b6 Within the SoftwareServer model we capture the userId that it operates under. Most metadata repositories are run in a secure mode requiring incoming requests to include the requester's security credentials. Therefore, we have an identifier for each unique logged on security identity ( userId ). This identity is recorded within specific entities and relationships when they are created or updated. By storing the user identifier for the server, it is possible to correlate the server with the changes to the metadata (and related data assets) that it makes. Further information See model 0110 Actors and 0117 IT Profiles for details of how user identifiers are correlated with ActorProfiles for people and teams. The ITProfile makes it possible to define a profile for a server's userId so that additional information about the userId can be captured. An OMAG Server is an example of a SoftwareServer .","title":"Software Servers"},{"location":"types/0/0040-software-servers/#0040-software-servers","text":"Software servers describe the middleware software servers (such as application servers, data movement engines and database servers) that run on the Host s .","title":"0040 Software Servers"},{"location":"types/0/0040-software-servers/#softwareserver","text":"Within the SoftwareServer model we capture the userId that it operates under. Most metadata repositories are run in a secure mode requiring incoming requests to include the requester's security credentials. Therefore, we have an identifier for each unique logged on security identity ( userId ). This identity is recorded within specific entities and relationships when they are created or updated. By storing the user identifier for the server, it is possible to correlate the server with the changes to the metadata (and related data assets) that it makes. Further information See model 0110 Actors and 0117 IT Profiles for details of how user identifiers are correlated with ActorProfiles for people and teams. The ITProfile makes it possible to define a profile for a server's userId so that additional information about the userId can be captured. An OMAG Server is an example of a SoftwareServer .","title":"SoftwareServer"},{"location":"types/0/0042-software-server-capabilities/","text":"0042 Software Server Capabilities \u00b6 SoftwareServerCapability \u00b6 Within a software server are many capabilities. Different organizations and tools can choose the granularity in which the capabilities are captured in order to provide appropriate context to data assets and the decisions made around them. These are the software server capabilities defined in the open types: APIManager - A capability that manages callable APIs that typically delegate onto Software Services. Application - A capability supporting a specific business function. Catalog - A capability that manages collections of descriptions about people, places, digital assets, things, ... DataManager - A capability that manages collections of data. Engine - A programmable engine for running automated processes. WorkflowEngine - An engine capable of running a mixture of human and automated tasks as part of a workflow process. ReportingEngine - An engine capable of creating reports by combining information from multiple data sets. AnalyticsEngine - An engine capable of running analytics models using data from one or more data sets. DataMovementEngine - An engine capable of copying data from one data store to another. DataVirtualizationEngine - An engine capable of creating new data sets by dynamically combining data from one or more data stores or data sets. EventBroker - A capability that supports event-based services, typically around topics. SoftwareService s - A capability that provides externally callable functions to other services. ApplicationService - A software service that supports a reusable business function. MetadataIntegrationService - A software service that exchanges metadata between servers. MetadataAccessService - A software service that provides access to stored metadata. EngineHostingService - A software service that provides services that delegate to a hosted engine. UserViewService - A software service that provides user interfaces access to digital resources. NetworkGateway - A connection point enabling network traffic to pass between two networks. DatabaseManager - A capability that manages data organized as relational schemas. EnterpriseAccessLayer - Repository services for the Open Metadata Access Services ( OMAS ) supporting federated queries and aggregated events from the connected cohorts. CohortMember - A capability enabling a server to access an open metadata repository cohort. GovernanceEngine - A collection of related governance services of the same type. GovernanceActionEngine - A collection of related governance services supporting the Governance Action Framework ( GAF ). OpenDiscoveryEngine - A collection of related governance services supporting the Open Discovery Framework ( ODF ). In addition, it is possible to augment software server capabilities with the following classifications: CloudService - A capability enabled for a tenant on a cloud platform. ContentCollectionManager - A manager of controlled documents and related media. FileSystem - A capability that supports a store of files organized into a hierarchy of file folders for general use. FileManager - A manager of a collection of files and folders. NotificationManager - A server capability that is distributing events from a topic to its subscriber list.","title":"Software Server Capabilities"},{"location":"types/0/0042-software-server-capabilities/#0042-software-server-capabilities","text":"","title":"0042 Software Server Capabilities"},{"location":"types/0/0042-software-server-capabilities/#softwareservercapability","text":"Within a software server are many capabilities. Different organizations and tools can choose the granularity in which the capabilities are captured in order to provide appropriate context to data assets and the decisions made around them. These are the software server capabilities defined in the open types: APIManager - A capability that manages callable APIs that typically delegate onto Software Services. Application - A capability supporting a specific business function. Catalog - A capability that manages collections of descriptions about people, places, digital assets, things, ... DataManager - A capability that manages collections of data. Engine - A programmable engine for running automated processes. WorkflowEngine - An engine capable of running a mixture of human and automated tasks as part of a workflow process. ReportingEngine - An engine capable of creating reports by combining information from multiple data sets. AnalyticsEngine - An engine capable of running analytics models using data from one or more data sets. DataMovementEngine - An engine capable of copying data from one data store to another. DataVirtualizationEngine - An engine capable of creating new data sets by dynamically combining data from one or more data stores or data sets. EventBroker - A capability that supports event-based services, typically around topics. SoftwareService s - A capability that provides externally callable functions to other services. ApplicationService - A software service that supports a reusable business function. MetadataIntegrationService - A software service that exchanges metadata between servers. MetadataAccessService - A software service that provides access to stored metadata. EngineHostingService - A software service that provides services that delegate to a hosted engine. UserViewService - A software service that provides user interfaces access to digital resources. NetworkGateway - A connection point enabling network traffic to pass between two networks. DatabaseManager - A capability that manages data organized as relational schemas. EnterpriseAccessLayer - Repository services for the Open Metadata Access Services ( OMAS ) supporting federated queries and aggregated events from the connected cohorts. CohortMember - A capability enabling a server to access an open metadata repository cohort. GovernanceEngine - A collection of related governance services of the same type. GovernanceActionEngine - A collection of related governance services supporting the Governance Action Framework ( GAF ). OpenDiscoveryEngine - A collection of related governance services supporting the Open Discovery Framework ( ODF ). In addition, it is possible to augment software server capabilities with the following classifications: CloudService - A capability enabled for a tenant on a cloud platform. ContentCollectionManager - A manager of controlled documents and related media. FileSystem - A capability that supports a store of files organized into a hierarchy of file folders for general use. FileManager - A manager of a collection of files and folders. NotificationManager - A server capability that is distributing events from a topic to its subscriber list.","title":"SoftwareServerCapability"},{"location":"types/0/0045-servers-and-assets/","text":"0045 Servers and Assets \u00b6 ServerAssetUse \u00b6 Asset s are managed or consumed by SoftwareServerCapabilities , which is captured by the ServerAssetUse relationship.","title":"Servers and Assets"},{"location":"types/0/0045-servers-and-assets/#0045-servers-and-assets","text":"","title":"0045 Servers and Assets"},{"location":"types/0/0045-servers-and-assets/#serverassetuse","text":"Asset s are managed or consumed by SoftwareServerCapabilities , which is captured by the ServerAssetUse relationship.","title":"ServerAssetUse"},{"location":"types/0/0050-applications-and-processes/","text":"0050 Applications and Processes \u00b6 Application \u00b6 Application s provide business or management logic. They are often custom-built but may also be brought as a package. They are deployed onto a server as a SoftwareServerCapability . Deprecated types The RuntimeForProcess relationship is superfluous: use ServerAssetUse since Application is a SoftwareServerCapability .","title":"Applications and Processes"},{"location":"types/0/0050-applications-and-processes/#0050-applications-and-processes","text":"","title":"0050 Applications and Processes"},{"location":"types/0/0050-applications-and-processes/#application","text":"Application s provide business or management logic. They are often custom-built but may also be brought as a package. They are deployed onto a server as a SoftwareServerCapability . Deprecated types The RuntimeForProcess relationship is superfluous: use ServerAssetUse since Application is a SoftwareServerCapability .","title":"Application"},{"location":"types/0/0055-data-processing-engines/","text":"0055 Data Processing Engines \u00b6 Engine \u00b6 The Engine entity represents a programmable engine for running automated processes. Classifications \u00b6 WorkflowEngine \u00b6 The WorkflowEngine classification designates an engine as capable of running a mixture of human and automated tasks as part of a workflow process. ReportingEngine \u00b6 The ReportingEngine classification designates an engine as capable of creating reports by combining information from multiple data sets. AnalyticsEngine \u00b6 The AnalyticsEngine classification designates an engine as capable of running analytics models and using data from one or more data sets. DataMovementEngine \u00b6 The DataMovementEngine classification designates an engine as capable of copying data from one data store to another. DataVirtualizationEngine \u00b6 The DataVirtualizationEngine classification designates an engine as capable of creating new data sets by dynamically combining data from one or more data stores or data sets.","title":"Data Processing Engines"},{"location":"types/0/0055-data-processing-engines/#0055-data-processing-engines","text":"","title":"0055 Data Processing Engines"},{"location":"types/0/0055-data-processing-engines/#engine","text":"The Engine entity represents a programmable engine for running automated processes.","title":"Engine"},{"location":"types/0/0055-data-processing-engines/#classifications","text":"","title":"Classifications"},{"location":"types/0/0055-data-processing-engines/#workflowengine","text":"The WorkflowEngine classification designates an engine as capable of running a mixture of human and automated tasks as part of a workflow process.","title":"WorkflowEngine"},{"location":"types/0/0055-data-processing-engines/#reportingengine","text":"The ReportingEngine classification designates an engine as capable of creating reports by combining information from multiple data sets.","title":"ReportingEngine"},{"location":"types/0/0055-data-processing-engines/#analyticsengine","text":"The AnalyticsEngine classification designates an engine as capable of running analytics models and using data from one or more data sets.","title":"AnalyticsEngine"},{"location":"types/0/0055-data-processing-engines/#datamovementengine","text":"The DataMovementEngine classification designates an engine as capable of copying data from one data store to another.","title":"DataMovementEngine"},{"location":"types/0/0055-data-processing-engines/#datavirtualizationengine","text":"The DataVirtualizationEngine classification designates an engine as capable of creating new data sets by dynamically combining data from one or more data stores or data sets.","title":"DataVirtualizationEngine"},{"location":"types/0/0056-asset-managers/","text":"0056 Asset Managers \u00b6 AssetManager \u00b6 The AssetManager classification represents a technology that manages metadata about assets and may also provide services to manage and/or govern the assets themselves (or at least track such actions). Data catalogs and other types of metadata catalogs are examples of asset managers. Examples of asset managers Amundsen , Marquez and Apache Atlas are examples of data catalogs, and therefore of asset managers. An Egeria deployment using a metadata server and one or more integration daemons can also be enabled as an asset manager. The AssetManager classification on a SoftwareServerCapability entity is used by the Asset Manager OMAS to represent the third party asset manager that it is exchanging metadata with. Identities from this third party asset manager are linked to the AssetManager entity using the ExternalIdScope relationship. UserProfileManager \u00b6 The UserProfileManager classification describes a system that manages user profile information - such as a company directory. UserAccessManager \u00b6 The UserAccessManager classification describes a user directory such as LDAP. MasterDataManager \u00b6 A MasterDataManager classification describes a server that manages the rationalization of master data stored in many systems.","title":"0056 asset managers"},{"location":"types/0/0056-asset-managers/#0056-asset-managers","text":"","title":"0056 Asset Managers"},{"location":"types/0/0056-asset-managers/#assetmanager","text":"The AssetManager classification represents a technology that manages metadata about assets and may also provide services to manage and/or govern the assets themselves (or at least track such actions). Data catalogs and other types of metadata catalogs are examples of asset managers. Examples of asset managers Amundsen , Marquez and Apache Atlas are examples of data catalogs, and therefore of asset managers. An Egeria deployment using a metadata server and one or more integration daemons can also be enabled as an asset manager. The AssetManager classification on a SoftwareServerCapability entity is used by the Asset Manager OMAS to represent the third party asset manager that it is exchanging metadata with. Identities from this third party asset manager are linked to the AssetManager entity using the ExternalIdScope relationship.","title":"AssetManager"},{"location":"types/0/0056-asset-managers/#userprofilemanager","text":"The UserProfileManager classification describes a system that manages user profile information - such as a company directory.","title":"UserProfileManager"},{"location":"types/0/0056-asset-managers/#useraccessmanager","text":"The UserAccessManager classification describes a user directory such as LDAP.","title":"UserAccessManager"},{"location":"types/0/0056-asset-managers/#masterdatamanager","text":"A MasterDataManager classification describes a server that manages the rationalization of master data stored in many systems.","title":"MasterDataManager"},{"location":"types/0/0057-integration-capabilities/","text":"0057 Integration Capabilities \u00b6 SoftwareService \u00b6 A SoftwareService provides a well-defined software component that can be called by remote clients across the network. They may offer a request-response or an event-driven interface or both. ApplicationService \u00b6 Typically, software services implement specific business functions such as on-boarding a new customer, taking an order or sending an invoice. These are called ApplicationService s Egeria offers specialized software services related to the capture and management of open metadata. These are shown as specialist types: MetadataIntegrationService \u00b6 A MetadataIntegrationService describes an Open Metadata Integration Service ( OMIS ) that runs in an integration daemon . MetadataAccessService \u00b6 A MetadataAccessService describes an Open Metadata Access Service ( OMAS ) that runs in a metadata access point . EngineHostingService \u00b6 An EngineHostingService describes an Open Metadata Engine Service ( OMES ) that runs in an engine host . UserViewService \u00b6 A UserViewService describes an Open Metadata View Service ( OMVS ) that runs in a view server .","title":"Integration Capabilities"},{"location":"types/0/0057-integration-capabilities/#0057-integration-capabilities","text":"","title":"0057 Integration Capabilities"},{"location":"types/0/0057-integration-capabilities/#softwareservice","text":"A SoftwareService provides a well-defined software component that can be called by remote clients across the network. They may offer a request-response or an event-driven interface or both.","title":"SoftwareService"},{"location":"types/0/0057-integration-capabilities/#applicationservice","text":"Typically, software services implement specific business functions such as on-boarding a new customer, taking an order or sending an invoice. These are called ApplicationService s Egeria offers specialized software services related to the capture and management of open metadata. These are shown as specialist types:","title":"ApplicationService"},{"location":"types/0/0057-integration-capabilities/#metadataintegrationservice","text":"A MetadataIntegrationService describes an Open Metadata Integration Service ( OMIS ) that runs in an integration daemon .","title":"MetadataIntegrationService"},{"location":"types/0/0057-integration-capabilities/#metadataaccessservice","text":"A MetadataAccessService describes an Open Metadata Access Service ( OMAS ) that runs in a metadata access point .","title":"MetadataAccessService"},{"location":"types/0/0057-integration-capabilities/#enginehostingservice","text":"An EngineHostingService describes an Open Metadata Engine Service ( OMES ) that runs in an engine host .","title":"EngineHostingService"},{"location":"types/0/0057-integration-capabilities/#userviewservice","text":"A UserViewService describes an Open Metadata View Service ( OMVS ) that runs in a view server .","title":"UserViewService"},{"location":"types/0/0070-networks-and-gateways/","text":"0070 Networks and Gateways \u00b6 The network model for open metadata is very simple, to allow hosts to be grouped into the networks they are connected to. This can show details such as where hosts are isolated in private networks, and where the gateways onto the Internet are.","title":"Networks and Gateways"},{"location":"types/0/0070-networks-and-gateways/#0070-networks-and-gateways","text":"The network model for open metadata is very simple, to allow hosts to be grouped into the networks they are connected to. This can show details such as where hosts are isolated in private networks, and where the gateways onto the Internet are.","title":"0070 Networks and Gateways"},{"location":"types/0/0090-cloud-platforms-and-services/","text":"0090 Cloud Platforms and Services \u00b6 The cloud platforms and services model shows that cloud computing is not so different from what we have been doing before. Cloud infrastructure and services are classified as such to show that the organization is not completely in control of the technology supporting their data and processes. CloudProvider \u00b6 The CloudProvider is the organization that provides and runs the infrastructure for a cloud service. Typically, the host it offers is actually a HostCluster . The cloud provider may offer infrastructure as a service (IaaS), in which case, an organization can deploy VirtualContainer s onto the cloud provider's HostCluster . CloudPlatform \u00b6 If the cloud provider is offering platform as a service (PaaS), an application may deploy server capability onto the CloudPlatform . CloudService \u00b6 If the cloud provider is offering Software as a Service (SaaS) then it has provided APIs backed by pre-deployed server capability that an organization can call as a CloudService .","title":"Cloud Platforms and Services"},{"location":"types/0/0090-cloud-platforms-and-services/#0090-cloud-platforms-and-services","text":"The cloud platforms and services model shows that cloud computing is not so different from what we have been doing before. Cloud infrastructure and services are classified as such to show that the organization is not completely in control of the technology supporting their data and processes.","title":"0090 Cloud Platforms and Services"},{"location":"types/0/0090-cloud-platforms-and-services/#cloudprovider","text":"The CloudProvider is the organization that provides and runs the infrastructure for a cloud service. Typically, the host it offers is actually a HostCluster . The cloud provider may offer infrastructure as a service (IaaS), in which case, an organization can deploy VirtualContainer s onto the cloud provider's HostCluster .","title":"CloudProvider"},{"location":"types/0/0090-cloud-platforms-and-services/#cloudplatform","text":"If the cloud provider is offering platform as a service (PaaS), an application may deploy server capability onto the CloudPlatform .","title":"CloudPlatform"},{"location":"types/0/0090-cloud-platforms-and-services/#cloudservice","text":"If the cloud provider is offering Software as a Service (SaaS) then it has provided APIs backed by pre-deployed server capability that an organization can call as a CloudService .","title":"CloudService"},{"location":"types/1/","text":"Area 1 Models - Collaboration \u00b6 Area 1 collects information from people using their organization's assets. It includes their use of the assets and their feedback. It also manages crowd-sourced recommended enhancements to the metadata from other areas before it is approved and incorporated into the governance program. 0110 Actors - generic description of a profile describing a person, team or engine. 0112 People - profiles and roles for people 0115 Teams - team profiles and structures 0117 IT Profiles - profiles for engines 0130 Projects - projects for organizing change to the IT landscape 0135 Meetings - meetings where ideas, situations and plans are discussed and reviewed 0137 Actions for People - descriptions of actions for people 0140 Communities - communities of like-minded people 0150 Feedback - comments, likes, reviews and ratings 0155 Crowd Sourcing - collecting ideas from subject matter experts 0160 Notes - maintaining notes and note logs","title":"Area 1 Collaboration"},{"location":"types/1/#area-1-models-collaboration","text":"Area 1 collects information from people using their organization's assets. It includes their use of the assets and their feedback. It also manages crowd-sourced recommended enhancements to the metadata from other areas before it is approved and incorporated into the governance program. 0110 Actors - generic description of a profile describing a person, team or engine. 0112 People - profiles and roles for people 0115 Teams - team profiles and structures 0117 IT Profiles - profiles for engines 0130 Projects - projects for organizing change to the IT landscape 0135 Meetings - meetings where ideas, situations and plans are discussed and reviewed 0137 Actions for People - descriptions of actions for people 0140 Communities - communities of like-minded people 0150 Feedback - comments, likes, reviews and ratings 0155 Crowd Sourcing - collecting ideas from subject matter experts 0160 Notes - maintaining notes and note logs","title":"Area 1 Models - Collaboration"},{"location":"types/1/0110-actors/","text":"0110 Actors \u00b6 Most metadata repositories are run in a secure mode requiring incoming requests to include the requester\u2019s security credentials. Therefore we have an identifier for each unique logged on security identity (aka userId). This identity is recorded with specific entities and relationships when they are created or updated. The userId for a server is also captured in the metadata model (see 0040 Servers in Area 0 ) so it is possible to correlate the actions of a data processing server with changes to the metadata. UserIdentity \u00b6 UserIdentity provides a structure for storing the security authentication information about a person. Initially we have a simple string for the userId - but this could be extended to include more sophisticated identification information. ActorProfile \u00b6 An ActorProfile describes the actual person, or possibly team if group userIds are being used, that is working either with the data assets or with the metadata directly. The profile is a record to add additional information about the person or engine that is making the requests. They may have more than one UserIdentity. Actors \u00b6 Actors are associated with the new metadata that they create and comment on via their user identities. More information about the person behind the user identity is available through the ActorProfile. This separation is maintained because the user identity is the only information available on calls to the metadata repository. The ActorProfile is used to aggregate the activity of the individual or team (or IT infrastructure - see ITProfile ). This includes crowd-sourcing and project participation.","title":"Actors"},{"location":"types/1/0110-actors/#0110-actors","text":"Most metadata repositories are run in a secure mode requiring incoming requests to include the requester\u2019s security credentials. Therefore we have an identifier for each unique logged on security identity (aka userId). This identity is recorded with specific entities and relationships when they are created or updated. The userId for a server is also captured in the metadata model (see 0040 Servers in Area 0 ) so it is possible to correlate the actions of a data processing server with changes to the metadata.","title":"0110 Actors"},{"location":"types/1/0110-actors/#useridentity","text":"UserIdentity provides a structure for storing the security authentication information about a person. Initially we have a simple string for the userId - but this could be extended to include more sophisticated identification information.","title":"UserIdentity"},{"location":"types/1/0110-actors/#actorprofile","text":"An ActorProfile describes the actual person, or possibly team if group userIds are being used, that is working either with the data assets or with the metadata directly. The profile is a record to add additional information about the person or engine that is making the requests. They may have more than one UserIdentity.","title":"ActorProfile"},{"location":"types/1/0110-actors/#actors","text":"Actors are associated with the new metadata that they create and comment on via their user identities. More information about the person behind the user identity is available through the ActorProfile. This separation is maintained because the user identity is the only information available on calls to the metadata repository. The ActorProfile is used to aggregate the activity of the individual or team (or IT infrastructure - see ITProfile ). This includes crowd-sourcing and project participation.","title":"Actors"},{"location":"types/1/0112-people/","text":"0112 People, their personal network and their roles \u00b6 Person \u00b6 The 'ActorProfile' is extended to capture more information about a person. This is recorded in the Person entity. Peer \u00b6 Open metadata supports Karma Points . These are awarded for participation in the collaboration around open metadata. The number of karma points awarded to the individual is recorded in their Person entity. Roles \u00b6 Person entities can be linked together to a list of a person's close/important colleagues. The perspective on who is a close/important colleague is a personal perspective. Therefore the Peer relationship separates the concept of who has linked to a person ( myFollowers ) from who they have specifically linked to ( myPeers ). PersonRoleAppointment \u00b6 Open metadata also separates the person from the roles they perform. This is because people often perform many roles and these change over time. Also roles may be put in place before the person is appointed to it and the person appointed can change from time to time. PersonRole \u00b6 The PersonRole entity is linked to a Person entity with the PersonRoleAppointment relationship to show that the person has been appointed. The PersonRole entity is extended in multiple places to show different types of roles. For example: - 'TeamLeader' and 'TeamMember' - 'GovernanceRole' - 'ProjectManager' The Community Profile OMAS provides support for a person's profile. See 'personalprofile' . It also supports the ability to query a person's roles (see 'personalroles' ) and their peer network (see 'peernetwork' )","title":"People"},{"location":"types/1/0112-people/#0112-people-their-personal-network-and-their-roles","text":"","title":"0112 People, their personal network and their roles"},{"location":"types/1/0112-people/#person","text":"The 'ActorProfile' is extended to capture more information about a person. This is recorded in the Person entity.","title":"Person"},{"location":"types/1/0112-people/#peer","text":"Open metadata supports Karma Points . These are awarded for participation in the collaboration around open metadata. The number of karma points awarded to the individual is recorded in their Person entity.","title":"Peer"},{"location":"types/1/0112-people/#roles","text":"Person entities can be linked together to a list of a person's close/important colleagues. The perspective on who is a close/important colleague is a personal perspective. Therefore the Peer relationship separates the concept of who has linked to a person ( myFollowers ) from who they have specifically linked to ( myPeers ).","title":"Roles"},{"location":"types/1/0112-people/#personroleappointment","text":"Open metadata also separates the person from the roles they perform. This is because people often perform many roles and these change over time. Also roles may be put in place before the person is appointed to it and the person appointed can change from time to time.","title":"PersonRoleAppointment"},{"location":"types/1/0112-people/#personrole","text":"The PersonRole entity is linked to a Person entity with the PersonRoleAppointment relationship to show that the person has been appointed. The PersonRole entity is extended in multiple places to show different types of roles. For example: - 'TeamLeader' and 'TeamMember' - 'GovernanceRole' - 'ProjectManager' The Community Profile OMAS provides support for a person's profile. See 'personalprofile' . It also supports the ability to query a person's roles (see 'personalroles' ) and their peer network (see 'peernetwork' )","title":"PersonRole"},{"location":"types/1/0115-teams/","text":"0115 Teams \u00b6 Team \u00b6 A team is a group of people who are working to a common goal. The 'ActorProfile' is extended to capture more information about a team. This is recorded in the Team entity. TeamLeader \u00b6 The roles within the team divide into TeamLeader and TeamMember . A team can have multiple leaders and members. These roles extend from 'PersonRole' which links the role to the person appointed.","title":"Teams"},{"location":"types/1/0115-teams/#0115-teams","text":"","title":"0115 Teams"},{"location":"types/1/0115-teams/#team","text":"A team is a group of people who are working to a common goal. The 'ActorProfile' is extended to capture more information about a team. This is recorded in the Team entity.","title":"Team"},{"location":"types/1/0115-teams/#teamleader","text":"The roles within the team divide into TeamLeader and TeamMember . A team can have multiple leaders and members. These roles extend from 'PersonRole' which links the role to the person appointed.","title":"TeamLeader"},{"location":"types/1/0117-it-profiles/","text":"0117 IT Profiles \u00b6 ITProfile \u00b6 Often 'engines' and other IT infrastructure run as background processes with their own user identity. The ability to create an IT profile helps to identify which engine is responsible for specific metadata content.","title":"IT Profiles"},{"location":"types/1/0117-it-profiles/#0117-it-profiles","text":"","title":"0117 IT Profiles"},{"location":"types/1/0117-it-profiles/#itprofile","text":"Often 'engines' and other IT infrastructure run as background processes with their own user identity. The ability to create an IT profile helps to identify which engine is responsible for specific metadata content.","title":"ITProfile"},{"location":"types/1/0120-collections/","text":"0120 Collections \u00b6 Collections are now located in model 0021 .","title":"Collections"},{"location":"types/1/0120-collections/#0120-collections","text":"Collections are now located in model 0021 .","title":"0120 Collections"},{"location":"types/1/0130-projects/","text":"0130 Projects \u00b6 Projects \u00b6 Projects are used to organize a specific activity. The project is used to control the use of resources and associated costs so they are used appropriately in order to successfully achieve the project's goals. Projects organize resources to build new capability or improve existing capability. Related projects can be organized into campaigns. Small items of work, typically performed by a single person, can be defined as tasks for a project. Notice that the project acts as an anchor for collections of resources that the project is using. Since it is a Referenceable, it can have links to external URLs, such as the project home page, project plan or APIs as well as images (see 0015 Linked Media Types in Area 0). The description attribute should be used instead of the scopeDescription in ProjectScope; the scopeDescription attribute has been deprecated.","title":"Projects"},{"location":"types/1/0130-projects/#0130-projects","text":"","title":"0130 Projects"},{"location":"types/1/0130-projects/#projects","text":"Projects are used to organize a specific activity. The project is used to control the use of resources and associated costs so they are used appropriately in order to successfully achieve the project's goals. Projects organize resources to build new capability or improve existing capability. Related projects can be organized into campaigns. Small items of work, typically performed by a single person, can be defined as tasks for a project. Notice that the project acts as an anchor for collections of resources that the project is using. Since it is a Referenceable, it can have links to external URLs, such as the project home page, project plan or APIs as well as images (see 0015 Linked Media Types in Area 0). The description attribute should be used instead of the scopeDescription in ProjectScope; the scopeDescription attribute has been deprecated.","title":"Projects"},{"location":"types/1/0135-meetings/","text":"0135 Meetings \u00b6 Meetings \u00b6 Meetings allows a record of meetings for projects or the governance program to be associated with the appropriate metadata elements.","title":"Meetings"},{"location":"types/1/0135-meetings/#0135-meetings","text":"","title":"0135 Meetings"},{"location":"types/1/0135-meetings/#meetings","text":"Meetings allows a record of meetings for projects or the governance program to be associated with the appropriate metadata elements.","title":"Meetings"},{"location":"types/1/0137-actions/","text":"0137 Actions for People \u00b6 In an ideal world, most governance activity is automated by the 'governanceengines' . However there are inevitably actions that require a person to do. An item of work for a person is described in a ToDo.","title":"Actions for People"},{"location":"types/1/0137-actions/#0137-actions-for-people","text":"In an ideal world, most governance activity is automated by the 'governanceengines' . However there are inevitably actions that require a person to do. An item of work for a person is described in a ToDo.","title":"0137 Actions for People"},{"location":"types/1/0140-communities/","text":"0140 Communities \u00b6 Communities \u00b6 Communities are groups of people related by a common interest or skill. People tend to stay in communities for the long term, whilst they are are associated with projects just for the lifetime of the project and then they move on to another.","title":"Communities"},{"location":"types/1/0140-communities/#0140-communities","text":"","title":"0140 Communities"},{"location":"types/1/0140-communities/#communities","text":"Communities are groups of people related by a common interest or skill. People tend to stay in communities for the long term, whilst they are are associated with projects just for the lifetime of the project and then they move on to another.","title":"Communities"},{"location":"types/1/0150-feedback/","text":"0150 Feedback \u00b6 Feedback \u00b6 An important principle of good metadata it to be continually capturing the experience of subject matter experts. The feedback model captures comments and ratings from subject matter experts. Comments and ratings are a key mechanism for providing feedback on the metadata definitions by any user. Note: that because comments inherit from Referenceable they can be tagged, rated and commented on. More Information \u00b6 More details on the different types of feedback","title":"Feedback"},{"location":"types/1/0150-feedback/#0150-feedback","text":"","title":"0150 Feedback"},{"location":"types/1/0150-feedback/#feedback","text":"An important principle of good metadata it to be continually capturing the experience of subject matter experts. The feedback model captures comments and ratings from subject matter experts. Comments and ratings are a key mechanism for providing feedback on the metadata definitions by any user. Note: that because comments inherit from Referenceable they can be tagged, rated and commented on.","title":"Feedback"},{"location":"types/1/0150-feedback/#more-information","text":"More details on the different types of feedback","title":"More Information"},{"location":"types/1/0155-crowd-sourcing/","text":"0155 Crowd Sourcing \u00b6 CrowdSourcing \u00b6 Crowd-sourcing captures suggestions from consumers of assets and definitions.","title":"Crowd Sourcing"},{"location":"types/1/0155-crowd-sourcing/#0155-crowd-sourcing","text":"","title":"0155 Crowd Sourcing"},{"location":"types/1/0155-crowd-sourcing/#crowdsourcing","text":"Crowd-sourcing captures suggestions from consumers of assets and definitions.","title":"CrowdSourcing"},{"location":"types/1/0160-notes/","text":"0160 Notes \u00b6 Notes \u00b6 Notes provide additional information about a Referenceable object. They are used by resource owners and stewards to document the current status of their resources. Engines that are performing processing on the resources may also write notes to the note log. The note log can be attached to any referenceable metadata object. A referenceable object can have many notes linked off of it. Notes are used by the people with edit access to the referenceable object to provide information about its content, proposed changes and other useful information. Notes are also used by engines that are working on the related assets to add an informal audit trail of activity around the object.","title":"Notes"},{"location":"types/1/0160-notes/#0160-notes","text":"","title":"0160 Notes"},{"location":"types/1/0160-notes/#notes","text":"Notes provide additional information about a Referenceable object. They are used by resource owners and stewards to document the current status of their resources. Engines that are performing processing on the resources may also write notes to the note log. The note log can be attached to any referenceable metadata object. A referenceable object can have many notes linked off of it. Notes are used by the people with edit access to the referenceable object to provide information about its content, proposed changes and other useful information. Notes are also used by engines that are working on the related assets to add an informal audit trail of activity around the object.","title":"Notes"},{"location":"types/2/","text":"Area 2 Models - Assets \u00b6 Area 2 of the open metadata model covers the basic types of asset that need to be governed in order to make best use of them. It builds out the core types of assets, extending from Asset, Infrastructure, DataSet and Process defined in the 0010 Base Model . This includes the data sources, APIs, analytics models, transformation functions and rule implementations that store and manage data. The definitions in Area 2 also include connectivity information that is used by the Open Connector Framework ( OCF ) (and other tools) to get access to the data assets. 0201 Connectors and Connections 0205 Connection Linkage 0210 Data Stores 0211 Data Sets 0212 Deployed APIs 0215 Software Components 0217 Ports 0220 Files and Folders 0221 Document Stores 0222 Graph Stores 0223 Event Stores and Logs 0224 Databases 0225 Metadata Repositories 0227 Keystores 0230 Code Tables 0235 Information View 0239 Reports 0265 Analytics Assets 0280 Software Development Assets 0281 Software Modules 0282 Released Software Components 0285 Analytics Development Assets","title":"Area 2 Data Assets"},{"location":"types/2/#area-2-models-assets","text":"Area 2 of the open metadata model covers the basic types of asset that need to be governed in order to make best use of them. It builds out the core types of assets, extending from Asset, Infrastructure, DataSet and Process defined in the 0010 Base Model . This includes the data sources, APIs, analytics models, transformation functions and rule implementations that store and manage data. The definitions in Area 2 also include connectivity information that is used by the Open Connector Framework ( OCF ) (and other tools) to get access to the data assets. 0201 Connectors and Connections 0205 Connection Linkage 0210 Data Stores 0211 Data Sets 0212 Deployed APIs 0215 Software Components 0217 Ports 0220 Files and Folders 0221 Document Stores 0222 Graph Stores 0223 Event Stores and Logs 0224 Databases 0225 Metadata Repositories 0227 Keystores 0230 Code Tables 0235 Information View 0239 Reports 0265 Analytics Assets 0280 Software Development Assets 0281 Software Modules 0282 Released Software Components 0285 Analytics Development Assets","title":"Area 2 Models - Assets"},{"location":"types/2/0201-Connectors-and-Connections/","text":"0201 Connectors and Connections \u00b6 In Area 0 we introduced the definitions for a server with an endpoint ( model 0040 ). The server could host data and APIs. The Open Connector Framework ( OCF ) provides client java classes called connectors to enable an application, tool or engine to access this data and other deployed functions. A Connection metadata entity contains the configuration information to allow the OCF 's Connector Broker to select and configure the appropriate a client application or tool to connect to a particular Endpoint . The ConnectorType defines which connector implementation should be used to connect to the endpoint. The securedProperties holds authentication properties such as userId and password. They are securely stored to protect the assets. If they are missing then the security credentials of the current user are used with the connection. By default, connector implementations are assume to support the OCF . However, many vendor platforms have their own connector frameworks. The ConnectorCategory allows equivalent connector types from different connector frameworks to be gathered together so that the connector type from a connection can be swapped for an equivalent connector type for the locally supported connector framework. The picture below shows how the connector category can be used to navigate to a different connector type implementation. The next picture shows the ConnectorTypeDirectory can be used to organize the ConnectorCategories.","title":"Connectors and Connections"},{"location":"types/2/0201-Connectors-and-Connections/#0201-connectors-and-connections","text":"In Area 0 we introduced the definitions for a server with an endpoint ( model 0040 ). The server could host data and APIs. The Open Connector Framework ( OCF ) provides client java classes called connectors to enable an application, tool or engine to access this data and other deployed functions. A Connection metadata entity contains the configuration information to allow the OCF 's Connector Broker to select and configure the appropriate a client application or tool to connect to a particular Endpoint . The ConnectorType defines which connector implementation should be used to connect to the endpoint. The securedProperties holds authentication properties such as userId and password. They are securely stored to protect the assets. If they are missing then the security credentials of the current user are used with the connection. By default, connector implementations are assume to support the OCF . However, many vendor platforms have their own connector frameworks. The ConnectorCategory allows equivalent connector types from different connector frameworks to be gathered together so that the connector type from a connection can be swapped for an equivalent connector type for the locally supported connector framework. The picture below shows how the connector category can be used to navigate to a different connector type implementation. The next picture shows the ConnectorTypeDirectory can be used to organize the ConnectorCategories.","title":"0201 Connectors and Connections"},{"location":"types/2/0205-Connection-Linkage/","text":"0205 Connection Linkage \u00b6 The purpose of a connector is to access the content and related properties (metadata) about an Asset owned or used by an organization. In order for the connector to provide details of the know properties of an Asset, the open metadata types support a relationship between a Connection and the Asset. Notice that the connection can only be associated with one asset, although an Asset may support multiple connections, each providing a different class of service, or security permissions to the consumer. In addition, some connectors are virtual connectors - by that we mean they implement an abstraction to a business level asset and internally use one of more technical connectors as part of their implementation. The metadata repository can reflect these connection relationships using a VirtualConnection .","title":"Connection Linkage"},{"location":"types/2/0205-Connection-Linkage/#0205-connection-linkage","text":"The purpose of a connector is to access the content and related properties (metadata) about an Asset owned or used by an organization. In order for the connector to provide details of the know properties of an Asset, the open metadata types support a relationship between a Connection and the Asset. Notice that the connection can only be associated with one asset, although an Asset may support multiple connections, each providing a different class of service, or security permissions to the consumer. In addition, some connectors are virtual connectors - by that we mean they implement an abstraction to a business level asset and internally use one of more technical connectors as part of their implementation. The metadata repository can reflect these connection relationships using a VirtualConnection .","title":"0205 Connection Linkage"},{"location":"types/2/0210-Data-Stores/","text":"0210 Data Stores \u00b6 The base model introduced the concept of a data set ( DataSet ). The data store definition shows how the data set relates to the server that it is hosted on.","title":"Data Stores"},{"location":"types/2/0210-Data-Stores/#0210-data-stores","text":"The base model introduced the concept of a data set ( DataSet ). The data store definition shows how the data set relates to the server that it is hosted on.","title":"0210 Data Stores"},{"location":"types/2/0211-Data-Sets/","text":"0211 Data Sets \u00b6 VirtualDataSet extends the concept of DataSet to include virtual data sets - that is data sets built up from calling other data sets.","title":"Data Sets"},{"location":"types/2/0211-Data-Sets/#0211-data-sets","text":"VirtualDataSet extends the concept of DataSet to include virtual data sets - that is data sets built up from calling other data sets.","title":"0211 Data Sets"},{"location":"types/2/0212-Deployed-APIs/","text":"0212 Deployed APIs \u00b6 Deployed APIs are Assets that provide remote access to DeployedSoftwareComponents . The APIEndPoint identifies the network address used to call the API (defined in Endpoint ). The classifications RequestResponseInterface , ListenerInterface and PublisherInterface can be used to describe the style of the API. They can appear in combination on a single API. The structure of the API's interface is described in the APISchema . The definition of the API's operation, parameters and responses are supported by the API Schema Types .","title":"Deployed APIs"},{"location":"types/2/0212-Deployed-APIs/#0212-deployed-apis","text":"Deployed APIs are Assets that provide remote access to DeployedSoftwareComponents . The APIEndPoint identifies the network address used to call the API (defined in Endpoint ). The classifications RequestResponseInterface , ListenerInterface and PublisherInterface can be used to describe the style of the API. They can appear in combination on a single API. The structure of the API's interface is described in the APISchema . The definition of the API's operation, parameters and responses are supported by the API Schema Types .","title":"0212 Deployed APIs"},{"location":"types/2/0215-Software-Components/","text":"0215 Software Components \u00b6 DeployedSoftwareComponent describes a code asset that is deployed to implement a software capability . Each software component has a well defined interface describe by an APISchema that is linked to the DeployedSoftwareComponent by the AssetSchemaType relationship. DeployedConnector represents specialist software component called a connector that provides pluggable access to third party technologies. These connectors implement the Open Connector Framework ( OCF ) interfaces. EmbeddedProcess describes a processing element nested within a DeployedSoftwareComponent. The TransientEmbeddedProcess describes an EmbeddedProcess that runs only for a short period of time. These variations are used to provide more information for lineage graphs. ProcessHierarchy defines a parent-child relationship between processes, which can be used to define more abstract processes that are comprised of lower-level processes; helping to support navigating the process hierarchy. More information \u00b6 Related Open Metadata Type Definitions \u00b6 Definition of Process Linking of processes into lineage graphs Ports to show specific input and output flows for a process PortSchema relationships to describe the structure of data supported by a Port Use of these open metadata types \u00b6 Egeria Developer Guide for more information on connectors and how to implement them. Lineage describes the different types of lineage and how the open metadata types link together to form lineage graphs.","title":"Software Components"},{"location":"types/2/0215-Software-Components/#0215-software-components","text":"DeployedSoftwareComponent describes a code asset that is deployed to implement a software capability . Each software component has a well defined interface describe by an APISchema that is linked to the DeployedSoftwareComponent by the AssetSchemaType relationship. DeployedConnector represents specialist software component called a connector that provides pluggable access to third party technologies. These connectors implement the Open Connector Framework ( OCF ) interfaces. EmbeddedProcess describes a processing element nested within a DeployedSoftwareComponent. The TransientEmbeddedProcess describes an EmbeddedProcess that runs only for a short period of time. These variations are used to provide more information for lineage graphs. ProcessHierarchy defines a parent-child relationship between processes, which can be used to define more abstract processes that are comprised of lower-level processes; helping to support navigating the process hierarchy.","title":"0215 Software Components"},{"location":"types/2/0215-Software-Components/#more-information","text":"","title":"More information"},{"location":"types/2/0215-Software-Components/#related-open-metadata-type-definitions","text":"Definition of Process Linking of processes into lineage graphs Ports to show specific input and output flows for a process PortSchema relationships to describe the structure of data supported by a Port","title":"Related Open Metadata Type Definitions"},{"location":"types/2/0215-Software-Components/#use-of-these-open-metadata-types","text":"Egeria Developer Guide for more information on connectors and how to implement them. Lineage describes the different types of lineage and how the open metadata types link together to form lineage graphs.","title":"Use of these open metadata types"},{"location":"types/2/0217-Ports/","text":"0217 Ports \u00b6 Ports are used to define the interfaces of Processes . PortImplementation - at the most detailed level, a PortImplementation defines the specific interface of a process: for example, its expected inputs or produced outputs. PortAlias - a PortAlias provides a reference point to some other Port (either another PortAlias or a more detailed PortImplementation). PortDelegation - defines the parent-child relationship between Ports: for example, which PortImplementation a particular PortAlias delegates to. ProcessPort - defines the Port(s) that are used by a given Process as its interface(s). Further Information \u00b6 Base definition of Process LineageMapping relationships Process Hierarchies","title":"Ports"},{"location":"types/2/0217-Ports/#0217-ports","text":"Ports are used to define the interfaces of Processes . PortImplementation - at the most detailed level, a PortImplementation defines the specific interface of a process: for example, its expected inputs or produced outputs. PortAlias - a PortAlias provides a reference point to some other Port (either another PortAlias or a more detailed PortImplementation). PortDelegation - defines the parent-child relationship between Ports: for example, which PortImplementation a particular PortAlias delegates to. ProcessPort - defines the Port(s) that are used by a given Process as its interface(s).","title":"0217 Ports"},{"location":"types/2/0217-Ports/#further-information","text":"Base definition of Process LineageMapping relationships Process Hierarchies","title":"Further Information"},{"location":"types/2/0220-Files-and-Folders/","text":"0220 Files and Folders \u00b6 A metadata catalog typically contains information about the data files that can be processed and their location. Files and folders describe physical files and how they are organized on the file system. The file system is a Software Server Capability . The root folders ( FileFolders ) are connected to it using the ServerAssetUse relationship. Beneath that are FileFolders with DataFiles nested beneath them. Data files can also have a symbolic link ( LinkedFile ) to a element to show that it logically belongs to the other content in the element. There is also a special case of a DataFolder which is a element that is the container of a collection of data. The files and nested folders within it collectively make up the data content. They are not individually catalogued. The diagram below illustrates the structure.","title":"Files and Folders"},{"location":"types/2/0220-Files-and-Folders/#0220-files-and-folders","text":"A metadata catalog typically contains information about the data files that can be processed and their location. Files and folders describe physical files and how they are organized on the file system. The file system is a Software Server Capability . The root folders ( FileFolders ) are connected to it using the ServerAssetUse relationship. Beneath that are FileFolders with DataFiles nested beneath them. Data files can also have a symbolic link ( LinkedFile ) to a element to show that it logically belongs to the other content in the element. There is also a special case of a DataFolder which is a element that is the container of a collection of data. The files and nested folders within it collectively make up the data content. They are not individually catalogued. The diagram below illustrates the structure.","title":"0220 Files and Folders"},{"location":"types/2/0221-Document-Stores/","text":"0221 Document Stores \u00b6 Document stores describes a specialist type of server that manages documents and their metadata. Deprecated types ContentManager - Use ContentCollectionManager","title":"Document Stores"},{"location":"types/2/0221-Document-Stores/#0221-document-stores","text":"Document stores describes a specialist type of server that manages documents and their metadata. Deprecated types ContentManager - Use ContentCollectionManager","title":"0221 Document Stores"},{"location":"types/2/0222-Graph-Stores/","text":"0222 Graph Stores \u00b6 Graph stores describe a type of data store that has its content organized as a graph.","title":"Graph Stores"},{"location":"types/2/0222-Graph-Stores/#0222-graph-stores","text":"Graph stores describe a type of data store that has its content organized as a graph.","title":"0222 Graph Stores"},{"location":"types/2/0223-Events-and-Logs/","text":"0223 Events and Logs \u00b6","title":"Events and Logs"},{"location":"types/2/0223-Events-and-Logs/#0223-events-and-logs","text":"","title":"0223 Events and Logs"},{"location":"types/2/0224-Databases/","text":"0224 Databases \u00b6","title":"Databases"},{"location":"types/2/0224-Databases/#0224-databases","text":"","title":"0224 Databases"},{"location":"types/2/0225-Metadata-Repositories/","text":"0225 Metadata Repositories \u00b6","title":"Metadata Repositories"},{"location":"types/2/0225-Metadata-Repositories/#0225-metadata-repositories","text":"","title":"0225 Metadata Repositories"},{"location":"types/2/0227-Keystores/","text":"0227 Keystores \u00b6","title":"Keystores"},{"location":"types/2/0227-Keystores/#0227-keystores","text":"","title":"0227 Keystores"},{"location":"types/2/0230-Code-Tables/","text":"0230 Code Tables \u00b6","title":"Code Tables"},{"location":"types/2/0230-Code-Tables/#0230-code-tables","text":"","title":"0230 Code Tables"},{"location":"types/2/0235-Information-View/","text":"0235 Information View \u00b6","title":"Information View"},{"location":"types/2/0235-Information-View/#0235-information-view","text":"","title":"0235 Information View"},{"location":"types/2/0239-Reports/","text":"0239 Reports \u00b6","title":"Reports"},{"location":"types/2/0239-Reports/#0239-reports","text":"","title":"0239 Reports"},{"location":"types/2/0265-Analytics-Assets/","text":"0265 Analytics Assets \u00b6 This classification enables analytical components to be identified in lineage.","title":"Analytics Assets"},{"location":"types/2/0265-Analytics-Assets/#0265-analytics-assets","text":"This classification enables analytical components to be identified in lineage.","title":"0265 Analytics Assets"},{"location":"types/2/0280-Software-Development-Assets/","text":"0280 Software Development Assets \u00b6","title":"Software Development Assets"},{"location":"types/2/0280-Software-Development-Assets/#0280-software-development-assets","text":"","title":"0280 Software Development Assets"},{"location":"types/2/0281-Software-Modules/","text":"0281 Software Components and Modules \u00b6","title":"Software Modules"},{"location":"types/2/0281-Software-Modules/#0281-software-components-and-modules","text":"","title":"0281 Software Components and Modules"},{"location":"types/2/0282-Released-Software-Components/","text":"0282 Released Software Components \u00b6","title":"Released Software Components"},{"location":"types/2/0282-Released-Software-Components/#0282-released-software-components","text":"","title":"0282 Released Software Components"},{"location":"types/2/0285-Analytics-Development-Assets/","text":"0285 Analytics Development Assets \u00b6","title":"Analytics Development Assets"},{"location":"types/2/0285-Analytics-Development-Assets/#0285-analytics-development-assets","text":"","title":"0285 Analytics Development Assets"},{"location":"types/3/","text":"Area 3 Models - Glossary and Semantics \u00b6 Area 3 describes the glossary. This enables the definition of the terminology used in an organization. This terminology reflects the processing and the data needed in its operations. The glossary is made up of terms, each one describing a word or short phrase. The terms can be linked together to show the relationships between different types of terminology. Most glossary terms are created through a manual process by subject matter experts. They may be part of a trade or industry organization, or experts within the business. This investment is typically made using a specialist tool and then replicated automatically into other metadata repositories. There can be multiple glossaries in the metadata repositories. Each glossary owns a set of glossary terms and (optionally) a category hierarchy. Glossary terms can be linked into none, one or many categories, from any glossary. Similarly, terms from different glossaries may have relationships linking them together. This is the definitions of terms and concepts and how they relate to one another. Linking the concepts/terms defined in the glossary to the data assets in Area 2 , defines the meaning of the data that is managed by the data assets. This is a key relationship that helps people locate and understand the data assets they are working with. 0310 Glossary 0320 Category Hierarchy 0330 Glossary Terms 0335 Primary Category 0340 Dictionary 0350 Related Terms 0360 Contexts 0370 Semantic Assignment 0380 Spine Objects 0385 Controlled Glossary Development 0390 Glossary Projects 0395 Supplementary Properties Return to Overview .","title":"Area 3 Glossary"},{"location":"types/3/#area-3-models-glossary-and-semantics","text":"Area 3 describes the glossary. This enables the definition of the terminology used in an organization. This terminology reflects the processing and the data needed in its operations. The glossary is made up of terms, each one describing a word or short phrase. The terms can be linked together to show the relationships between different types of terminology. Most glossary terms are created through a manual process by subject matter experts. They may be part of a trade or industry organization, or experts within the business. This investment is typically made using a specialist tool and then replicated automatically into other metadata repositories. There can be multiple glossaries in the metadata repositories. Each glossary owns a set of glossary terms and (optionally) a category hierarchy. Glossary terms can be linked into none, one or many categories, from any glossary. Similarly, terms from different glossaries may have relationships linking them together. This is the definitions of terms and concepts and how they relate to one another. Linking the concepts/terms defined in the glossary to the data assets in Area 2 , defines the meaning of the data that is managed by the data assets. This is a key relationship that helps people locate and understand the data assets they are working with. 0310 Glossary 0320 Category Hierarchy 0330 Glossary Terms 0335 Primary Category 0340 Dictionary 0350 Related Terms 0360 Contexts 0370 Semantic Assignment 0380 Spine Objects 0385 Controlled Glossary Development 0390 Glossary Projects 0395 Supplementary Properties Return to Overview .","title":"Area 3 Models - Glossary and Semantics"},{"location":"types/3/0310-Glossary/","text":"0310 Glossary Model \u00b6 A glossary is a collection of related semantic definitions. A semantic definition describes the meaning of something. This may be, for example, a concept, object or activity. A metadata repository may contain many glossaries, particularly when it is part of a bigger enterprise cohort of repositories. Each glossary may come from a specific team or external organization. Or it may be focused on a particular topic or set of use cases. The anchor for each glossary is the Glossary object. The classifications associated with the glossary object are used to document the type of vocabulary it contains and its purpose: Taxonomy - A Taxonomy is a glossary that has a formal structure. Typically the terms have been organized into a category hierarchy that reflects their meaning or use. There may also be term relationships that also form part of the hierarchy. Taxonomies are often used to organize documents and other media in content repositories. Canonical Vocabulary - this glossary provides the standard vocabulary definitions for an organization. Typically terms from other glossaries are linked to terms from the canonical glossary. These classifications are independent of one another so a Glossary object may have none, one or all of these classifications attached. In addition, there is a relationship to an external glossary called ExternallySourcedGlossary . This indicates that the content from this glossary comes from an external source. It may be, for example an industry-specific glossary, or from a standards body, or from an open data site, or from a commercial organization.","title":"Glossary"},{"location":"types/3/0310-Glossary/#0310-glossary-model","text":"A glossary is a collection of related semantic definitions. A semantic definition describes the meaning of something. This may be, for example, a concept, object or activity. A metadata repository may contain many glossaries, particularly when it is part of a bigger enterprise cohort of repositories. Each glossary may come from a specific team or external organization. Or it may be focused on a particular topic or set of use cases. The anchor for each glossary is the Glossary object. The classifications associated with the glossary object are used to document the type of vocabulary it contains and its purpose: Taxonomy - A Taxonomy is a glossary that has a formal structure. Typically the terms have been organized into a category hierarchy that reflects their meaning or use. There may also be term relationships that also form part of the hierarchy. Taxonomies are often used to organize documents and other media in content repositories. Canonical Vocabulary - this glossary provides the standard vocabulary definitions for an organization. Typically terms from other glossaries are linked to terms from the canonical glossary. These classifications are independent of one another so a Glossary object may have none, one or all of these classifications attached. In addition, there is a relationship to an external glossary called ExternallySourcedGlossary . This indicates that the content from this glossary comes from an external source. It may be, for example an industry-specific glossary, or from a standards body, or from an open data site, or from a commercial organization.","title":"0310 Glossary Model"},{"location":"types/3/0320-Category-Hierarchy/","text":"0320 Category Hierarchy \u00b6 The vocabulary for the glossary is organized into a hierarchy of categories. These categories effectively provide a element structure for the glossary. GlossaryCategory represents a category in a glossary. CategoryAnchor links each category to exactly one Glossary object. This means that this is its home glossary. If the Glossary object is deleted then so are all of the categories linked to it. CategoryHierarchyLink is a relationship used to organize categories into a hierarchy to, for example, create a structure for a taxonomy. A category may have none or one super-categories. However this super-category may be in a different glossary. SubjectArea is a classification for a category that indicates that the category represents a subject area. LibraryCategoryReference provides reference information for how this category corresponds to a category in an external glossary.","title":"Category Hierarchy"},{"location":"types/3/0320-Category-Hierarchy/#0320-category-hierarchy","text":"The vocabulary for the glossary is organized into a hierarchy of categories. These categories effectively provide a element structure for the glossary. GlossaryCategory represents a category in a glossary. CategoryAnchor links each category to exactly one Glossary object. This means that this is its home glossary. If the Glossary object is deleted then so are all of the categories linked to it. CategoryHierarchyLink is a relationship used to organize categories into a hierarchy to, for example, create a structure for a taxonomy. A category may have none or one super-categories. However this super-category may be in a different glossary. SubjectArea is a classification for a category that indicates that the category represents a subject area. LibraryCategoryReference provides reference information for how this category corresponds to a category in an external glossary.","title":"0320 Category Hierarchy"},{"location":"types/3/0330-Terms/","text":"0330 Terms \u00b6 The vocabulary for the glossary is documented using terms. Each term represents a concept of short phrase in the vocabulary. Just like a category, a term is owned by a glossary but can be linked into a category from any glossary. Model 0330 shows the glossary term. GlossaryTerm represents a term in a glossary. TermAnchor links each term to exactly one Glossary object. This means that this is its home glossary. If the Glossary object is deleted then so are all of the terms linked to it. TermCategorization is a relationship used to organize terms into categories. A term may be linked with many categories and a category may have many terms linked to it. This relationship may connect terms and categories both in the same glossary and in different glossaries. LibraryTermReference provides reference information for how this term corresponds to a term in an external glossary.","title":"Glossary Terms"},{"location":"types/3/0330-Terms/#0330-terms","text":"The vocabulary for the glossary is documented using terms. Each term represents a concept of short phrase in the vocabulary. Just like a category, a term is owned by a glossary but can be linked into a category from any glossary. Model 0330 shows the glossary term. GlossaryTerm represents a term in a glossary. TermAnchor links each term to exactly one Glossary object. This means that this is its home glossary. If the Glossary object is deleted then so are all of the terms linked to it. TermCategorization is a relationship used to organize terms into categories. A term may be linked with many categories and a category may have many terms linked to it. This relationship may connect terms and categories both in the same glossary and in different glossaries. LibraryTermReference provides reference information for how this term corresponds to a term in an external glossary.","title":"0330 Terms"},{"location":"types/3/0335-Primary-Category/","text":"0335 Primary Category \u00b6 This Classification marks the Primary Category associated with a GlossaryTerm and helps to identify it in the lineage graph. It contains a single property, categoryQualifiedName which represents the qualified name of the primary category associated with the term.","title":"Primary Category"},{"location":"types/3/0335-Primary-Category/#0335-primary-category","text":"This Classification marks the Primary Category associated with a GlossaryTerm and helps to identify it in the lineage graph. It contains a single property, categoryQualifiedName which represents the qualified name of the primary category associated with the term.","title":"0335 Primary Category"},{"location":"types/3/0340-Dictionary/","text":"0340 Dictionary \u00b6 The dictionary model adds some basic term classification used to show how particular terms are used. ActivityDescription is a classification used to indicate that the term describes a verb, or an activity. Most term definitions are nouns, they describe concepts or things. However, it is useful to be able to define the assets of particular activities in the glossary. The ActivityDescription classification highlights when a term describes such an activity. OPERATION - describes a function or API call ACTION - describes a governance action that results from evaluating governance rules. TASK - describes a task performed by a person. PROCESS - describes a process, which is a series of steps that are performed in a defined order. PROJECT - describes a type of project. OTHER - describes some other type of activity AbstractConcept means that the term describes an abstract concept. DataValue means that the glossary term describes a valid value for a data item.","title":"Dictionary"},{"location":"types/3/0340-Dictionary/#0340-dictionary","text":"The dictionary model adds some basic term classification used to show how particular terms are used. ActivityDescription is a classification used to indicate that the term describes a verb, or an activity. Most term definitions are nouns, they describe concepts or things. However, it is useful to be able to define the assets of particular activities in the glossary. The ActivityDescription classification highlights when a term describes such an activity. OPERATION - describes a function or API call ACTION - describes a governance action that results from evaluating governance rules. TASK - describes a task performed by a person. PROCESS - describes a process, which is a series of steps that are performed in a defined order. PROJECT - describes a type of project. OTHER - describes some other type of activity AbstractConcept means that the term describes an abstract concept. DataValue means that the glossary term describes a valid value for a data item.","title":"0340 Dictionary"},{"location":"types/3/0350-Related-Terms/","text":"0350 Related Terms \u00b6 The Related Terms model contains relationships used to show how the assets of different terms are related to one another. The TermRelationshipStatus defines how reliable the relationship is between two glossary terms: DRAFT means the relationship is under development. ACTIVE means the relationship is validated and in use. DEPRECATED means the the relationship is being phased out. OBSOLETE means that the relationship should not be used anymore. OTHER means that the status is not one of the statuses listed above. The description field can be used to add more details. The related term relationships are as follows: RelatedTerm is a relationship used to say that the linked glossary term may also be of interest. It is like a \"see also\" link in a dictionary. The description field can be used to explain why the linked term is of interest. Synonym is a relationship between glossary terms that have the same, or a very similar meaning. Antonym is a relationship between glossary terms that have the opposite (or near opposite) meaning. PreferredTerm is a relationship that indicates that the preferredTerm should be used in place of the preferredToTerm. ReplacementTerm is a relationship that indicates that the replacementTerm must be used instead of the replacedByTerm. This is stronger version of the PreferredTerm. Translation is a relationship that defines that the related terms represent the same meaning but each are written in a different language. Hence one is a translation of the other. The language of each term is defined in the Glossary object that anchors the term. IsA is a relationship that defines that the \"isA\" term is a more generic term than the \"isOf\" term. For example, this relationship would be use to say that \"Cat\" ISA \"Animal\". ValidValue is a relationship that shows the validValue term represents one of the valid values that could be assigned to a data item that has the meaning described in the validValueFor term.","title":"Related Terms"},{"location":"types/3/0350-Related-Terms/#0350-related-terms","text":"The Related Terms model contains relationships used to show how the assets of different terms are related to one another. The TermRelationshipStatus defines how reliable the relationship is between two glossary terms: DRAFT means the relationship is under development. ACTIVE means the relationship is validated and in use. DEPRECATED means the the relationship is being phased out. OBSOLETE means that the relationship should not be used anymore. OTHER means that the status is not one of the statuses listed above. The description field can be used to add more details. The related term relationships are as follows: RelatedTerm is a relationship used to say that the linked glossary term may also be of interest. It is like a \"see also\" link in a dictionary. The description field can be used to explain why the linked term is of interest. Synonym is a relationship between glossary terms that have the same, or a very similar meaning. Antonym is a relationship between glossary terms that have the opposite (or near opposite) meaning. PreferredTerm is a relationship that indicates that the preferredTerm should be used in place of the preferredToTerm. ReplacementTerm is a relationship that indicates that the replacementTerm must be used instead of the replacedByTerm. This is stronger version of the PreferredTerm. Translation is a relationship that defines that the related terms represent the same meaning but each are written in a different language. Hence one is a translation of the other. The language of each term is defined in the Glossary object that anchors the term. IsA is a relationship that defines that the \"isA\" term is a more generic term than the \"isOf\" term. For example, this relationship would be use to say that \"Cat\" ISA \"Animal\". ValidValue is a relationship that shows the validValue term represents one of the valid values that could be assigned to a data item that has the meaning described in the validValueFor term.","title":"0350 Related Terms"},{"location":"types/3/0360-Contexts/","text":"0360 Contexts \u00b6 The Context model defines a classification for a glossary term that indicates it defines a context, and a relationship called UsedInContext to link terms that are relevant in that context. The ContextDefinition classification indicates that the term describes a context. Glossary Terms that are relevant in that context are linked to the context definition term using the UsedInContext relationship.","title":"Contexts"},{"location":"types/3/0360-Contexts/#0360-contexts","text":"The Context model defines a classification for a glossary term that indicates it defines a context, and a relationship called UsedInContext to link terms that are relevant in that context. The ContextDefinition classification indicates that the term describes a context. Glossary Terms that are relevant in that context are linked to the context definition term using the UsedInContext relationship.","title":"0360 Contexts"},{"location":"types/3/0370-Semantic-Assignment/","text":"0370 Semantic Assignment \u00b6 SemanticAssignment is a relationship used to assign a term to a referenceable object. This means that the term describes the meaning of the referenceable object. The semantic assignment needs to be a controlled relationship when glossary definitions are used to provide classifications for the data assets and hence define how the data is to be governed. Thus TermAssignmentStatus defines how much the semantic assignment should be trusted. The relationship is created by the user (person or engine) identified by the createdBy attribute. The confidence attribute in the relationship stores the level of confidence (0-100%) in the correctness of the relationship - it is typically used by discovery engines. The steward is the person responsible for assessing the relationship and deciding if it should be approved or not. DISCOVERED - this semantic assignment was added by a discovery engine. PROPOSED - this semantic assignment was proposed by person - they may be a subject matter expert, or consumer of the Referenceable asset. IMPORTED - the relationship has been imported from outside of the open metadata cohort. VALIDATED - this relationship has been reviewed and is highly trusted. DEPRECATED - this relationship is being phased out. There may be another semantic relationship to the Referenceable that will ultimately replace this relationship. OBSOLETE - this relationship is no longer in use. OTHER - the status of the relationship does not match any of the other term status values. The description field can be used to add details about the relationship.","title":"Semantic Assignment"},{"location":"types/3/0370-Semantic-Assignment/#0370-semantic-assignment","text":"SemanticAssignment is a relationship used to assign a term to a referenceable object. This means that the term describes the meaning of the referenceable object. The semantic assignment needs to be a controlled relationship when glossary definitions are used to provide classifications for the data assets and hence define how the data is to be governed. Thus TermAssignmentStatus defines how much the semantic assignment should be trusted. The relationship is created by the user (person or engine) identified by the createdBy attribute. The confidence attribute in the relationship stores the level of confidence (0-100%) in the correctness of the relationship - it is typically used by discovery engines. The steward is the person responsible for assessing the relationship and deciding if it should be approved or not. DISCOVERED - this semantic assignment was added by a discovery engine. PROPOSED - this semantic assignment was proposed by person - they may be a subject matter expert, or consumer of the Referenceable asset. IMPORTED - the relationship has been imported from outside of the open metadata cohort. VALIDATED - this relationship has been reviewed and is highly trusted. DEPRECATED - this relationship is being phased out. There may be another semantic relationship to the Referenceable that will ultimately replace this relationship. OBSOLETE - this relationship is no longer in use. OTHER - the status of the relationship does not match any of the other term status values. The description field can be used to add details about the relationship.","title":"0370 Semantic Assignment"},{"location":"types/3/0380-Spine-Objects/","text":"0380 Spine Objects \u00b6 The spine object model adds the relationships that enable a glossary to contain the definition of spine objects that can be used to control access to data, and the guild the design of new data stores and APIs. Model 0380 shows the relationships and classifications used to describe spine object. SpineObject - is a classification to say the term represents a type of object SpineAttribute - is a classification to say the term represents a type of attribute that is common for a spine object. ObjectIdentifier - is a classification saying that a term is typically an identifier attributed for a spine object. Note that a term may be a spine object and/or a spine attribute and/or an object identifier at the same time. TermHASARelationship - is a term relationship between a term representing a SpineObject and a term representing a SpineAttribute. IsATypeOfRelationship - is a term relationship between two SpineObjects saying that one is the subtype (specialisation) of the other. TermTYPEDBYRelationship - is a term relationship between a SpineAttribute and a SpineObject to say that the SpineAttribute is implemented using a type represented by the SpineObject . The following relationship is deprecated, use IsATypeOfRelationship instead: * TermISATYPEOFRelationship - Deprecated is a term relationship between two SpineObjects saying that one is the subtype (specialisation) of the other.","title":"Spine Objects"},{"location":"types/3/0380-Spine-Objects/#0380-spine-objects","text":"The spine object model adds the relationships that enable a glossary to contain the definition of spine objects that can be used to control access to data, and the guild the design of new data stores and APIs. Model 0380 shows the relationships and classifications used to describe spine object. SpineObject - is a classification to say the term represents a type of object SpineAttribute - is a classification to say the term represents a type of attribute that is common for a spine object. ObjectIdentifier - is a classification saying that a term is typically an identifier attributed for a spine object. Note that a term may be a spine object and/or a spine attribute and/or an object identifier at the same time. TermHASARelationship - is a term relationship between a term representing a SpineObject and a term representing a SpineAttribute. IsATypeOfRelationship - is a term relationship between two SpineObjects saying that one is the subtype (specialisation) of the other. TermTYPEDBYRelationship - is a term relationship between a SpineAttribute and a SpineObject to say that the SpineAttribute is implemented using a type represented by the SpineObject . The following relationship is deprecated, use IsATypeOfRelationship instead: * TermISATYPEOFRelationship - Deprecated is a term relationship between two SpineObjects saying that one is the subtype (specialisation) of the other.","title":"0380 Spine Objects"},{"location":"types/3/0385-Controlled-Glossary-Development/","text":"0385 Controlled Glossary Development \u00b6 The ControlledGlossaryTerm extends the standard GlossaryTerm with states for supporting a complex development lifecycle.","title":"Controlled Glossary"},{"location":"types/3/0385-Controlled-Glossary-Development/#0385-controlled-glossary-development","text":"The ControlledGlossaryTerm extends the standard GlossaryTerm with states for supporting a complex development lifecycle.","title":"0385 Controlled Glossary Development"},{"location":"types/3/0390-Glossary-Projects/","text":"0390 Glossary Projects \u00b6 A glossary project is used to develop new elements for the glossary.","title":"Glossary Projects"},{"location":"types/3/0390-Glossary-Projects/#0390-glossary-projects","text":"A glossary project is used to develop new elements for the glossary.","title":"0390 Glossary Projects"},{"location":"types/3/0395-Supplementary-Properties/","text":"0395 Supplementary Properties \u00b6 The SupplementaryProperties link a Referenceable element to a glossary term that contains additional descriptive properties about the linked element. This enables a steward or owner to maintain additional information about the element event if the element is read-only because it is technical metadata extracted from an engine or platform.","title":"Supplementary Properties"},{"location":"types/3/0395-Supplementary-Properties/#0395-supplementary-properties","text":"The SupplementaryProperties link a Referenceable element to a glossary term that contains additional descriptive properties about the linked element. This enables a steward or owner to maintain additional information about the element event if the element is read-only because it is technical metadata extracted from an engine or platform.","title":"0395 Supplementary Properties"},{"location":"types/4/","text":"Area 4 Models - Governance \u00b6 Area 4 defines how the data assets should be governed. This is where the classifications, policies and rules are defined for governance. In a similar way to the glossary ( area 3 ) this information is authored in the metadata repositories and then distributed to the enforcement points and data platforms to action and return measurements that can be used to confirm that the governance program has a positive effect. 0401 Governance Definitions 0405 Governance Drivers 0415 Governance Responses 0417 Governance Projects 0420 Governance Controls 0421 Governance Classification Levels 0422 Governance Action Classifications 0423 Security Tags 0424 Governance Zones 0425 Subject Areas 0430 Technical Controls 0435 Policy Management Capabilities 0438 Naming Standards 0440 Organizational Controls 0442 Project Charter 0445 Governance Roles 0450 Governance Rollout 0455 Exception Management 0460 Governance Execution Points 0461 Governance Engines 0462 Governance Action Types 0463 Governance Actions 0465 Duplicate Processing 0470 Incident Reporting 0481 Licenses 0482 Certifications 0485 Data Processing Purposes","title":"Area 4 Governance"},{"location":"types/4/#area-4-models-governance","text":"Area 4 defines how the data assets should be governed. This is where the classifications, policies and rules are defined for governance. In a similar way to the glossary ( area 3 ) this information is authored in the metadata repositories and then distributed to the enforcement points and data platforms to action and return measurements that can be used to confirm that the governance program has a positive effect. 0401 Governance Definitions 0405 Governance Drivers 0415 Governance Responses 0417 Governance Projects 0420 Governance Controls 0421 Governance Classification Levels 0422 Governance Action Classifications 0423 Security Tags 0424 Governance Zones 0425 Subject Areas 0430 Technical Controls 0435 Policy Management Capabilities 0438 Naming Standards 0440 Organizational Controls 0442 Project Charter 0445 Governance Roles 0450 Governance Rollout 0455 Exception Management 0460 Governance Execution Points 0461 Governance Engines 0462 Governance Action Types 0463 Governance Actions 0465 Duplicate Processing 0470 Incident Reporting 0481 Licenses 0482 Certifications 0485 Data Processing Purposes","title":"Area 4 Models - Governance"},{"location":"types/4/0401-Governance-Definitions/","text":"0401 Governance Definitions \u00b6 The world of governance is divided into different governance domains that focus on a specific set of assets or activities. Egeria aims to unify the metadata and governance activity across these governance domains. GovernanceDomain provides a default list of the different types of governance domains that can be unified by Egeria. Notice that there are obvious overlaps and linkages between the domains: DATA - the governance of data and its use. PRIVACY - the support for data privacy. SECURITY - the governance that ensures IT systems and the data they hold are secure. IT_INFRASTRUCTURE - the governance of the configuration and management of IT infrastructure and the software that runs on it. SOFTWARE_DEVELOPMENT - the governance of the software development lifecycle. CORPORATE - the governance of the organization as a legal entity. ASSET_MANAGEMENT - the governance of physical assets. The GovernanceDomainDescription provides the definition of a governance domain. You can choose to define your own or use the standard set that are defined by GovernanceDomain . Related governance domains can be grouped into GovernanceDomainSets . The role of leader of a governance domain is represented as a GovernanceOfficer . GovernanceDefinition describes an aspect of a governance program. They are authored in the metadata repository. They inherit from Referenceable , which means they have a unique identifier and link to external references for more information. GovernedBy links the governance definitions to the elements they are governing. Further Information \u00b6 The governance definitions are organized into specific subtypes and linked together to provide a complete description of the governance program. The types for these more specialized definitions can be found on the following pages: 0405 Governance Drivers - describe the motivations behind the governance program. 0415 Governance Responses - describe the policies that support each of the drivers. 0420 Governance Controls - describe how the policies will be implemented. 0430 Technical Controls - describe automated behaviour that implements a governance control. 0438 Naming Standards - defines naming standard rules. 0460 Governance Execution Points - describe classifications for software components that link them to a technical control. 0461 Governance Action Engines - support the execution of technical controls. 0462 Governance Action Types - provide the choreography of the execution of technical controls. 0440 Organizational Controls - identity governance roles and manual procedures (such as approvals) that implement a governance control. 0445 Governance Roles - define governance roles and the people associated with them. 0481 License Types - terms and conditions used in rights management. 0482 Certification Types - types of certifications used to shw compliance to a specific governance requirement. 0485 Data Processing Purposes - definitions of purposes used in data privacy regulations. The Governance Program OMAS provides the APIs for maintaining the definitions of the governance domains, governance definitions and governance officers. It uses the GovernedBy relationship to link governance definitions with subject area definitions and governance zone definitions . The Asset Manager OMAS supports the exchange of governance definitions with third party asset managers and governance tools as well as the use of the GovernedBy relationship through its Governance Exchange Interface .","title":"Governance Definitions"},{"location":"types/4/0401-Governance-Definitions/#0401-governance-definitions","text":"The world of governance is divided into different governance domains that focus on a specific set of assets or activities. Egeria aims to unify the metadata and governance activity across these governance domains. GovernanceDomain provides a default list of the different types of governance domains that can be unified by Egeria. Notice that there are obvious overlaps and linkages between the domains: DATA - the governance of data and its use. PRIVACY - the support for data privacy. SECURITY - the governance that ensures IT systems and the data they hold are secure. IT_INFRASTRUCTURE - the governance of the configuration and management of IT infrastructure and the software that runs on it. SOFTWARE_DEVELOPMENT - the governance of the software development lifecycle. CORPORATE - the governance of the organization as a legal entity. ASSET_MANAGEMENT - the governance of physical assets. The GovernanceDomainDescription provides the definition of a governance domain. You can choose to define your own or use the standard set that are defined by GovernanceDomain . Related governance domains can be grouped into GovernanceDomainSets . The role of leader of a governance domain is represented as a GovernanceOfficer . GovernanceDefinition describes an aspect of a governance program. They are authored in the metadata repository. They inherit from Referenceable , which means they have a unique identifier and link to external references for more information. GovernedBy links the governance definitions to the elements they are governing.","title":"0401 Governance Definitions"},{"location":"types/4/0401-Governance-Definitions/#further-information","text":"The governance definitions are organized into specific subtypes and linked together to provide a complete description of the governance program. The types for these more specialized definitions can be found on the following pages: 0405 Governance Drivers - describe the motivations behind the governance program. 0415 Governance Responses - describe the policies that support each of the drivers. 0420 Governance Controls - describe how the policies will be implemented. 0430 Technical Controls - describe automated behaviour that implements a governance control. 0438 Naming Standards - defines naming standard rules. 0460 Governance Execution Points - describe classifications for software components that link them to a technical control. 0461 Governance Action Engines - support the execution of technical controls. 0462 Governance Action Types - provide the choreography of the execution of technical controls. 0440 Organizational Controls - identity governance roles and manual procedures (such as approvals) that implement a governance control. 0445 Governance Roles - define governance roles and the people associated with them. 0481 License Types - terms and conditions used in rights management. 0482 Certification Types - types of certifications used to shw compliance to a specific governance requirement. 0485 Data Processing Purposes - definitions of purposes used in data privacy regulations. The Governance Program OMAS provides the APIs for maintaining the definitions of the governance domains, governance definitions and governance officers. It uses the GovernedBy relationship to link governance definitions with subject area definitions and governance zone definitions . The Asset Manager OMAS supports the exchange of governance definitions with third party asset managers and governance tools as well as the use of the GovernedBy relationship through its Governance Exchange Interface .","title":"Further Information"},{"location":"types/4/0405-Governance-Drivers/","text":"0405 Governance Drivers \u00b6 Governance drivers define the motivation behind the governance program. The GovernanceStrategy is derived from the business strategy. It defines how the governance program supports the business strategy. Regulations define relevant legal requirements relating to the business operation. Reconciling the governance strategy with the regulations creates synergies in an organization's approach to governance. Related Information \u00b6 Governance Drivers are types of GovernanceDefinitions which are located in model 0401 . The Governance Program OMAS provides support for defining governance drivers through its GovernanceDriversInterface .","title":"Governance Drivers"},{"location":"types/4/0405-Governance-Drivers/#0405-governance-drivers","text":"Governance drivers define the motivation behind the governance program. The GovernanceStrategy is derived from the business strategy. It defines how the governance program supports the business strategy. Regulations define relevant legal requirements relating to the business operation. Reconciling the governance strategy with the regulations creates synergies in an organization's approach to governance.","title":"0405 Governance Drivers"},{"location":"types/4/0405-Governance-Drivers/#related-information","text":"Governance Drivers are types of GovernanceDefinitions which are located in model 0401 . The Governance Program OMAS provides support for defining governance drivers through its GovernanceDriversInterface .","title":"Related Information"},{"location":"types/4/0415-Governance-Responses/","text":"0415 Governance Responses \u00b6 Governance policies define how a governance program will provide support to the governance drives. They are said to be the \"responses to the challenges proposed by the governance drivers\". There are three main types of policy: Principles define the overall values and guidelines for the governance program Obligations define specific actions or processing that must be accommodated Approaches define best practices for how an asset should be implemented and managed. Related Information \u00b6 Governance policies are types of GovernanceDefinitions which are located in model 0401 . The governance drivers are defined in model 0405 . The Governance Program OMAS provides support for defining governance policies through its GovernancePolicyMakingInterface .","title":"Governance Responses"},{"location":"types/4/0415-Governance-Responses/#0415-governance-responses","text":"Governance policies define how a governance program will provide support to the governance drives. They are said to be the \"responses to the challenges proposed by the governance drivers\". There are three main types of policy: Principles define the overall values and guidelines for the governance program Obligations define specific actions or processing that must be accommodated Approaches define best practices for how an asset should be implemented and managed.","title":"0415 Governance Responses"},{"location":"types/4/0415-Governance-Responses/#related-information","text":"Governance policies are types of GovernanceDefinitions which are located in model 0401 . The governance drivers are defined in model 0405 . The Governance Program OMAS provides support for defining governance policies through its GovernancePolicyMakingInterface .","title":"Related Information"},{"location":"types/4/0417-Governance-Projects/","text":"0417 Governance Projects \u00b6 The roll-out of a governance program is typically divided into projects that are grouped together into a campaign (see Projects in Area 1). The GovernanceProject classification tags these projects so they are easy for the governance team to identify when it comes to reporting.","title":"Governance Projects"},{"location":"types/4/0417-Governance-Projects/#0417-governance-projects","text":"The roll-out of a governance program is typically divided into projects that are grouped together into a campaign (see Projects in Area 1). The GovernanceProject classification tags these projects so they are easy for the governance team to identify when it comes to reporting.","title":"0417 Governance Projects"},{"location":"types/4/0420-Governance-Controls/","text":"0420 Governance Controls \u00b6 Governance is enabled through People, Process and Technology. These are controlled through a combination of technical controls (implemented IT function) and organizational controls (training, responsibility, buddy-checking etc). Further Information \u00b6 Governance controls are types of GovernanceDefinitions which are located in model 0401 . The governance policies are defined in model 0415 . The Governance Program OMAS provides support for defining governance policies through its GovernancePolicyMakingInterface . There is further detail on the content of the governance controls in the following models: 0430 Technical Controls - describe automated behaviour that implements a governance control. 0438 Naming Standards - defines naming standard rules. 0460 Governance Execution Points - describe classifications for software components that link them to a technical control. 0461 Governance Action Engines - support the execution of technical controls. 0462 Governance Action Types - provide the choreography of the execution of technical controls. 0440 Organizational Controls - identity governance roles and manual procedures (such as approvals) that implement a governance control. 0445 Governance Roles - define governance roles and the people associated with them.","title":"Governance Controls"},{"location":"types/4/0420-Governance-Controls/#0420-governance-controls","text":"Governance is enabled through People, Process and Technology. These are controlled through a combination of technical controls (implemented IT function) and organizational controls (training, responsibility, buddy-checking etc).","title":"0420 Governance Controls"},{"location":"types/4/0420-Governance-Controls/#further-information","text":"Governance controls are types of GovernanceDefinitions which are located in model 0401 . The governance policies are defined in model 0415 . The Governance Program OMAS provides support for defining governance policies through its GovernancePolicyMakingInterface . There is further detail on the content of the governance controls in the following models: 0430 Technical Controls - describe automated behaviour that implements a governance control. 0438 Naming Standards - defines naming standard rules. 0460 Governance Execution Points - describe classifications for software components that link them to a technical control. 0461 Governance Action Engines - support the execution of technical controls. 0462 Governance Action Types - provide the choreography of the execution of technical controls. 0440 Organizational Controls - identity governance roles and manual procedures (such as approvals) that implement a governance control. 0445 Governance Roles - define governance roles and the people associated with them.","title":"Further Information"},{"location":"types/4/0421-Governance-Classification-Levels/","text":"Governance Classification Levels \u00b6 Most organizations already define their standard levels for governance classifications such as confidentiality. Although the Open Metadata Types include Standard Enumerations for these classification, the GovernanceClassificationLevel allows an organization to make use of their own definitions. An organization creates one of these entities for each of their confidentiality levels. The levelIdentifier value is then used in the classifications. It can be programmatically examined by security processing to, for example, compare the confidentiality of an asset against a person's access. Set of classification levels used in a particular classification can be grouped using a Collection which can be classified using GovernanceClassificationSet with details of the classification the values are used in. Similarly, the status of governance classification, entities and relationships can be customized through the GovernanceStatusLevel . The levelIdentifier values should be set up so Positive values relate to statuses which mean the element is ok to use. Zero means the element has just been created, but not vetted so use with caution. Negative values mean that the element is not to be trusted because it is, for example, obsolete or incorrect. Deprecated types GovernanceConfidentialityLevel - use GovernanceClassificationLevel .","title":"Governance Classification Levels"},{"location":"types/4/0421-Governance-Classification-Levels/#governance-classification-levels","text":"Most organizations already define their standard levels for governance classifications such as confidentiality. Although the Open Metadata Types include Standard Enumerations for these classification, the GovernanceClassificationLevel allows an organization to make use of their own definitions. An organization creates one of these entities for each of their confidentiality levels. The levelIdentifier value is then used in the classifications. It can be programmatically examined by security processing to, for example, compare the confidentiality of an asset against a person's access. Set of classification levels used in a particular classification can be grouped using a Collection which can be classified using GovernanceClassificationSet with details of the classification the values are used in. Similarly, the status of governance classification, entities and relationships can be customized through the GovernanceStatusLevel . The levelIdentifier values should be set up so Positive values relate to statuses which mean the element is ok to use. Zero means the element has just been created, but not vetted so use with caution. Negative values mean that the element is not to be trusted because it is, for example, obsolete or incorrect. Deprecated types GovernanceConfidentialityLevel - use GovernanceClassificationLevel .","title":"Governance Classification Levels"},{"location":"types/4/0422-Governance-Action-Classifications/","text":"0422 Governance Action Classifications \u00b6 Governance Action Classifications describe the common (ie typical) types of classifications that are used in the governance controls. Impact describes the impact of a situation on a particular resource. Criticality describes how critical a resource is to the operations of the organization. Confidentiality typically is used with a data resource and indicates how confidential its content is. Confidence indicates how confident the organization in the use of this resource in terms of its quality. Retention defines how long a resource (typically a data resource) needs to be kept. The values used in levelIdentifier , severityIdentifier and basisIdentifier are define using GovernanceClassificationLevels . The values used in statusIdentifier are defined using GovernanceStatusLevels .","title":"Governance Action Classifications"},{"location":"types/4/0422-Governance-Action-Classifications/#0422-governance-action-classifications","text":"Governance Action Classifications describe the common (ie typical) types of classifications that are used in the governance controls. Impact describes the impact of a situation on a particular resource. Criticality describes how critical a resource is to the operations of the organization. Confidentiality typically is used with a data resource and indicates how confidential its content is. Confidence indicates how confident the organization in the use of this resource in terms of its quality. Retention defines how long a resource (typically a data resource) needs to be kept. The values used in levelIdentifier , severityIdentifier and basisIdentifier are define using GovernanceClassificationLevels . The values used in statusIdentifier are defined using GovernanceStatusLevels .","title":"0422 Governance Action Classifications"},{"location":"types/4/0423-Security-Tags/","text":"0423 Security Tags \u00b6 Security Tags can be attached to assets or schema elements to drive the rules inside a security engine.","title":"Security Tags"},{"location":"types/4/0423-Security-Tags/#0423-security-tags","text":"Security Tags can be attached to assets or schema elements to drive the rules inside a security engine.","title":"0423 Security Tags"},{"location":"types/4/0424-Governance-Zones/","text":"0424 Governance Zones \u00b6 A GovernanceZone describes a collection of Assets that are used, or processed in a specific way. The governance zone definitions define the governance zones in use in the organization and how they are used. It is possible to then attach governance policies and controls to the zone definitions using the GovernedBy relationship to show how assets assigned to a zone should be managed and governed. Linking the zones in a hierarchy implies that the governance definitions linked to a zone that is higher in the hierarchy also apply to all governance zones linked underneath it. An Asset may belong to many Governance Zones. This is defined in the AssetZoneMembership classification. A classification is used rather than a relationship between Asset and GovernanceZoneDefinition to improve the performance of the asset processing since the classification flows with the Asset. There is more information on governance zones in governance zones . Deprecated types ZoneGovernance - use GovernedBy .","title":"Governance Zones"},{"location":"types/4/0424-Governance-Zones/#0424-governance-zones","text":"A GovernanceZone describes a collection of Assets that are used, or processed in a specific way. The governance zone definitions define the governance zones in use in the organization and how they are used. It is possible to then attach governance policies and controls to the zone definitions using the GovernedBy relationship to show how assets assigned to a zone should be managed and governed. Linking the zones in a hierarchy implies that the governance definitions linked to a zone that is higher in the hierarchy also apply to all governance zones linked underneath it. An Asset may belong to many Governance Zones. This is defined in the AssetZoneMembership classification. A classification is used rather than a relationship between Asset and GovernanceZoneDefinition to improve the performance of the asset processing since the classification flows with the Asset. There is more information on governance zones in governance zones . Deprecated types ZoneGovernance - use GovernedBy .","title":"0424 Governance Zones"},{"location":"types/4/0425-Subject-Areas/","text":"0425 Subject Areas \u00b6 Subject areas are topic areas that are important to the organization. Typically they cover data that is widely shared across the organization and there is business value in maintaining consistency in the data values in each copy. The role of the subject area definition is to act as an anchor for all of the subject area materials. This helps to coordinate the efforts to build the common definitions and standards for each subject area. Each subject area has an owner who is responsible for the common definitions relating to the subject area. Often the subject area owner is a senior person in the organization with expertise in the subject area. He/she coordinates other subject matter experts to author and maintain the common definitions and standards. This includes: A glossary of terms that describe the key concepts in the subject area. Lists and hierarchies of reference data that relate to particular data values in the subject area. Quality rules for specific data values in the subject area. Preferred data structures and schemas. The effort required to author and maintain these definitions, plus the governance process required to ensure they are used wherever appropriate is offset by the savings in managing and using the shared data associated with the subject area. Open Metadata Types \u00b6 The SubjectAreaDefinition provides the description of the subject area. By creating this definition, is a declaration that data about this subject area is of significance to the organization and will be receiving special attention. A subject area may be sub-divided into more specific subject areas. The subject areas can be linked together into a hierarchy using SubjectAreaHierarchy relationships. The subject area definition can be linked to the governance definitions via the SubjectAreaGovernance relationship. An organization can create governance definitions that are applicable to all subject areas, or are specific to the subject area they are linked to. Typically they will have a mixture of these. Finally the content for the subject area (glossaries, reference data, schemas etc) are identified using the SubjectArea classification that carries the name of the subject area it belongs to. This classification makes it easy to locate all of the subject area's content. Support for Subject Areas in Egeria \u00b6 The following Open Metadata Access Services (OMASs) support subject areas: Governance Program OMAS supports the maintenance of the hierarchy of subject area definitions and the associated governance definitions. Subject Area OMAS supports the subject matter experts in building the glossary and valid values for a subject area. Digital Architecture OMAS is for use by technical architects to define reference data, common data models and schema and rule implementations for the data and associated processing of the subject area. Further Information \u00b6 The Coco Pharmaceuticals case study includes * Planning for Common Data Definitions * Defining Subject Area Deprecated types SubjectAreaGovernance - use GovernedBy relationship instead.","title":"Subject Areas"},{"location":"types/4/0425-Subject-Areas/#0425-subject-areas","text":"Subject areas are topic areas that are important to the organization. Typically they cover data that is widely shared across the organization and there is business value in maintaining consistency in the data values in each copy. The role of the subject area definition is to act as an anchor for all of the subject area materials. This helps to coordinate the efforts to build the common definitions and standards for each subject area. Each subject area has an owner who is responsible for the common definitions relating to the subject area. Often the subject area owner is a senior person in the organization with expertise in the subject area. He/she coordinates other subject matter experts to author and maintain the common definitions and standards. This includes: A glossary of terms that describe the key concepts in the subject area. Lists and hierarchies of reference data that relate to particular data values in the subject area. Quality rules for specific data values in the subject area. Preferred data structures and schemas. The effort required to author and maintain these definitions, plus the governance process required to ensure they are used wherever appropriate is offset by the savings in managing and using the shared data associated with the subject area.","title":"0425 Subject Areas"},{"location":"types/4/0425-Subject-Areas/#open-metadata-types","text":"The SubjectAreaDefinition provides the description of the subject area. By creating this definition, is a declaration that data about this subject area is of significance to the organization and will be receiving special attention. A subject area may be sub-divided into more specific subject areas. The subject areas can be linked together into a hierarchy using SubjectAreaHierarchy relationships. The subject area definition can be linked to the governance definitions via the SubjectAreaGovernance relationship. An organization can create governance definitions that are applicable to all subject areas, or are specific to the subject area they are linked to. Typically they will have a mixture of these. Finally the content for the subject area (glossaries, reference data, schemas etc) are identified using the SubjectArea classification that carries the name of the subject area it belongs to. This classification makes it easy to locate all of the subject area's content.","title":"Open Metadata Types"},{"location":"types/4/0425-Subject-Areas/#support-for-subject-areas-in-egeria","text":"The following Open Metadata Access Services (OMASs) support subject areas: Governance Program OMAS supports the maintenance of the hierarchy of subject area definitions and the associated governance definitions. Subject Area OMAS supports the subject matter experts in building the glossary and valid values for a subject area. Digital Architecture OMAS is for use by technical architects to define reference data, common data models and schema and rule implementations for the data and associated processing of the subject area.","title":"Support for Subject Areas in Egeria"},{"location":"types/4/0425-Subject-Areas/#further-information","text":"The Coco Pharmaceuticals case study includes * Planning for Common Data Definitions * Defining Subject Area Deprecated types SubjectAreaGovernance - use GovernedBy relationship instead.","title":"Further Information"},{"location":"types/4/0430-Technical-Controls/","text":"0430 Technical Controls \u00b6 Technical controls are governance controls that are implemented using technology. They are deployed into the IT landscape as software components and processes.","title":"Technical Controls"},{"location":"types/4/0430-Technical-Controls/#0430-technical-controls","text":"Technical controls are governance controls that are implemented using technology. They are deployed into the IT landscape as software components and processes.","title":"0430 Technical Controls"},{"location":"types/4/0435-Policy-Management-Capabilities/","text":"0435 Policy Management Capabilities \u00b6 The policy management capabilities describe the different capabilities needed to automate the enforcement of policies. These capabilities were originally identified in the eXtensible Access Control Mark-up Language (XACML) standard. XACML is an OASIS standard specifically focused at access control policies. However the architecture is clean enough to generalise to the management of all types of governance policy and so it has been included in the open metadata types. There are five components involved in policy management: * Policy Administration Point (PAP) - the tool/API used to administer policies. * Policy Decision Point (PDP) - the component that evaluates policies for a specific situation and selects a course of action. * Policy Enforcement Point (PEP) - the component thar enforces the policy decision made by the PDP. Usually this is the component that is used to access a resource or perform a task. The PEP calls the PDP to find out what the decision that needs to be enforced and then enforces the resulting decision in real-time. * Policy Information Point (PIP) - a component that provides additional information to the PDP to enable it to make a decision. * Policy Retrieval Point (PRP) - a component used by the PDP to retrieve the policy details that apply to the situation that the PDP is evaluating. Open Metadata Types \u00b6 The open metadata types are implemented as classifications. The classifications can be applied to Referenceables so that they can be used to classify solution components during solution design and software server capabilities for the running implementation. Using the Policy Management Capabilities open metadata types \u00b6 The Digital Architecture OMAS and IT Infrastructure OMAS provide mechanisms to set up the Policy Management Capabilities classifications on metadata elements. Implementation of Policy Management Capabilities in Egeria \u00b6 Not only does Egeria support the use of the Policy Management Capabilities in your architectures and metadata, we have also the concepts in the design of Egeria itself. In Egeria, the Policy Administration Point is Governance Program OMAS . Services such as Governance Engine OMAS act as a Policy Retrieval Points to push policy information to external Policy Enforcement Points such as Apache Ranger . Egeria's metadata access points and metadata servers can act as Policy Information Points. Egeria's Metadata Security module is a Policy Enforcement Point, calling the metadata security connectors as Policy Decision Points. The Engine Services running in the Engine Host OMAG Server can act as Policy Enforcement Points.","title":"Policy Management Capabilities"},{"location":"types/4/0435-Policy-Management-Capabilities/#0435-policy-management-capabilities","text":"The policy management capabilities describe the different capabilities needed to automate the enforcement of policies. These capabilities were originally identified in the eXtensible Access Control Mark-up Language (XACML) standard. XACML is an OASIS standard specifically focused at access control policies. However the architecture is clean enough to generalise to the management of all types of governance policy and so it has been included in the open metadata types. There are five components involved in policy management: * Policy Administration Point (PAP) - the tool/API used to administer policies. * Policy Decision Point (PDP) - the component that evaluates policies for a specific situation and selects a course of action. * Policy Enforcement Point (PEP) - the component thar enforces the policy decision made by the PDP. Usually this is the component that is used to access a resource or perform a task. The PEP calls the PDP to find out what the decision that needs to be enforced and then enforces the resulting decision in real-time. * Policy Information Point (PIP) - a component that provides additional information to the PDP to enable it to make a decision. * Policy Retrieval Point (PRP) - a component used by the PDP to retrieve the policy details that apply to the situation that the PDP is evaluating.","title":"0435 Policy Management Capabilities"},{"location":"types/4/0435-Policy-Management-Capabilities/#open-metadata-types","text":"The open metadata types are implemented as classifications. The classifications can be applied to Referenceables so that they can be used to classify solution components during solution design and software server capabilities for the running implementation.","title":"Open Metadata Types"},{"location":"types/4/0435-Policy-Management-Capabilities/#using-the-policy-management-capabilities-open-metadata-types","text":"The Digital Architecture OMAS and IT Infrastructure OMAS provide mechanisms to set up the Policy Management Capabilities classifications on metadata elements.","title":"Using the Policy Management Capabilities open metadata types"},{"location":"types/4/0435-Policy-Management-Capabilities/#implementation-of-policy-management-capabilities-in-egeria","text":"Not only does Egeria support the use of the Policy Management Capabilities in your architectures and metadata, we have also the concepts in the design of Egeria itself. In Egeria, the Policy Administration Point is Governance Program OMAS . Services such as Governance Engine OMAS act as a Policy Retrieval Points to push policy information to external Policy Enforcement Points such as Apache Ranger . Egeria's metadata access points and metadata servers can act as Policy Information Points. Egeria's Metadata Security module is a Policy Enforcement Point, calling the metadata security connectors as Policy Decision Points. The Engine Services running in the Engine Host OMAG Server can act as Policy Enforcement Points.","title":"Implementation of Policy Management Capabilities in Egeria"},{"location":"types/4/0438-Naming-Standards/","text":"0438 Naming Standards \u00b6 Naming standards provide means for classifying glossary terms to allow naming rules to use them. Deprecated types NamingConventionRule - use Modifier","title":"Naming Standards"},{"location":"types/4/0438-Naming-Standards/#0438-naming-standards","text":"Naming standards provide means for classifying glossary terms to allow naming rules to use them. Deprecated types NamingConventionRule - use Modifier","title":"0438 Naming Standards"},{"location":"types/4/0440-Organizational-Controls/","text":"0440 Organizational Controls \u00b6 Organizational controls describe governance controls that are implemented through people, organizational structures and responsibilities plus manual procedures and rules.","title":"Organizational Controls"},{"location":"types/4/0440-Organizational-Controls/#0440-organizational-controls","text":"Organizational controls describe governance controls that are implemented through people, organizational structures and responsibilities plus manual procedures and rules.","title":"0440 Organizational Controls"},{"location":"types/4/0442-Project-Charter/","text":"0442 Project Charter \u00b6 The project charter defines the mission and purpose of the project. The access to resources for a project may be partially controlled by the type/mission of the project. For example, the purposes, specifically are used in GDPR scenarios.","title":"Project Charter"},{"location":"types/4/0442-Project-Charter/#0442-project-charter","text":"The project charter defines the mission and purpose of the project. The access to resources for a project may be partially controlled by the type/mission of the project. For example, the purposes, specifically are used in GDPR scenarios.","title":"0442 Project Charter"},{"location":"types/4/0445-Governance-Roles/","text":"0445 Governance Roles \u00b6 Although we aim to automate governance as much as possible, it is often necessary to assign responsibility for specific actions to specific people. In Figure 1, the responsibilities of someone assigned to managed a particular aspect of governing a resource ( Referenceable ) is represented by a GovernanceRole entity. Since GovernanceRole inherits from PersonRole an individual is assigned the Governance Role through the PersonRoleAppointment relationship. Figure 1: Assignment of Governance Roles Specific subtypes for GovernanceRole are also defined to group governance roles into the typical types of responsibility. GovernanceOfficer - person leading a governance domain. AssetOwner - person responsible for the correct management of an asset. SubjectAreaOwner - person responsible for the definitions within a subject area. ComponentOwner - person responsible for a component within an asset. DataItemOwner - person responsible for the correctness of a particular type of data value throughout its lifetime. Often these data values flow between systems and the DataItemOwner must be sure it is correct in all places. Ownership is assigned to a resource by adding the Ownership classification to it. This classification can assign ownership to an ActorProfile , UserIdentity or PersonRole . It does not need to be a GovernanceRole. Deprecated types ResponsibilityStaffContact relationship is deprecated in favour of the more generic GovernanceResponsibilityAssignment . The original ownership types did not allow resources to be owned by a person role. They are all replaced by the more generic Ownership classification. AssetOwnership - use Ownership AssetOwnerType - use Ownership* properties OwnerType - use Ownership properties","title":"Governance Roles"},{"location":"types/4/0445-Governance-Roles/#0445-governance-roles","text":"Although we aim to automate governance as much as possible, it is often necessary to assign responsibility for specific actions to specific people. In Figure 1, the responsibilities of someone assigned to managed a particular aspect of governing a resource ( Referenceable ) is represented by a GovernanceRole entity. Since GovernanceRole inherits from PersonRole an individual is assigned the Governance Role through the PersonRoleAppointment relationship. Figure 1: Assignment of Governance Roles Specific subtypes for GovernanceRole are also defined to group governance roles into the typical types of responsibility. GovernanceOfficer - person leading a governance domain. AssetOwner - person responsible for the correct management of an asset. SubjectAreaOwner - person responsible for the definitions within a subject area. ComponentOwner - person responsible for a component within an asset. DataItemOwner - person responsible for the correctness of a particular type of data value throughout its lifetime. Often these data values flow between systems and the DataItemOwner must be sure it is correct in all places. Ownership is assigned to a resource by adding the Ownership classification to it. This classification can assign ownership to an ActorProfile , UserIdentity or PersonRole . It does not need to be a GovernanceRole. Deprecated types ResponsibilityStaffContact relationship is deprecated in favour of the more generic GovernanceResponsibilityAssignment . The original ownership types did not allow resources to be owned by a person role. They are all replaced by the more generic Ownership classification. AssetOwnership - use Ownership AssetOwnerType - use Ownership* properties OwnerType - use Ownership properties","title":"0445 Governance Roles"},{"location":"types/4/0450-Governance-Rollout/","text":"0450 Governance Rollout \u00b6 As important aspect of the governance program is the ability to measure its effectiveness and identify the assets that are delivering the highest value, or operating with the greatest efficiency etc. A value that should be captured to demonstrate the effectiveness of the governance program is documented using the GovernanceMetric entity. It is linked to the appropriate GovernanceDefinition and can be linked to a data set where the specific measurements are being gathered. The calculation of governance metrics is often a summary of many other measurements associated with specific resources (such as data sources and processes) operating under the scope of the governance program. These resources are catalogued as Assets . The definition of their expected behavior or content can be capture using the GovernanceExpectations classification attached to the Asset. The measurements that support the assessment of a particular resource can be gathered and stored in a GovernanceMeasurements classification attached to its Asset.","title":"Governance Rollout"},{"location":"types/4/0450-Governance-Rollout/#0450-governance-rollout","text":"As important aspect of the governance program is the ability to measure its effectiveness and identify the assets that are delivering the highest value, or operating with the greatest efficiency etc. A value that should be captured to demonstrate the effectiveness of the governance program is documented using the GovernanceMetric entity. It is linked to the appropriate GovernanceDefinition and can be linked to a data set where the specific measurements are being gathered. The calculation of governance metrics is often a summary of many other measurements associated with specific resources (such as data sources and processes) operating under the scope of the governance program. These resources are catalogued as Assets . The definition of their expected behavior or content can be capture using the GovernanceExpectations classification attached to the Asset. The measurements that support the assessment of a particular resource can be gathered and stored in a GovernanceMeasurements classification attached to its Asset.","title":"0450 Governance Rollout"},{"location":"types/4/0455-Exception-Management/","text":"0455 Exception Management \u00b6 Governance is supported by a number of operational logs. Each operational log is a collection of log records. In many cases each log record is stored as an individual file for ease of management. It is not uncommon that the volume of log records is high and the value of the information in each log record is variable. As a result individual log records are not catalogued unless they are significant in some way. (For example, it may be that the log record needs to be kept for regulatory purposes, or there is stewardship action required.) As such, the log records are written to storage as the processing that they describe proceeds. Asynchronous processes then scan and review the content of the log records to ensure the processing is as expected. They may also purge the log records that are no longer needed. This log record processing may maintain various counts and other measurements that can be captured in the metadata or in an external data store. The LogAnalysis classification enables the capture of these measurements in metadata. For example, log records that represent significant events may be catalogued as assets and the LogAnalysis classification attached to the asset. The results of the log analysis across many record may be rolled up into a GovernanceMeasurement attached to the appropriate GovernanceDefinition . The types of operational logs and associated processing are: Metering captures the usage of resources. This may be to enforce usage quotas, or for billing. A collection of related metering record is represented as a MeteringLog . If it is implemented using files then each file can be classified with MeteringLogFile . Operational lineage logging captures the execution path and results of processes. It is used to prove that processes ran, and ran at the right time, processing the right quantity of data at appropriate quality. A collection of related lineage log records is represented as a LineageLog . If the lineage log is implemented using files, each file can be classified with LineageLogFile . Audit logging records significant events. This may be successful processing events or detected errors that need action. A collection of related audit log records is represented as a AuditLog . If the audit log is implemented using files, each file can be classified with AuditLogFile . Exception management handles errors detected by verification points . Exception records are managed in one or more ExceptionBacklog collections. The exception backlog may be implemented as a series of files classified as ExceptionLogFile . The software servers that are managing operational governance can be classified with the following: StewardshipServer describes a server that is handling the stewardship processes. GovernanceDaemon describes a background server that is hosing automated governance processing.","title":"Exception Management"},{"location":"types/4/0455-Exception-Management/#0455-exception-management","text":"Governance is supported by a number of operational logs. Each operational log is a collection of log records. In many cases each log record is stored as an individual file for ease of management. It is not uncommon that the volume of log records is high and the value of the information in each log record is variable. As a result individual log records are not catalogued unless they are significant in some way. (For example, it may be that the log record needs to be kept for regulatory purposes, or there is stewardship action required.) As such, the log records are written to storage as the processing that they describe proceeds. Asynchronous processes then scan and review the content of the log records to ensure the processing is as expected. They may also purge the log records that are no longer needed. This log record processing may maintain various counts and other measurements that can be captured in the metadata or in an external data store. The LogAnalysis classification enables the capture of these measurements in metadata. For example, log records that represent significant events may be catalogued as assets and the LogAnalysis classification attached to the asset. The results of the log analysis across many record may be rolled up into a GovernanceMeasurement attached to the appropriate GovernanceDefinition . The types of operational logs and associated processing are: Metering captures the usage of resources. This may be to enforce usage quotas, or for billing. A collection of related metering record is represented as a MeteringLog . If it is implemented using files then each file can be classified with MeteringLogFile . Operational lineage logging captures the execution path and results of processes. It is used to prove that processes ran, and ran at the right time, processing the right quantity of data at appropriate quality. A collection of related lineage log records is represented as a LineageLog . If the lineage log is implemented using files, each file can be classified with LineageLogFile . Audit logging records significant events. This may be successful processing events or detected errors that need action. A collection of related audit log records is represented as a AuditLog . If the audit log is implemented using files, each file can be classified with AuditLogFile . Exception management handles errors detected by verification points . Exception records are managed in one or more ExceptionBacklog collections. The exception backlog may be implemented as a series of files classified as ExceptionLogFile . The software servers that are managing operational governance can be classified with the following: StewardshipServer describes a server that is handling the stewardship processes. GovernanceDaemon describes a background server that is hosing automated governance processing.","title":"0455 Exception Management"},{"location":"types/4/0460-Governance-Execution-Points/","text":"0460 Governance Execution Points \u00b6 A governance execution point defines specific activity that is supporting governance. There are three types: A Control Point is a place in the processing where a decision needs to be made. It may be a choice on whether to tolerate a reported situation or to resolve it - or it may be a decision on how to solve it. A Verification Point describes processing that is testing if a desired condition is true. Quality rules are examples of verification points. The result of a verification point is the output of the test. It may, for example, be a boolean, classification or a set of invalid values. An Enforcement Point describes processing that enforces an specific condition. For example, data may need to be encrypted at a certain point in the processing. The encryption processing is an enforcement point. The ExecutionPointDefinition elements are created during the design of the governance program. They characterize the types of execution points that are needed to support the governance requirements. They are linked to the Governance Definition that they support using the ExecutionPointUse relationship. Typically the governance definitions linked to the governance execution point definitions are: Governance Processes Governance Procedures Often execution points need to be integrated with the normal activity of the business, but they may also represent additional standalone activity. The classifications ControlPoint , VerificationPoint and EnforcementPoint are used to label governance implementation elements with the type of execution point and the qualified name of the corresponding definition if any. They are often found on element such as: Governance Action Types Governance Actions These classifications help in the review of the implementation of the governance program and can be used to drive additional audit logging.","title":"Governance Execution Points"},{"location":"types/4/0460-Governance-Execution-Points/#0460-governance-execution-points","text":"A governance execution point defines specific activity that is supporting governance. There are three types: A Control Point is a place in the processing where a decision needs to be made. It may be a choice on whether to tolerate a reported situation or to resolve it - or it may be a decision on how to solve it. A Verification Point describes processing that is testing if a desired condition is true. Quality rules are examples of verification points. The result of a verification point is the output of the test. It may, for example, be a boolean, classification or a set of invalid values. An Enforcement Point describes processing that enforces an specific condition. For example, data may need to be encrypted at a certain point in the processing. The encryption processing is an enforcement point. The ExecutionPointDefinition elements are created during the design of the governance program. They characterize the types of execution points that are needed to support the governance requirements. They are linked to the Governance Definition that they support using the ExecutionPointUse relationship. Typically the governance definitions linked to the governance execution point definitions are: Governance Processes Governance Procedures Often execution points need to be integrated with the normal activity of the business, but they may also represent additional standalone activity. The classifications ControlPoint , VerificationPoint and EnforcementPoint are used to label governance implementation elements with the type of execution point and the qualified name of the corresponding definition if any. They are often found on element such as: Governance Action Types Governance Actions These classifications help in the review of the implementation of the governance program and can be used to drive additional audit logging.","title":"0460 Governance Execution Points"},{"location":"types/4/0461-Governance-Engines/","text":"0461 Governance Engines \u00b6 A governance engine is a software server capability that is able to run specific services on demand. These services, called governance services, typically implement specific logic that is needed to govern an organization's resources or the metadata associated with them. Open metadata recognizes two types of governance engine: Governance action engines and services support the active governance of metadata and the resources they represent. There are different types of governance action engines/services that are defined by the Governance Action Framework ( GAF ) . Discovery engines and services support the analysis of the real world resources. The results of this analysis are stored in a discovery analysis report chained off of the corresponding Asset metadata element. The interfaces for discovery are found in the Open Discovery Framework ( ODF ) . The Open Metadata Engine Services ( OMES ) support the implementation of each type of governance engine. They run in an Engine Host OMAG Server and draw their configuration from the GovernanceEngine and the linked GovernanceService elements in the associated metadata server.","title":"Governance Engines"},{"location":"types/4/0461-Governance-Engines/#0461-governance-engines","text":"A governance engine is a software server capability that is able to run specific services on demand. These services, called governance services, typically implement specific logic that is needed to govern an organization's resources or the metadata associated with them. Open metadata recognizes two types of governance engine: Governance action engines and services support the active governance of metadata and the resources they represent. There are different types of governance action engines/services that are defined by the Governance Action Framework ( GAF ) . Discovery engines and services support the analysis of the real world resources. The results of this analysis are stored in a discovery analysis report chained off of the corresponding Asset metadata element. The interfaces for discovery are found in the Open Discovery Framework ( ODF ) . The Open Metadata Engine Services ( OMES ) support the implementation of each type of governance engine. They run in an Engine Host OMAG Server and draw their configuration from the GovernanceEngine and the linked GovernanceService elements in the associated metadata server.","title":"0461 Governance Engines"},{"location":"types/4/0462-Governance-Action-Types/","text":"0462 Governance Action Types \u00b6 The GovernanceActionType is used to define a set of linked governance actions that support a specific GovernanceProcess . They are used as a template to create GovernanceActions .","title":"Governance Action Types"},{"location":"types/4/0462-Governance-Action-Types/#0462-governance-action-types","text":"The GovernanceActionType is used to define a set of linked governance actions that support a specific GovernanceProcess . They are used as a template to create GovernanceActions .","title":"0462 Governance Action Types"},{"location":"types/4/0463-Governance-Actions/","text":"0463 Governance Actions \u00b6 A GovernanceAction describes some processing that is part of the governance of an organization's asset or the metadata tht describes them. The creation of a GovernanceAction typically triggers services in the governance engines . As the services run, they add information to the GovernanceAction describing the activities run and the actions taken against specific resources (see TargetForAction ). Once the action is complete, the GovernanceAction acts as an audit record for the actions taken. The GovernanceActionExecutor identifies the governance engine that will run the service that will execute the action. The specific service is identified by the requestType property. The governance engine is shown as a SoftwareServerCapability but is typically either a DiscoveryEngine or a GovernanceActionEngine . The GovernanceActionRequestSource links the first GovernanceAction in a chain to the cause/originator of the action. This could be, for example, a GovernanceProcess or a RequestForActionAnnotation . The GovernanceAction is also linked to any follow on activities through the NextGovernanceAction relationship so it is possible to trace through a chain of actions. The guard describes the output guard from the previous action(s) that will trigger the next action(s). If the guard is mandatory (ie mandatoryGuard = true), a next action can not run until a previous action has produced this guard. If ignoreMultipleTriggers = true, the next action is only triggered once. If it is false then the next action is triggered each time the guard is produced by the previous action(s).","title":"Governance Actions"},{"location":"types/4/0463-Governance-Actions/#0463-governance-actions","text":"A GovernanceAction describes some processing that is part of the governance of an organization's asset or the metadata tht describes them. The creation of a GovernanceAction typically triggers services in the governance engines . As the services run, they add information to the GovernanceAction describing the activities run and the actions taken against specific resources (see TargetForAction ). Once the action is complete, the GovernanceAction acts as an audit record for the actions taken. The GovernanceActionExecutor identifies the governance engine that will run the service that will execute the action. The specific service is identified by the requestType property. The governance engine is shown as a SoftwareServerCapability but is typically either a DiscoveryEngine or a GovernanceActionEngine . The GovernanceActionRequestSource links the first GovernanceAction in a chain to the cause/originator of the action. This could be, for example, a GovernanceProcess or a RequestForActionAnnotation . The GovernanceAction is also linked to any follow on activities through the NextGovernanceAction relationship so it is possible to trace through a chain of actions. The guard describes the output guard from the previous action(s) that will trigger the next action(s). If the guard is mandatory (ie mandatoryGuard = true), a next action can not run until a previous action has produced this guard. If ignoreMultipleTriggers = true, the next action is only triggered once. If it is false then the next action is triggered each time the guard is produced by the previous action(s).","title":"0463 Governance Actions"},{"location":"types/4/0465-Duplicate-Processing/","text":"0465 Duplicate Processing \u00b6 Since metadata is being created by many tools, it is possible that the same resource is catalogued multiple times. These duplicate elements are then exposed when the tools are connected together with Egeria. The duplicate processing types are used by the governance engines and stewards to link elements that are duplicates so that the open metadata ecosystem can ensure consumers of open metadata do not see the duplicates when they query the open metadata repositories. PeerDuplicateLink \u00b6 When a governance engine or steward detects that two elements are duplicates of one another, they are linked using the PeerDuplicateLink . This link on its own indicates a potential duplicate. KnownDuplicate \u00b6 When the duplicate is confirmed (either by a steward, or a governance engine) the KnownDuplicate classification is added to the entities that are linked with the PeerDuplicateLink . This classification is detected by metadata retrieval processes and triggers the following duplicate processing: When an entity is retrieved either by guid or via a query and it has the KnownDuplicate classification attached, its header and properties are returned along with a combination of the classifications from itself and each of the entities linked with the PeerDuplicateLink relationship. If there are conflicts in the classifications they are logged in the audit log and the newest classification takes precedence. When the relationships linked to an entity with the KnownDuplicate classification is requested, the relationships attached to this entity, along with the relationships attached to all entities linked with the PeerDuplicateLink relationship. If there should only be one of a particular type of relationship then the conflicts are logged to the audit log and the newest relationship takes precedence. There is no special duplicate processing when a relationship is retrieved independently of an entity. ConsolidatedDuplicate and ConsolidatedDuplicateLink \u00b6 It may be that this simple set of survivorship rules and consolidation process is insufficient (or too expensive from a performance perspective). It is possible for a steward/governance engine to construct and store a consolidated entity with its consolidated classification and relationships. Such an entity is decorated with the ConsolidatedDuplicate classification and is linked to each of the source entities using the ConsolidatedDuplicateLink relationship. Once the ConsolidatedDuplicateLink relationship is in place, the simple survivorship rules and peer consolidation process are ignored and the properties, classifications and relationships from the consolidated entity are used for a query to one of the linked entities with the KnownDuplicate classification. The steward/governance engine is responsible for the ongoing maintenance of this consolidated entity. Support for duplicate processing \u00b6 The Stewardship Action OMAS provides APIs for setting up peer duplicates and consolidated entities. The Governance Action Services running in the Governance Engines can automate the detection of duplicates and the maintenance of consolidated entities. The governance engines are supported by the Governance Engine OMAS . Deprecated types KnownDuplicateLink is deprecated in favor of the two specialized relationships: PeerDuplicateLink and ConsolidatedDuplicateLink.","title":"Duplicate Processing"},{"location":"types/4/0465-Duplicate-Processing/#0465-duplicate-processing","text":"Since metadata is being created by many tools, it is possible that the same resource is catalogued multiple times. These duplicate elements are then exposed when the tools are connected together with Egeria. The duplicate processing types are used by the governance engines and stewards to link elements that are duplicates so that the open metadata ecosystem can ensure consumers of open metadata do not see the duplicates when they query the open metadata repositories.","title":"0465 Duplicate Processing"},{"location":"types/4/0465-Duplicate-Processing/#peerduplicatelink","text":"When a governance engine or steward detects that two elements are duplicates of one another, they are linked using the PeerDuplicateLink . This link on its own indicates a potential duplicate.","title":"PeerDuplicateLink"},{"location":"types/4/0465-Duplicate-Processing/#knownduplicate","text":"When the duplicate is confirmed (either by a steward, or a governance engine) the KnownDuplicate classification is added to the entities that are linked with the PeerDuplicateLink . This classification is detected by metadata retrieval processes and triggers the following duplicate processing: When an entity is retrieved either by guid or via a query and it has the KnownDuplicate classification attached, its header and properties are returned along with a combination of the classifications from itself and each of the entities linked with the PeerDuplicateLink relationship. If there are conflicts in the classifications they are logged in the audit log and the newest classification takes precedence. When the relationships linked to an entity with the KnownDuplicate classification is requested, the relationships attached to this entity, along with the relationships attached to all entities linked with the PeerDuplicateLink relationship. If there should only be one of a particular type of relationship then the conflicts are logged to the audit log and the newest relationship takes precedence. There is no special duplicate processing when a relationship is retrieved independently of an entity.","title":"KnownDuplicate"},{"location":"types/4/0465-Duplicate-Processing/#consolidatedduplicate-and-consolidatedduplicatelink","text":"It may be that this simple set of survivorship rules and consolidation process is insufficient (or too expensive from a performance perspective). It is possible for a steward/governance engine to construct and store a consolidated entity with its consolidated classification and relationships. Such an entity is decorated with the ConsolidatedDuplicate classification and is linked to each of the source entities using the ConsolidatedDuplicateLink relationship. Once the ConsolidatedDuplicateLink relationship is in place, the simple survivorship rules and peer consolidation process are ignored and the properties, classifications and relationships from the consolidated entity are used for a query to one of the linked entities with the KnownDuplicate classification. The steward/governance engine is responsible for the ongoing maintenance of this consolidated entity.","title":"ConsolidatedDuplicate and ConsolidatedDuplicateLink"},{"location":"types/4/0465-Duplicate-Processing/#support-for-duplicate-processing","text":"The Stewardship Action OMAS provides APIs for setting up peer duplicates and consolidated entities. The Governance Action Services running in the Governance Engines can automate the detection of duplicates and the maintenance of consolidated entities. The governance engines are supported by the Governance Engine OMAS . Deprecated types KnownDuplicateLink is deprecated in favor of the two specialized relationships: PeerDuplicateLink and ConsolidatedDuplicateLink.","title":"Support for duplicate processing"},{"location":"types/4/0470-Incident-Reporting/","text":"0470 Incident Reporting \u00b6 The IncidentReport is used to record that an incident (such as data breach) has occurred. It can be linked to the assets that are affected and its resolution can be governed through normal processes.","title":"Incident Reporting"},{"location":"types/4/0470-Incident-Reporting/#0470-incident-reporting","text":"The IncidentReport is used to record that an incident (such as data breach) has occurred. It can be linked to the assets that are affected and its resolution can be governed through normal processes.","title":"0470 Incident Reporting"},{"location":"types/4/0481-Licenses/","text":"0481 Licenses \u00b6 The data economy brings licensing to data and metadata. Even open data typically has a license. The license will define the permitted uses and other requirements for using the asset. Details of a type of license are described in a LicenseType . The asset that is licensed is identified with the License relationship.","title":"Licenses"},{"location":"types/4/0481-Licenses/#0481-licenses","text":"The data economy brings licensing to data and metadata. Even open data typically has a license. The license will define the permitted uses and other requirements for using the asset. Details of a type of license are described in a LicenseType . The asset that is licensed is identified with the License relationship.","title":"0481 Licenses"},{"location":"types/4/0482-Certifications/","text":"0482 Certifications \u00b6 Many regulations and industry bodies define certifications that can confirm a level of support, capability or competence in an aspect of a digital organization\u2019s operation. Having certifications may be necessary to operating legally or may be a business advantage. The certifications awarded can be captured in the metadata repository to enable both use and management of the certification process.","title":"Certifications"},{"location":"types/4/0482-Certifications/#0482-certifications","text":"Many regulations and industry bodies define certifications that can confirm a level of support, capability or competence in an aspect of a digital organization\u2019s operation. Having certifications may be necessary to operating legally or may be a business advantage. The certifications awarded can be captured in the metadata repository to enable both use and management of the certification process.","title":"0482 Certifications"},{"location":"types/4/0485-Data-Processing-Purposes/","text":"0485 Data Processing Purposes \u00b6 Privacy regulations such as the EU's General Data Processing Regulation (GDPR) require data subjects to agree the processing that is permitted on their data. Often the processing is summarized in terms of the outcome (or the \"purpose\" of the processing) with the option to drill down into the details of how this processing is achieved. Other regulations The types below are used to capture the purposes and detailed data processing descriptions and record who or what has permission to perform the specified processing.","title":"Data Processing Purposes"},{"location":"types/4/0485-Data-Processing-Purposes/#0485-data-processing-purposes","text":"Privacy regulations such as the EU's General Data Processing Regulation (GDPR) require data subjects to agree the processing that is permitted on their data. Often the processing is summarized in terms of the outcome (or the \"purpose\" of the processing) with the option to drill down into the details of how this processing is achieved. Other regulations The types below are used to capture the purposes and detailed data processing descriptions and record who or what has permission to perform the specified processing.","title":"0485 Data Processing Purposes"},{"location":"types/5/","text":"Area 5 Models - Schema, Models and Reference Data \u00b6 Area 5 is where standards are established. This includes data models, schema fragments and reference data that are used to assist developers and architects in using best practice data structures and valid values as they develop new capability around the data assets. The first set of models describe the structure of data as it is deployed. These models describe the abstract definition of structured data. 0501 Schema Elements 0505 Schema Attributes 0507 External Schema Types 0511 Map Schema Element 0512 Derived Schema Elements These next models show how the schema is attached to assets and ports on a process. 0503 Asset Schema 0520 Process Schemas 0525 Process Variables This next model provides the ability to capture a template for generating schema artifacts for direct inclusion in an implementation. 0504 Implementation Snippets The next set of models are specializations of the abstract schema elements described aimed at different types of technology. 0530 Tabular Schema 0531 Document Schemas 0532 Object Schemas 0533 Graph Schema 0534 Relational Schema 0535 Event Schema 0536 API Schemas 0537 Display Schemas Data classes describe specify types of data - such as data, address, credit card, social security number. A data class is identified for a specific schema attribute by looking at the data values stored in it. 0540 Data Classes Reference data describes standard sets of data values - such as a list of country codes. 0545 Reference Data Instance metadata identifies schema attributes that contain metadata, rather than business data. 0550 Instance Metadata The next set of models describe the content of different types of data models 0565 Design Model Elements 0566 Design Model Organization 0568 Design Model Scoping 0569 Design Model Implementation 0570 Metamodels 0571 Concept Models The final set of models capture architectures and patterns. 0580 Solution Blueprints 0581 Solution Ports and Wires 0595 Design Patterns Further reading \u00b6 Modelling schemas Specific schema structures supported by the integration services For API Schemas - API Integrator OMIS For File Schemas - Files Integrator OMIS For Database Schemas - Database Integrator OMIS For Event Schemas - Topic Integrator OMIS For Forms and Report Schemas - Display Integrator OMIS","title":"Area 5 Structures"},{"location":"types/5/#area-5-models-schema-models-and-reference-data","text":"Area 5 is where standards are established. This includes data models, schema fragments and reference data that are used to assist developers and architects in using best practice data structures and valid values as they develop new capability around the data assets. The first set of models describe the structure of data as it is deployed. These models describe the abstract definition of structured data. 0501 Schema Elements 0505 Schema Attributes 0507 External Schema Types 0511 Map Schema Element 0512 Derived Schema Elements These next models show how the schema is attached to assets and ports on a process. 0503 Asset Schema 0520 Process Schemas 0525 Process Variables This next model provides the ability to capture a template for generating schema artifacts for direct inclusion in an implementation. 0504 Implementation Snippets The next set of models are specializations of the abstract schema elements described aimed at different types of technology. 0530 Tabular Schema 0531 Document Schemas 0532 Object Schemas 0533 Graph Schema 0534 Relational Schema 0535 Event Schema 0536 API Schemas 0537 Display Schemas Data classes describe specify types of data - such as data, address, credit card, social security number. A data class is identified for a specific schema attribute by looking at the data values stored in it. 0540 Data Classes Reference data describes standard sets of data values - such as a list of country codes. 0545 Reference Data Instance metadata identifies schema attributes that contain metadata, rather than business data. 0550 Instance Metadata The next set of models describe the content of different types of data models 0565 Design Model Elements 0566 Design Model Organization 0568 Design Model Scoping 0569 Design Model Implementation 0570 Metamodels 0571 Concept Models The final set of models capture architectures and patterns. 0580 Solution Blueprints 0581 Solution Ports and Wires 0595 Design Patterns","title":"Area 5 Models - Schema, Models and Reference Data"},{"location":"types/5/#further-reading","text":"Modelling schemas Specific schema structures supported by the integration services For API Schemas - API Integrator OMIS For File Schemas - Files Integrator OMIS For Database Schemas - Database Integrator OMIS For Event Schemas - Topic Integrator OMIS For Forms and Report Schemas - Display Integrator OMIS","title":"Further reading"},{"location":"types/5/0501-Schema-Elements/","text":"0501 Schema Elements \u00b6 Schema are used to represent the structure of data. They show the fields (also known as attributes or properties) of the data along with its type. SchemaElement describes the base definition for representing schema elements in metadata. The SchemaType describes the top-level name of a schema and also the types of any fields nested in it.","title":"Schema Elements"},{"location":"types/5/0501-Schema-Elements/#0501-schema-elements","text":"Schema are used to represent the structure of data. They show the fields (also known as attributes or properties) of the data along with its type. SchemaElement describes the base definition for representing schema elements in metadata. The SchemaType describes the top-level name of a schema and also the types of any fields nested in it.","title":"0501 Schema Elements"},{"location":"types/5/0503-Asset-Schema/","text":"0503 Asset Schema \u00b6 Model 0503 shows the relationship between an Asset and a SchemaType . When an asset is linked to a schema type it means that the schema type describes the structure of the Asset. The schema type can not be shared between different assets. If you are cataloging multiple assets with the same data structure, you can use a template which will copy the schema structure from the template asset to the new asset. (See Templated Cataloging for more details.","title":"Asset Schema"},{"location":"types/5/0503-Asset-Schema/#0503-asset-schema","text":"Model 0503 shows the relationship between an Asset and a SchemaType . When an asset is linked to a schema type it means that the schema type describes the structure of the Asset. The schema type can not be shared between different assets. If you are cataloging multiple assets with the same data structure, you can use a template which will copy the schema structure from the template asset to the new asset. (See Templated Cataloging for more details.","title":"0503 Asset Schema"},{"location":"types/5/0504-Implementation-Snippets/","text":"0504 Implementation Snippets \u00b6 Developers can be aided in their work by having snippets of schema implementation that follow approved structures and naming conventions that they can include in their APIs and data structures. Model 0504 shows how these can be linked to a Referenceable . The ImplementationSnippet is a Referenceable which means it can have a link to an external reference (say a physical schema implementation in a source code repository).","title":"Implementation Snippets"},{"location":"types/5/0504-Implementation-Snippets/#0504-implementation-snippets","text":"Developers can be aided in their work by having snippets of schema implementation that follow approved structures and naming conventions that they can include in their APIs and data structures. Model 0504 shows how these can be linked to a Referenceable . The ImplementationSnippet is a Referenceable which means it can have a link to an external reference (say a physical schema implementation in a source code repository).","title":"0504 Implementation Snippets"},{"location":"types/5/0505-Schema-Attributes/","text":"0505 Schema Attributes \u00b6 Schemas typically have a hierarchical structure. Model 0505 provides for a structure of complex schema types that have their own internal structure. This structure is defined through one or more nested attributes each with their own type. The TypeEmbeddedAttribute classification is applied directly to the SchemaAttribute to provide its type information. For example, if a ComplexSchemaType has a simple string attribute this can be captured as a SchemaAttribute (giving the name of the attribute) with a TypeEmbeddedAttribute classification (whose dataType property indicates string ). TypeEmbeddedAttribute can represent any of the standard schema types. Where a schema type is described using multiple schema type objects, (such as MapSchemaType , SchemaOptionChoice and ExternalSchemaType ) the schema relationships for that type begin with SchemaElement and then map to more detailed SchemaTypes. This is so they can be connected to a SchemaAttribute or a SchemaType. SchemaAttribute s can be nested within other SchemaAttribute s using the NestedSchemaAttribute relationship. See 0534 Relational Schemas for an example of this between RelationalTables and RelationalColumns. The SchemaAttributeType relationship only should be used if the same schema type is used in multiple attributes within the same schema. (To use a standard, pre-defined type for a schema attribute's type, set an ExternalSchemaType in the TypeEmbeddedAttribute and link to the standard, pre-defined type using the LinkedExternalSchemaType relationship.) The combined properties of SchemaAttribute can be used to represent simple bounded types like sets and arrays: Array: minCardinality = 0 , maxCardinality = -1 , allowsDuplicateValues = true , orderedValues = true Set: minCardinality = 0 , maxCardinality = -1 , allowsDuplicateValues = false , orderedValues = false Bag: minCardinality = 0 , maxCardinality = -1 , allowsDuplicateValues = true , orderedValues = false","title":"Schema Attributes"},{"location":"types/5/0505-Schema-Attributes/#0505-schema-attributes","text":"Schemas typically have a hierarchical structure. Model 0505 provides for a structure of complex schema types that have their own internal structure. This structure is defined through one or more nested attributes each with their own type. The TypeEmbeddedAttribute classification is applied directly to the SchemaAttribute to provide its type information. For example, if a ComplexSchemaType has a simple string attribute this can be captured as a SchemaAttribute (giving the name of the attribute) with a TypeEmbeddedAttribute classification (whose dataType property indicates string ). TypeEmbeddedAttribute can represent any of the standard schema types. Where a schema type is described using multiple schema type objects, (such as MapSchemaType , SchemaOptionChoice and ExternalSchemaType ) the schema relationships for that type begin with SchemaElement and then map to more detailed SchemaTypes. This is so they can be connected to a SchemaAttribute or a SchemaType. SchemaAttribute s can be nested within other SchemaAttribute s using the NestedSchemaAttribute relationship. See 0534 Relational Schemas for an example of this between RelationalTables and RelationalColumns. The SchemaAttributeType relationship only should be used if the same schema type is used in multiple attributes within the same schema. (To use a standard, pre-defined type for a schema attribute's type, set an ExternalSchemaType in the TypeEmbeddedAttribute and link to the standard, pre-defined type using the LinkedExternalSchemaType relationship.) The combined properties of SchemaAttribute can be used to represent simple bounded types like sets and arrays: Array: minCardinality = 0 , maxCardinality = -1 , allowsDuplicateValues = true , orderedValues = true Set: minCardinality = 0 , maxCardinality = -1 , allowsDuplicateValues = false , orderedValues = false Bag: minCardinality = 0 , maxCardinality = -1 , allowsDuplicateValues = true , orderedValues = false","title":"0505 Schema Attributes"},{"location":"types/5/0507-External-Schema-Type/","text":"0507 External Schema Type \u00b6 External schema types allow a schema to reference another schema type defined outside of the scope of its asset. The schema type that is linked to is often defined as part of a standard, of a set of types supported by a specific type of technology. It is typically reused in assets' schemas where the asset is supporting a standard schema. It may also be used as types for schema attributes where the schema is defined for a specific technology that has a fixed set of types. For example, a relational database column may be defined with external types that represent the defined types of the database platform where the database schema resides. LinkedExternalSchemaType is linked to a SchemaElement to enable it to be linked to both an ExternalSchemaType and a SchemaAttribute . Deprecated types The following types are replaced by the attributes in SchemaAttribute . - BoundedSchemaType - BoundedSchemaElementType - ArraySchemaType - SetSchemaType","title":"External Schema Types"},{"location":"types/5/0507-External-Schema-Type/#0507-external-schema-type","text":"External schema types allow a schema to reference another schema type defined outside of the scope of its asset. The schema type that is linked to is often defined as part of a standard, of a set of types supported by a specific type of technology. It is typically reused in assets' schemas where the asset is supporting a standard schema. It may also be used as types for schema attributes where the schema is defined for a specific technology that has a fixed set of types. For example, a relational database column may be defined with external types that represent the defined types of the database platform where the database schema resides. LinkedExternalSchemaType is linked to a SchemaElement to enable it to be linked to both an ExternalSchemaType and a SchemaAttribute . Deprecated types The following types are replaced by the attributes in SchemaAttribute . - BoundedSchemaType - BoundedSchemaElementType - ArraySchemaType - SetSchemaType","title":"0507 External Schema Type"},{"location":"types/5/0510-Schema-Link-Element/","text":"0510 Schema Link Element \u00b6 Schema link elements allow a schema to reference an external schema. This could be a schema from an external standard or tool.","title":"0510 Schema Link Element"},{"location":"types/5/0510-Schema-Link-Element/#0510-schema-link-element","text":"Schema link elements allow a schema to reference an external schema. This could be a schema from an external standard or tool.","title":"0510 Schema Link Element"},{"location":"types/5/0511-Map-Schema-Elements/","text":"0511 Map Schema Elements \u00b6 Maps hold the relationship between pairs of values. Often they are used to show how one value (the domain) can be mapped to another value (the range). The MapSchemaType describes the types of the values being mapped. The MapFromElementType relationship describes the domain type and the MapToElementType relationship describes the range type. The relationships start from SchemaElement rather than MapSchemaType since the schema type may be located in the the TypeEmbeddedAttribute classification","title":"Map Schema Elements"},{"location":"types/5/0511-Map-Schema-Elements/#0511-map-schema-elements","text":"Maps hold the relationship between pairs of values. Often they are used to show how one value (the domain) can be mapped to another value (the range). The MapSchemaType describes the types of the values being mapped. The MapFromElementType relationship describes the domain type and the MapToElementType relationship describes the range type. The relationships start from SchemaElement rather than MapSchemaType since the schema type may be located in the the TypeEmbeddedAttribute classification","title":"0511 Map Schema Elements"},{"location":"types/5/0512-Derived-Schema-Elements/","text":"0512 Derived Schema Elements \u00b6 Derived schema elements access other data, possibly in the same or a different asset to generate/derive the values for the attribute. Examples of this are database views and derived database columns. The CalculatedValue classification contains the formula. There are optional links to DerivedSchemaTypeQueryTarget to identify which schema elements are accessed by the formula. The formula may contain placeholders that refer to the queryId in DerivedSchemaTypeQueryTarget . Deprecated types The following types were replaced by DerivedSchemaTypeQueryTarget . - DerivedSchemaAttribute - SchemaLinkElement - LinkedType - SchemaLinkToType","title":"Derived Schema Elements"},{"location":"types/5/0512-Derived-Schema-Elements/#0512-derived-schema-elements","text":"Derived schema elements access other data, possibly in the same or a different asset to generate/derive the values for the attribute. Examples of this are database views and derived database columns. The CalculatedValue classification contains the formula. There are optional links to DerivedSchemaTypeQueryTarget to identify which schema elements are accessed by the formula. The formula may contain placeholders that refer to the queryId in DerivedSchemaTypeQueryTarget . Deprecated types The following types were replaced by DerivedSchemaTypeQueryTarget . - DerivedSchemaAttribute - SchemaLinkElement - LinkedType - SchemaLinkToType","title":"0512 Derived Schema Elements"},{"location":"types/5/0520-Process-Schemas/","text":"0520 - Process Schemas \u00b6 Process Schemas describe how the structure of the data passed through a processes ports is described. This is important in understanding how processes can be composed of other processes and it provides the basis for detailed lineage. (See also Ports .)","title":"Process Schemas"},{"location":"types/5/0520-Process-Schemas/#0520-process-schemas","text":"Process Schemas describe how the structure of the data passed through a processes ports is described. This is important in understanding how processes can be composed of other processes and it provides the basis for detailed lineage. (See also Ports .)","title":"0520 - Process Schemas"},{"location":"types/5/0525-Process-Variables/","text":"0525 Process Variables \u00b6 Process variables describe the data values that are used to initialize a process when it runs.","title":"Process Variables"},{"location":"types/5/0525-Process-Variables/#0525-process-variables","text":"Process variables describe the data values that are used to initialize a process when it runs.","title":"0525 Process Variables"},{"location":"types/5/0530-Tabular-Schemas/","text":"0530 Tabular Schemas \u00b6 Model 0530 shows the the structure of a single table. This could be a file that is organized into columns such as a CSV file . Note that for such a simple structure, the type information for each column can be directly embedded on the TabularColumn through the TypeEmbeddedAttribute classification. Further Information \u00b6 Files Integrator OMIS Data Manager OMAS Deprecated types The TabularColumnType entity has been deprecated because it restricts tabular columns to primitive types and some technologies will be able to support more types.","title":"Tabular Schemas"},{"location":"types/5/0530-Tabular-Schemas/#0530-tabular-schemas","text":"Model 0530 shows the the structure of a single table. This could be a file that is organized into columns such as a CSV file . Note that for such a simple structure, the type information for each column can be directly embedded on the TabularColumn through the TypeEmbeddedAttribute classification.","title":"0530 Tabular Schemas"},{"location":"types/5/0530-Tabular-Schemas/#further-information","text":"Files Integrator OMIS Data Manager OMAS Deprecated types The TabularColumnType entity has been deprecated because it restricts tabular columns to primitive types and some technologies will be able to support more types.","title":"Further Information"},{"location":"types/5/0531-Document-Schemas/","text":"0531 Document Schemas \u00b6 Model 0531 shows the definitions for structured documents such as JSON or XML. Note that the type information for each attribute within these structures can be directly embedded on the DocumentSchemaAttribute through the TypeEmbeddedAttribute classification. Also recall that the NestedSchemaAttribute relationship can be used to capture nested (hierarchical) structures within such documents. Deprecated types The SimpleDocumentType , StructDocumentType , MapDocumentType , ArrayDocumentType , and SetDocumentType types have been deprecated because they offer little value since the type is typically stored in the TypeEmbeddedAttribute classification. This change makes the document schemas consistent with other types of schema.","title":"Document Schemas"},{"location":"types/5/0531-Document-Schemas/#0531-document-schemas","text":"Model 0531 shows the definitions for structured documents such as JSON or XML. Note that the type information for each attribute within these structures can be directly embedded on the DocumentSchemaAttribute through the TypeEmbeddedAttribute classification. Also recall that the NestedSchemaAttribute relationship can be used to capture nested (hierarchical) structures within such documents. Deprecated types The SimpleDocumentType , StructDocumentType , MapDocumentType , ArrayDocumentType , and SetDocumentType types have been deprecated because they offer little value since the type is typically stored in the TypeEmbeddedAttribute classification. This change makes the document schemas consistent with other types of schema.","title":"0531 Document Schemas"},{"location":"types/5/0532-Object-Schemas/","text":"0532 Object Schemas \u00b6 Model 0532 describes an object schema - such as the structure for a series of POJO Java objects.","title":"Object Schemas"},{"location":"types/5/0532-Object-Schemas/#0532-object-schemas","text":"Model 0532 describes an object schema - such as the structure for a series of POJO Java objects.","title":"0532 Object Schemas"},{"location":"types/5/0533-Graph-Schemas/","text":"0533 Graph Schemas \u00b6 Model 0533 describes the schema for a property graph.","title":"Graph Schemas"},{"location":"types/5/0533-Graph-Schemas/#0533-graph-schemas","text":"Model 0533 describes the schema for a property graph.","title":"0533 Graph Schemas"},{"location":"types/5/0534-Relational-Schemas/","text":"0534 Relational Schemas \u00b6 Model 0534 describes the parts of a relational database schema. These are used in relational databases. There are multiple tables and views defined within the relational schema. The columns are within both the tables and views. Note that the type information for each column can be directly embedded on the RelationalColumn through the TypeEmbeddedAttribute classification, as both TabularColumn and DerivedSchemaAttribute extend SchemaAttribute . Also recall that the NestedSchemaAttribute relationship can be used to link directly between RelationalTable (or RelationalView ) and the RelationalColumn s contained within the table (or view). Deprecated types The supertype of RelationalTableType has be changed to ComplexSchemaType rather than TabularColumnType since TabularColumnType is now deprecated. DerivedRelationalColumn has been replaced by CalculatedValue and DerivedSchemaTypeQueryTarget . RelationalView should be changed to has been replaced by CalculatedValue .","title":"Relational Schemas"},{"location":"types/5/0534-Relational-Schemas/#0534-relational-schemas","text":"Model 0534 describes the parts of a relational database schema. These are used in relational databases. There are multiple tables and views defined within the relational schema. The columns are within both the tables and views. Note that the type information for each column can be directly embedded on the RelationalColumn through the TypeEmbeddedAttribute classification, as both TabularColumn and DerivedSchemaAttribute extend SchemaAttribute . Also recall that the NestedSchemaAttribute relationship can be used to link directly between RelationalTable (or RelationalView ) and the RelationalColumn s contained within the table (or view). Deprecated types The supertype of RelationalTableType has be changed to ComplexSchemaType rather than TabularColumnType since TabularColumnType is now deprecated. DerivedRelationalColumn has been replaced by CalculatedValue and DerivedSchemaTypeQueryTarget . RelationalView should be changed to has been replaced by CalculatedValue .","title":"0534 Relational Schemas"},{"location":"types/5/0535-Event-Schemas/","text":"0535 Event Schemas \u00b6 Events are simple linear structures. They typically are defined in sets of related events.","title":"Event Schemas"},{"location":"types/5/0535-Event-Schemas/#0535-event-schemas","text":"Events are simple linear structures. They typically are defined in sets of related events.","title":"0535 Event Schemas"},{"location":"types/5/0536-API-Schemas/","text":"0536 API Schemas \u00b6 APIs exchange data structures and commands. The schema of the API is its interface definition. It is an access point for data and so it is important to understand and control what data is passing over an API. Model 0536 shows the structure of an API schema. The top level schema for the API lists the operations. Under that, each operation defines its requests and responses.","title":"API Schemas"},{"location":"types/5/0536-API-Schemas/#0536-api-schemas","text":"APIs exchange data structures and commands. The schema of the API is its interface definition. It is an access point for data and so it is important to understand and control what data is passing over an API. Model 0536 shows the structure of an API schema. The top level schema for the API lists the operations. Under that, each operation defines its requests and responses.","title":"0536 API Schemas"},{"location":"types/5/0537-Display-Schemas/","text":"0537 Display Schemas \u00b6 At some point data is assembled and displayed to an end user. Model 0537 shows the structure of data that is displayed to end users either in reports or forms.","title":"Display Schemas"},{"location":"types/5/0537-Display-Schemas/#0537-display-schemas","text":"At some point data is assembled and displayed to an end user. Model 0537 shows the structure of data that is displayed to end users either in reports or forms.","title":"0537 Display Schemas"},{"location":"types/5/0540-Data-Classes/","text":"0540 Data Classes \u00b6 Data classes provide the specification of a logical data type. This goes beyond the type used to store the data value and includes a specification of the values that are found in this logical type. For example, a credit card number is typically stored as a string. However it has a well defined pattern of four groups of four digits. The data class allows the capture of the specification of a credit card number type that can be used by discovery engines to find more information out about the data values within an Asset.","title":"Data Classes"},{"location":"types/5/0540-Data-Classes/#0540-data-classes","text":"Data classes provide the specification of a logical data type. This goes beyond the type used to store the data value and includes a specification of the values that are found in this logical type. For example, a credit card number is typically stored as a string. However it has a well defined pattern of four groups of four digits. The data class allows the capture of the specification of a credit card number type that can be used by discovery engines to find more information out about the data values within an Asset.","title":"0540 Data Classes"},{"location":"types/5/0545-Reference-Data/","text":"0545 Reference Data \u00b6 Reference data provides authoritative definitions of valid values for data. The list of valid values can be modelled directly in open metadata using the ValidValuesSet entity with one or more ValidValue entities linked off of it. There is one ValidValue entity instance for each of the valid values. Typically the valid values set is linked off of a GlossaryTerm or a SchemaElement . A valid values set can also be implemented in an asset that can be used as a look up table while data is being processed.","title":"Reference Data"},{"location":"types/5/0545-Reference-Data/#0545-reference-data","text":"Reference data provides authoritative definitions of valid values for data. The list of valid values can be modelled directly in open metadata using the ValidValuesSet entity with one or more ValidValue entities linked off of it. There is one ValidValue entity instance for each of the valid values. Typically the valid values set is linked off of a GlossaryTerm or a SchemaElement . A valid values set can also be implemented in an asset that can be used as a look up table while data is being processed.","title":"0545 Reference Data"},{"location":"types/5/0550-Instance-Metadata/","text":"0550 Instance Metadata \u00b6 The InstanceMetadata classification is used to show that a data field represented by the SchemaElement contains metadata (rather than business data). This is needed when each record/instance/row/object in the data needs a different metadata classification.","title":"Instance Metadata"},{"location":"types/5/0550-Instance-Metadata/#0550-instance-metadata","text":"The InstanceMetadata classification is used to show that a data field represented by the SchemaElement contains metadata (rather than business data). This is needed when each record/instance/row/object in the data needs a different metadata classification.","title":"0550 Instance Metadata"},{"location":"types/5/0565-Design-Model-Elements/","text":"0565 Design Model Elements \u00b6 Design models are used during the development of data structures and their related software to provide templates and abstractions of the implementation(s). Representations of design models are supported in the open metadata types to support implementation generation and to show the lineage of software components from their design to implementation. Model 0565 shows the definition of a generic model element.","title":"Design Model Elements"},{"location":"types/5/0565-Design-Model-Elements/#0565-design-model-elements","text":"Design models are used during the development of data structures and their related software to provide templates and abstractions of the implementation(s). Representations of design models are supported in the open metadata types to support implementation generation and to show the lineage of software components from their design to implementation. Model 0565 shows the definition of a generic model element.","title":"0565 Design Model Elements"},{"location":"types/5/0566-Design-Model-Organization/","text":"0566 Design Model Organization \u00b6 In this model we define the top-level Design Model that is the anchor for a collection of related design model elements . Design models can get quite large so it helps the software architects and developers to be able to organize the content of the models into related groups. These groups can themselves be organized into a hierarchy.","title":"Design Model Organization"},{"location":"types/5/0566-Design-Model-Organization/#0566-design-model-organization","text":"In this model we define the top-level Design Model that is the anchor for a collection of related design model elements . Design models can get quite large so it helps the software architects and developers to be able to organize the content of the models into related groups. These groups can themselves be organized into a hierarchy.","title":"0566 Design Model Organization"},{"location":"types/5/0568-Design-Model-Scoping/","text":"0568 Design Model Scoping \u00b6 When a reusable design model is being used in a project, The DesignModelScope defines the subset of the model that is to be used. It can then be passed to implementation generators to create artifacts for the project.","title":"Design Model Scoping"},{"location":"types/5/0568-Design-Model-Scoping/#0568-design-model-scoping","text":"When a reusable design model is being used in a project, The DesignModelScope defines the subset of the model that is to be used. It can then be passed to implementation generators to create artifacts for the project.","title":"0568 Design Model Scoping"},{"location":"types/5/0569-Design-Model-Implementation/","text":"0569 Design Model Implementation \u00b6 When new software implementation have been derived from a design model, the DesignModelImplementation allows the tools to document the relationship between the model element and the implementation. This provides","title":"Design Model Implementation"},{"location":"types/5/0569-Design-Model-Implementation/#0569-design-model-implementation","text":"When new software implementation have been derived from a design model, the DesignModelImplementation allows the tools to document the relationship between the model element and the implementation. This provides","title":"0569 Design Model Implementation"},{"location":"types/5/0570-Metamodels/","text":"0570 Metamodels \u00b6 A metadata model is a design mode that describes the structure of another, specific model types. The MetamodelInstance classification indicates which element in the metamodel is this metamodel element mapped to.","title":"Metamodels"},{"location":"types/5/0570-Metamodels/#0570-metamodels","text":"A metadata model is a design mode that describes the structure of another, specific model types. The MetamodelInstance classification indicates which element in the metamodel is this metamodel element mapped to.","title":"0570 Metamodels"},{"location":"types/5/0571-Concept-Models/","text":"0571 Concept Models \u00b6 Concept Models describe the core concepts for data oriented models. Concept models are defined as a specialized of the concept model element and there are three main subtypes: ConceptBead - an entity structure for a concept in a data-oriented model. ConceptBeadAttribute - an attribute of the concept bead. ConceptBead link - a relationship between two concept beads.","title":"Concept Models"},{"location":"types/5/0571-Concept-Models/#0571-concept-models","text":"Concept Models describe the core concepts for data oriented models. Concept models are defined as a specialized of the concept model element and there are three main subtypes: ConceptBead - an entity structure for a concept in a data-oriented model. ConceptBeadAttribute - an attribute of the concept bead. ConceptBead link - a relationship between two concept beads.","title":"0571 Concept Models"},{"location":"types/5/0580-Solution-Blueprints/","text":"0580 Solution Blueprints \u00b6 Solution blueprints are models of an IT deployment. They show the way different processes and assets are used in combinations to deliver a solution.","title":"Solution Blueprints"},{"location":"types/5/0580-Solution-Blueprints/#0580-solution-blueprints","text":"Solution blueprints are models of an IT deployment. They show the way different processes and assets are used in combinations to deliver a solution.","title":"0580 Solution Blueprints"},{"location":"types/5/0581-Solution-Ports-and-Wires/","text":"0581 Solution Ports and Wires \u00b6 Model 0581 covers the data and control wiring of a solution blueprint.","title":"Solution Ports and Wires"},{"location":"types/5/0581-Solution-Ports-and-Wires/#0581-solution-ports-and-wires","text":"Model 0581 covers the data and control wiring of a solution blueprint.","title":"0581 Solution Ports and Wires"},{"location":"types/5/0595-Design-Patterns/","text":"0595 Design Patterns \u00b6 Design patterns document proven approaches to solving well known problems.","title":"Design Patterns"},{"location":"types/5/0595-Design-Patterns/#0595-design-patterns","text":"Design patterns document proven approaches to solving well known problems.","title":"0595 Design Patterns"},{"location":"types/6/","text":"Area 6 Models - Metadata Discovery \u00b6 Area 6 provides structures for recording the results of automated metadata discovery as annotations to associated assets in the metadata repository. Metadata discovery requires different types of analysis. This analysis may run just once, say when the asset is created, on demand or based on an event or schedule. A particular type of analysis is implemented in a discovery service. Within the discovery service are one to many discovery steps. Each step performs some sort of analysis that may result in an annotation for one or more assets. The annotations from a particular run of a discovery service are grouped together into a discovery analysis report. The annotations may be reviewed and approved by a steward. The steward may convert the annotation to a harden metadata type, or they may flag the annotation as invalid. When the discovery service is rerun, the new annotations can be matched to the annotations from the previous run. The steward's actions will impact how the new annotations are processed. 0601 Open Discovery Engines and Services 0605 Discovery Analysis Report 0610 Annotation 0611 Annotation Reviews 0615 Schema Extraction 0617 Data Field Analysis 0620 Data Profiling 0625 Data Class Discovery 0630 Semantic Discovery 0635 Classification Discovery 0640 Quality Scores 0650 Relationship Discovery 0655 Asset Deduplication 0660 Measurements 0690 Request for Action Egeria's Open Discovery Framework ( ODF ) that supports the development and execution of discovery services. The ODF runs in an open metadata discovery server. ODF discovery services use connectors from the Open Connector Framework ( OCF ) to connect to the data assets and access the known metadata about them.","title":"Area 6 Metadata Discovery"},{"location":"types/6/#area-6-models-metadata-discovery","text":"Area 6 provides structures for recording the results of automated metadata discovery as annotations to associated assets in the metadata repository. Metadata discovery requires different types of analysis. This analysis may run just once, say when the asset is created, on demand or based on an event or schedule. A particular type of analysis is implemented in a discovery service. Within the discovery service are one to many discovery steps. Each step performs some sort of analysis that may result in an annotation for one or more assets. The annotations from a particular run of a discovery service are grouped together into a discovery analysis report. The annotations may be reviewed and approved by a steward. The steward may convert the annotation to a harden metadata type, or they may flag the annotation as invalid. When the discovery service is rerun, the new annotations can be matched to the annotations from the previous run. The steward's actions will impact how the new annotations are processed. 0601 Open Discovery Engines and Services 0605 Discovery Analysis Report 0610 Annotation 0611 Annotation Reviews 0615 Schema Extraction 0617 Data Field Analysis 0620 Data Profiling 0625 Data Class Discovery 0630 Semantic Discovery 0635 Classification Discovery 0640 Quality Scores 0650 Relationship Discovery 0655 Asset Deduplication 0660 Measurements 0690 Request for Action Egeria's Open Discovery Framework ( ODF ) that supports the development and execution of discovery services. The ODF runs in an open metadata discovery server. ODF discovery services use connectors from the Open Connector Framework ( OCF ) to connect to the data assets and access the known metadata about them.","title":"Area 6 Models - Metadata Discovery"},{"location":"types/6/0601-Open-Discovery-Engine/","text":"0601 Open Discovery Engines and Services \u00b6 An open discovery engine executes open discovery services on request. The OpenDiscoveryEngine entity creates a description of an instance of these types of engines. It is represented as a special type GovernanceEngine when it is documented in metadata. Open discovery services are pluggable components that analyse data sources and document the results. The OpenDiscoveryService entity describes an implementation of an open discovery service. This implementation is an OCF Connector so the OpenDiscoveryService is linked with a DiscoveryServiceImplementation relationship to a Connection entity that defines how to create an instance of the open discovery service. A description of an open discovery service is linked with a SupportedGovernanceService relationship to the description of an OpenDiscoveryEngine to indicate that the discovery engine supports the open discovery service. Open discovery pipelines are specialized open discovery services that execute multiple open discovery services in a single run. The OpenDiscoveryPipeline describes an open discovery pipeline. It is typically linked to a VirtualConnection with the connections of the open discovery services embedded within it. Deprecated types SupportedDiscoveryService - Use SupportedGovernanceService .","title":"Open Discovery Engines and Services"},{"location":"types/6/0601-Open-Discovery-Engine/#0601-open-discovery-engines-and-services","text":"An open discovery engine executes open discovery services on request. The OpenDiscoveryEngine entity creates a description of an instance of these types of engines. It is represented as a special type GovernanceEngine when it is documented in metadata. Open discovery services are pluggable components that analyse data sources and document the results. The OpenDiscoveryService entity describes an implementation of an open discovery service. This implementation is an OCF Connector so the OpenDiscoveryService is linked with a DiscoveryServiceImplementation relationship to a Connection entity that defines how to create an instance of the open discovery service. A description of an open discovery service is linked with a SupportedGovernanceService relationship to the description of an OpenDiscoveryEngine to indicate that the discovery engine supports the open discovery service. Open discovery pipelines are specialized open discovery services that execute multiple open discovery services in a single run. The OpenDiscoveryPipeline describes an open discovery pipeline. It is typically linked to a VirtualConnection with the connections of the open discovery services embedded within it. Deprecated types SupportedDiscoveryService - Use SupportedGovernanceService .","title":"0601 Open Discovery Engines and Services"},{"location":"types/6/0605-Open-Discovery-Analysis-Reports/","text":"0605 Open Discovery Analysis Report \u00b6 Each time a discovery engine runs an open discovery service, the open discovery service creates a collection of annotations. These annotations are managed in an in-memory cache during the execution of the discovery service to allow later steps in the discovery service to access annotations from the previous steps. When the open discovery service completes, the annotations are published to the metadata repository as an open discovery analysis report. The open discovery analysis report is linked to the Asset that was analysed (see AssetDiscoveryReport relationship), to the discovery engine that ran the discovery service (see DiscoveryEngineReport relationship) and the discovery service description itself (see DiscoveryInvocationReport relationship) so it is possible to navigate to the report from different perspectives. The OpenDiscoveryAnalysisReport entity is the report header. It identifies the date of the report and the parameters used. It may also include a name and description that is supplied by the initiator of the discovery service run.","title":"Discovery Analysis Report"},{"location":"types/6/0605-Open-Discovery-Analysis-Reports/#0605-open-discovery-analysis-report","text":"Each time a discovery engine runs an open discovery service, the open discovery service creates a collection of annotations. These annotations are managed in an in-memory cache during the execution of the discovery service to allow later steps in the discovery service to access annotations from the previous steps. When the open discovery service completes, the annotations are published to the metadata repository as an open discovery analysis report. The open discovery analysis report is linked to the Asset that was analysed (see AssetDiscoveryReport relationship), to the discovery engine that ran the discovery service (see DiscoveryEngineReport relationship) and the discovery service description itself (see DiscoveryInvocationReport relationship) so it is possible to navigate to the report from different perspectives. The OpenDiscoveryAnalysisReport entity is the report header. It identifies the date of the report and the parameters used. It may also include a name and description that is supplied by the initiator of the discovery service run.","title":"0605 Open Discovery Analysis Report"},{"location":"types/6/0610-Annotations/","text":"0610 Annotations \u00b6 The Annotation entity captures the discovered characteristics of an asset. Annotations are created by the analysis steps in the discovery service. The attributes of the annotation capture the details of the discovery processing. The sub-classes of Annotation capture specific details of the discovered metadata. Each annotation is linked the the discovery analysis report it was generated from. It also links to each asset that the annotation relates to. Strings are used in many of the attributes to keep the model open for discovery service developers and the tools that process them. annotationType - descriptive string that acts as an identifier for the specific annotation type. This is a simple means to sub-type any one of the annotation subclasses. summary - a human readable string to describe the annotation. confidence - an indicator of the certainty that the annotation is correct. expression - this attribute is used to provide more detail on how the asset is related to the annotation. explanation - another description field to assist human analysts reviewing the discovery results. analysisStep - identifier of the step in the discovery service that detected the annotation. jsonProperties - the properties that were used to initiate the discovery service. The types that follow provide more specialized annotations. 0615 Schema Extraction 0617 Data Field Analysis 0620 Data Profiling 0625 Data Class Discovery 0630 Semantic Discovery 0635 Classification Discovery 0640 Quality Scores 0650 Relationship Discovery 0655 Asset Deduplication 0660 Measurements 0690 Request for Action","title":"Annotation"},{"location":"types/6/0610-Annotations/#0610-annotations","text":"The Annotation entity captures the discovered characteristics of an asset. Annotations are created by the analysis steps in the discovery service. The attributes of the annotation capture the details of the discovery processing. The sub-classes of Annotation capture specific details of the discovered metadata. Each annotation is linked the the discovery analysis report it was generated from. It also links to each asset that the annotation relates to. Strings are used in many of the attributes to keep the model open for discovery service developers and the tools that process them. annotationType - descriptive string that acts as an identifier for the specific annotation type. This is a simple means to sub-type any one of the annotation subclasses. summary - a human readable string to describe the annotation. confidence - an indicator of the certainty that the annotation is correct. expression - this attribute is used to provide more detail on how the asset is related to the annotation. explanation - another description field to assist human analysts reviewing the discovery results. analysisStep - identifier of the step in the discovery service that detected the annotation. jsonProperties - the properties that were used to initiate the discovery service. The types that follow provide more specialized annotations. 0615 Schema Extraction 0617 Data Field Analysis 0620 Data Profiling 0625 Data Class Discovery 0630 Semantic Discovery 0635 Classification Discovery 0640 Quality Scores 0650 Relationship Discovery 0655 Asset Deduplication 0660 Measurements 0690 Request for Action","title":"0610 Annotations"},{"location":"types/6/0612-Annotation-Reviews/","text":"0612 Annotation Reviews \u00b6 The annotations associated with an asset can be seen by people and tools querying the associated asset, servers or discovery service. However, often the analysis within a discovery service can only make recommendations based on the information within the asset. Where annotations refer to information that is used for governance, they need to be approved and converted into classifications, or related metadata. The AnnotationReview entity records how the discovered annotations have been actioned in the metadata server and the steward that approved it.","title":"Annotation Reviews"},{"location":"types/6/0612-Annotation-Reviews/#0612-annotation-reviews","text":"The annotations associated with an asset can be seen by people and tools querying the associated asset, servers or discovery service. However, often the analysis within a discovery service can only make recommendations based on the information within the asset. Where annotations refer to information that is used for governance, they need to be approved and converted into classifications, or related metadata. The AnnotationReview entity records how the discovered annotations have been actioned in the metadata server and the steward that approved it.","title":"0612 Annotation Reviews"},{"location":"types/6/0615-Schema-Extraction/","text":"0615 Schema Extraction \u00b6 One of the simplest discovery processes for relational data is to extract the schema details from the asset through the JDBC connector getMetadata() API. Other connectors or data sources may also provide APIs for schema extraction. The schema is first added as an annotation that links together the data fields found. This is then either matched with an existing schema or a new schema is created (see Area 5 ). This may be completely automated, or with stewards assistance.","title":"Schema Extraction"},{"location":"types/6/0615-Schema-Extraction/#0615-schema-extraction","text":"One of the simplest discovery processes for relational data is to extract the schema details from the asset through the JDBC connector getMetadata() API. Other connectors or data sources may also provide APIs for schema extraction. The schema is first added as an annotation that links together the data fields found. This is then either matched with an existing schema or a new schema is created (see Area 5 ). This may be completely automated, or with stewards assistance.","title":"0615 Schema Extraction"},{"location":"types/6/0617-Data-Field-Analysis/","text":"0617 Data Field Analysis \u00b6 Annotations can be attached to a DataField entity through the DataFieldAnalysis relationship. This relationship works with a specialization of Annotation called DataFieldAnnotation. A DataFieldAnnotation is one that could apply to a single data field - or more broadly to the Asset.","title":"Data Field Analysis"},{"location":"types/6/0617-Data-Field-Analysis/#0617-data-field-analysis","text":"Annotations can be attached to a DataField entity through the DataFieldAnalysis relationship. This relationship works with a specialization of Annotation called DataFieldAnnotation. A DataFieldAnnotation is one that could apply to a single data field - or more broadly to the Asset.","title":"0617 Data Field Analysis"},{"location":"types/6/0620-Data-Profiling/","text":"0620 Data Profiling \u00b6 Profiling analysis looks at the data values in the asset and summarizes their characteristics.","title":"Data Profiling"},{"location":"types/6/0620-Data-Profiling/#0620-data-profiling","text":"Profiling analysis looks at the data values in the asset and summarizes their characteristics.","title":"0620 Data Profiling"},{"location":"types/6/0625-Data-Class-Discovery/","text":"0625 Data Class Discovery \u00b6 Data class discovery captures the analysis on how close a data field matches the specification defined in a data class.","title":"Data Class Discovery"},{"location":"types/6/0625-Data-Class-Discovery/#0625-data-class-discovery","text":"Data class discovery captures the analysis on how close a data field matches the specification defined in a data class.","title":"0625 Data Class Discovery"},{"location":"types/6/0630-Semantic-Discovery/","text":"0630 Semantic Discovery \u00b6 Semantic discovery is attempting to define the meaning of the data values in the asset. The result is a recommended glossary term stored as an annotation.","title":"Semantic Discovery"},{"location":"types/6/0630-Semantic-Discovery/#0630-semantic-discovery","text":"Semantic discovery is attempting to define the meaning of the data values in the asset. The result is a recommended glossary term stored as an annotation.","title":"0630 Semantic Discovery"},{"location":"types/6/0635-Classification-Discovery/","text":"0635 Classification Discovery \u00b6 Classification discovery adds suggestions for how the data could be classified. These annotations are the discovery engine equivalent of the Informal Tag shown in 0150 - Feedback in Area 1.","title":"Classification Discovery"},{"location":"types/6/0635-Classification-Discovery/#0635-classification-discovery","text":"Classification discovery adds suggestions for how the data could be classified. These annotations are the discovery engine equivalent of the Informal Tag shown in 0150 - Feedback in Area 1.","title":"0635 Classification Discovery"},{"location":"types/6/0640-Quality-Scores/","text":"0640 Quality Scores \u00b6 Quality scores describe how well the data values, typically in a data field, conform to a specification. A data field can have multiple quality scores associated to it, for different types of problems. Examples of quality problem types include: Data class violations Data type violations Format violations Minimum/Maximum value violations Missing values Suspect values Duplicate values Rule violations The set of problem types is open and dependent on a given system and the discovery service capabilities. Each quality score for each type of problem could have additional properties associated to it such as confidence, date it was calculated, for example. The set of such properties may differ across discovery services and should be open. A combined quality score for an entire Asset can be typically calculated as the average of the scores for all its columns, but other factors may be taken into account by a given system and we should be able to associate a score to an Asset, independently of the way it is calculated.","title":"Quality Scores"},{"location":"types/6/0640-Quality-Scores/#0640-quality-scores","text":"Quality scores describe how well the data values, typically in a data field, conform to a specification. A data field can have multiple quality scores associated to it, for different types of problems. Examples of quality problem types include: Data class violations Data type violations Format violations Minimum/Maximum value violations Missing values Suspect values Duplicate values Rule violations The set of problem types is open and dependent on a given system and the discovery service capabilities. Each quality score for each type of problem could have additional properties associated to it such as confidence, date it was calculated, for example. The set of such properties may differ across discovery services and should be open. A combined quality score for an entire Asset can be typically calculated as the average of the scores for all its columns, but other factors may be taken into account by a given system and we should be able to associate a score to an Asset, independently of the way it is calculated.","title":"0640 Quality Scores"},{"location":"types/6/0650-Relationship-Discovery/","text":"0650 Relationship Discovery \u00b6 Relationship discovery identifies relationships between different assets (or parts of assets), such as 2 columns that have a foreign key relationship.","title":"Relationship Discovery"},{"location":"types/6/0650-Relationship-Discovery/#0650-relationship-discovery","text":"Relationship discovery identifies relationships between different assets (or parts of assets), such as 2 columns that have a foreign key relationship.","title":"0650 Relationship Discovery"},{"location":"types/6/0655-Asset-Deduplication/","text":"0655 Asset Deduplication \u00b6 In the open metadata ecosystem, it is possible that the same asset has been defined in more than one tool/engine/platform. When these technologies are connected together and exchange metadata, there are then multiple asset definitions for the same physical asset. It is often necessary to keep each original copy since they are needed by the originating technology. However, the values of the metadata and attachments can diverge over time - or may already be different at the time that the assets are exchanged). If these values are being used for governance, or there is a desire to keep descriptions and other types of attachments synchronized across the copies, then the open metadata and governance ( OMAG ) services need to detect these duplicates and monitor divergent values. The annotations shown below are used by discovery services to record first that two or more Asset entities seem to describe the same (real/physical) asset. This is the SuspectDuplicateAnnotation . When this annotation is recorded, it is processed by the stewardship Governance Actions to decide if they are really duplicates or not. Where duplicates have been established, discovery services can use the remaining annotation to record divergent values. Again the stewardship governance actions will determine what action, if any, to take. Specifically, DivergentValueAnnotation , DivergentClassificationAnnotation and DivergentRelationshipAnnotation are used to record divergent values in the Asset entities' properties, classifications and direct relationships respectively. DivergentAttachmentValueAnnotation , DivergentAttachmentClassificationAnnotation and DivergentAttachmentRelationshipAnnotation record divergent values in attachments such as schemas, feedback and connections.","title":"0655 Asset Deduplication"},{"location":"types/6/0655-Asset-Deduplication/#0655-asset-deduplication","text":"In the open metadata ecosystem, it is possible that the same asset has been defined in more than one tool/engine/platform. When these technologies are connected together and exchange metadata, there are then multiple asset definitions for the same physical asset. It is often necessary to keep each original copy since they are needed by the originating technology. However, the values of the metadata and attachments can diverge over time - or may already be different at the time that the assets are exchanged). If these values are being used for governance, or there is a desire to keep descriptions and other types of attachments synchronized across the copies, then the open metadata and governance ( OMAG ) services need to detect these duplicates and monitor divergent values. The annotations shown below are used by discovery services to record first that two or more Asset entities seem to describe the same (real/physical) asset. This is the SuspectDuplicateAnnotation . When this annotation is recorded, it is processed by the stewardship Governance Actions to decide if they are really duplicates or not. Where duplicates have been established, discovery services can use the remaining annotation to record divergent values. Again the stewardship governance actions will determine what action, if any, to take. Specifically, DivergentValueAnnotation , DivergentClassificationAnnotation and DivergentRelationshipAnnotation are used to record divergent values in the Asset entities' properties, classifications and direct relationships respectively. DivergentAttachmentValueAnnotation , DivergentAttachmentClassificationAnnotation and DivergentAttachmentRelationshipAnnotation record divergent values in attachments such as schemas, feedback and connections.","title":"0655 Asset Deduplication"},{"location":"types/6/0660-Data-Source-Measurements/","text":"0660 Data Source Measurements \u00b6 The Data Source Measurements capture a snapshot of the physical dimensions and activity levels at a particular moment in time.","title":"Measurements"},{"location":"types/6/0660-Data-Source-Measurements/#0660-data-source-measurements","text":"The Data Source Measurements capture a snapshot of the physical dimensions and activity levels at a particular moment in time.","title":"0660 Data Source Measurements"},{"location":"types/6/0690-Request-for-Action/","text":"0690 Request for Action \u00b6 A RequestForAction entity (RfA) is used to trigger the Stewardship Action OMAS . It is used when the discovery service performs a test on the data (such as a discovery rule) or has discovered an anomaly in the data landscape compared to its metadata that potentially needs a steward or a curator's action. The governance action framework is configured to respond to the requests for actions (RfAs).","title":"Request for Action"},{"location":"types/6/0690-Request-for-Action/#0690-request-for-action","text":"A RequestForAction entity (RfA) is used to trigger the Stewardship Action OMAS . It is used when the discovery service performs a test on the data (such as a discovery rule) or has discovered an anomaly in the data landscape compared to its metadata that potentially needs a steward or a curator's action. The governance action framework is configured to respond to the requests for actions (RfAs).","title":"0690 Request for Action"},{"location":"types/7/","text":"Area 7 Models - Lineage \u00b6 Lineage basically describes the origin of something such as an asset, component or data values. Area 7 provides the structures for adding context to asset definitions to help explain their origin. The aim is to provide information that allows a consumer of data to be sure they are looking at the right data from an authoritative source and the intermediate processing is correct. 0710 Digital Service 0715 Digital Service Ownership 0717 Digital Service Implementation 0720 Information Supply Chains 0730 Solution Components 0735 Solution Ports and Wires 0740 Solution Blueprints 0750 Data Passing 0760 Business Lineage 0770 Lineage Mapping 0780 Code Analysis","title":"Area 7 Lineage"},{"location":"types/7/#area-7-models-lineage","text":"Lineage basically describes the origin of something such as an asset, component or data values. Area 7 provides the structures for adding context to asset definitions to help explain their origin. The aim is to provide information that allows a consumer of data to be sure they are looking at the right data from an authoritative source and the intermediate processing is correct. 0710 Digital Service 0715 Digital Service Ownership 0717 Digital Service Implementation 0720 Information Supply Chains 0730 Solution Components 0735 Solution Ports and Wires 0740 Solution Blueprints 0750 Data Passing 0760 Business Lineage 0770 Lineage Mapping 0780 Code Analysis","title":"Area 7 Models - Lineage"},{"location":"types/7/0710-Digital-Service/","text":"0710 Digital Service \u00b6","title":"Digital Service"},{"location":"types/7/0710-Digital-Service/#0710-digital-service","text":"","title":"0710 Digital Service"},{"location":"types/7/0715-Digital-Service-Ownership/","text":"0715 Digital Service Ownership \u00b6","title":"Digital Service Ownership"},{"location":"types/7/0715-Digital-Service-Ownership/#0715-digital-service-ownership","text":"","title":"0715 Digital Service Ownership"},{"location":"types/7/0717-Digital-Service-Implementation/","text":"0717 Digital Service Implementation \u00b6","title":"Digital Service Implementation"},{"location":"types/7/0717-Digital-Service-Implementation/#0717-digital-service-implementation","text":"","title":"0717 Digital Service Implementation"},{"location":"types/7/0720-Information-Supply-Chains/","text":"0720 Information Supply Chains \u00b6","title":"Information Supply Chains"},{"location":"types/7/0720-Information-Supply-Chains/#0720-information-supply-chains","text":"","title":"0720 Information Supply Chains"},{"location":"types/7/0730-Solution-Components/","text":"0730 Solution Components \u00b6","title":"Solution Components"},{"location":"types/7/0730-Solution-Components/#0730-solution-components","text":"","title":"0730 Solution Components"},{"location":"types/7/0735-Solution-Ports-and-Wires/","text":"0735 Solution Ports and Wires \u00b6","title":"Solution Ports and Wires"},{"location":"types/7/0735-Solution-Ports-and-Wires/#0735-solution-ports-and-wires","text":"","title":"0735 Solution Ports and Wires"},{"location":"types/7/0740-Solution-Blueprints/","text":"0740 Solution Blueprints \u00b6","title":"Solution Blueprints"},{"location":"types/7/0740-Solution-Blueprints/#0740-solution-blueprints","text":"","title":"0740 Solution Blueprints"},{"location":"types/7/0750-Data-Passing/","text":"0750 Data Passing \u00b6 Describes relationships that show where data and control is passed between processes and assets. These relationships show the structure of the data processing. They can link Assets , or Ports or SchemaAttributes depending on the level of detail that is known. These relationships are then overlaid by the LineageMapping relationship to show which are significant for lineage. Deprecated types ProcessInput ProcessOutput","title":"Data Passing"},{"location":"types/7/0750-Data-Passing/#0750-data-passing","text":"Describes relationships that show where data and control is passed between processes and assets. These relationships show the structure of the data processing. They can link Assets , or Ports or SchemaAttributes depending on the level of detail that is known. These relationships are then overlaid by the LineageMapping relationship to show which are significant for lineage. Deprecated types ProcessInput ProcessOutput","title":"0750 Data Passing"},{"location":"types/7/0760-Business-Lineage/","text":"0760 Business Lineage \u00b6 Business lineage is a type of lineage where only elements that have been tagged as business significant are shown. This allows some of the technical detail to be eliminated from the display.","title":"Business Lineage"},{"location":"types/7/0760-Business-Lineage/#0760-business-lineage","text":"Business lineage is a type of lineage where only elements that have been tagged as business significant are shown. This allows some of the technical detail to be eliminated from the display.","title":"0760 Business Lineage"},{"location":"types/7/0770-Lineage-Mapping/","text":"0770 - Lineage Mapping \u00b6 Lineage Mapping enables data fields from different schemas or ports to be linked to show how data is flowing between assets. It provides a finer0grained level of lineage than the Data Passing relationships.","title":"Lineage Mapping"},{"location":"types/7/0770-Lineage-Mapping/#0770-lineage-mapping","text":"Lineage Mapping enables data fields from different schemas or ports to be linked to show how data is flowing between assets. It provides a finer0grained level of lineage than the Data Passing relationships.","title":"0770 - Lineage Mapping"},{"location":"types/7/0780-Code-Analysis/","text":"0780 - Code Analysis \u00b6","title":"0780 Code Analysis"},{"location":"types/7/0780-Code-Analysis/#0780-code-analysis","text":"","title":"0780 - Code Analysis"}]}